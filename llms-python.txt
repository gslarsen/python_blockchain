# MAX Python API Documentation

> The MAX Python API reference.

This file contains all documentation content in a single document following the llmstxt.org standard.

## driver

Exposes APIs for interacting with hardware, such as allocating tensors on a GPU
and moving tensors between the CPU and GPU. It provides interfaces for memory
management, device properties, and hardware monitoring. Through these APIs, you
can control data placement, track resource utilization, and configure device
settings for optimal performance.

For example, you can use the following code to use an accelerator if one is
available, otherwise use the CPU:

```python
from max import driver

device = driver.CPU() if driver.accelerator_count() == 0 else driver.Accelerator()
print(f"Using {device} device")
```

## `Accelerator` {#max.driver.Accelerator}

> class max.driver.Accelerator(self, id: [int](https://docs.python.org/3/library/functions.html#int) = -1)

Creates an accelerator device with the specified ID.

Provides access to GPU or other hardware accelerators in the system.

```python
from max import driver
device = driver.Accelerator()
# Or specify GPU id
device = driver.Accelerator(id=0)  # First GPU
device = driver.Accelerator(id=1)  # Second GPU
# Get device id
device_id = device.id
```

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

id ([int](https://docs.python.org/3/library/functions.html#int), optional) â€“ The device ID to use. Defaults to -1, which selects
the first available accelerator.

</dd><dt>

**Returns:**

</dt><dd>

A new Accelerator device object.

</dd><dt>

**Return type:**

</dt><dd>

[Accelerator](#max.driver.Accelerator)

</dd></dl>

## `CPU` {#max.driver.CPU}

> class max.driver.CPU(self, id: [int](https://docs.python.org/3/library/functions.html#int) = -1)

Creates a CPU device.

```python
from max import driver
# Create default CPU device
device = driver.CPU()
# Device id is always 0 for CPU devices
device_id = device.id
```

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

id ([int](https://docs.python.org/3/library/functions.html#int), optional) â€“ The device ID to use.
Defaults to -1.

</dd><dt>

**Returns:**

</dt><dd>

A new CPU device object.

</dd><dt>

**Return type:**

</dt><dd>

[CPU](#max.driver.CPU)

</dd></dl>

## `DLPackArray` {#max.driver.DLPackArray}

> class max.driver.DLPackArray(\*args, \*\*kwargs)

## `Device` {#max.driver.Device}

> class max.driver.Device

### `api` {#max.driver.Device.api}

> property api

Returns the API used to program the device.

Possible values are:

* `cpu` for host devices.
* `cuda` for NVIDIA GPUs.
* `hip` for AMD GPUs.

```python
from max import driver

device = driver.CPU()
device.api
```

### `architecture_name` {#max.driver.Device.architecture_name}

> property architecture\_name

Returns the architecture name of the device.

Examples of possible values:

* `gfx90a`, `gfx942` for AMD GPUs.
* `sm_80`, `sm_86` for NVIDIA GPUs.
* CPU devices raise an exception.

```python
from max import driver

device = driver.Accelerator()
device.archname
```

### `can_access()` {#max.driver.Device.can_access}

> can\_access(self, other: [max.driver.Device](#max.driver.Device)) â†’ [bool](https://docs.python.org/3/library/functions.html#bool)

Checks if this device can directly access memory of another device.

```python
from max import driver

gpu0 = driver.Accelerator(id=0)
gpu1 = driver.Accelerator(id=1)

if gpu0.can_access(gpu1):
    print("GPU0 can directly access GPU1 memory.")
```

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

other ([Device](#max.driver.Device)) â€“ The other device to check peer access against.

</dd><dt>

**Returns:**

</dt><dd>

True if peer access is possible, False otherwise.

</dd><dt>

**Return type:**

</dt><dd>

[bool](https://docs.python.org/3/library/functions.html#bool)

</dd></dl>

### `cpu` {#max.driver.Device.cpu}

> cpu = \<nanobind.nb\_func object>

### `default_stream` {#max.driver.Device.default_stream}

> property default\_stream

Returns the default stream for this device.

The default stream is initialized when the device object is created.

<dl class='field-list'><dt>

**Returns:**

</dt><dd>

The default execution stream for this device.

</dd><dt>

**Return type:**

</dt><dd>

[DeviceStream](#max.driver.DeviceStream)

</dd></dl>

### `id` {#max.driver.Device.id}

> property id

Returns a zero-based device id. For a CPU device this is always 0.
For GPU accelerators this is the id of the device relative to this host.
Along with the `label`, an id can uniquely identify a device,
e.g. `gpu:0`, `gpu:1`.

```python
from max import driver

device = driver.Accelerator()
device_id = device.id
```

<dl class='field-list'><dt>

**Returns:**

</dt><dd>

The device ID.

</dd><dt>

**Return type:**

</dt><dd>

[int](https://docs.python.org/3/library/functions.html#int)

</dd></dl>

### `is_compatible` {#max.driver.Device.is_compatible}

> property is\_compatible

Returns whether this device is compatible with MAX.

<dl class='field-list'><dt>

**Returns:**

</dt><dd>

True if the device is compatible with MAX, False otherwise.

</dd><dt>

**Return type:**

</dt><dd>

[bool](https://docs.python.org/3/library/functions.html#bool)

</dd></dl>

### `is_host` {#max.driver.Device.is_host}

> property is\_host

Whether this device is the CPU (host) device.

```python
from max import driver

device = driver.CPU()
device.is_host
```

### `label` {#max.driver.Device.label}

> property label

Returns device label.

Possible values are:

* `cpu` for host devices.
* `gpu` for accelerators.

```python
from max import driver

device = driver.CPU()
device.label
```

### `stats` {#max.driver.Device.stats}

> property stats

Returns utilization data for the device.

```python
from max import driver

device = driver.CPU()
stats = device.stats
```

<dl class='field-list'><dt>

**Returns:**

</dt><dd>

A dictionary containing device utilization statistics.

</dd><dt>

**Return type:**

</dt><dd>

[dict](https://docs.python.org/3/library/stdtypes.html#dict)

</dd></dl>

### `synchronize()` {#max.driver.Device.synchronize}

> synchronize(self) â†’ [None](https://docs.python.org/3/library/constants.html#None)

Ensures all operations on this device complete before returning.

<dl class='field-list'><dt>

**Raises:**

</dt><dd>

[ValueError](https://docs.python.org/3/library/exceptions.html#ValueError) â€“ If any enqueued operations had an internal error.

</dd></dl>

## `DeviceSpec` {#max.driver.DeviceSpec}

> class max.driver.DeviceSpec(id, device\_type='cpu')

Specification for a device, containing its ID and type.

This class provides a way to specify device parameters like ID and type (CPU/GPU)
for creating Device instances.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* id ([int](https://docs.python.org/3/library/functions.html#int))
* device\_type ([Literal](https://docs.python.org/3/library/typing.html#typing.Literal)\['cpu', 'gpu'])

</dd></dl>

### `accelerator()` {#max.driver.DeviceSpec.accelerator}

> static accelerator(id=0)

Creates an accelerator (GPU) device specification.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

id ([int](https://docs.python.org/3/library/functions.html#int))

</dd></dl>

### `cpu()` {#max.driver.DeviceSpec.cpu}

> static cpu(id=-1)

Creates a CPU device specification.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

id ([int](https://docs.python.org/3/library/functions.html#int))

</dd></dl>

### `device_type` {#max.driver.DeviceSpec.device_type}

> device\_type: [Literal](https://docs.python.org/3/library/typing.html#typing.Literal)\['cpu', 'gpu'] = 'cpu'

Type of specified device.

### `id` {#max.driver.DeviceSpec.id}

> id: [int](https://docs.python.org/3/library/functions.html#int)

Provided id for this device.

## `DeviceStream` {#max.driver.DeviceStream}

> class max.driver.DeviceStream(self, device: [max.driver.Device](#max.driver.Device))

Provides access to a stream of execution on a device.

A stream represents a sequence of operations that will be executed in order.
Multiple streams on the same device can execute concurrently.

```python
from max import driver
# Create a default accelerator device
device = driver.Accelerator()
# Get the default stream for the device
stream = device.default_stream
# Create a new stream of execution on the device
new_stream = driver.DeviceStream(device)
```

Creates a new stream of execution associated with the device.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

device ([Device](#max.driver.Device)) â€“ The device to create the stream on.

</dd><dt>

**Returns:**

</dt><dd>

A new stream of execution.

</dd><dt>

**Return type:**

</dt><dd>

[DeviceStream](#max.driver.DeviceStream)

</dd></dl>

### `device` {#max.driver.DeviceStream.device}

> property device

The device this stream is executing on.

### `synchronize()` {#max.driver.DeviceStream.synchronize}

> synchronize(self) â†’ [None](https://docs.python.org/3/library/constants.html#None)

Ensures all operations on this stream complete before returning.

<dl class='field-list'><dt>

**Raises:**

</dt><dd>

[ValueError](https://docs.python.org/3/library/exceptions.html#ValueError) â€“ If any enqueued operations had an internal error.

</dd></dl>

### `wait_for()` {#max.driver.DeviceStream.wait_for}

> wait\_for(self, stream: [max.driver.DeviceStream](#max.driver.DeviceStream)) â†’ [None](https://docs.python.org/3/library/constants.html#None)

> wait\_for(self, device: [max.driver.Device](#max.driver.Device)) â†’ [None](https://docs.python.org/3/library/constants.html#None)

Overloaded function.

1. `wait_for(self, stream: max.driver.DeviceStream) -> None`

   > Ensures all operations on the other stream complete before future work
   > submitted to this stream is scheduled.

   > Args:
   > : stream (DeviceStream): The stream to wait for.
2. `wait_for(self, device: max.driver.Device) -> None`

   > Ensures all operations on deviceâ€™s default stream complete before
   > future work submitted to this stream is scheduled.

   > Args:
   > : device (Device): The device whose default stream to wait for.

## `Tensor` {#max.driver.Tensor}

> class max.driver.Tensor(self, dtype: [max.dtype.DType](dtype.md#max.dtype.DType), shape: [collections.abc.Sequence](https://docs.python.org/3/library/collections.abc.html#collections.abc.Sequence)\[[int](https://docs.python.org/3/library/functions.html#int)], device: [max.driver.Device](#max.driver.Device) | [None](https://docs.python.org/3/library/constants.html#None) = None, pinned: [bool](https://docs.python.org/3/library/functions.html#bool) = False)

> class max.driver.Tensor(self, dtype: [max.dtype.DType](dtype.md#max.dtype.DType), shape: [collections.abc.Sequence](https://docs.python.org/3/library/collections.abc.html#collections.abc.Sequence)\[[int](https://docs.python.org/3/library/functions.html#int)], stream: [max.driver.DeviceStream](#max.driver.DeviceStream), pinned: [bool](https://docs.python.org/3/library/functions.html#bool) = False)

> class max.driver.Tensor(self, shape: ndarray\[writable=False], device: max.driver.Device)

Device-resident tensor representation.

Allocates memory onto a given device with the provided shape and dtype.
Tensors can be sliced to provide strided views of the underlying memory,
but any tensors input into model execution must be contiguous.

Supports numpy-style slicing but does not currently support setting
items across multiple indices.

```python
from max import driver
from max.dtype import DType

# Create a tensor on CPU
cpu_tensor = driver.Tensor(shape=[2, 3], dtype=DType.float32)

# Create a tensor on GPU
gpu = driver.Accelerator()
gpu_tensor = driver.Tensor(shape=[2, 3], dtype=DType.float32, device=gpu)
```

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* dtype ([DType](dtype.md#max.dtype.DType)) â€“ Data type of tensor elements.
* shape (Sequence\[[int](https://docs.python.org/3/library/functions.html#int)]) â€“ Tuple of positive, non-zero integers denoting the tensor shape.
* device ([Device](#max.driver.Device), optional) â€“ Device to allocate tensor onto. Defaults to the CPU.
* pinned ([bool](https://docs.python.org/3/library/functions.html#bool), optional) â€“ If True, memory is page-locked (pinned). Defaults to False.
* stream ([DeviceStream](#max.driver.DeviceStream), optional) â€“ Stream to associate the tensor with.

</dd></dl>

### `contiguous()` {#max.driver.Tensor.contiguous}

> contiguous()

Creates a contiguous copy of the parent tensor.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

self ([Tensor](#max.driver.Tensor))

</dd><dt>

**Return type:**

</dt><dd>

[Tensor](#max.driver.Tensor)

</dd></dl>

### `copy()` {#max.driver.Tensor.copy}

> copy(self, stream: [max.driver.DeviceStream](#max.driver.DeviceStream)) â†’ [max.driver.Tensor](#max.driver.Tensor)

> copy(self, device: [max.driver.Device](#max.driver.Device) | [None](https://docs.python.org/3/library/constants.html#None) = None) â†’ [max.driver.Tensor](#max.driver.Tensor)

Overloaded function.

1. `copy(self, stream: max.driver.DeviceStream) -> max.driver.Tensor`

   > Creates a deep copy on the device associated with the stream.

   > Args:
   > : stream (DeviceStream): The stream to associate the new tensor with.

   > Returns:
   > : Tensor: A new tensor that is a copy of this tensor.
2. `copy(self, device: max.driver.Device | None = None) -> max.driver.Tensor`

   > Creates a deep copy on an optionally given device.

   > If device is None (default), a copy is created on the same device.
   >
   > ```python
   > from max import driver
   > from max.dtype import DType
   > â€‹
   > cpu_tensor = driver.Tensor(shape=[2, 3], dtype=DType.bfloat16, device=driver.CPU())
   > cpu_copy = cpu_tensor.copy()
   > â€‹
   > # Copy to GPU
   > gpu = driver.Accelerator()
   > gpu_copy = cpu_tensor.copy(device=gpu)
   > ```

   > Args:
   > : device (Device, optional): The device to create the copy on.
   > : Defaults to None (same device).

   > Returns:
   > : Tensor: A new tensor that is a copy of this tensor.

### `device` {#max.driver.Tensor.device}

> property device

Device on which tensor is resident.

### `dtype` {#max.driver.Tensor.dtype}

> property dtype

DType of constituent elements in tensor.

### `element_size` {#max.driver.Tensor.element_size}

> property element\_size

Return the size of the element type in bytes.

### `from_dlpack()` {#max.driver.Tensor.from_dlpack}

> from\_dlpack(\*, copy=None)

Create a tensor from an object implementing the dlpack protocol.

This usually does not result in a copy, and the producer of the object
retains ownership of the underlying memory.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* array ([Any](https://docs.python.org/3/library/typing.html#typing.Any))
* copy ([bool](https://docs.python.org/3/library/functions.html#bool) | None)

</dd><dt>

**Return type:**

</dt><dd>

[Tensor](#max.driver.Tensor)

</dd></dl>

### `from_numpy()` {#max.driver.Tensor.from_numpy}

> from\_numpy()

Creates a tensor from a provided numpy array on the host device.

The underlying data is not copied unless the array is noncontiguous. If
it is, a contiguous copy will be returned.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

arr ([ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]])

</dd><dt>

**Return type:**

</dt><dd>

[Tensor](#max.driver.Tensor)

</dd></dl>

### `inplace_copy_from()` {#max.driver.Tensor.inplace_copy_from}

> inplace\_copy\_from(src)

Copy the contents of another tensor into this one. These tensors may
be on different devices.

Requires that both tensors are contiguous and have same size.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* self ([Tensor](#max.driver.Tensor))
* src ([Tensor](#max.driver.Tensor))

</dd><dt>

**Return type:**

</dt><dd>

None

</dd></dl>

### `is_contiguous` {#max.driver.Tensor.is_contiguous}

> property is\_contiguous

Whether or not tensor is contiguously allocated in memory. Returns
false if the tensor is a non-contiguous slice.

Currently, we consider certain situations that are contiguous as
non-contiguous for the purposes of our engine, such as when a tensor
has negative steps.

### `is_host` {#max.driver.Tensor.is_host}

> property is\_host

Whether or not tensor is host-resident. Returns false for GPU tensors,
true for CPU tensors.

```python
from max import driver
from max.dtype import DType

cpu_tensor = driver.Tensor(shape=[2, 3], dtype=DType.bfloat16, device=driver.CPU())

print(cpu_tensor.is_host)
```

### `item()` {#max.driver.Tensor.item}

> item(self) â†’ Any

Returns the scalar value at a given location. Currently
implemented only for zero-rank tensors. The return type is
converted to a Python built-in type.

### `mmap()` {#max.driver.Tensor.mmap}

> mmap(dtype, shape, mode='copyonwrite', offset=0)

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* filename (PathLike\[[str](https://docs.python.org/3/library/stdtypes.html#str)] | [str](https://docs.python.org/3/library/stdtypes.html#str))
* dtype ([DType](dtype.md#max.dtype.DType))
* shape (ShapeType | [int](https://docs.python.org/3/library/functions.html#int))
* mode (np.\_MemMapModeKind)
* offset ([int](https://docs.python.org/3/library/functions.html#int))

</dd><dt>

**Return type:**

</dt><dd>

[Tensor](#max.driver.Tensor)

</dd></dl>

### `num_elements` {#max.driver.Tensor.num_elements}

> property num\_elements

Returns the number of elements in this tensor.

Rank-0 tensors have 1 element by convention.

### `pinned` {#max.driver.Tensor.pinned}

> property pinned

Whether or not the underlying memory is pinned (page-locked).

### `rank` {#max.driver.Tensor.rank}

> property rank

Tensor rank.

### `scalar` {#max.driver.Tensor.scalar}

> scalar = \<nanobind.nb\_func object>

### `shape` {#max.driver.Tensor.shape}

> property shape

Shape of tensor.

### `stream` {#max.driver.Tensor.stream}

> property stream

Stream to which tensor is bound.

### `to()` {#max.driver.Tensor.to}

> to(self, device: [max.driver.Device](#max.driver.Device)) â†’ [Tensor](#max.driver.Tensor)

> to(self, device: [max.driver.DeviceStream](#max.driver.DeviceStream)) â†’ [Tensor](#max.driver.Tensor)

Overloaded function.

1. `to(self, device: max.driver.Device) -> Tensor`

   > Return a tensor thatâ€™s guaranteed to be on the given device.

   > The tensor is only copied if the requested device is different from the
   > device upon which the tensor is already resident.
2. `to(self, device: max.driver.DeviceStream) -> Tensor`

   > Return a tensor thatâ€™s guaranteed to be on the given device and associated
   > with the given stream.

   > The tensor is only copied if the requested device is different from the
   > device upon which the tensor is already resident.

### `to_numpy()` {#max.driver.Tensor.to_numpy}

> to\_numpy()

Converts the tensor to a numpy array.

If the tensor is not on the host, an exception is raised.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

self ([Tensor](#max.driver.Tensor))

</dd><dt>

**Return type:**

</dt><dd>

[ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]

</dd></dl>

### `view()` {#max.driver.Tensor.view}

> view(dtype, shape=None)

Return a new tensor with the given type and shape that shares the
underlying memory.

If the shape is not given, it will be deduced if possible, or a
ValueError is raised.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* self ([Tensor](#max.driver.Tensor))
* dtype ([DType](dtype.md#max.dtype.DType))
* shape ([Sequence](https://docs.python.org/3/library/collections.abc.html#collections.abc.Sequence)\[[int](https://docs.python.org/3/library/functions.html#int)] | None)

</dd><dt>

**Return type:**

</dt><dd>

[Tensor](#max.driver.Tensor)

</dd></dl>

### `zeros` {#max.driver.Tensor.zeros}

> zeros = \<nanobind.nb\_func object>

## `accelerator_api()` {#max.driver.accelerator_api}

> max.driver.accelerator\_api()

Returns the API used to program the accelerator.

<dl class='field-list'><dt>

**Return type:**

</dt><dd>

[str](https://docs.python.org/3/library/stdtypes.html#str)

</dd></dl>

## `accelerator_architecture_name()` {#max.driver.accelerator_architecture_name}

> max.driver.accelerator\_architecture\_name()

Returns the architecture name of the accelerator device.

<dl class='field-list'><dt>

**Return type:**

</dt><dd>

[str](https://docs.python.org/3/library/stdtypes.html#str)

</dd></dl>

## `devices_exist()` {#max.driver.devices_exist}

> max.driver.devices\_exist(devices)

Identify if devices exist.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

devices ([list](https://docs.python.org/3/library/stdtypes.html#list)\[[DeviceSpec](#max.driver.DeviceSpec)])

</dd><dt>

**Return type:**

</dt><dd>

[bool](https://docs.python.org/3/library/functions.html#bool)

</dd></dl>

## `load_devices()` {#max.driver.load_devices}

> max.driver.load\_devices(device\_specs)

Initialize and return a list of devices, given a list of device specs.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

device\_specs ([list](https://docs.python.org/3/library/stdtypes.html#list)\[[DeviceSpec](#max.driver.DeviceSpec)])

</dd><dt>

**Return type:**

</dt><dd>

[list](https://docs.python.org/3/library/stdtypes.html#list)\[[Device](#max.driver.Device)]

</dd></dl>

## `scan_available_devices()` {#max.driver.scan_available_devices}

> max.driver.scan\_available\_devices()

Returns all accelerators if available, else return cpu.

<dl class='field-list'><dt>

**Return type:**

</dt><dd>

[list](https://docs.python.org/3/library/stdtypes.html#list)\[[DeviceSpec](#max.driver.DeviceSpec)]

</dd></dl>

## `accelerator_count()` {#max.driver.accelerator_count}

> max.driver.accelerator\_count() â†’ [int](https://docs.python.org/3/library/functions.html#int)

Returns number of accelerator devices available.

---

## dtype

Provides data type definitions for tensors in MAX Engine. These data types are
essential for defining the precision and memory layout of tensor data when
working with machine learning models.

This module defines the [`DType`](#max.dtype.DType) enum, which represents all supported tensor
data types in MAX Engine, including:

* Integer types (signed and unsigned): `int8` | `uint8` | `int16` | `uint16` | `int32` | `uint32` | `int64` | `uint64`
* Floating-point types: `float8` variants | `float16` | `bfloat16` | `float32` | `float64`
* Boolean type

The module also provides utilities for converting between MAX Engine data types
and [NumPy dtypes](https://numpy.org/doc/stable/user/basics.types.html), making
it easy to interoperate with the NumPy ecosystem.

```python
import numpy as np
from max.dtype import DType

tensor = np.zeros((2, 3), dtype=DType.float32.to_numpy())

# Convert NumPy dtype to MAX DType
array = np.ones((4, 4), dtype=np.float16)
max_dtype = DType.from_numpy(array.dtype)

# Check properties of data types
is_float = DType.float32.is_float()  # True
is_int = DType.int64.is_integral()   # True
size = DType.float64.size_in_bytes   # 8
```

## `DType` {#max.dtype.DType}

> class max.dtype.DType(value, names=\<not given>, \*values, module=None, qualname=None, type=None, start=1, boundary=None)

The tensor data type.

### `align` {#max.dtype.DType.align}

> property align

Returns the alignment requirement of the data type in bytes.

The alignment specifies the memory boundary that values of this data type
must be aligned to for optimal performance and correctness.

### `bfloat16` {#max.dtype.DType.bfloat16}

> bfloat16 = 71

### `bool` {#max.dtype.DType.bool}

> bool = 1

### `float16` {#max.dtype.DType.float16}

> float16 = 70

### `float32` {#max.dtype.DType.float32}

> float32 = 72

### `float64` {#max.dtype.DType.float64}

> float64 = 73

### `float8_e4m3fn` {#max.dtype.DType.float8_e4m3fn}

> float8\_e4m3fn = 66

### `float8_e4m3fnuz` {#max.dtype.DType.float8_e4m3fnuz}

> float8\_e4m3fnuz = 67

### `float8_e5m2` {#max.dtype.DType.float8_e5m2}

> float8\_e5m2 = 68

### `float8_e5m2fnuz` {#max.dtype.DType.float8_e5m2fnuz}

> float8\_e5m2fnuz = 69

### `from_numpy()` {#max.dtype.DType.from_numpy}

> from\_numpy()

Converts a NumPy dtype to the corresponding DType.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

dtype (np.dtype) â€“ The NumPy dtype to convert.

</dd><dt>

**Returns:**

</dt><dd>

The corresponding DType enum value.

</dd><dt>

**Return type:**

</dt><dd>

[DType](#max.dtype.DType)

</dd><dt>

**Raises:**

</dt><dd>

[ValueError](https://docs.python.org/3/library/exceptions.html#ValueError) â€“ If the input dtype is not supported.

</dd></dl>

### `from_torch()` {#max.dtype.DType.from_torch}

> from\_torch()

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

dtype (dtype)

</dd><dt>

**Return type:**

</dt><dd>

[DType](#max.dtype.DType)

</dd></dl>

### `int16` {#max.dtype.DType.int16}

> int16 = 137

### `int32` {#max.dtype.DType.int32}

> int32 = 139

### `int64` {#max.dtype.DType.int64}

> int64 = 141

### `int8` {#max.dtype.DType.int8}

> int8 = 135

### `is_float()` {#max.dtype.DType.is_float}

> is\_float(self) â†’ [bool](https://docs.python.org/3/library/functions.html#bool)

Checks if the data type is a floating-point type.

### `is_float8()` {#max.dtype.DType.is_float8}

> is\_float8(self) â†’ [bool](https://docs.python.org/3/library/functions.html#bool)

Checks if the data type is an 8-bit floating-point type.

### `is_half()` {#max.dtype.DType.is_half}

> is\_half(self) â†’ [bool](https://docs.python.org/3/library/functions.html#bool)

Checks if the data type is a half-precision floating-point type.

### `is_integral()` {#max.dtype.DType.is_integral}

> is\_integral(self) â†’ [bool](https://docs.python.org/3/library/functions.html#bool)

Checks if the data type is an integer type.

### `is_signed_integral()` {#max.dtype.DType.is_signed_integral}

> is\_signed\_integral(self) â†’ [bool](https://docs.python.org/3/library/functions.html#bool)

Checks if the data type is a signed integer type.

### `is_unsigned_integral()` {#max.dtype.DType.is_unsigned_integral}

> is\_unsigned\_integral(self) â†’ [bool](https://docs.python.org/3/library/functions.html#bool)

Checks if the data type is an unsigned integer type.

### `size_in_bytes` {#max.dtype.DType.size_in_bytes}

> property size\_in\_bytes

Returns the size of the data type in bytes.

This indicates how many bytes are required to store a single value
of this data type in memory.

### `to_numpy()` {#max.dtype.DType.to_numpy}

> to\_numpy()

Converts this `DType` to the corresponding NumPy dtype.

<dl class='field-list'><dt>

**Returns:**

</dt><dd>

The corresponding NumPy dtype object.

</dd><dt>

**Return type:**

</dt><dd>

[DType](#max.dtype.DType)

</dd><dt>

**Raises:**

</dt><dd>

[ValueError](https://docs.python.org/3/library/exceptions.html#ValueError) â€“ If the dtype is not supported.

</dd><dt>

**Parameters:**

</dt><dd>

self ([DType](#max.dtype.DType))

</dd></dl>

### `to_torch()` {#max.dtype.DType.to_torch}

> to\_torch()

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

dtype ([DType](#max.dtype.DType))

</dd><dt>

**Return type:**

</dt><dd>

dtype

</dd></dl>

### `uint16` {#max.dtype.DType.uint16}

> uint16 = 136

### `uint32` {#max.dtype.DType.uint32}

> uint32 = 138

### `uint64` {#max.dtype.DType.uint64}

> uint64 = 140

### `uint8` {#max.dtype.DType.uint8}

> uint8 = 134

---

## engine

The APIs in this module allow you to run inference with MAX Engineâ€”a graph
compiler and runtime that accelerates your AI models on a wide variety of
hardware.

## `InferenceSession` {#max.engine.InferenceSession}

> class max.engine.InferenceSession(devices, num\_threads=None, \*, custom\_extensions=None)

Manages an inference session in which you can load and run models.

You need an instance of this to load a model as a [`Model`](#max.engine.Model) object.
For example:

```python
session = engine.InferenceSession(devices=...)
model_path = Path('bert-base-uncased')
model = session.load(model_path)
```

Construct an inference session.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* num\_threads ([int](https://docs.python.org/3/library/functions.html#int) | None) â€“ Number of threads to use for the inference session.
  This defaults to the number of physical cores on your machine.
* devices (Iterable\[[Device](driver.md#max.driver.Device)]) â€“ A list of devices on which to run inference. Default is
  the host CPU only.
* custom\_extensions (CustomExtensionsType | None) â€“ The extensions to load for the model.
  Supports paths to a .mojopkg custom ops library or a .mojo
  source file.

</dd></dl>

### `devices` {#max.engine.InferenceSession.devices}

> property devices: [list](https://docs.python.org/3/library/stdtypes.html#list)\[[Device](driver.md#max.driver.Device)]

A list of available devices.

### `gpu_profiling()` {#max.engine.InferenceSession.gpu_profiling}

> gpu\_profiling(mode)

Enables end to end gpu profiling configuration.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

mode ([GPUProfilingMode](#max.engine.GPUProfilingMode))

</dd><dt>

**Return type:**

</dt><dd>

None

</dd></dl>

### `load()` {#max.engine.InferenceSession.load}

> load(model, \*, custom\_extensions=None, custom\_ops\_path=None, weights\_registry=None)

Loads a trained model and compiles it for inference.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* model (Union\[[str](https://docs.python.org/3/library/stdtypes.html#str), Path, Any]) â€“ Path to a model.
* custom\_extensions (CustomExtensionsType | None) â€“ The extensions to load for the model.
  Supports paths to .mojopkg custom ops.
* custom\_ops\_path ([str](https://docs.python.org/3/library/stdtypes.html#str) | None) â€“ The path to your custom ops Mojo package.
  Deprecated, use `custom_extensions` instead.
* weights\_registry (Mapping\[[str](https://docs.python.org/3/library/stdtypes.html#str), [DLPackArray](driver.md#max.driver.DLPackArray)] | None) â€“ A mapping from names of model weightsâ€™ names to
  their values. The values are currently expected to be dlpack
  arrays. If an array is a read-only numpy array, the user must
  ensure that its lifetime extends beyond the lifetime of the model.

</dd><dt>

**Returns:**

</dt><dd>

The loaded model, compiled and ready to execute.

</dd><dt>

**Raises:**

</dt><dd>

[RuntimeError](https://docs.python.org/3/library/exceptions.html#RuntimeError) â€“ If the path provided is invalid.

</dd><dt>

**Return type:**

</dt><dd>

[Model](#max.engine.Model)

</dd></dl>

### `set_mojo_assert_level()` {#max.engine.InferenceSession.set_mojo_assert_level}

> set\_mojo\_assert\_level(level)

Sets which mojo asserts are kept in the compiled model.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

level ([str](https://docs.python.org/3/library/stdtypes.html#str) | AssertLevel)

</dd><dt>

**Return type:**

</dt><dd>

None

</dd></dl>

### `set_mojo_log_level()` {#max.engine.InferenceSession.set_mojo_log_level}

> set\_mojo\_log\_level(level)

Sets the verbosity of mojo logging in the compiled model.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

level ([str](https://docs.python.org/3/library/stdtypes.html#str) | [LogLevel](#max.engine.LogLevel))

</dd><dt>

**Return type:**

</dt><dd>

None

</dd></dl>

### `set_split_k_reduction_precision()` {#max.engine.InferenceSession.set_split_k_reduction_precision}

> set\_split\_k\_reduction\_precision(precision)

Sets the accumulation precision for split k reductions in large matmuls.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

precision ([str](https://docs.python.org/3/library/stdtypes.html#str) | SplitKReductionPrecision)

</dd><dt>

**Return type:**

</dt><dd>

None

</dd></dl>

## `Model` {#max.engine.Model}

> class max.engine.Model

A loaded model that you can execute.

Do not instantiate this class directly. Instead, create it with
[`InferenceSession`](#max.engine.InferenceSession).

### `__call__()` {#max.engine.Model.__call}

> \_\_call\_\_(\*args, \*\*kwargs)

Call self as a function.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* self ([Model](#max.engine.Model))
* args ([DLPackArray](driver.md#max.driver.DLPackArray) | [Tensor](driver.md#max.driver.Tensor) | [MojoValue](#max.engine.MojoValue) | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [bool](https://docs.python.org/3/library/functions.html#bool) | [generic](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.generic))
* kwargs ([DLPackArray](driver.md#max.driver.DLPackArray) | [Tensor](driver.md#max.driver.Tensor) | [MojoValue](#max.engine.MojoValue) | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [bool](https://docs.python.org/3/library/functions.html#bool) | [generic](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.generic))

</dd><dt>

**Return type:**

</dt><dd>

[list](https://docs.python.org/3/library/stdtypes.html#list)\[[Tensor](driver.md#max.driver.Tensor) | [MojoValue](#max.engine.MojoValue)]

</dd></dl>

### `execute()` {#max.engine.Model.execute}

> execute(\*args)

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* self ([Model](#max.engine.Model))
* args ([DLPackArray](driver.md#max.driver.DLPackArray) | [Tensor](driver.md#max.driver.Tensor) | [MojoValue](#max.engine.MojoValue) | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [bool](https://docs.python.org/3/library/functions.html#bool) | [generic](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.generic))

</dd><dt>

**Return type:**

</dt><dd>

[list](https://docs.python.org/3/library/stdtypes.html#list)\[[Tensor](driver.md#max.driver.Tensor) | [MojoValue](#max.engine.MojoValue)]

</dd></dl>

### `input_metadata` {#max.engine.Model.input_metadata}

> property input\_metadata

Metadata about the modelâ€™s input tensors, as a list of
[`TensorSpec`](#max.engine.TensorSpec) objects.

For example, you can print the input tensor names, shapes, and dtypes:

```python
for tensor in model.input_metadata:
    print(f'name: {tensor.name}, shape: {tensor.shape}, dtype: {tensor.dtype}')
```

### `output_metadata` {#max.engine.Model.output_metadata}

> property output\_metadata

Metadata about the modelâ€™s output tensors, as a list of
[`TensorSpec`](#max.engine.TensorSpec) objects.

For example, you can print the output tensor names, shapes, and dtypes:

```python
for tensor in model.output_metadata:
    print(f'name: {tensor.name}, shape: {tensor.shape}, dtype: {tensor.dtype}')
```

## `GPUProfilingMode` {#max.engine.GPUProfilingMode}

> class max.engine.GPUProfilingMode(value, names=\<not given>, \*values, module=None, qualname=None, type=None, start=1, boundary=None)

The supported modes for GPU profiling.

### `DETAILED` {#max.engine.GPUProfilingMode.DETAILED}

> DETAILED = 'detailed'

### `OFF` {#max.engine.GPUProfilingMode.OFF}

> OFF = 'off'

### `ON` {#max.engine.GPUProfilingMode.ON}

> ON = 'on'

## `LogLevel` {#max.engine.LogLevel}

> class max.engine.LogLevel(value, names=\<not given>, \*values, module=None, qualname=None, type=None, start=1, boundary=None)

The LogLevel specifies the log level used by the Mojo Ops.

### `CRITICAL` {#max.engine.LogLevel.CRITICAL}

> CRITICAL = 'critical'

### `DEBUG` {#max.engine.LogLevel.DEBUG}

> DEBUG = 'debug'

### `ERROR` {#max.engine.LogLevel.ERROR}

> ERROR = 'error'

### `INFO` {#max.engine.LogLevel.INFO}

> INFO = 'info'

### `NOTSET` {#max.engine.LogLevel.NOTSET}

> NOTSET = 'notset'

### `TRACE` {#max.engine.LogLevel.TRACE}

> TRACE = 'trace'

### `WARNING` {#max.engine.LogLevel.WARNING}

> WARNING = 'warning'

## `MojoValue` {#max.engine.MojoValue}

> class max.engine.MojoValue

This is work in progress and you should ignore it for now.

## `TensorSpec` {#max.engine.TensorSpec}

> class max.engine.TensorSpec

Defines the properties of a tensor, including its name, shape and
data type.

For usage examples, see [`Model.input_metadata`](#max.engine.Model.input_metadata).

### `dtype` {#max.engine.TensorSpec.dtype}

> property dtype

A tensor data type.

### `name` {#max.engine.TensorSpec.name}

> property name

A tensor name.

### `shape` {#max.engine.TensorSpec.shape}

> property shape

The shape of the tensor as a list of integers.

If a dimension size is unknown/dynamic (such as the batch size), its
value is `None`.

## `CustomExtensionsType` {#max.engine.CustomExtensionsType}

> max.engine.CustomExtensionsType

alias of [`list`](https://docs.python.org/3/library/stdtypes.html#list)\[[`str`](https://docs.python.org/3/library/stdtypes.html#str) | [`Path`](https://docs.python.org/3/library/pathlib.html#pathlib.Path) | [`Any`](https://docs.python.org/3/library/typing.html#typing.Any)] | [`str`](https://docs.python.org/3/library/stdtypes.html#str) | [`Path`](https://docs.python.org/3/library/pathlib.html#pathlib.Path) | [`Any`](https://docs.python.org/3/library/typing.html#typing.Any)

---

## entrypoints

## `LLM` {#max.entrypoints.llm.LLM}

> class max.entrypoints.llm.LLM(pipeline\_config)

A high level interface for interacting with LLMs.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

pipeline\_config ([PipelineConfig](pipelines/config.md#max.pipelines.lib.config.PipelineConfig))

</dd></dl>

### `generate()` {#max.entrypoints.llm.LLM.generate}

> generate(prompts, max\_new\_tokens=100, use\_tqdm=True)

Generates text completions for the given prompts.

This method is thread safe and may be used on the same LLM instance
from multiple threads concurrently with no external synchronization.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* prompts ([str](https://docs.python.org/3/library/stdtypes.html#str) | [Sequence](https://docs.python.org/3/library/collections.abc.html#collections.abc.Sequence)\[[str](https://docs.python.org/3/library/stdtypes.html#str)]) â€“ The input string or list of strings to generate completions for.
* max\_new\_tokens ([int](https://docs.python.org/3/library/functions.html#int) | None) â€“ The maximum number of tokens to generate in the response.
* use\_tqdm ([bool](https://docs.python.org/3/library/functions.html#bool)) â€“ Whether to display a progress bar during generation.

</dd><dt>

**Returns:**

</dt><dd>

A list of generated text completions corresponding to each input prompt.

</dd><dt>

**Raises:**

</dt><dd>

* [ValueError](https://docs.python.org/3/library/exceptions.html#ValueError) â€“ If prompts is empty or contains invalid data.
* [RuntimeError](https://docs.python.org/3/library/exceptions.html#RuntimeError) â€“ If the model fails to generate completions.

</dd><dt>

**Return type:**

</dt><dd>

[Sequence](https://docs.python.org/3/library/collections.abc.html#collections.abc.Sequence)\[[str](https://docs.python.org/3/library/stdtypes.html#str)]

</dd></dl>

---

## functional

Provides experimental functional APIs for tensor operations.

#### WARNING

This module contains experimental APIs that are subject to change or
removal in future versions. Use with caution in production environments.

This module provides functional-style tensor operations that work seamlessly
with both MAX Graph construction and eager Tensor execution. All operations
are wrapped versions of the core graph operations that automatically handle
different execution contexts.
These operations can be used in both graph construction and eager execution.

## `abs()` {#max.experimental.functional.abs}

> max.experimental.functional.abs(x)

Computes the absolute value element-wise.
See [`max.graph.ops.abs()`](../graph/ops.md#max.graph.ops.abs) for details.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

x (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](../graph/TensorValue.md#max.graph.TensorValue)

</dd></dl>

## `add()` {#max.experimental.functional.add}

> max.experimental.functional.add(lhs, rhs)

Adds two tensors element-wise.
See [`max.graph.ops.add()`](../graph/ops.md#max.graph.ops.add) for details.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* lhs (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])
* rhs (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](../graph/TensorValue.md#max.graph.TensorValue)

</dd></dl>

## `argmax()` {#max.experimental.functional.argmax}

> max.experimental.functional.argmax(x, axis=-1)

Returns the indices of the maximum values along an axis.
See [`max.graph.ops.argmax()`](../graph/ops.md#max.graph.ops.argmax) for details.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* x (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])
* axis ([int](https://docs.python.org/3/library/functions.html#int))

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](../graph/TensorValue.md#max.graph.TensorValue)

</dd></dl>

## `argmin()` {#max.experimental.functional.argmin}

> max.experimental.functional.argmin(x, axis=-1)

Returns the indices of the minimum values along an axis.
See [`max.graph.ops.argmin()`](../graph/ops.md#max.graph.ops.argmin) for details.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* x (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])
* axis ([int](https://docs.python.org/3/library/functions.html#int))

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](../graph/TensorValue.md#max.graph.TensorValue)

</dd></dl>

## `argsort()` {#max.experimental.functional.argsort}

> max.experimental.functional.argsort(x, ascending=True)

Returns the indices that would sort a tensor along an axis.
See [`max.graph.ops.argsort()`](../graph/ops.md#max.graph.ops.argsort) for details.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* x (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue)
* ascending ([bool](https://docs.python.org/3/library/functions.html#bool))

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](../graph/TensorValue.md#max.graph.TensorValue)

</dd></dl>

## `as_interleaved_complex()` {#max.experimental.functional.as_interleaved_complex}

> max.experimental.functional.as\_interleaved\_complex(x)

Converts a tensor to interleaved complex representation.
See [`max.graph.ops.as_interleaved_complex()`](../graph/ops.md#max.graph.ops.as_interleaved_complex) for details.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

x (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](../graph/TensorValue.md#max.graph.TensorValue)

</dd></dl>

## `atanh()` {#max.experimental.functional.atanh}

> max.experimental.functional.atanh(x)

Computes the inverse hyperbolic tangent element-wise.
See [`max.graph.ops.atanh()`](../graph/ops.md#max.graph.ops.atanh) for details.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

x (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](../graph/TensorValue.md#max.graph.TensorValue)

</dd></dl>

## `avg_pool2d()` {#max.experimental.functional.avg_pool2d}

> max.experimental.functional.avg\_pool2d(input, kernel\_size, stride=1, dilation=1, padding=0, ceil\_mode=False, count\_boundary=True)

Applies 2D average pooling.
See [`max.graph.ops.avg_pool2d()`](../graph/ops.md#max.graph.ops.avg_pool2d) for details.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* input (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])
* kernel\_size ([tuple](https://docs.python.org/3/library/stdtypes.html#tuple)\[[int](https://docs.python.org/3/library/functions.html#int) | [str](https://docs.python.org/3/library/stdtypes.html#str) | [Dim](../graph/dim.md#max.graph.dim.Dim) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)], [int](https://docs.python.org/3/library/functions.html#int) | [str](https://docs.python.org/3/library/stdtypes.html#str) | [Dim](../graph/dim.md#max.graph.dim.Dim) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]])
* stride ([int](https://docs.python.org/3/library/functions.html#int) | [tuple](https://docs.python.org/3/library/stdtypes.html#tuple)\[[int](https://docs.python.org/3/library/functions.html#int), [int](https://docs.python.org/3/library/functions.html#int)])
* dilation ([int](https://docs.python.org/3/library/functions.html#int) | [tuple](https://docs.python.org/3/library/stdtypes.html#tuple)\[[int](https://docs.python.org/3/library/functions.html#int), [int](https://docs.python.org/3/library/functions.html#int)])
* padding ([int](https://docs.python.org/3/library/functions.html#int) | [tuple](https://docs.python.org/3/library/stdtypes.html#tuple)\[[int](https://docs.python.org/3/library/functions.html#int), [int](https://docs.python.org/3/library/functions.html#int)])
* ceil\_mode ([bool](https://docs.python.org/3/library/functions.html#bool))
* count\_boundary ([bool](https://docs.python.org/3/library/functions.html#bool))

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](../graph/TensorValue.md#max.graph.TensorValue)

</dd></dl>

## `band_part()` {#max.experimental.functional.band_part}

> max.experimental.functional.band\_part(x, num\_lower=None, num\_upper=None, exclude=False)

Copies a tensor setting everything outside a central band to zero.
See [`max.graph.ops.band_part()`](../graph/ops.md#max.graph.ops.band_part) for details.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* x (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])
* num\_lower ([int](https://docs.python.org/3/library/functions.html#int) | None)
* num\_upper ([int](https://docs.python.org/3/library/functions.html#int) | None)
* exclude ([bool](https://docs.python.org/3/library/functions.html#bool))

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](../graph/TensorValue.md#max.graph.TensorValue)

</dd></dl>

## `broadcast_to()` {#max.experimental.functional.broadcast_to}

> max.experimental.functional.broadcast\_to(x, shape, out\_dims=None)

Broadcasts a tensor to a new shape.
See [`max.graph.ops.broadcast_to()`](../graph/ops.md#max.graph.ops.broadcast_to) for details.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* x (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue)
* shape ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Iterable](https://docs.python.org/3/library/collections.abc.html#collections.abc.Iterable)\[[int](https://docs.python.org/3/library/functions.html#int) | [str](https://docs.python.org/3/library/stdtypes.html#str) | [Dim](../graph/dim.md#max.graph.dim.Dim) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]])
* out\_dims ([Iterable](https://docs.python.org/3/library/collections.abc.html#collections.abc.Iterable)\[[int](https://docs.python.org/3/library/functions.html#int) | [str](https://docs.python.org/3/library/stdtypes.html#str) | [Dim](../graph/dim.md#max.graph.dim.Dim) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]] | None)

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](../graph/TensorValue.md#max.graph.TensorValue)

</dd></dl>

## `cast()` {#max.experimental.functional.cast}

> max.experimental.functional.cast(x, dtype)

Casts a tensor to a different data type.
See [`max.graph.ops.cast()`](../graph/ops.md#max.graph.ops.cast) for details.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* x (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue)
* dtype ([DType](../dtype.md#max.dtype.DType))

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](../graph/TensorValue.md#max.graph.TensorValue)

</dd></dl>

## `chunk()` {#max.experimental.functional.chunk}

> max.experimental.functional.chunk(x, chunks, axis=0)

Splits a tensor into chunks along a dimension.
See [`max.graph.ops.chunk()`](../graph/ops.md#max.graph.ops.chunk) for details.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* x (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])
* chunks ([int](https://docs.python.org/3/library/functions.html#int))
* axis ([int](https://docs.python.org/3/library/functions.html#int))

</dd><dt>

**Return type:**

</dt><dd>

[list](https://docs.python.org/3/library/stdtypes.html#list)\[[TensorValue](../graph/TensorValue.md#max.graph.TensorValue)]

</dd></dl>

## `constant()` {#max.experimental.functional.constant}

> max.experimental.functional.constant(value, dtype, device)

Creates a constant tensor.
See [`max.graph.ops.constant()`](../graph/ops.md#max.graph.ops.constant) for details.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* value ([ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]] | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)])
* dtype ([DType](../dtype.md#max.dtype.DType))
* device ([Device](../driver.md#max.driver.Device) | [DeviceRef](../graph/type.md#max.graph.type.DeviceRef))

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](../graph/TensorValue.md#max.graph.TensorValue)

</dd></dl>

## `constant_external()` {#max.experimental.functional.constant_external}

> max.experimental.functional.constant\_external(name, type)

Creates a constant tensor from external data.
See [`max.graph.ops.constant_external()`](../graph/ops.md#max.graph.ops.constant_external) for details.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* name ([str](https://docs.python.org/3/library/stdtypes.html#str))
* type ([TensorType](../graph/type.md#max.graph.type.TensorType))

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](../graph/TensorValue.md#max.graph.TensorValue)

</dd></dl>

## `conv2d()` {#max.experimental.functional.conv2d}

> max.experimental.functional.conv2d(x, filter, stride=(1, 1), dilation=(1, 1), padding=(0, 0, 0, 0), groups=1, bias=None, input\_layout=ConvInputLayout.NHWC, filter\_layout=FilterLayout.RSCF)

Applies 2D convolution.
See [`max.graph.ops.conv2d()`](../graph/ops.md#max.graph.ops.conv2d) for details.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* x (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])
* filter (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])
* stride ([tuple](https://docs.python.org/3/library/stdtypes.html#tuple)\[[int](https://docs.python.org/3/library/functions.html#int), [int](https://docs.python.org/3/library/functions.html#int)])
* dilation ([tuple](https://docs.python.org/3/library/stdtypes.html#tuple)\[[int](https://docs.python.org/3/library/functions.html#int), [int](https://docs.python.org/3/library/functions.html#int)])
* padding ([tuple](https://docs.python.org/3/library/stdtypes.html#tuple)\[[int](https://docs.python.org/3/library/functions.html#int), [int](https://docs.python.org/3/library/functions.html#int), [int](https://docs.python.org/3/library/functions.html#int), [int](https://docs.python.org/3/library/functions.html#int)])
* groups ([int](https://docs.python.org/3/library/functions.html#int))
* bias (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]] | None)
* input\_layout ([ConvInputLayout](../graph/type.md#max.graph.type.ConvInputLayout))
* filter\_layout ([FilterLayout](../graph/type.md#max.graph.type.FilterLayout))

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](../graph/TensorValue.md#max.graph.TensorValue)

</dd></dl>

## `conv2d_transpose()` {#max.experimental.functional.conv2d_transpose}

> max.experimental.functional.conv2d\_transpose(x, filter, stride=(1, 1), dilation=(1, 1), padding=(0, 0, 0, 0), output\_paddings=(0, 0), bias=None, input\_layout=ConvInputLayout.NHWC, filter\_layout=FilterLayout.RSCF)

Applies 2D transposed convolution.
See [`max.graph.ops.conv2d_transpose()`](../graph/ops.md#max.graph.ops.conv2d_transpose) for details.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* x (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])
* filter (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])
* stride ([tuple](https://docs.python.org/3/library/stdtypes.html#tuple)\[[int](https://docs.python.org/3/library/functions.html#int), [int](https://docs.python.org/3/library/functions.html#int)])
* dilation ([tuple](https://docs.python.org/3/library/stdtypes.html#tuple)\[[int](https://docs.python.org/3/library/functions.html#int), [int](https://docs.python.org/3/library/functions.html#int)])
* padding ([tuple](https://docs.python.org/3/library/stdtypes.html#tuple)\[[int](https://docs.python.org/3/library/functions.html#int), [int](https://docs.python.org/3/library/functions.html#int), [int](https://docs.python.org/3/library/functions.html#int), [int](https://docs.python.org/3/library/functions.html#int)])
* output\_paddings ([tuple](https://docs.python.org/3/library/stdtypes.html#tuple)\[[int](https://docs.python.org/3/library/functions.html#int), [int](https://docs.python.org/3/library/functions.html#int)])
* bias (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]] | None)
* input\_layout ([ConvInputLayout](../graph/type.md#max.graph.type.ConvInputLayout))
* filter\_layout ([FilterLayout](../graph/type.md#max.graph.type.FilterLayout))

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](../graph/TensorValue.md#max.graph.TensorValue)

</dd></dl>

## `conv3d()` {#max.experimental.functional.conv3d}

> max.experimental.functional.conv3d(x, filter, stride=(1, 1, 1), dilation=(1, 1, 1), padding=(0, 0, 0, 0, 0, 0), groups=1, bias=None, input\_layout=ConvInputLayout.NHWC, filter\_layout=FilterLayout.QRSCF)

Applies 3D convolution.
See [`max.graph.ops.conv3d()`](../graph/ops.md#max.graph.ops.conv3d) for details.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* x (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])
* filter (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])
* stride ([tuple](https://docs.python.org/3/library/stdtypes.html#tuple)\[[int](https://docs.python.org/3/library/functions.html#int), [int](https://docs.python.org/3/library/functions.html#int), [int](https://docs.python.org/3/library/functions.html#int)])
* dilation ([tuple](https://docs.python.org/3/library/stdtypes.html#tuple)\[[int](https://docs.python.org/3/library/functions.html#int), [int](https://docs.python.org/3/library/functions.html#int), [int](https://docs.python.org/3/library/functions.html#int)])
* padding ([tuple](https://docs.python.org/3/library/stdtypes.html#tuple)\[[int](https://docs.python.org/3/library/functions.html#int), [int](https://docs.python.org/3/library/functions.html#int), [int](https://docs.python.org/3/library/functions.html#int), [int](https://docs.python.org/3/library/functions.html#int), [int](https://docs.python.org/3/library/functions.html#int), [int](https://docs.python.org/3/library/functions.html#int)])
* groups ([int](https://docs.python.org/3/library/functions.html#int))
* bias (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]] | None)
* input\_layout ([ConvInputLayout](../graph/type.md#max.graph.type.ConvInputLayout))
* filter\_layout ([FilterLayout](../graph/type.md#max.graph.type.FilterLayout))

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](../graph/TensorValue.md#max.graph.TensorValue)

</dd></dl>

## `cos()` {#max.experimental.functional.cos}

> max.experimental.functional.cos(x)

Computes the cosine element-wise.
See [`max.graph.ops.cos()`](../graph/ops.md#max.graph.ops.cos) for details.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

x (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](../graph/TensorValue.md#max.graph.TensorValue)

</dd></dl>

## `cumsum()` {#max.experimental.functional.cumsum}

> max.experimental.functional.cumsum(x, axis=-1, exclusive=False, reverse=False)

Computes the cumulative sum along an axis.
See [`max.graph.ops.cumsum()`](../graph/ops.md#max.graph.ops.cumsum) for details.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* x (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])
* axis ([int](https://docs.python.org/3/library/functions.html#int))
* exclusive ([bool](https://docs.python.org/3/library/functions.html#bool))
* reverse ([bool](https://docs.python.org/3/library/functions.html#bool))

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](../graph/TensorValue.md#max.graph.TensorValue)

</dd></dl>

## `custom()` {#max.experimental.functional.custom}

> max.experimental.functional.custom(name, device, values, out\_types, parameters=None)

Applies a custom operation.
See [`max.graph.ops.custom()`](../graph/ops.md#max.graph.ops.custom) for details.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* name ([str](https://docs.python.org/3/library/stdtypes.html#str))
* device ([DeviceRef](../graph/type.md#max.graph.type.DeviceRef))
* values ([Sequence](https://docs.python.org/3/library/collections.abc.html#collections.abc.Sequence)\[[Value](../graph/Value.md#max.graph.Value)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]])
* out\_types ([Sequence](https://docs.python.org/3/library/collections.abc.html#collections.abc.Sequence)\[[Type](../graph/type.md#max.graph.type.Type)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]])
* parameters ([Mapping](https://docs.python.org/3/library/collections.abc.html#collections.abc.Mapping)\[[str](https://docs.python.org/3/library/stdtypes.html#str), [bool](https://docs.python.org/3/library/functions.html#bool) | [int](https://docs.python.org/3/library/functions.html#int) | [str](https://docs.python.org/3/library/stdtypes.html#str) | [DType](../dtype.md#max.dtype.DType)] | None)

</dd><dt>

**Return type:**

</dt><dd>

[list](https://docs.python.org/3/library/stdtypes.html#list)\[[Value](../graph/Value.md#max.graph.Value)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]

</dd></dl>

## `div()` {#max.experimental.functional.div}

> max.experimental.functional.div(lhs, rhs)

Divides two tensors element-wise.
See [`max.graph.ops.div()`](../graph/ops.md#max.graph.ops.div) for details.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* lhs (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])
* rhs (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](../graph/TensorValue.md#max.graph.TensorValue)

</dd></dl>

## `equal()` {#max.experimental.functional.equal}

> max.experimental.functional.equal(lhs, rhs)

Computes element-wise equality comparison.
See [`max.graph.ops.equal()`](../graph/ops.md#max.graph.ops.equal) for details.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* lhs (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])
* rhs (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](../graph/TensorValue.md#max.graph.TensorValue)

</dd></dl>

## `erf()` {#max.experimental.functional.erf}

> max.experimental.functional.erf(x)

Computes the error function element-wise.
See [`max.graph.ops.erf()`](../graph/ops.md#max.graph.ops.erf) for details.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

x (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](../graph/TensorValue.md#max.graph.TensorValue)

</dd></dl>

## `exp()` {#max.experimental.functional.exp}

> max.experimental.functional.exp(x)

Computes the exponential element-wise.
See [`max.graph.ops.exp()`](../graph/ops.md#max.graph.ops.exp) for details.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

x (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](../graph/TensorValue.md#max.graph.TensorValue)

</dd></dl>

## `flatten()` {#max.experimental.functional.flatten}

> max.experimental.functional.flatten(x, start\_dim=0, end\_dim=-1)

Flattens a tensor.
See [`max.graph.ops.flatten()`](../graph/ops.md#max.graph.ops.flatten) for details.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* x (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])
* start\_dim ([int](https://docs.python.org/3/library/functions.html#int))
* end\_dim ([int](https://docs.python.org/3/library/functions.html#int))

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](../graph/TensorValue.md#max.graph.TensorValue)

</dd></dl>

## `floor()` {#max.experimental.functional.floor}

> max.experimental.functional.floor(x)

Computes the floor element-wise.
See [`max.graph.ops.floor()`](../graph/ops.md#max.graph.ops.floor) for details.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

x (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](../graph/TensorValue.md#max.graph.TensorValue)

</dd></dl>

## `fold()` {#max.experimental.functional.fold}

> max.experimental.functional.fold(input, output\_size, kernel\_size, stride=1, dilation=1, padding=0)

Performs tensor folding operation.
See [`max.graph.ops.fold()`](../graph/ops.md#max.graph.ops.fold) for details.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* input (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])
* output\_size ([tuple](https://docs.python.org/3/library/stdtypes.html#tuple)\[[int](https://docs.python.org/3/library/functions.html#int) | [str](https://docs.python.org/3/library/stdtypes.html#str) | [Dim](../graph/dim.md#max.graph.dim.Dim) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)], [int](https://docs.python.org/3/library/functions.html#int) | [str](https://docs.python.org/3/library/stdtypes.html#str) | [Dim](../graph/dim.md#max.graph.dim.Dim) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]])
* kernel\_size ([tuple](https://docs.python.org/3/library/stdtypes.html#tuple)\[[int](https://docs.python.org/3/library/functions.html#int) | [str](https://docs.python.org/3/library/stdtypes.html#str) | [Dim](../graph/dim.md#max.graph.dim.Dim) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)], [int](https://docs.python.org/3/library/functions.html#int) | [str](https://docs.python.org/3/library/stdtypes.html#str) | [Dim](../graph/dim.md#max.graph.dim.Dim) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]])
* stride ([int](https://docs.python.org/3/library/functions.html#int) | [tuple](https://docs.python.org/3/library/stdtypes.html#tuple)\[[int](https://docs.python.org/3/library/functions.html#int), [int](https://docs.python.org/3/library/functions.html#int)])
* dilation ([int](https://docs.python.org/3/library/functions.html#int) | [tuple](https://docs.python.org/3/library/stdtypes.html#tuple)\[[int](https://docs.python.org/3/library/functions.html#int), [int](https://docs.python.org/3/library/functions.html#int)])
* padding ([int](https://docs.python.org/3/library/functions.html#int) | [tuple](https://docs.python.org/3/library/stdtypes.html#tuple)\[[int](https://docs.python.org/3/library/functions.html#int), [int](https://docs.python.org/3/library/functions.html#int)])

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](../graph/TensorValue.md#max.graph.TensorValue)

</dd></dl>

## `functional()` {#max.experimental.functional.functional}

> max.experimental.functional.functional(op)

Decorator that converts a graph operation to support multiple tensor
types.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

op ([Callable](https://docs.python.org/3/library/typing.html#typing.Callable)\[\[\~Args], Result])

</dd><dt>

**Return type:**

</dt><dd>

[Callable](https://docs.python.org/3/library/typing.html#typing.Callable)\[\[\~Args], Result]

</dd></dl>

## `gather()` {#max.experimental.functional.gather}

> max.experimental.functional.gather(input, indices, axis=-1)

Gathers values along an axis specified by indices.
See [`max.graph.ops.gather()`](../graph/ops.md#max.graph.ops.gather) for details.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* input (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])
* indices (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])
* axis ([int](https://docs.python.org/3/library/functions.html#int))

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](../graph/TensorValue.md#max.graph.TensorValue)

</dd></dl>

## `gather_nd()` {#max.experimental.functional.gather_nd}

> max.experimental.functional.gather\_nd(input, indices, batch\_dims=0)

Gathers values using multi-dimensional indices.
See [`max.graph.ops.gather_nd()`](../graph/ops.md#max.graph.ops.gather_nd) for details.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* input (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])
* indices (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])
* batch\_dims ([int](https://docs.python.org/3/library/functions.html#int))

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](../graph/TensorValue.md#max.graph.TensorValue)

</dd></dl>

## `gelu()` {#max.experimental.functional.gelu}

> max.experimental.functional.gelu(x, approximate='none')

Applies the Gaussian Error Linear Unit (GELU) activation.
See [`max.graph.ops.gelu()`](../graph/ops.md#max.graph.ops.gelu) for details.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* x ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue))
* approximate ([str](https://docs.python.org/3/library/stdtypes.html#str))

</dd></dl>

## `greater()` {#max.experimental.functional.greater}

> max.experimental.functional.greater(lhs, rhs)

Computes element-wise greater-than comparison.
See [`max.graph.ops.greater()`](../graph/ops.md#max.graph.ops.greater) for details.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* lhs (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])
* rhs (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](../graph/TensorValue.md#max.graph.TensorValue)

</dd></dl>

## `greater_equal()` {#max.experimental.functional.greater_equal}

> max.experimental.functional.greater\_equal(lhs, rhs)

Computes element-wise greater-than-or-equal comparison.
See [`max.graph.ops.greater_equal()`](../graph/ops.md#max.graph.ops.greater_equal) for details.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* lhs (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])
* rhs (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](../graph/TensorValue.md#max.graph.TensorValue)

</dd></dl>

## `hann_window()` {#max.experimental.functional.hann_window}

> max.experimental.functional.hann\_window(window\_length, device, periodic=True, dtype=float32)

Creates a Hann window.
See [`max.graph.ops.hann_window()`](../graph/ops.md#max.graph.ops.hann_window) for details.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* window\_length ([int](https://docs.python.org/3/library/functions.html#int))
* device ([DeviceRef](../graph/type.md#max.graph.type.DeviceRef))
* periodic ([bool](https://docs.python.org/3/library/functions.html#bool))
* dtype ([DType](../dtype.md#max.dtype.DType))

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](../graph/TensorValue.md#max.graph.TensorValue)

</dd></dl>

## `irfft()` {#max.experimental.functional.irfft}

> max.experimental.functional.irfft(input\_tensor, n=None, axis=-1, normalization=Normalization.BACKWARD, input\_is\_complex=False, buffer\_size\_mb=512)

Computes the inverse real FFT.
See [`max.graph.ops.irfft()`](../graph/ops.md#max.graph.ops.irfft) for details.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* input\_tensor (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue)
* n ([int](https://docs.python.org/3/library/functions.html#int) | None)
* axis ([int](https://docs.python.org/3/library/functions.html#int))
* normalization (Normalization | [str](https://docs.python.org/3/library/stdtypes.html#str))
* input\_is\_complex ([bool](https://docs.python.org/3/library/functions.html#bool))
* buffer\_size\_mb ([int](https://docs.python.org/3/library/functions.html#int))

</dd></dl>

## `is_inf()` {#max.experimental.functional.is_inf}

> max.experimental.functional.is\_inf(x)

Checks for infinite values element-wise.
See [`max.graph.ops.is_inf()`](../graph/ops.md#max.graph.ops.is_inf) for details.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

x (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](../graph/TensorValue.md#max.graph.TensorValue)

</dd></dl>

## `is_nan()` {#max.experimental.functional.is_nan}

> max.experimental.functional.is\_nan(x)

Checks for NaN values element-wise.
See [`max.graph.ops.is_nan()`](../graph/ops.md#max.graph.ops.is_nan) for details.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

x (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](../graph/TensorValue.md#max.graph.TensorValue)

</dd></dl>

## `layer_norm()` {#max.experimental.functional.layer_norm}

> max.experimental.functional.layer\_norm(input, gamma, beta, epsilon)

Applies layer normalization.
See [`max.graph.ops.layer_norm()`](../graph/ops.md#max.graph.ops.layer_norm) for details.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* input ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue))
* gamma (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])
* beta (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])
* epsilon ([float](https://docs.python.org/3/library/functions.html#float))

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](../graph/TensorValue.md#max.graph.TensorValue)

</dd></dl>

## `log()` {#max.experimental.functional.log}

> max.experimental.functional.log(x)

Computes the natural logarithm element-wise.
See [`max.graph.ops.log()`](../graph/ops.md#max.graph.ops.log) for details.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

x (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](../graph/TensorValue.md#max.graph.TensorValue)

</dd></dl>

## `log1p()` {#max.experimental.functional.log1p}

> max.experimental.functional.log1p(x)

Computes log(1 + x) element-wise.
See [`max.graph.ops.log1p()`](../graph/ops.md#max.graph.ops.log1p) for details.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

x (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](../graph/TensorValue.md#max.graph.TensorValue)

</dd></dl>

## `logical_and()` {#max.experimental.functional.logical_and}

> max.experimental.functional.logical\_and(lhs, rhs)

Computes element-wise logical AND.
See [`max.graph.ops.logical_and()`](../graph/ops.md#max.graph.ops.logical_and) for details.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* lhs (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])
* rhs (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](../graph/TensorValue.md#max.graph.TensorValue)

</dd></dl>

## `logical_not()` {#max.experimental.functional.logical_not}

> max.experimental.functional.logical\_not(x)

Computes element-wise logical NOT.
See [`max.graph.ops.logical_not()`](../graph/ops.md#max.graph.ops.logical_not) for details.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

x (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](../graph/TensorValue.md#max.graph.TensorValue)

</dd></dl>

## `logical_or()` {#max.experimental.functional.logical_or}

> max.experimental.functional.logical\_or(lhs, rhs)

Computes element-wise logical OR.
See [`max.graph.ops.logical_or()`](../graph/ops.md#max.graph.ops.logical_or) for details.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* lhs (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])
* rhs (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](../graph/TensorValue.md#max.graph.TensorValue)

</dd></dl>

## `logical_xor()` {#max.experimental.functional.logical_xor}

> max.experimental.functional.logical\_xor(lhs, rhs)

Computes element-wise logical XOR.
See [`max.graph.ops.logical_xor()`](../graph/ops.md#max.graph.ops.logical_xor) for details.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* lhs (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])
* rhs (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](../graph/TensorValue.md#max.graph.TensorValue)

</dd></dl>

## `logsoftmax()` {#max.experimental.functional.logsoftmax}

> max.experimental.functional.logsoftmax(x)

Applies the log softmax function.
See [`max.graph.ops.logsoftmax()`](../graph/ops.md#max.graph.ops.logsoftmax) for details.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

x (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](../graph/TensorValue.md#max.graph.TensorValue)

</dd></dl>

## `masked_scatter()` {#max.experimental.functional.masked_scatter}

> max.experimental.functional.masked\_scatter(input, mask, updates, out\_dim)

Scatters values according to a mask.
See [`max.graph.ops.masked_scatter()`](../graph/ops.md#max.graph.ops.masked_scatter) for details.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* input (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])
* mask (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])
* updates (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])
* out\_dim ([int](https://docs.python.org/3/library/functions.html#int) | [str](https://docs.python.org/3/library/stdtypes.html#str) | [Dim](../graph/dim.md#max.graph.dim.Dim) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)])

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](../graph/TensorValue.md#max.graph.TensorValue)

</dd></dl>

## `matmul()` {#max.experimental.functional.matmul}

> max.experimental.functional.matmul(lhs, rhs)

Performs matrix multiplication.
See [`max.graph.ops.matmul()`](../graph/ops.md#max.graph.ops.matmul) for details.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* lhs (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])
* rhs (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](../graph/TensorValue.md#max.graph.TensorValue)

</dd></dl>

## `max()` {#max.experimental.functional.max}

> max.experimental.functional.max(x, y=None, /, axis=None)

Returns the maximum values along an axis.
See [`max.graph.ops.max()`](../graph/ops.md#max.graph.ops.max) for details.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* x (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])
* y (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]] | None)
* axis ([int](https://docs.python.org/3/library/functions.html#int) | None)

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](../graph/TensorValue.md#max.graph.TensorValue)

</dd></dl>

## `max_pool2d()` {#max.experimental.functional.max_pool2d}

> max.experimental.functional.max\_pool2d(input, kernel\_size, stride=1, dilation=1, padding=0, ceil\_mode=False)

Applies 2D max pooling.
See [`max.graph.ops.max_pool2d()`](../graph/ops.md#max.graph.ops.max_pool2d) for details.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* input (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])
* kernel\_size ([tuple](https://docs.python.org/3/library/stdtypes.html#tuple)\[[int](https://docs.python.org/3/library/functions.html#int) | [str](https://docs.python.org/3/library/stdtypes.html#str) | [Dim](../graph/dim.md#max.graph.dim.Dim) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)], [int](https://docs.python.org/3/library/functions.html#int) | [str](https://docs.python.org/3/library/stdtypes.html#str) | [Dim](../graph/dim.md#max.graph.dim.Dim) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]])
* stride ([int](https://docs.python.org/3/library/functions.html#int) | [tuple](https://docs.python.org/3/library/stdtypes.html#tuple)\[[int](https://docs.python.org/3/library/functions.html#int), [int](https://docs.python.org/3/library/functions.html#int)])
* dilation ([int](https://docs.python.org/3/library/functions.html#int) | [tuple](https://docs.python.org/3/library/stdtypes.html#tuple)\[[int](https://docs.python.org/3/library/functions.html#int), [int](https://docs.python.org/3/library/functions.html#int)])
* padding ([int](https://docs.python.org/3/library/functions.html#int) | [tuple](https://docs.python.org/3/library/stdtypes.html#tuple)\[[int](https://docs.python.org/3/library/functions.html#int), [int](https://docs.python.org/3/library/functions.html#int)])
* ceil\_mode ([bool](https://docs.python.org/3/library/functions.html#bool))

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](../graph/TensorValue.md#max.graph.TensorValue)

</dd></dl>

## `mean()` {#max.experimental.functional.mean}

> max.experimental.functional.mean(x, axis=-1)

Computes the mean along specified axes.
See [`max.graph.ops.mean()`](../graph/ops.md#max.graph.ops.mean) for details.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* x (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])
* axis ([int](https://docs.python.org/3/library/functions.html#int))

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](../graph/TensorValue.md#max.graph.TensorValue)

</dd></dl>

## `min()` {#max.experimental.functional.min}

> max.experimental.functional.min(x, y=None, /, axis=None)

Returns the minimum values along an axis.
See [`max.graph.ops.min()`](../graph/ops.md#max.graph.ops.min) for details.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* x (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])
* y (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]] | None)
* axis ([int](https://docs.python.org/3/library/functions.html#int) | None)

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](../graph/TensorValue.md#max.graph.TensorValue)

</dd></dl>

## `mod()` {#max.experimental.functional.mod}

> max.experimental.functional.mod(lhs, rhs)

Computes the modulo operation element-wise.
See [`max.graph.ops.mod()`](../graph/ops.md#max.graph.ops.mod) for details.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* lhs (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])
* rhs (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](../graph/TensorValue.md#max.graph.TensorValue)

</dd></dl>

## `mul()` {#max.experimental.functional.mul}

> max.experimental.functional.mul(lhs, rhs)

Multiplies two tensors element-wise.
See [`max.graph.ops.mul()`](../graph/ops.md#max.graph.ops.mul) for details.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* lhs (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])
* rhs (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](../graph/TensorValue.md#max.graph.TensorValue)

</dd></dl>

## `negate()` {#max.experimental.functional.negate}

> max.experimental.functional.negate(x)

Negates a tensor element-wise.
See [`max.graph.ops.negate()`](../graph/ops.md#max.graph.ops.negate) for details.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

x (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](../graph/TensorValue.md#max.graph.TensorValue)

</dd></dl>

## `nonzero()` {#max.experimental.functional.nonzero}

> max.experimental.functional.nonzero(x, out\_dim)

Returns the indices of non-zero elements.
See [`max.graph.ops.nonzero()`](../graph/ops.md#max.graph.ops.nonzero) for details.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* x (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])
* out\_dim ([int](https://docs.python.org/3/library/functions.html#int) | [str](https://docs.python.org/3/library/stdtypes.html#str) | [Dim](../graph/dim.md#max.graph.dim.Dim) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)])

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](../graph/TensorValue.md#max.graph.TensorValue)

</dd></dl>

## `not_equal()` {#max.experimental.functional.not_equal}

> max.experimental.functional.not\_equal(lhs, rhs)

Computes element-wise inequality comparison.
See [`max.graph.ops.not_equal()`](../graph/ops.md#max.graph.ops.not_equal) for details.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* lhs (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])
* rhs (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](../graph/TensorValue.md#max.graph.TensorValue)

</dd></dl>

## `outer()` {#max.experimental.functional.outer}

> max.experimental.functional.outer(lhs, rhs)

Computes the outer product of two vectors.
See [`max.graph.ops.outer()`](../graph/ops.md#max.graph.ops.outer) for details.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* lhs (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])
* rhs (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](../graph/TensorValue.md#max.graph.TensorValue)

</dd></dl>

## `pad()` {#max.experimental.functional.pad}

> max.experimental.functional.pad(input, paddings, mode='constant', value=0)

Pads a tensor.
See [`max.graph.ops.pad()`](../graph/ops.md#max.graph.ops.pad) for details.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* input (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])
* paddings ([Iterable](https://docs.python.org/3/library/collections.abc.html#collections.abc.Iterable)\[[int](https://docs.python.org/3/library/functions.html#int)])
* mode ([Literal](https://docs.python.org/3/library/typing.html#typing.Literal)\['constant'])
* value (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](../graph/TensorValue.md#max.graph.TensorValue)

</dd></dl>

## `permute()` {#max.experimental.functional.permute}

> max.experimental.functional.permute(x, dims)

Permutes the dimensions of a tensor.
See [`max.graph.ops.permute()`](../graph/ops.md#max.graph.ops.permute) for details.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* x (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])
* dims ([list](https://docs.python.org/3/library/stdtypes.html#list)\[[int](https://docs.python.org/3/library/functions.html#int)])

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](../graph/TensorValue.md#max.graph.TensorValue)

</dd></dl>

## `pow()` {#max.experimental.functional.pow}

> max.experimental.functional.pow(lhs, rhs)

Raises tensor elements to a power.
See [`max.graph.ops.pow()`](../graph/ops.md#max.graph.ops.pow) for details.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* lhs (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])
* rhs (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](../graph/TensorValue.md#max.graph.TensorValue)

</dd></dl>

## `range()` {#max.experimental.functional.range}

> max.experimental.functional.range(start, stop, step=1, out\_dim=None, \*, dtype, device)

Creates a tensor with evenly spaced values.
See [`max.graph.ops.range()`](../graph/ops.md#max.graph.ops.range) for details.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* start (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])
* stop (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])
* step (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])
* out\_dim ([int](https://docs.python.org/3/library/functions.html#int) | [str](https://docs.python.org/3/library/stdtypes.html#str) | [Dim](../graph/dim.md#max.graph.dim.Dim) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | None)
* dtype ([DType](../dtype.md#max.dtype.DType))
* device ([Device](../driver.md#max.driver.Device) | [DeviceRef](../graph/type.md#max.graph.type.DeviceRef))

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](../graph/TensorValue.md#max.graph.TensorValue)

</dd></dl>

## `relu()` {#max.experimental.functional.relu}

> max.experimental.functional.relu(x)

Applies the ReLU activation function.
See [`max.graph.ops.relu()`](../graph/ops.md#max.graph.ops.relu) for details.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

x (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](../graph/TensorValue.md#max.graph.TensorValue)

</dd></dl>

## `repeat_interleave()` {#max.experimental.functional.repeat_interleave}

> max.experimental.functional.repeat\_interleave(x, repeats, axis=None, out\_dim=None)

Repeats elements of a tensor.
See [`max.graph.ops.repeat_interleave()`](../graph/ops.md#max.graph.ops.repeat_interleave) for details.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* x (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])
* repeats ([int](https://docs.python.org/3/library/functions.html#int) | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue))
* axis ([int](https://docs.python.org/3/library/functions.html#int) | None)
* out\_dim ([int](https://docs.python.org/3/library/functions.html#int) | [str](https://docs.python.org/3/library/stdtypes.html#str) | [Dim](../graph/dim.md#max.graph.dim.Dim) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | None)

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](../graph/TensorValue.md#max.graph.TensorValue)

</dd></dl>

## `reshape()` {#max.experimental.functional.reshape}

> max.experimental.functional.reshape(x, shape)

Reshapes a tensor to a new shape.
See [`max.graph.ops.reshape()`](../graph/ops.md#max.graph.ops.reshape) for details.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* x (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])
* shape ([Iterable](https://docs.python.org/3/library/collections.abc.html#collections.abc.Iterable)\[[int](https://docs.python.org/3/library/functions.html#int) | [str](https://docs.python.org/3/library/stdtypes.html#str) | [Dim](../graph/dim.md#max.graph.dim.Dim) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]])

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](../graph/TensorValue.md#max.graph.TensorValue)

</dd></dl>

## `round()` {#max.experimental.functional.round}

> max.experimental.functional.round(x)

Rounds tensor values element-wise.
See [`max.graph.ops.round()`](../graph/ops.md#max.graph.ops.round) for details.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

x (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](../graph/TensorValue.md#max.graph.TensorValue)

</dd></dl>

## `rsqrt()` {#max.experimental.functional.rsqrt}

> max.experimental.functional.rsqrt(x)

Computes the reciprocal square root element-wise.
See [`max.graph.ops.rsqrt()`](../graph/ops.md#max.graph.ops.rsqrt) for details.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

x (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](../graph/TensorValue.md#max.graph.TensorValue)

</dd></dl>

## `scatter()` {#max.experimental.functional.scatter}

> max.experimental.functional.scatter(input, updates, indices, axis=-1)

Scatters values along an axis.
See [`max.graph.ops.scatter()`](../graph/ops.md#max.graph.ops.scatter) for details.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* input (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])
* updates (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])
* indices (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])
* axis ([int](https://docs.python.org/3/library/functions.html#int))

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](../graph/TensorValue.md#max.graph.TensorValue)

</dd></dl>

## `scatter_nd()` {#max.experimental.functional.scatter_nd}

> max.experimental.functional.scatter\_nd(input, updates, indices)

Scatters values using multi-dimensional indices.
See [`max.graph.ops.scatter_nd()`](../graph/ops.md#max.graph.ops.scatter_nd) for details.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* input (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])
* updates (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])
* indices (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](../graph/TensorValue.md#max.graph.TensorValue)

</dd></dl>

## `sigmoid()` {#max.experimental.functional.sigmoid}

> max.experimental.functional.sigmoid(x)

Applies the sigmoid activation function.
See [`max.graph.ops.sigmoid()`](../graph/ops.md#max.graph.ops.sigmoid) for details.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

x (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](../graph/TensorValue.md#max.graph.TensorValue)

</dd></dl>

## `silu()` {#max.experimental.functional.silu}

> max.experimental.functional.silu(x)

Applies the SiLU (Swish) activation function.
See [`max.graph.ops.silu()`](../graph/ops.md#max.graph.ops.silu) for details.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

x ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue))

</dd></dl>

## `sin()` {#max.experimental.functional.sin}

> max.experimental.functional.sin(x)

Computes the sine element-wise.
See [`max.graph.ops.sin()`](../graph/ops.md#max.graph.ops.sin) for details.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

x (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](../graph/TensorValue.md#max.graph.TensorValue)

</dd></dl>

## `slice_tensor()` {#max.experimental.functional.slice_tensor}

> max.experimental.functional.slice\_tensor(x, indices)

Slices a tensor along specified dimensions.
See [`max.graph.ops.slice_tensor()`](../graph/ops.md#max.graph.ops.slice_tensor) for details.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* x ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue))
* indices (SliceIndices)

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](../graph/TensorValue.md#max.graph.TensorValue)

</dd></dl>

## `softmax()` {#max.experimental.functional.softmax}

> max.experimental.functional.softmax(x)

Applies the softmax function.
See [`max.graph.ops.softmax()`](../graph/ops.md#max.graph.ops.softmax) for details.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

x (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](../graph/TensorValue.md#max.graph.TensorValue)

</dd></dl>

## `split()` {#max.experimental.functional.split}

> max.experimental.functional.split(x, split\_sizes, axis=0)

Splits a tensor into multiple tensors.
See [`max.graph.ops.split()`](../graph/ops.md#max.graph.ops.split) for details.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* x (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])
* split\_sizes ([Sequence](https://docs.python.org/3/library/collections.abc.html#collections.abc.Sequence)\[[int](https://docs.python.org/3/library/functions.html#int) | [str](https://docs.python.org/3/library/stdtypes.html#str) | [Dim](../graph/dim.md#max.graph.dim.Dim) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]])
* axis ([int](https://docs.python.org/3/library/functions.html#int))

</dd><dt>

**Return type:**

</dt><dd>

[list](https://docs.python.org/3/library/stdtypes.html#list)\[[TensorValue](../graph/TensorValue.md#max.graph.TensorValue)]

</dd></dl>

## `sqrt()` {#max.experimental.functional.sqrt}

> max.experimental.functional.sqrt(x)

Computes the square root element-wise.
See [`max.graph.ops.sqrt()`](../graph/ops.md#max.graph.ops.sqrt) for details.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

x (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](../graph/TensorValue.md#max.graph.TensorValue)

</dd></dl>

## `squeeze()` {#max.experimental.functional.squeeze}

> max.experimental.functional.squeeze(x, axis)

Removes dimensions of size 1.
See [`max.graph.ops.squeeze()`](../graph/ops.md#max.graph.ops.squeeze) for details.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* x (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])
* axis ([int](https://docs.python.org/3/library/functions.html#int))

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](../graph/TensorValue.md#max.graph.TensorValue)

</dd></dl>

## `stack()` {#max.experimental.functional.stack}

> max.experimental.functional.stack(values, axis=0)

Stacks tensors along a new dimension.
See [`max.graph.ops.stack()`](../graph/ops.md#max.graph.ops.stack) for details.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* values ([Iterable](https://docs.python.org/3/library/collections.abc.html#collections.abc.Iterable)\[Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]]])
* axis ([int](https://docs.python.org/3/library/functions.html#int))

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](../graph/TensorValue.md#max.graph.TensorValue)

</dd></dl>

## `sub()` {#max.experimental.functional.sub}

> max.experimental.functional.sub(lhs, rhs)

Subtracts two tensors element-wise.
See [`max.graph.ops.sub()`](../graph/ops.md#max.graph.ops.sub) for details.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* lhs (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])
* rhs (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](../graph/TensorValue.md#max.graph.TensorValue)

</dd></dl>

## `sum()` {#max.experimental.functional.sum}

> max.experimental.functional.sum(x, axis=-1)

Computes the sum along specified axes.
See [`max.graph.ops.sum()`](../graph/ops.md#max.graph.ops.sum) for details.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* x (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])
* axis ([int](https://docs.python.org/3/library/functions.html#int))

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](../graph/TensorValue.md#max.graph.TensorValue)

</dd></dl>

## `tanh()` {#max.experimental.functional.tanh}

> max.experimental.functional.tanh(x)

Computes the hyperbolic tangent element-wise.
See [`max.graph.ops.tanh()`](../graph/ops.md#max.graph.ops.tanh) for details.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

x (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](../graph/TensorValue.md#max.graph.TensorValue)

</dd></dl>

## `tile()` {#max.experimental.functional.tile}

> max.experimental.functional.tile(x, repeats)

Tiles a tensor by repeating it.
See [`max.graph.ops.tile()`](../graph/ops.md#max.graph.ops.tile) for details.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* x (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])
* repeats ([Iterable](https://docs.python.org/3/library/collections.abc.html#collections.abc.Iterable)\[[int](https://docs.python.org/3/library/functions.html#int) | [str](https://docs.python.org/3/library/stdtypes.html#str) | [Dim](../graph/dim.md#max.graph.dim.Dim) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]])

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](../graph/TensorValue.md#max.graph.TensorValue)

</dd></dl>

## `top_k()` {#max.experimental.functional.top_k}

> max.experimental.functional.top\_k(input, k, axis=-1)

Returns the k largest elements along an axis.
See [`max.graph.ops.top_k()`](../graph/ops.md#max.graph.ops.top_k) for details.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* input (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])
* k ([int](https://docs.python.org/3/library/functions.html#int))
* axis ([int](https://docs.python.org/3/library/functions.html#int))

</dd><dt>

**Return type:**

</dt><dd>

[tuple](https://docs.python.org/3/library/stdtypes.html#tuple)\[[TensorValue](../graph/TensorValue.md#max.graph.TensorValue), [TensorValue](../graph/TensorValue.md#max.graph.TensorValue)]

</dd></dl>

## `transfer_to()` {#max.experimental.functional.transfer_to}

> max.experimental.functional.transfer\_to(x, device)

Transfers a tensor to a specified device.
See [`max.graph.ops.transfer_to()`](../graph/ops.md#max.graph.ops.transfer_to) for details.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* x (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue)
* device ([Device](../driver.md#max.driver.Device) | [DeviceRef](../graph/type.md#max.graph.type.DeviceRef))

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](../graph/TensorValue.md#max.graph.TensorValue)

</dd></dl>

## `transpose()` {#max.experimental.functional.transpose}

> max.experimental.functional.transpose(x, axis\_1, axis\_2)

Transposes a tensor.
See [`max.graph.ops.transpose()`](../graph/ops.md#max.graph.ops.transpose) for details.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* x (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])
* axis\_1 ([int](https://docs.python.org/3/library/functions.html#int))
* axis\_2 ([int](https://docs.python.org/3/library/functions.html#int))

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](../graph/TensorValue.md#max.graph.TensorValue)

</dd></dl>

## `trunc()` {#max.experimental.functional.trunc}

> max.experimental.functional.trunc(x)

Truncates tensor values element-wise.
See [`max.graph.ops.trunc()`](../graph/ops.md#max.graph.ops.trunc) for details.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

x (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](../graph/TensorValue.md#max.graph.TensorValue)

</dd></dl>

## `unsqueeze()` {#max.experimental.functional.unsqueeze}

> max.experimental.functional.unsqueeze(x, axis)

Adds dimensions of size 1.
See [`max.graph.ops.unsqueeze()`](../graph/ops.md#max.graph.ops.unsqueeze) for details.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* x (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])
* axis ([int](https://docs.python.org/3/library/functions.html#int))

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](../graph/TensorValue.md#max.graph.TensorValue)

</dd></dl>

## `where()` {#max.experimental.functional.where}

> max.experimental.functional.where(condition, x, y)

Selects elements from two tensors based on a condition.
See [`max.graph.ops.where()`](../graph/ops.md#max.graph.ops.where) for details.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* condition (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])
* x (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])
* y (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](../graph/TensorValue.md#max.graph.TensorValue)

</dd></dl>

---

## experimental

#### WARNING

The APIs in this module are experimental and subject to change or removal
in future releases without prior notice. Use with caution in production
environments.

The `max.experimental` package provides experimental APIs for the MAX
platform. These APIs are designed for early adopters who want to explore new
features before they become stable.

Experimental APIs may have:

* Incomplete or changing interfaces.
* Limited documentation or examples.
* Performance characteristics that may change.
* Breaking changes between releases.

---

## random

Provides experimental random tensor generation utilities.

#### WARNING

This module contains experimental APIs that are subject to change or
removal in future versions. Use with caution in production environments.

This module provides functions for generating random tensors with various
distributions. All functions support specifying data type and device,
with sensible defaults based on the target device.

You can generate random tensors using different distributions:

```default
from max.experimental import random
from max.dtype import DType
from max.driver import CPU

tensor1 = random.uniform((2, 3), dtype=DType.float32, device=CPU())

tensor2 = random.uniform((4, 4), range=(0, 1), dtype=DType.float32, device=CPU())
```

## `gaussian()` {#max.experimental.random.gaussian}

> max.experimental.random.gaussian(shape=(), mean=0.0, std=1.0, \*, dtype=None, device=None)

Creates a tensor filled with random values from a Gaussian (normal) distribution.

#### WARNING

This is an experimental API that may change in future versions.

Generates a tensor with values sampled from a normal (Gaussian) distribution
with the specified mean and standard deviation. This is commonly used for
weight initialization using techniques like Xavier/Glorot or He initialization.

Create tensors with random values from a Gaussian distribution:

```default
from max.experimental import random
from max.driver import CPU
from max.dtype import DType

# Standard normal distribution
tensor = random.gaussian((2, 3), dtype=DType.float32, device=CPU())
```

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* shape ([Iterable](https://docs.python.org/3/library/collections.abc.html#collections.abc.Iterable)\[[int](https://docs.python.org/3/library/functions.html#int) | [str](https://docs.python.org/3/library/stdtypes.html#str) | [Dim](../graph/dim.md#max.graph.dim.Dim) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]) â€“ The shape of the output tensor. Defaults to scalar (empty tuple).
* mean ([float](https://docs.python.org/3/library/functions.html#float)) â€“ The mean (center) of the Gaussian distribution. This determines
  where the distribution is centered. Defaults to `0.0`.
* std ([float](https://docs.python.org/3/library/functions.html#float)) â€“ The standard deviation (spread) of the Gaussian distribution.
  Must be positive. Larger values create more spread in the distribution.
  Defaults to `1.0`.
* dtype ([DType](../dtype.md#max.dtype.DType) | None) â€“ The data type of the output tensor. If `None`, uses the
  default dtype for the specified device (float32 for CPU,
  bfloat16 for accelerators). Defaults to `None`.
* device ([Device](../driver.md#max.driver.Device) | None) â€“ The device where the tensor will be allocated. If `None`,
  uses the default device (accelerator if available, otherwise CPU).
  Defaults to `None`.

</dd><dt>

**Returns:**

</dt><dd>

A [`tensor`](tensor.md#module-max.experimental.tensor) with random values sampled from
the Gaussian distribution.

</dd><dt>

**Raises:**

</dt><dd>

[ValueError](https://docs.python.org/3/library/exceptions.html#ValueError) â€“ If std <= 0.

</dd></dl>

## `gaussian_like()` {#max.experimental.random.gaussian_like}

> max.experimental.random.gaussian\_like(like, mean=0, std=1)

Generates random values from a Gaussian (normal) distribution for tensors of a given type.
See `max.graph.ops.random.gaussian()` for details.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* like ([TensorType](../graph/type.md#max.graph.type.TensorType))
* mean (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])
* std (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](../graph/TensorValue.md#max.graph.TensorValue)

</dd></dl>

## `normal()` {#max.experimental.random.normal}

> max.experimental.random.normal(shape=(), mean=0.0, std=1.0, \*, dtype=None, device=None)

Alias for [`gaussian()`](#max.experimental.random.gaussian).
Creates a tensor with values from a normal (Gaussian) distribution.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* shape ([Iterable](https://docs.python.org/3/library/collections.abc.html#collections.abc.Iterable)\[[int](https://docs.python.org/3/library/functions.html#int) | [str](https://docs.python.org/3/library/stdtypes.html#str) | [Dim](../graph/dim.md#max.graph.dim.Dim) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]])
* mean ([float](https://docs.python.org/3/library/functions.html#float))
* std ([float](https://docs.python.org/3/library/functions.html#float))
* dtype ([DType](../dtype.md#max.dtype.DType) | None)
* device ([Device](../driver.md#max.driver.Device) | None)

</dd></dl>

## `normal_like()` {#max.experimental.random.normal_like}

> max.experimental.random.normal\_like(like, mean=0, std=1)

Alias for [`gaussian_like()`](#max.experimental.random.gaussian_like).

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* like ([TensorType](../graph/type.md#max.graph.type.TensorType))
* mean (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])
* std (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](../graph/TensorValue.md#max.graph.TensorValue)

</dd></dl>

## `uniform()` {#max.experimental.random.uniform}

> max.experimental.random.uniform(shape=(), range=(0, 1), \*, dtype=None, device=None)

Creates a tensor filled with random values from a uniform distribution.

#### WARNING

This is an experimental API that may change in future versions.

Generates a tensor with values uniformly distributed between the specified
minimum and maximum bounds. This is useful for initializing weights,
generating random inputs, or creating noise.

Create tensors with uniform random values:

```default
from max.experimental import random
from max.dtype import DType
from max.driver import CPU

# Generate 2x3 tensor with values between 0 and 1
tensor1 = random.uniform((2, 3), dtype=DType.float32, device=CPU())

tensor2 = random.uniform((4, 4), range=(0, 1), dtype=DType.float32, device=CPU())
```

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* shape ([Iterable](https://docs.python.org/3/library/collections.abc.html#collections.abc.Iterable)\[[int](https://docs.python.org/3/library/functions.html#int) | [str](https://docs.python.org/3/library/stdtypes.html#str) | [Dim](../graph/dim.md#max.graph.dim.Dim) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]) â€“ The shape of the output tensor. Defaults to scalar (empty tuple).
* range ([tuple](https://docs.python.org/3/library/stdtypes.html#tuple)\[[float](https://docs.python.org/3/library/functions.html#float), [float](https://docs.python.org/3/library/functions.html#float)]) â€“ A tuple specifying the (min, max) bounds of the uniform
  distribution. The minimum value is inclusive, the maximum value
  is exclusive. Defaults to `(0, 1)`.
* dtype ([DType](../dtype.md#max.dtype.DType) | None) â€“ The data type of the output tensor. If `None`, uses the
  default dtype for the specified device (float32 for CPU,
  bfloat16 for accelerators). Defaults to `None`.
* device ([Device](../driver.md#max.driver.Device) | None) â€“ The device where the tensor will be allocated. If `None`,
  uses the default device (accelerator if available, otherwise CPU).
  Defaults to `None`.

</dd><dt>

**Returns:**

</dt><dd>

A [`tensor`](tensor.md#module-max.experimental.tensor) with random values sampled from
the uniform distribution.

</dd><dt>

**Raises:**

</dt><dd>

[ValueError](https://docs.python.org/3/library/exceptions.html#ValueError) â€“ If the range tuple does not contain exactly two values
or if min >= max.

</dd></dl>

## `uniform_like()` {#max.experimental.random.uniform_like}

> max.experimental.random.uniform\_like(like, range=(0, 1))

Generates random values from a uniform distribution for tensors of a given type.
See `max.graph.ops.random.uniform()` for details.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* like ([TensorType](../graph/type.md#max.graph.type.TensorType))
* range ([tuple](https://docs.python.org/3/library/stdtypes.html#tuple)\[Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]], Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]]])

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](../graph/TensorValue.md#max.graph.TensorValue)

</dd></dl>

---

## tensor

Provides experimental tensor operations with eager execution capabilities.

#### WARNING

This module contains experimental APIs that are subject to change or
removal in future versions. Use with caution in production environments.

This module provides the [`tensor`](#module-max.experimental.tensor) class which supports
eager execution of tensor operations, complementing the graph-based execution
model provided by `graph`. The tensor operations automatically compile
and execute using the MAX runtime.

**Key Features:**

* **Eager execution**: Operations execute immediately rather than building a graph.
* **Automatic compilation**: Tensors are compiled and optimized automatically.
* **Lazy evaluation**: Tensors may be computed lazily until their values are needed.
* **NumPy compatibility**: Supports common NumPy-like operations and indexing.

Create and manipulate tensors with automatic compilation and optimization:

```default
from max.experimental import tensor
from max.driver import CPU
from max.dtype import DType
x = tensor.Tensor.ones((2, 3), dtype=DType.float32, device=CPU())
y = tensor.Tensor.zeros((2, 3), dtype=DType.float32, device=CPU())
result = x + y  # Eager execution with automatic compilation
```

## `ComputeGraph` {#max.experimental.tensor.ComputeGraph}

> class max.experimental.tensor.ComputeGraph(context=None, sources=(), seed=0)

Compute graph storage for unrealized tensors.

The compute graph is a directed acyclic graph.

There is a single global compute graph we use for Tensor operations.
New tensors are added as nodes to this graph by tensor operations.
Once they are realized the graph is simplified and the newly realized
tensors become sources of the graph.

Terminology:

* A â€œsourceâ€ of the graph is a realized tensor that some unrealized
  tensor depends on.
* â€œunrealizedâ€ refers to a node in the graph which is not a source,
  or to the tensor object that it backs. There is a 1:1 relationship
  between the node and the tensor object.

It is not obvious a priori which unrealized nodes to evaluate at
what time. The evaluate method of the graph is at its heart a
heuristic choosing among various tradeoffs of what to compute.

The current implementation first prunes the graph of all dead
nodes (nodes which no longer have live python references to them)
and then realizes all remaining nodes. This is an implementation
detail and is subject to change.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* context (mlir.Context | None)
* sources ([dict](https://docs.python.org/3/library/stdtypes.html#dict)\[Value\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)], [Tensor](#max.experimental.tensor.Tensor)])
* seed ([int](https://docs.python.org/3/library/functions.html#int))

</dd></dl>

### `add_source()` {#max.experimental.tensor.ComputeGraph.add_source}

> add\_source(tensor)

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

tensor ([Tensor](#max.experimental.tensor.Tensor))

</dd><dt>

**Return type:**

</dt><dd>

None

</dd></dl>

### `evaluate()` {#max.experimental.tensor.ComputeGraph.evaluate}

> async evaluate(tensor)

Realize the input tensor object.

It is currently undefined to operate on tensors during evaluation.

After execution:

* The compute graph object and all tensors realized or otherwise
  will be in valid states.
* The input tensor is guaranteed to be realized.
* Some other previously unrealized tensors may be realized
* Any realized tensors with live references will not be unrealized.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

tensor ([Tensor](#max.experimental.tensor.Tensor))

</dd><dt>

**Return type:**

</dt><dd>

None

</dd></dl>

### `graph` {#max.experimental.tensor.ComputeGraph.graph}

> graph: [Graph](../graph/Graph.md#max.graph.Graph)

### `sources` {#max.experimental.tensor.ComputeGraph.sources}

> sources: [dict](https://docs.python.org/3/library/stdtypes.html#dict)\[Value\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)], [Tensor](#max.experimental.tensor.Tensor)]

Keeps a strong reference to tensor data that we need to compute graph values

### `unrealized` {#max.experimental.tensor.ComputeGraph.unrealized}

> unrealized: WeakSet\[[Tensor](#max.experimental.tensor.Tensor)]

Keeps weak references to intermediate unrealized tensor values, which may
never need to be realized.

## `Tensor` {#max.experimental.tensor.Tensor}

> class max.experimental.tensor.Tensor(\*, storage=None, value=None)

A Tensor object with numerics.

A Tensor type that can do the kinds of things people expect
tensors to do.

Tensor operations should always meet the following criteria:

* Any illegal operation on a tensor must fail immediately with
  a python exception with a clear error message
* All operations on tensors that read or write Tensor memory
  values use our high-performance compiler and Mojo kernel library.

The out of the box experience should be the best one available
for working with Tensors and numerics, and give seemless access
to direct low-level programmability in Mojo.

Notably Tensor does not require that it is backed by memory.
If no side-effecting operation has been done on a Tensor object,
then there is no guarantee it has been computed yet. Critically
a user should never know or care whether the tensor is backed
by data: the behavior should be exactly as if it were.

For discussion purposes, a â€œrealizedâ€ tensor is a tensor which
references concrete memory, and an â€œunrealizedâ€ one does not.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* storage ([driver.Tensor](../driver.md#max.driver.Tensor) | None)
* value ([graph.TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | None)

</dd></dl>

### `T` {#max.experimental.tensor.Tensor.T}

> property T: [Tensor](#max.experimental.tensor.Tensor)

### `arange()` {#max.experimental.tensor.Tensor.arange}

> classmethod arange(start=0, stop=None, step=1, \*, dtype=None, device=None)

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* start ([int](https://docs.python.org/3/library/functions.html#int))
* stop ([int](https://docs.python.org/3/library/functions.html#int) | None)
* step ([int](https://docs.python.org/3/library/functions.html#int))
* dtype ([DType](../dtype.md#max.dtype.DType) | None)
* device ([Device](../driver.md#max.driver.Device) | None)

</dd><dt>

**Return type:**

</dt><dd>

[Tensor](#max.experimental.tensor.Tensor)

</dd></dl>

### `argmax()` {#max.experimental.tensor.Tensor.argmax}

> argmax()

<dl class='field-list'><dt>

**Return type:**

</dt><dd>

[Tensor](#max.experimental.tensor.Tensor)

</dd></dl>

### `cast()` {#max.experimental.tensor.Tensor.cast}

> cast(dtype)

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

dtype ([DType](../dtype.md#max.dtype.DType))

</dd><dt>

**Return type:**

</dt><dd>

[Tensor](#max.experimental.tensor.Tensor)

</dd></dl>

### `constant()` {#max.experimental.tensor.Tensor.constant}

> classmethod constant(value, \*, dtype=None, device=None)

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* value ([ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]] | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [Sequence](https://docs.python.org/3/library/collections.abc.html#collections.abc.Sequence)\[[int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float)])
* dtype ([DType](../dtype.md#max.dtype.DType) | None)
* device ([Device](../driver.md#max.driver.Device) | None)

</dd><dt>

**Return type:**

</dt><dd>

[Tensor](#max.experimental.tensor.Tensor)

</dd></dl>

### `device` {#max.experimental.tensor.Tensor.device}

> property device: [Device](../driver.md#max.driver.Device)

The tensorâ€™s device.

### `driver_tensor` {#max.experimental.tensor.Tensor.driver_tensor}

> property driver\_tensor: [Tensor](../driver.md#max.driver.Tensor)

A pointer to the underlying memory.

Raises if the tensor is unrealized.

### `dtype` {#max.experimental.tensor.Tensor.dtype}

> property dtype: [DType](../dtype.md#max.dtype.DType)

### `from_dlpack()` {#max.experimental.tensor.Tensor.from_dlpack}

> classmethod from\_dlpack(array)

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

array ([DLPackArray](../driver.md#max.driver.DLPackArray))

</dd><dt>

**Return type:**

</dt><dd>

[Tensor](#max.experimental.tensor.Tensor)

</dd></dl>

### `from_tensor_value()` {#max.experimental.tensor.Tensor.from_tensor_value}

> classmethod from\_tensor\_value(value)

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

value ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue))

</dd><dt>

**Return type:**

</dt><dd>

[Tensor](#max.experimental.tensor.Tensor)

</dd></dl>

### `full()` {#max.experimental.tensor.Tensor.full}

> classmethod full(shape, value, \*, dtype=None, device=None)

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* shape ([Iterable](https://docs.python.org/3/library/collections.abc.html#collections.abc.Iterable)\[[int](https://docs.python.org/3/library/functions.html#int) | [str](https://docs.python.org/3/library/stdtypes.html#str) | [Dim](../graph/dim.md#max.graph.dim.Dim) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]])
* value ([int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float))
* dtype ([DType](../dtype.md#max.dtype.DType) | None)
* device ([Device](../driver.md#max.driver.Device) | None)

</dd><dt>

**Return type:**

</dt><dd>

[Tensor](#max.experimental.tensor.Tensor)

</dd></dl>

### `full_like()` {#max.experimental.tensor.Tensor.full_like}

> classmethod full\_like(type, value)

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* type ([TensorType](../graph/type.md#max.graph.type.TensorType))
* value ([int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float))

</dd><dt>

**Return type:**

</dt><dd>

[Tensor](#max.experimental.tensor.Tensor)

</dd></dl>

### `item()` {#max.experimental.tensor.Tensor.item}

> item()

### `max()` {#max.experimental.tensor.Tensor.max}

> max()

<dl class='field-list'><dt>

**Return type:**

</dt><dd>

[Tensor](#max.experimental.tensor.Tensor)

</dd></dl>

### `num_elements()` {#max.experimental.tensor.Tensor.num_elements}

> num\_elements()

<dl class='field-list'><dt>

**Return type:**

</dt><dd>

[int](https://docs.python.org/3/library/functions.html#int)

</dd></dl>

### `ones()` {#max.experimental.tensor.Tensor.ones}

> classmethod ones(shape, \*, dtype=None, device=None)

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* shape ([Iterable](https://docs.python.org/3/library/collections.abc.html#collections.abc.Iterable)\[[int](https://docs.python.org/3/library/functions.html#int) | [str](https://docs.python.org/3/library/stdtypes.html#str) | [Dim](../graph/dim.md#max.graph.dim.Dim) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]])
* dtype ([DType](../dtype.md#max.dtype.DType) | None)
* device ([Device](../driver.md#max.driver.Device) | None)

</dd><dt>

**Return type:**

</dt><dd>

[Tensor](#max.experimental.tensor.Tensor)

</dd></dl>

### `ones_like()` {#max.experimental.tensor.Tensor.ones_like}

> classmethod ones\_like(type)

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

type ([TensorType](../graph/type.md#max.graph.type.TensorType))

</dd><dt>

**Return type:**

</dt><dd>

[Tensor](#max.experimental.tensor.Tensor)

</dd></dl>

### `permute()` {#max.experimental.tensor.Tensor.permute}

> permute(dims)

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

dims ([list](https://docs.python.org/3/library/stdtypes.html#list)\[[int](https://docs.python.org/3/library/functions.html#int)])

</dd><dt>

**Return type:**

</dt><dd>

[Tensor](#max.experimental.tensor.Tensor)

</dd></dl>

### `rank` {#max.experimental.tensor.Tensor.rank}

> property rank: [int](https://docs.python.org/3/library/functions.html#int)

### `real` {#max.experimental.tensor.Tensor.real}

> property real: [bool](https://docs.python.org/3/library/functions.html#bool)

Whether the tensor is realized or not.

### `realize` {#max.experimental.tensor.Tensor.realize}

> property realize

Force the tensor to realize if it is not already.

### `reshape()` {#max.experimental.tensor.Tensor.reshape}

> reshape(shape)

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

shape ([Iterable](https://docs.python.org/3/library/collections.abc.html#collections.abc.Iterable)\[[int](https://docs.python.org/3/library/functions.html#int) | [str](https://docs.python.org/3/library/stdtypes.html#str) | [Dim](../graph/dim.md#max.graph.dim.Dim) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]])

</dd><dt>

**Return type:**

</dt><dd>

[Tensor](#max.experimental.tensor.Tensor)

</dd></dl>

### `shape` {#max.experimental.tensor.Tensor.shape}

> property shape: [Shape](../graph/shape.md#max.graph.shape.Shape)

### `to()` {#max.experimental.tensor.Tensor.to}

> to(device)

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

device ([Device](../driver.md#max.driver.Device))

</dd><dt>

**Return type:**

</dt><dd>

[Tensor](#max.experimental.tensor.Tensor)

</dd></dl>

### `transpose()` {#max.experimental.tensor.Tensor.transpose}

> transpose(dim1, dim2)

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* dim1 ([int](https://docs.python.org/3/library/functions.html#int))
* dim2 ([int](https://docs.python.org/3/library/functions.html#int))

</dd><dt>

**Return type:**

</dt><dd>

[Tensor](#max.experimental.tensor.Tensor)

</dd></dl>

### `type` {#max.experimental.tensor.Tensor.type}

> property type: [TensorType](../graph/type.md#max.graph.type.TensorType)

### `zeros()` {#max.experimental.tensor.Tensor.zeros}

> classmethod zeros(shape, \*, dtype=None, device=None)

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* shape ([Iterable](https://docs.python.org/3/library/collections.abc.html#collections.abc.Iterable)\[[int](https://docs.python.org/3/library/functions.html#int) | [str](https://docs.python.org/3/library/stdtypes.html#str) | [Dim](../graph/dim.md#max.graph.dim.Dim) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]])
* dtype ([DType](../dtype.md#max.dtype.DType) | None)
* device ([Device](../driver.md#max.driver.Device) | None)

</dd><dt>

**Return type:**

</dt><dd>

[Tensor](#max.experimental.tensor.Tensor)

</dd></dl>

### `zeros_like()` {#max.experimental.tensor.Tensor.zeros_like}

> classmethod zeros\_like(type)

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

type ([TensorType](../graph/type.md#max.graph.type.TensorType))

</dd><dt>

**Return type:**

</dt><dd>

[Tensor](#max.experimental.tensor.Tensor)

</dd></dl>

## `contextvar_context()` {#max.experimental.tensor.contextvar_context}

> max.experimental.tensor.contextvar\_context(var, value)

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* var (ContextVar\[T])
* value (T)

</dd></dl>

## `default_device()` {#max.experimental.tensor.default_device}

> max.experimental.tensor.default\_device(device)

Context manager for setting the default device for tensors.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

device ([Device](../driver.md#max.driver.Device))

</dd></dl>

## `default_dtype()` {#max.experimental.tensor.default_dtype}

> max.experimental.tensor.default\_dtype(dtype)

Context manager for setting the default dtype for tensors.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

dtype ([DType](../dtype.md#max.dtype.DType))

</dd></dl>

## `defaults()` {#max.experimental.tensor.defaults}

> max.experimental.tensor.defaults(dtype=None, device=None)

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* dtype ([DType](../dtype.md#max.dtype.DType) | None)
* device ([Device](../driver.md#max.driver.Device) | None)

</dd><dt>

**Return type:**

</dt><dd>

[tuple](https://docs.python.org/3/library/stdtypes.html#tuple)\[[DType](../dtype.md#max.dtype.DType), [Device](../driver.md#max.driver.Device)]

</dd></dl>

## `driver_tensor_type()` {#max.experimental.tensor.driver_tensor_type}

> max.experimental.tensor.driver\_tensor\_type(t)

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

t ([Tensor](../driver.md#max.driver.Tensor))

</dd><dt>

**Return type:**

</dt><dd>

[TensorType](../graph/type.md#max.graph.type.TensorType)

</dd></dl>

---

## BufferValue

## `BufferValue` {#max.graph.BufferValue}

> class max.graph.BufferValue(value)

Bases: [`Value`](Value.md#max.graph.Value)\[`BufferType`]

Represents a mutable semantic tensor within a Graph.

Initializes a [`BufferValue`](#max.graph.BufferValue) from another value.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

value ([Value](Value.md#max.graph.Value)\[Any] | \_Value\[mo.BufferType]) â€“ The value to wrap, either an MLIR value of buffer type or another [`BufferValue`](#max.graph.BufferValue).

</dd></dl>

### `device` {#max.graph.BufferValue.device}

> property device: [DeviceRef](type.md#max.graph.type.DeviceRef)

Returns the device of the BufferValue.

### `dtype` {#max.graph.BufferValue.dtype}

> property dtype: [DType](../dtype.md#max.dtype.DType)

Returns the tensor data type.

### `from_mlir()` {#max.graph.BufferValue.from_mlir}

> classmethod from\_mlir(value)

Creates a [`BufferValue`](#max.graph.BufferValue) from an MLIR buffer value.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

value (Value\[BufferType]) â€“ The MLIR buffer value to wrap.

</dd><dt>

**Return type:**

</dt><dd>

[BufferValue](#max.graph.BufferValue)

</dd></dl>

### `print()` {#max.graph.BufferValue.print}

> print(label='debug\_buffer')

Prints detailed information about the buffer.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

label ([str](https://docs.python.org/3/library/stdtypes.html#str))

</dd><dt>

**Return type:**

</dt><dd>

None

</dd></dl>

### `rank` {#max.graph.BufferValue.rank}

> property rank: [int](https://docs.python.org/3/library/functions.html#int)

Returns the rank (number of dims) of the buffer.

### `shape` {#max.graph.BufferValue.shape}

> property shape: [Shape](shape.md#max.graph.shape.Shape)

Returns the shape of the BufferValue.

### `type` {#max.graph.BufferValue.type}

> property type: [BufferType](type.md#max.graph.type.BufferType)

Returns the type of the [`BufferValue`](#max.graph.BufferValue) as a `BufferType`.

---

## Graph

## `Graph` {#max.graph.Graph}

> class max.graph.Graph(name, forward=None, input\_types=(), path=None, \*args, custom\_extensions=\[], context=None, kernel\_library=None, module=None, \*\*kwargs)

Represents a single MAX graph.

A Graph is a callable routine in MAX Engine. Like functions, graphs have a
name and signature. Unlike a function, which follows an imperative
programming model, a Graph follows a dataflow programming model, using
lazily-executed, parallel operations instead of sequential instructions.

When you instantiate a graph, you must specify the input shapes as one or
more `TensorType` values. Then, build a sequence of ops and set the
graph output with [`output()`](#max.graph.Graph.output). For example:

```python
from dataclasses import dataclass

import numpy as np
from max.dtype import DType
from max.graph import Graph, TensorType, TensorValue, ops

@dataclass
class Linear:
    weight: np.ndarray
    bias: np.ndarray

    def __call__(self, x: TensorValue) -> TensorValue:
        weight_tensor = ops.constant(self.weight, dtype=DType.float32, device=DeviceRef.CPU())
        bias_tensor = ops.constant(self.bias, dtype=DType.float32, device=DeviceRef.CPU())
        return ops.matmul(x, weight_tensor) + bias_tensor

linear_graph = Graph(
    "linear",
    Linear(np.ones((2, 2)), np.ones((2,))),
    input_types=[TensorType(DType.float32, (2,))]
)
```

You canâ€™t call a Graph directly from Python. You must compile it and
execute it with MAX Engine. For more detail, see the tutorial about how to
[build a graph with MAX
Graph](/max/tutorials/get-started-with-max-graph-in-python).

When creating a graph, a global sequence of chains is initialized and stored
in Graph.\_current\_chain. Every side-effecting op, e.g. buffer\_load,
store\_buffer, load\_slice\_buffer, store\_slice\_buffer, will use the current
chain to perform the op and and update Graph.\_current\_chain with a new
chain. Currently, the input/output chains for mutable ops can be used at
most once. The goal of this design choice is to prevent data races.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* name ([str](https://docs.python.org/3/library/stdtypes.html#str)) â€“ A name for the graph.
* forward (Callable\[..., None | [Value](Value.md#max.graph.Value)\[Any] | Iterable\[[Value](Value.md#max.graph.Value)\[Any]]] | None) â€“ The sequence of graph ops for the forward pass (inference).
* input\_types (Iterable\[[Type](type.md#max.graph.type.Type)\[Any]]) â€“ The data type(s) for the input tensor(s).
* path (Optional\[Path]) â€“ The path to a saved graph (internal use only).
* custom\_extensions ([list](https://docs.python.org/3/library/stdtypes.html#list)\[Path]) â€“ The extensions to load for the model.
  Supports paths to .mojopkg or .mojo sources with custom ops.
* context (Optional\[mlir.Context])
* kernel\_library (Optional\[[KernelLibrary](KernelLibrary.md#max.graph.KernelLibrary)])
* module (Optional\[mlir.Module])

</dd></dl>

### `add_subgraph()` {#max.graph.Graph.add_subgraph}

> add\_subgraph(name, forward=None, input\_types=(), path=None, custom\_extensions=\[])

Creates and adds a subgraph to the current graph.

Creates a new [`Graph`](#max.graph.Graph) instance configured as a subgraph of the current
graph. The subgraph inherits the parent graphâ€™s MLIR context, module, and
symbolic parameters. A chain type is automatically appended to the input
types to enable proper operation sequencing within the subgraph.

The created subgraph is marked with special MLIR attributes to identify it
as a subgraph and is registered in the parent graphâ€™s subgraph registry.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* name ([str](https://docs.python.org/3/library/stdtypes.html#str)) â€“ The name identifier for the subgraph.
* forward ([Callable](https://docs.python.org/3/library/typing.html#typing.Callable)\[\[...], None | [Value](Value.md#max.graph.Value)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [Iterable](https://docs.python.org/3/library/collections.abc.html#collections.abc.Iterable)\[[Value](Value.md#max.graph.Value)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]] | None) â€“ The optional callable that defines the sequence of operations
  for the subgraphâ€™s forward pass. If provided, the subgraph will be
  built immediately using this callable.
* input\_types ([Iterable](https://docs.python.org/3/library/collections.abc.html#collections.abc.Iterable)\[[Type](type.md#max.graph.type.Type)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]) â€“ The data types for the subgraphâ€™s input tensors. A chain
  type will be automatically added to these input types.
* path ([Path](https://docs.python.org/3/library/pathlib.html#pathlib.Path) | None) â€“ The optional path to a saved subgraph definition to load from
  disk instead of creating a new one.
* custom\_extensions ([list](https://docs.python.org/3/library/stdtypes.html#list)\[[Path](https://docs.python.org/3/library/pathlib.html#pathlib.Path)]) â€“ The list of paths to custom operation libraries
  to load for the subgraph. Supports `.mojopkg` files and Mojo
  source directories.

</dd><dt>

**Return type:**

</dt><dd>

[Graph](#max.graph.Graph)

</dd></dl>

### `add_weight()` {#max.graph.Graph.add_weight}

> add\_weight(weight, force\_initial\_weight\_on\_host=True)

Adds a weight to the graph.

If the weight is in the graph already, return the existing value.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* weight ([Weight](Weight.md#max.graph.Weight)) â€“ The weight to add to the graph.
* force\_initial\_weight\_on\_host ([bool](https://docs.python.org/3/library/functions.html#bool)) â€“ If true, then forces weights
  to initially be allocated on host before being moved to
  the indicated device. This is needed as a stop gap
  until we have a more fleshed out ownership model of
  external constants.

</dd><dt>

**Returns:**

</dt><dd>

A [`TensorValue`](TensorValue.md#max.graph.TensorValue) that contains this weight.

</dd><dt>

**Raises:**

</dt><dd>

[ValueError](https://docs.python.org/3/library/exceptions.html#ValueError) â€“ If a weight with the same name already exists in the graph.

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](TensorValue.md#max.graph.TensorValue)

</dd></dl>

### `always_ready_chain` {#max.graph.Graph.always_ready_chain}

> property always\_ready\_chain: \_ChainValue

A graph-global, immutable chain that is always ready.

Created once per graph and never advanced/merged by the graph itself.
Use it for operations that are safe to schedule without threading
per-device ordering (e.g., hostâ†’device transfers for staging).

### `current` {#max.graph.Graph.current}

> current

### `device_chains` {#max.graph.Graph.device_chains}

> device\_chains: [defaultdict](https://docs.python.org/3/library/collections.html#collections.defaultdict)\[[DeviceRef](type.md#max.graph.type.DeviceRef), \_ChainValue]

### `inputs` {#max.graph.Graph.inputs}

> property inputs: [Sequence](https://docs.python.org/3/library/collections.abc.html#collections.abc.Sequence)\[[Value](Value.md#max.graph.Value)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]

The input values of the graph.

### `kernel_libraries_paths` {#max.graph.Graph.kernel_libraries_paths}

> property kernel\_libraries\_paths: [list](https://docs.python.org/3/library/stdtypes.html#list)\[[Path](https://docs.python.org/3/library/pathlib.html#pathlib.Path)]

Returns the list of extra kernel libraries paths for the custom ops.

### `merge_device_chains()` {#max.graph.Graph.merge_device_chains}

> merge\_device\_chains()

Joins device execution to a common point by merging chains.

<dl class='field-list'><dt>

**Return type:**

</dt><dd>

None

</dd></dl>

### `output()` {#max.graph.Graph.output}

> output(\*outputs)

Sets the output nodes of the [`Graph`](#max.graph.Graph).

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

outputs ([Value](Value.md#max.graph.Value)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | Value\[TensorType] | [TensorValue](TensorValue.md#max.graph.TensorValue) | [Shape](shape.md#max.graph.shape.Shape) | [Dim](dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])

</dd><dt>

**Return type:**

</dt><dd>

None

</dd></dl>

### `output_types` {#max.graph.Graph.output_types}

> property output\_types: [list](https://docs.python.org/3/library/stdtypes.html#list)\[[Type](type.md#max.graph.type.Type)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]

View of the types of the graph output terminator.

---

## KernelLibrary

## `KernelLibrary` {#max.graph.KernelLibrary}

> class max.graph.KernelLibrary(context, paths=\[])

Manages custom kernel libraries and operations for a graph.

A kernel library provides access to custom operations and kernels that can
be loaded from various sources including Mojo binary packages (`.mojopkg`)
and Mojo source directories. The library handles verification and registration
of custom operations within the MLIR context.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* context (mlir.Context)
* paths ([list](https://docs.python.org/3/library/stdtypes.html#list)\[Path])

</dd></dl>

### `add_path()` {#max.graph.KernelLibrary.add_path}

> add\_path(path)

Adds a kernel library path to the analysis.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

path ([Path](https://docs.python.org/3/library/pathlib.html#pathlib.Path)) â€“ The `Path` to the kernel library to be added to the
current analysis.

</dd><dt>

**Return type:**

</dt><dd>

None

</dd></dl>

### `library_paths()` {#max.graph.KernelLibrary.library_paths}

> library\_paths()

Returns the list of kernel library paths.

<dl class='field-list'><dt>

**Returns:**

</dt><dd>

A list of `Path` objects representing the currently loaded
kernel library paths.

</dd><dt>

**Return type:**

</dt><dd>

[list](https://docs.python.org/3/library/stdtypes.html#list)\[[Path](https://docs.python.org/3/library/pathlib.html#pathlib.Path)]

</dd></dl>

### `load_paths()` {#max.graph.KernelLibrary.load_paths}

> load\_paths(context, custom\_extensions)

Loads custom operations from provided library paths.

Performs additional â€œsmartâ€ library loading logic for custom operation
libraries in additional formats. The loading logic supports the
following formats:

* Compiled Mojo binary packages with `.mojopkg` extension
* Mojo source directory with custom operations

The loaded libraries are added to the current kernel library.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* context (Context) â€“ The MLIR context for loading MLIR operations.
* custom\_extensions ([Iterable](https://docs.python.org/3/library/collections.abc.html#collections.abc.Iterable)\[[Path](https://docs.python.org/3/library/pathlib.html#pathlib.Path)]) â€“ The file paths to the custom operation libraries.

</dd><dt>

**Return type:**

</dt><dd>

None

</dd></dl>

### `verify_custom_op()` {#max.graph.KernelLibrary.verify_custom_op}

> verify\_custom\_op(custom\_op)

Verifies that a custom operation is valid within the current context.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

custom\_op (Operation) â€“ The `mlir.Operation` to be verified against the
current kernel library analysis.

</dd><dt>

**Return type:**

</dt><dd>

None

</dd></dl>

---

## TensorValue

## `TensorValue` {#max.graph.TensorValue}

> class max.graph.TensorValue(value)

Bases: [`Value`](Value.md#max.graph.Value)\[`TensorType`]

Represents a value semantic tensor within a [`Graph`](Graph.md#max.graph.Graph). It provides
various methods and properties to manipulate and query tensor attributes
such as [`shape`](shape.md#module-max.graph.shape), data type ([`dtype`](#max.graph.TensorValue.dtype)), device placement ([`device`](#max.graph.TensorValue.device)), and more.

The following example demonstrates how to create and manipulate tensor values in a graph:

```python
import numpy as np
from max.dtype import DType
from max.graph import Graph, ops

matrix = np.array([[1, 2], [3, 4]], dtype=np.float32)

# Create a Graph context to work with tensors
with Graph("tensor_demo") as graph:
    # Create a constant tensor from the matrix
    tensor = ops.constant(matrix, dtype=DType.float32, device=DeviceRef.CPU())

    # Access tensor properties
    print(f"Shape: {tensor.shape}")  # Output: [2, 2]
    print(f"Data type: {tensor.dtype}")  # Output: DType.float32

    # Perform operations on the tensor
    transposed = tensor.T
    doubled = tensor * 2

    print(f"Original shape: {tensor.shape}")  # Output: [2, 2]
    print(f"Transposed shape: {transposed.shape}")  # Output: [2, 2]
```

Initializes a [`TensorValue`](#max.graph.TensorValue) from a tensor-like value.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

value (TensorValueLike) â€“ The value to wrap. Can be an MLIR tensor value, another [`TensorValue`](#max.graph.TensorValue),
a `Dim`, or a `Shape`.

</dd></dl>

### `T` {#max.graph.TensorValue.T}

> property T: [TensorValue](#max.graph.TensorValue)

Returns the transposed tensor.
[`T`](#max.graph.TensorValue.T) is the shorthand notation for transposing.
For more information, see [`transpose()`](#max.graph.TensorValue.transpose).

<dl class='field-list'><dt>

**Returns:**

</dt><dd>

A new [`TensorValue`](#max.graph.TensorValue) with swapped dimensions.

</dd></dl>

### `argmax()` {#max.graph.TensorValue.argmax}

> argmax(axis=-1)

Reduces the tensor using an argmax operation along `axis`.

When the result is ambiguous ie. there are multiple maxima,
selects one index arbitrarily.

```python
from max.dtype import DType
from max.graph import Graph, TensorType, DeviceRef

# Define a 2x3 float32 input tensor for the graph
input_type = TensorType(DType.float32, (2, 3), device=DeviceRef.CPU())
with Graph("argmax_demo", input_types=[input_type]) as graph:
    x = graph.inputs[0].tensor

    # Argmax along axis 1 (last dimension of each row)
    indices = x.argmax(axis=1)

    print(f"Input shape: {x.shape}")       # [2, 3]
    print(f"Argmax shape: {indices.shape}")  # [2, 1]
```

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

axis ([int](https://docs.python.org/3/library/functions.html#int)) â€“ The axis along which to compute the reduction. If negative,
indexes from the last dimension (e.g., `-1` is the last dimension).

</dd><dt>

**Returns:**

</dt><dd>

A [`TensorValue`](#max.graph.TensorValue) of dtype `DType.int64` with the same rank as the input,
and the same shape except along `axis`, which will have size 1.

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](#max.graph.TensorValue)

</dd></dl>

### `broadcast_to()` {#max.graph.TensorValue.broadcast_to}

> broadcast\_to(shape)

Broadcasts the tensor to a new shape.

The following example demonstrates how to broadcast a tensor to a larger shape:

```python
import numpy as np
from max.dtype import DType
from max.graph import Graph, ops

# Create a 2x2 matrix
matrix = np.array([[1, 2], [3, 4]], dtype=np.float32)

# Create a Graph context to work with tensors
with Graph("broadcast_to_demo") as graph:
    # Create a constant tensor from the matrix
    tensor = ops.constant(matrix, dtype=DType.float32, device=DeviceRef.CPU())

    # Broadcast tensor to a 3x2x2 tensor (add a new dimension of size 3)
    broadcasted_tensor = tensor.broadcast_to((3, 2, 2))

    print(f"Original shape: {tensor.shape}")  # Output: [2, 2]
    print(f"Broadcasted shape: {broadcasted_tensor.shape}")  # Output: [3, 2, 2]
```

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

shape ([Iterable](https://docs.python.org/3/library/collections.abc.html#collections.abc.Iterable)\[[int](https://docs.python.org/3/library/functions.html#int) | [str](https://docs.python.org/3/library/stdtypes.html#str) | [Dim](dim.md#max.graph.dim.Dim) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]) â€“ An iterable of integers or symbolic dimensions.

</dd><dt>

**Returns:**

</dt><dd>

A new [`TensorValue`](#max.graph.TensorValue) with the broadcasted shape.

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](#max.graph.TensorValue)

</dd></dl>

### `cast()` {#max.graph.TensorValue.cast}

> cast(dtype)

Casts a symbolic tensor to a different data type.

The following example demonstrates how to cast a tensor from one data type to another:

```python
import numpy as np
from max.dtype import DType
from max.graph import Graph, ops

# Create a matrix with float32 values
matrix = np.array([[1, 2], [3, 4]], dtype=np.float32)

# Create a Graph context to work with tensors
with Graph("cast_demo") as graph:
    # Create a constant tensor from the matrix
    tensor = ops.constant(matrix, dtype=DType.float32, device=DeviceRef.CPU())

    # Cast tensor to integer type
    casted_tensor = tensor.cast(DType.int32)

    print(f"Original dtype: {tensor.dtype}")  # Output: DType.float32
    print(f"Casted dtype: {casted_tensor.dtype}")  # Output: DType.int32
```

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

dtype ([DType](../dtype.md#max.dtype.DType)) â€“ The target data type (e.g., `DType.int32`, `DType.float64`).

</dd><dt>

**Returns:**

</dt><dd>

A new [`TensorValue`](#max.graph.TensorValue) with the casted data type.

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](#max.graph.TensorValue)

</dd></dl>

### `device` {#max.graph.TensorValue.device}

> property device: [DeviceRef](type.md#max.graph.type.DeviceRef)

Returns the device of the TensorValue.

### `dtype` {#max.graph.TensorValue.dtype}

> property dtype: [DType](../dtype.md#max.dtype.DType)

Returns the tensor data type.

The following example demonstrates how to access the data type of a tensor:

```python
import numpy as np
from max.dtype import DType
from max.graph import Graph, ops

# Create a matrix with float32 values
matrix = np.array([[1, 2], [3, 4]], dtype=np.float32)

# Create a Graph context to work with tensors
with Graph("dtype_demo") as graph:
    # Create a constant tensor from the matrix
    tensor = ops.constant(matrix, dtype=DType.float32, device=DeviceRef.CPU())

    # Access tensor data type
    print(f"Data type: {tensor.dtype}")  # Output: DType.float32
```

### `flatten()` {#max.graph.TensorValue.flatten}

> flatten(start\_dim=0, end\_dim=-1)

Flattens the specified dims of a symbolic tensor.

The number and order of the elements in the tensor is unchanged.
All dimensions from `start_dim` to `end_dim` (inclusive) are merged into a single output dim.

The following example demonstrates how to flatten a multi-dimensional tensor:

```python
import numpy as np
from max.dtype import DType
from max.graph import Graph, ops

# Create a 2x2 matrix
matrix = np.array([[1, 2], [3, 4]], dtype=np.float32)

# Create a Graph context to work with tensors
with Graph("flatten_demo") as graph:
    # Create a constant tensor from the matrix
    tensor = ops.constant(matrix, dtype=DType.float32, device=DeviceRef.CPU())

    # Flatten the tensor to a 1D array
    flattened_tensor = tensor.flatten()

    print(f"Original shape: {tensor.shape}")  # Output: [2, 2]
    print(f"Flattened shape: {flattened_tensor.shape}")  # Output: [4]
```

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* start\_dim ([int](https://docs.python.org/3/library/functions.html#int)) â€“ The starting dimension to flatten. Defaults to `1`.
* end\_dim ([int](https://docs.python.org/3/library/functions.html#int)) â€“ The ending dimension to flatten. Defaults to `-1`.

</dd><dt>

**Returns:**

</dt><dd>

A new [`TensorValue`](#max.graph.TensorValue) with the flattened dimensions.

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](#max.graph.TensorValue)

</dd></dl>

### `from_mlir()` {#max.graph.TensorValue.from_mlir}

> classmethod from\_mlir(value)

Creates a [`TensorValue`](#max.graph.TensorValue) from an MLIR tensor value.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

value (Value\[TensorType]) â€“ The MLIR tensor value to wrap.

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](#max.graph.TensorValue)

</dd></dl>

### `max()` {#max.graph.TensorValue.max}

> max(axis=-1)

Reduces the tensor using a max operation along `axis`.

```python
from max.dtype import DType
from max.graph import Graph, TensorType, DeviceRef

# Define a 2x3 float32 input tensor for the graph
input_type = TensorType(DType.float32, (2, 3), device=DeviceRef.CPU())
with Graph("max_demo", input_types=[input_type]) as graph:
    x = graph.inputs[0].tensor

    # Max along axis 1 (last dimension of each row)
    m = x.max(axis=1)

    print(f"Input shape: {x.shape}")  # [2, 3]
    print(f"Max shape: {m.shape}")    # [2, 1]
```

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

axis ([int](https://docs.python.org/3/library/functions.html#int)) â€“ The axis along which to compute the reduction. If negative,
indexes from the last dimension (e.g., `-1` is the last dimension).

</dd><dt>

**Returns:**

</dt><dd>

A [`TensorValue`](#max.graph.TensorValue) with the same rank as the input and the same
shape except along `axis`, which will have size 1.

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](#max.graph.TensorValue)

</dd></dl>

### `mean()` {#max.graph.TensorValue.mean}

> mean(axis=-1)

Reduces the tensor using a mean operation along `axis`.

```python
from max.dtype import DType
from max.graph import Graph, TensorType, DeviceRef

# Define a 2x3 float32 input tensor for the graph
input_type = TensorType(DType.float32, (2, 3), device=DeviceRef.CPU())
with Graph("mean_demo", input_types=[input_type]) as graph:
    x = graph.inputs[0].tensor

    # Mean along axis 1 (last dimension of each row)
    mu = x.mean(axis=1)

    print(f"Input shape: {x.shape}")  # [2, 3]
    print(f"Mean shape: {mu.shape}")  # [2, 1]
```

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

axis ([int](https://docs.python.org/3/library/functions.html#int)) â€“ The axis along which to compute the reduction. If negative,
indexes from the last dimension (e.g., `-1` is the last dimension).

</dd><dt>

**Returns:**

</dt><dd>

A [`TensorValue`](#max.graph.TensorValue) with the same rank as the input and the same
shape except along `axis`, which will have size 1.

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](#max.graph.TensorValue)

</dd></dl>

### `min()` {#max.graph.TensorValue.min}

> min(axis=-1)

Reduces the tensor using a min operation along `axis`.

```python
from max.dtype import DType

from max.graph import Graph, TensorType, DeviceRef

# Define a 2x3 float32 input tensor for the graph
input_type = TensorType(DType.float32, (2, 3), device=DeviceRef.CPU())
with Graph("min_demo", input_types=[input_type]) as graph:
    x = graph.inputs[0].tensor

    # Min along axis 1 (last dimension of each row)
    mn = x.min(axis=1)

    print(f"Input shape: {x.shape}")  # [2, 3]
    print(f"Min shape: {mn.shape}")   # [2, 1]
```

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

axis ([int](https://docs.python.org/3/library/functions.html#int)) â€“ The axis along which to compute the reduction. If negative,
indexes from the last dimension (e.g., `-1` is the last dimension).

</dd><dt>

**Returns:**

</dt><dd>

A [`TensorValue`](#max.graph.TensorValue) with the same rank as the input and the same
shape except along `axis`, which will have size 1.

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](#max.graph.TensorValue)

</dd></dl>

### `permute()` {#max.graph.TensorValue.permute}

> permute(dims)

Permutes the tensorâ€™s dimensions based on provided indices.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

dims ([list](https://docs.python.org/3/library/stdtypes.html#list)\[[int](https://docs.python.org/3/library/functions.html#int)]) â€“ A list of integers specifying the new order of dimensions.

</dd><dt>

**Returns:**

</dt><dd>

A new [`TensorValue`](#max.graph.TensorValue) with permuted dimensions.

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](#max.graph.TensorValue)

</dd></dl>

### `print()` {#max.graph.TensorValue.print}

> print(label='debug\_tensor')

Prints detailed information about the tensor.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

label ([str](https://docs.python.org/3/library/stdtypes.html#str)) â€“ A string label for the printed output. Defaults `debug_tensor`.

</dd><dt>

**Return type:**

</dt><dd>

None

</dd></dl>

### `rank` {#max.graph.TensorValue.rank}

> property rank: [int](https://docs.python.org/3/library/functions.html#int)

Returns the rank (number of dims) of the buffer.

The following example demonstrates how to access the rank of a tensor:

```python
import numpy as np
from max.dtype import DType
from max.graph import Graph, ops

# Create a 2x2 matrix (2-dimensional array)
matrix = np.array([[1, 2], [3, 4]], dtype=np.float32)

# Create a Graph context to work with tensors
with Graph("rank_demo") as graph:
    # Create a constant tensor from the matrix
    tensor = ops.constant(matrix, dtype=DType.float32, device=DeviceRef.CPU())

    # Access tensor rank (number of dimensions)
    print(f"Rank: {tensor.rank}")  # Output: 2
```

### `rebind()` {#max.graph.TensorValue.rebind}

> rebind(shape, message='')

Rebinds the tensor to a new shape with error handling.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* shape ([Iterable](https://docs.python.org/3/library/collections.abc.html#collections.abc.Iterable)\[[int](https://docs.python.org/3/library/functions.html#int) | [str](https://docs.python.org/3/library/stdtypes.html#str) | [Dim](dim.md#max.graph.dim.Dim) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]) â€“ The new shape as an iterable of integers or symbolic dimensions.
* message ([str](https://docs.python.org/3/library/stdtypes.html#str)) â€“ (optional) A message for logging or debugging.

</dd><dt>

**Returns:**

</dt><dd>

A new [`TensorValue`](#max.graph.TensorValue) with the updated shape.

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](#max.graph.TensorValue)

</dd></dl>

### `reshape()` {#max.graph.TensorValue.reshape}

> reshape(shape)

Creates a new tensor with the same data but reshaped.

The following example demonstrates how to reshape a tensor to change its dimensions:

```python
import numpy as np
from max.dtype import DType
from max.graph import Graph, ops

# Create a 2x2 matrix
matrix = np.array([[1, 2], [3, 4]], dtype=np.float32)

# Create a Graph context to work with tensors
with Graph("reshape_demo") as graph:
    # Create a constant tensor from the matrix
    tensor = ops.constant(matrix, dtype=DType.float32, device=DeviceRef.CPU())

    # Reshape tensor to a 1x4 matrix
    reshaped_tensor = tensor.reshape((1, 4))

    print(f"Original shape: {tensor.shape}")  # Output: [2, 2]
    print(f"Reshaped shape: {reshaped_tensor.shape}")  # Output: [1, 4]
```

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

shape ([Iterable](https://docs.python.org/3/library/collections.abc.html#collections.abc.Iterable)\[[int](https://docs.python.org/3/library/functions.html#int) | [str](https://docs.python.org/3/library/stdtypes.html#str) | [Dim](dim.md#max.graph.dim.Dim) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]) â€“ The new shape as an iterable of integers or symbolic dimensions.

</dd><dt>

**Returns:**

</dt><dd>

A new [`TensorValue`](#max.graph.TensorValue) with the reshaped dimensions.

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](#max.graph.TensorValue)

</dd></dl>

### `shape` {#max.graph.TensorValue.shape}

> property shape: [Shape](shape.md#max.graph.shape.Shape)

Returns the shape of the [`TensorValue`](#max.graph.TensorValue).

The following example demonstrates how to access the shape of a tensor:

```python
import numpy as np
from max.dtype import DType
from max.graph import Graph, ops

# Create a 2x2 matrix
matrix = np.array([[1, 2], [3, 4]], dtype=np.float32)

# Create a Graph context to work with tensors
with Graph("shape_demo") as graph:
    # Create a constant tensor from the matrix
    tensor = ops.constant(matrix, dtype=DType.float32, device=DeviceRef.CPU())

    # Access tensor shape
    print(f"Shape: {tensor.shape}")  # Shape: [Dim(2), Dim(2)]
```

### `stdev()` {#max.graph.TensorValue.stdev}

> stdev(axis=-1)

Reduces the tensor using a standard deviation operation along `axis`.

The standard deviation is computed as the square root of the population
variance along the specified axis.

```python
from max.dtype import DType
from max.graph import Graph, TensorType, DeviceRef

# Define a 2x3 float32 input tensor for the graph
input_type = TensorType(DType.float32, (2, 3), device=DeviceRef.CPU())
with Graph("stdev_demo", input_types=[input_type]) as graph:
    x = graph.inputs[0].tensor

    # Standard deviation along axis 1 (last dimension of each row)
    sd = x.stdev(axis=1)

    print(f"Input shape: {x.shape}")    # [2, 3]
    print(f"Stdev shape: {sd.shape}")  # [2, 1]
```

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

axis ([int](https://docs.python.org/3/library/functions.html#int)) â€“ The axis along which to compute the reduction. If negative,
indexes from the last dimension (e.g., `-1` is the last dimension).

</dd><dt>

**Returns:**

</dt><dd>

A [`TensorValue`](#max.graph.TensorValue) with the same rank as the input and the same
shape except along `axis`, which will have size 1.

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](#max.graph.TensorValue)

</dd></dl>

### `to()` {#max.graph.TensorValue.to}

> to(device)

Transfers the tensor to a specified device without mutation.

The following example demonstrates how to move a tensor from one device to another:

```python
import numpy as np
from max.dtype import DType
from max.graph import Graph, ops, DeviceRef

# Create a 2x2 matrix
matrix = np.array([[1, 2], [3, 4]], dtype=np.float32)

with Graph("to_device_example") as graph:
    # Create a tensor on the default device
    tensor = ops.constant(matrix, dtype=DType.float32, device=DeviceRef.CPU())

    # Move the tensor to a GPU device
    gpu_tensor = tensor.to(DeviceRef.GPU())

    print(f"Original device: {tensor.device}")  # Output depends on default device
    print(f"New device: {gpu_tensor.device}")  # Output: gpu:0
```

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

device ([DeviceRef](type.md#max.graph.type.DeviceRef)) â€“ A `DeviceRef` object specifying the target device.

</dd><dt>

**Returns:**

</dt><dd>

A new [`TensorValue`](#max.graph.TensorValue) on the specified device.

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](#max.graph.TensorValue)

</dd></dl>

### `transpose()` {#max.graph.TensorValue.transpose}

> transpose(dim\_1, dim\_2)

Swaps two dimensions of the tensor.

The following example demonstrates how to transpose a tensor by swapping its dimensions:

```python
import numpy as np
from max.dtype import DType
from max.graph import Graph, ops

# Create a 2x3 matrix
matrix = np.array([[1, 2, 3], [4, 5, 6]], dtype=np.float32)

with Graph("transpose_demo") as graph:
    tensor = ops.constant(matrix, dtype=DType.float32, device=DeviceRef.CPU())

    # Transpose the tensor (swap dimensions 0 and 1)
    transposed_tensor = tensor.transpose(dim_1=0, dim_2=1)

    print(f"Original shape: {tensor.shape}")  # Output: [2, 3]
    print(f"Transposed shape: {transposed_tensor.shape}")  # Output: [3, 2]
```

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* dim\_1 ([int](https://docs.python.org/3/library/functions.html#int)) â€“ The first dimension to swap.
* dim\_2 ([int](https://docs.python.org/3/library/functions.html#int)) â€“ The second dimension to swap.

</dd><dt>

**Returns:**

</dt><dd>

A new [`TensorValue`](#max.graph.TensorValue) with swapped dimensions.

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](#max.graph.TensorValue)

</dd></dl>

### `type` {#max.graph.TensorValue.type}

> property type: [TensorType](type.md#max.graph.type.TensorType)

Returns the type of the [`TensorValue`](#max.graph.TensorValue) as a `TensorType`.

### `var()` {#max.graph.TensorValue.var}

> var(axis=-1)

Reduces the tensor using a variance operation along `axis`.

The variance is computed as the mean of squared deviations from the mean
(population variance, i.e., without Besselâ€™s correction) along the specified axis.

```python
from max.dtype import DType
from max.graph import Graph, TensorType, DeviceRef

# Define a 2x3 float32 input tensor for the graph
input_type = TensorType(DType.float32, (2, 3), device=DeviceRef.CPU())
with Graph("var_demo", input_types=[input_type]) as graph:
    x = graph.inputs[0].tensor

    # Variance along axis 1 (last dimension of each row)
    vr = x.var(axis=1)

    print(f"Input shape: {x.shape}")  # [2, 3]
    print(f"Var shape: {vr.shape}")  # [2, 1]
```

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

axis ([int](https://docs.python.org/3/library/functions.html#int)) â€“ The axis along which to compute the reduction. If negative,
indexes from the last dimension (e.g., `-1` is the last dimension).

</dd><dt>

**Returns:**

</dt><dd>

A [`TensorValue`](#max.graph.TensorValue) with the same rank as the input and the same
shape except along `axis`, which will have size 1.

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](#max.graph.TensorValue)

</dd></dl>

---

## Value

## `Value` {#max.graph.Value}

> class max.graph.Value

Represents a symbolic value within a Graph.

A Value can represent the output of a node, the arguments of a
Graph (as seen from within its body), and more generally any symbolic
value available within the Graph. Other nodes receive Value
values as inputs to form a computation graph.

A Value may also refer to an existing input or output of a node,
and you can change them, such as by swapping a new Value.

Conceptually, think of a Value as an edge in the dataflow graph,
with the other end being the user of that value.

The following example shows how to work with Values in a graph to create a simple computation:

```python
from max.graph import Graph, ops, Value
from max.dtype import DType
import numpy as np

with Graph("value_example") as graph:
    # Create input values
    a = ops.constant(np.array([1, 2, 3]), dtype=DType.float32, device=DeviceRef.CPU())
    b = ops.constant(np.array([4, 5, 6]), dtype=DType.float32, device=DeviceRef.CPU())

    # Use values to perform operations
    c = a + b  # c is a Value representing the addition

    # Demonstrate that the result is a Value
    print(f"Type of c: {type(c)}")
    print(f"Is c a Value? {isinstance(c, Value)}")
```

Similar to a regular variable, a Value has a data type.

Value is abstract, it shouldnâ€™t be constructed directly.

### `buffer` {#max.graph.Value.buffer}

> property buffer: [BufferValue](BufferValue.md#max.graph.BufferValue)

Returns the Value as a [`BufferValue`](BufferValue.md#max.graph.BufferValue).

Raises an exception if the Value is not a BufferValue.

### `from_mlir()` {#max.graph.Value.from_mlir}

> classmethod from\_mlir(value)

Creates a [`Value`](#max.graph.Value) from an MLIR value.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

value (Value\[MlirType]) â€“ The MLIR value to wrap.

</dd><dt>

**Return type:**

</dt><dd>

[Value](#max.graph.Value)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]

</dd></dl>

### `opaque` {#max.graph.Value.opaque}

> property opaque: \_OpaqueValue

Returns the Value as an `_OpaqueValue`.

Raises an exception if the Value is not a \_OpaqueValue.

### `tensor` {#max.graph.Value.tensor}

> property tensor: [TensorValue](TensorValue.md#max.graph.TensorValue)

Returns the Value as a [`TensorValue`](TensorValue.md#max.graph.TensorValue).

Raises an exception if the Value is not a TensorValue.

### `to_mlir()` {#max.graph.Value.to_mlir}

> to\_mlir()

Converts the [`Value`](#max.graph.Value) to an MLIR value.

<dl class='field-list'><dt>

**Return type:**

</dt><dd>

Value\[MlirType]

</dd></dl>

### `type` {#max.graph.Value.type}

> property type: [Type](type.md#max.graph.type.Type)\[MlirType]

Returns the type of the [`Value`](#max.graph.Value) as a `Type`.

---

## Weight

## `Weight` {#max.graph.Weight}

> class max.graph.Weight(\*args, \*\*kwargs)

Bases: [`TensorValue`](TensorValue.md#max.graph.TensorValue)

Represents a value in a Graph that can be loaded at a later time.

Weights can be initialized outside of a Graph and are lazily-added to
the parent graph when used. If there is no parent graph when a weight is
used, an error will be raised.

Initializes a [`TensorValue`](TensorValue.md#max.graph.TensorValue) from a tensor-like value.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

value â€“ The value to wrap. Can be an MLIR tensor value, another [`TensorValue`](TensorValue.md#max.graph.TensorValue),
a `Dim`, or a `Shape`.

</dd></dl>

### `align` {#max.graph.Weight.align}

> align: [int](https://docs.python.org/3/library/functions.html#int) | [None](https://docs.python.org/3/library/constants.html#None)

### `device` {#max.graph.Weight.device}

> property device: [DeviceRef](type.md#max.graph.type.DeviceRef)

Returns the device of the TensorValue.

### `dtype` {#max.graph.Weight.dtype}

> property dtype: [DType](../dtype.md#max.dtype.DType)

Returns the tensor data type.

The following example demonstrates how to access the data type of a tensor:

```python
import numpy as np
from max.dtype import DType
from max.graph import Graph, ops

matrix = np.array([[1, 2], [3, 4]], dtype=np.float32)

# Create a Graph context to work with tensors
with Graph("dtype_demo") as graph:
    # Create a constant tensor from the matrix
    tensor = ops.constant(matrix, dtype=DType.float32, device=DeviceRef.CPU())

    # Access tensor data type
    print(f"Data type: {tensor.dtype}")  # Output: DType.float32
```

### `original_dtype_and_shape` {#max.graph.Weight.original_dtype_and_shape}

> property original\_dtype\_and\_shape: [tuple](https://docs.python.org/3/library/stdtypes.html#tuple)\[[DType](../dtype.md#max.dtype.DType), [Shape](shape.md#max.graph.shape.Shape)]

The original dtype and shape of this weight.

This property should be used to store the original weightâ€™s dtype and
shape the quantization encoding forces the weight to be loaded as uint8.

### `quantization_encoding` {#max.graph.Weight.quantization_encoding}

> quantization\_encoding: [QuantizationEncoding](quantization.md#max.graph.quantization.QuantizationEncoding) | [None](https://docs.python.org/3/library/constants.html#None)

### `shape` {#max.graph.Weight.shape}

> property shape: [Shape](shape.md#max.graph.shape.Shape)

Returns the shape of the [`TensorValue`](TensorValue.md#max.graph.TensorValue).

The following example demonstrates how to access the shape of a tensor:

```python
import numpy as np
from max.dtype import DType
from max.graph import Graph, ops

# Create a 2x2 matrix
matrix = np.array([[1, 2], [3, 4]], dtype=np.float32)

# Create a Graph context to work with tensors
with Graph("shape_demo") as graph:
    # Create a constant tensor from the matrix
    tensor = ops.constant(matrix, dtype=DType.float32, device=DeviceRef.CPU())

    # Access tensor shape
    print(f"Shape: {tensor.shape}")  # Shape: [Dim(2), Dim(2)]
```

### `shard()` {#max.graph.Weight.shard}

> shard(devices)

Creates sharded views of this Weight across multiple devices.

This Weight must have sharding\_strategy defined. The shard objects
returned are also Weight objects, but cannot be sharded further.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

devices ([Iterable](https://docs.python.org/3/library/collections.abc.html#collections.abc.Iterable)\[[DeviceRef](type.md#max.graph.type.DeviceRef)]) â€“ Iterable of devices to place the shards on.

</dd><dt>

**Returns:**

</dt><dd>

List of sharded weights, one for each device.

</dd><dt>

**Return type:**

</dt><dd>

[list](https://docs.python.org/3/library/stdtypes.html#list)\[[Weight](#max.graph.Weight)]

</dd></dl>

### `shard_idx` {#max.graph.Weight.shard_idx}

> shard\_idx: [int](https://docs.python.org/3/library/functions.html#int) | [None](https://docs.python.org/3/library/constants.html#None)

### `sharding_strategy` {#max.graph.Weight.sharding_strategy}

> property sharding\_strategy: ShardingStrategy | [None](https://docs.python.org/3/library/constants.html#None)

Gets the weight sharding strategy.

---

## dim

Library for graph dimension types.

## `AlgebraicDim` {#max.graph.dim.AlgebraicDim}

> class max.graph.dim.AlgebraicDim(value)

An algebraic tensor dimension to enable expressions over symbolic
dimensions.

That is, any expression over a symbolic dimension returns `AlgebraicDim`.
Furthermore, algebraic dimensions automatically simplify into a canonical
form.

The following example demonstrates how to create and use algebraic dimensions with symbolic values:

```python
from max.graph import AlgebraicDim, Dim
isinstance(Dim("batch") * 5, AlgebraicDim)  # Returns True
print(Dim("batch") * 5)  # Outputs: batch * 5
-Dim("x") - 4 == -(Dim("x") + 4)  # Returns True
```

Converts valid input values to Dim.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

attr (ParamOperatorAttr)

</dd></dl>

### `apply()` {#max.graph.dim.AlgebraicDim.apply}

> classmethod apply(op, \*operands)

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* op (POC)
* operands ([int](https://docs.python.org/3/library/functions.html#int) | [str](https://docs.python.org/3/library/stdtypes.html#str) | [Dim](#max.graph.dim.Dim) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)])

</dd></dl>

### `attr` {#max.graph.dim.AlgebraicDim.attr}

> attr: ParamOperatorAttr

### `from_mlir()` {#max.graph.dim.AlgebraicDim.from_mlir}

> static from\_mlir(attr)

Constructs a dimension from an `mlir.Attribute`.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* dim\_attr â€“ The MLIR Attribute object to parse into a dimension.
* attr (TypedAttr)

</dd><dt>

**Returns:**

</dt><dd>

The dimension represented by the MLIR Attr value.

</dd><dt>

**Return type:**

</dt><dd>

[Dim](#max.graph.dim.Dim)

</dd></dl>

### `parameters` {#max.graph.dim.AlgebraicDim.parameters}

> property parameters: [Iterable](https://docs.python.org/3/library/collections.abc.html#collections.abc.Iterable)\[[SymbolicDim](#max.graph.dim.SymbolicDim)]

Lists the symbolic dimension names on which this dim depends.

### `to_mlir()` {#max.graph.dim.AlgebraicDim.to_mlir}

> to\_mlir()

Creates an mlir.Attribute representing this dimension.
This is used internally when constructing tensor MLIR types.

<dl class='field-list'><dt>

**Returns:**

</dt><dd>

An mlir.Attribute in the context representing the dimension.

</dd><dt>

**Return type:**

</dt><dd>

ParamOperatorAttr

</dd></dl>

## `Dim` {#max.graph.dim.Dim}

> class max.graph.dim.Dim(value)

A tensor dimension.

Tensor dimensions can be one of three types:

* **Static**: Known size
* **Symbolic**: Unknown size but named
* **Algebraic**: Unknown size has an algebraic expression

In most cases, you donâ€™t need to work with a `Dim` directly.
Instead, use conversion constructors:

```python
from max.graph import Dim, TensorType, DeviceRef

tensor_type = TensorType(DType.int64, ("batch", 10), device=DeviceRef.CPU())
```

This creates a tensor type with three dimensions:

* A symbolic â€œbatchâ€ dimension
* A static dimension of size 10

For explicit dimension construction, use the following helpers:

```python
from max.graph import Dim

some_dims = [
    SymbolicDim("batch"),
    StaticDim(5),
    AlgebraicDim(Dim("batch") + 1),
]
```

Constraining tensor dimensions is one important way to improve model
performance. If tensors have unknown dimensions, we canâ€™t optimize them
as aggressively. Symbolic tensors allow the compiler to learn constraints
on a specific dimension (eg. if 2 inputs have the same batch dimension),
but static dims are the easiest to optimize and therefore the easiest to
create and work with.

Converts valid input values to Dim.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

value (DimLike)

</dd></dl>

### `from_mlir()` {#max.graph.dim.Dim.from_mlir}

> static from\_mlir(attr)

Constructs a dimension from an `mlir.Attribute`.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* dim\_attr â€“ The MLIR Attribute object to parse into a dimension.
* attr (TypedAttr)

</dd><dt>

**Returns:**

</dt><dd>

The dimension represented by the MLIR Attr value.

</dd><dt>

**Return type:**

</dt><dd>

[Dim](#max.graph.dim.Dim)

</dd></dl>

### `parameters` {#max.graph.dim.Dim.parameters}

> property parameters: [Iterable](https://docs.python.org/3/library/collections.abc.html#collections.abc.Iterable)\[[SymbolicDim](#max.graph.dim.SymbolicDim)]

Lists the symbolic dimension names on which this dim depends.

### `to_mlir()` {#max.graph.dim.Dim.to_mlir}

> to\_mlir()

Creates an `mlir.Attribute` representing this dimension.

This is used internally when constructing tensor MLIR types.

<dl class='field-list'><dt>

**Returns:**

</dt><dd>

An `mlir.Attribute` in the context representing the dimension.

</dd><dt>

**Return type:**

</dt><dd>

TypedAttr

</dd></dl>

## `StaticDim` {#max.graph.dim.StaticDim}

> class max.graph.dim.StaticDim(value)

A static tensor dimension.

Static tensor dimensions will always have exactly the same value,
and are key to good model performance.

The following example shows how static dimensions can be created implicitly:

```python
from max.graph import TensorType
from max.dtype import DType
tensor = TensorType(DType.int64, (4, 5))
```

Converts valid input values to Dim.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

dim ([int](https://docs.python.org/3/library/functions.html#int))

</dd></dl>

### `dim` {#max.graph.dim.StaticDim.dim}

> dim: [int](https://docs.python.org/3/library/functions.html#int)

The size of the static dimension.

### `from_mlir()` {#max.graph.dim.StaticDim.from_mlir}

> static from\_mlir(attr)

Constructs a dimension from an `mlir.Attribute`.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* dim\_attr â€“ The MLIR Attribute object to parse into a dimension.
* attr (TypedAttr)

</dd><dt>

**Returns:**

</dt><dd>

The dimension represented by the MLIR Attr value.

</dd><dt>

**Return type:**

</dt><dd>

[Dim](#max.graph.dim.Dim)

</dd></dl>

### `parameters` {#max.graph.dim.StaticDim.parameters}

> property parameters: [Iterable](https://docs.python.org/3/library/collections.abc.html#collections.abc.Iterable)\[[SymbolicDim](#max.graph.dim.SymbolicDim)]

Lists the symbolic dimension names on which this dim depends.

### `to_mlir()` {#max.graph.dim.StaticDim.to_mlir}

> to\_mlir()

Creates an `mlir.Attribute` representing this dimension.

This is used internally when constructing tensor MLIR types.

<dl class='field-list'><dt>

**Returns:**

</dt><dd>

An `mlir.Attribute` in the context representing the dimension.

</dd><dt>

**Return type:**

</dt><dd>

IntegerAttr

</dd></dl>

## `SymbolicDim` {#max.graph.dim.SymbolicDim}

> class max.graph.dim.SymbolicDim(value)

A symbolic tensor dimension.

Symbolic dimensions represent named dimensions in MO tensor types.

Symbolic dimensions donâ€™t have a static value, but they allow a readable
name to understand whatâ€™s going on in the model IR better, and they also
allow users to hint to the compiler that two dimensions will have the same
value, which can often allow important speedups.

In tensor type notation:

```default
!mo.tensor<[batch, x, 10], si32]>
```

The first and second dimensions are named `batch` and `x` respectively.

Creating a `SymbolicDim`:

```python
dim = SymbolicDim("name")
```

Using `SymbolicDim` in a `TensorType`:

```python
tensor_type = TensorType(DType.bool, (SymbolicDim("batch"), SymbolicDim("x"), 10))
```

Converts valid input values to Dim.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

name ([str](https://docs.python.org/3/library/stdtypes.html#str))

</dd></dl>

### `from_mlir()` {#max.graph.dim.SymbolicDim.from_mlir}

> static from\_mlir(attr)

Constructs a dimension from an `mlir.Attribute`.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* dim\_attr â€“ The MLIR Attribute object to parse into a dimension.
* attr (TypedAttr)

</dd><dt>

**Returns:**

</dt><dd>

The dimension represented by the MLIR Attr value.

</dd><dt>

**Return type:**

</dt><dd>

[Dim](#max.graph.dim.Dim)

</dd></dl>

### `name` {#max.graph.dim.SymbolicDim.name}

> name: [str](https://docs.python.org/3/library/stdtypes.html#str)

The name of the dimension.

### `parameters` {#max.graph.dim.SymbolicDim.parameters}

> property parameters: [Iterable](https://docs.python.org/3/library/collections.abc.html#collections.abc.Iterable)\[[SymbolicDim](#max.graph.dim.SymbolicDim)]

Lists the symbolic dimension names on which this dim depends.

### `to_mlir()` {#max.graph.dim.SymbolicDim.to_mlir}

> to\_mlir()

Creates an `mlir.Attribute` representing this dimension.

This is used internally when constructing tensor MLIR types.

<dl class='field-list'><dt>

**Returns:**

</dt><dd>

An `mlir.Attribute` in the context representing the dimension.

</dd><dt>

**Return type:**

</dt><dd>

ParamDeclRefAttr

</dd></dl>

---

## graph (Graph)

APIs to build inference graphs for MAX Engine with Python.

## Classes

* [`BufferValue`](/max/api/python/graph/BufferValue): Represents a mutable semantic tensor within a Graph.
* [`Graph`](/max/api/python/graph/Graph): Represents a graph for MAX Engine.
* [`KernelLibrary`](/max/api/python/graph/KernelLibrary): Represents a library with custom ops.
* [`TensorValue`](/max/api/python/graph/TensorValue): Represents a value semantic tensor within a Graph.
* [`Value`](/max/api/python/graph/Value): Represents a symbolic value within a Graph.
* [`Weight`](/max/api/python/graph/Weight): Represents a weight value in a graph.

## Modules

* [`dim`](/max/api/python/graph/dim): APIs for graph value tensor dimensions.
* [`ops`](/max/api/python/graph/ops): Ops you can add when staging a graph.
* [`quantization`](/max/api/python/graph/quantization): APIs to quantize graph tensors.
* [`shape`](/max/api/python/graph/shape): APIs for graph value tensor shapes.
* [`type`](/max/api/python/graph/type): APIs for graph value types.
* [`weights`](/max/api/python/graph/weights): APIs for loading weights into a graph.

---

## ops

Implements operations used when staging a graph.

This module provides operations for building computational graphs in MAX. These
operations create, transform, and manipulate tensor values within the graph.

You can also use functions in [Graph](/max/api/python/graph/Graph) to add
constant values to your graph with operations like
[constant()](/max/api/python/graph/ops#max.graph.ops.constant).

The [TensorValue](/max/api/python/graph/TensorValue/) type (returned by most
operations) implements various dunder methods to support operations between
TensorValues, such as + for addition, \* for multiplication, and @ for
matrix multiplication. It also provides convenience methods like
[reshape()](/max/api/python/graph/TensorValue/#max.graph.TensorValue.reshape)
and
[flatten()](/max/api/python/graph/TensorValue/#max.graph.TensorValue.flatten).

### `InterpolationMode` {#max.graph.ops.InterpolationMode}

> class max.graph.ops.InterpolationMode(value, names=\<not given>, \*values, module=None, qualname=None, type=None, start=1, boundary=None)

Interpolation modes for image resize operations.

This enum defines the available interpolation methods that can be used
when resizing tensors. Currently only BICUBIC is implemented, with
BILINEAR and NEAREST planned for future support.

#### `BICUBIC` {#max.graph.ops.InterpolationMode.BICUBIC}

> BICUBIC = 'bicubic'

#### `BILINEAR` {#max.graph.ops.InterpolationMode.BILINEAR}

> BILINEAR = 'bilinear'

#### `NEAREST` {#max.graph.ops.InterpolationMode.NEAREST}

> NEAREST = 'nearest'

### `TensorType` {#max.graph.ops.TensorType}

> class max.graph.ops.TensorType(dtype, shape, device, \_layout=None)

A symbolic [`TensorType`](#max.graph.ops.TensorType).

This is not an eager tensor type! This contains no actual data, but
instead represents the type of a value at some point in time during model
execution.

Most internal values in a model will be tensors. This type represents
their element type (`dtype`) and dimensions (`dims`) at a specific point during
model computation. It allows us to do some optimistic optimizations and
shape inference during graph construction, and to provide more detailed
shape information to the compiler for further optimization passes.

The following example shows how to create a tensor type with static dimensions and access its properties:

```python
from max.graph import TensorType
from max.dtype import DType
tensor_type = TensorType(DType.float32, (2, 3))
print(tensor_type.dtype)  # Outputs: DType.float32
print(tensor_type.shape)  # Outputs: [2, 3]
```

It can also represent a fully dynamic rank tensor. The presence of dynamic
rank tensors in a graph will often degrade performance dramatically and
prevents many classes of optimizations.

An optional device (`device`) can also be provided to indicate the explicit
device the tensor is associated with.

Constructs a tensor type.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* dtype ([DType](../dtype.md#max.dtype.DType)) â€“ The element type of the tensor data.
* dims â€“ The shape dimensions of the tensor. The number of dims
  is the rank of the tensor.
* shape ([Shape](shape.md#max.graph.shape.Shape))
* device ([DeviceRef](type.md#max.graph.type.DeviceRef))
* \_layout ([FilterLayout](type.md#max.graph.type.FilterLayout) | None)

</dd></dl>

#### `as_buffer()` {#max.graph.ops.TensorType.as_buffer}

> as\_buffer()

Returns the analogous buffer type.

<dl class='field-list'><dt>

**Return type:**

</dt><dd>

[BufferType](type.md#max.graph.type.BufferType)

</dd></dl>

#### `from_mlir()` {#max.graph.ops.TensorType.from_mlir}

> classmethod from\_mlir(type)

Constructs a tensor type from an MLIR type.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* t â€“ The MLIR Type object to parse into a tensor type.
* type (TensorType)

</dd><dt>

**Returns:**

</dt><dd>

The tensor type represented by the MLIR Type value.

</dd><dt>

**Return type:**

</dt><dd>

[TensorType](type.md#max.graph.type.TensorType)

</dd></dl>

#### `to_mlir()` {#max.graph.ops.TensorType.to_mlir}

> to\_mlir()

Converts to an `mlir.Type` instance.

<dl class='field-list'><dt>

**Returns:**

</dt><dd>

An `mlir.Type` in the specified Context.

</dd><dt>

**Return type:**

</dt><dd>

TensorType

</dd></dl>

### `abs()` {#max.graph.ops.abs}

> max.graph.ops.abs(x)

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

x (Value\[TensorType] | [TensorValue](TensorValue.md#max.graph.TensorValue) | [Shape](shape.md#max.graph.shape.Shape) | [Dim](dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](TensorValue.md#max.graph.TensorValue)

</dd></dl>

### `add()` {#max.graph.ops.add}

> max.graph.ops.add(lhs, rhs)

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* lhs (Value\[TensorType] | [TensorValue](TensorValue.md#max.graph.TensorValue) | [Shape](shape.md#max.graph.shape.Shape) | [Dim](dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])
* rhs (Value\[TensorType] | [TensorValue](TensorValue.md#max.graph.TensorValue) | [Shape](shape.md#max.graph.shape.Shape) | [Dim](dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](TensorValue.md#max.graph.TensorValue)

</dd></dl>

### `allgather()` {#max.graph.ops.allgather}

> max.graph.ops.allgather(inputs, signal\_buffers, axis=0)

Collective allgather operation.

This op is a collective op which takes in tensors from different devices and
outputs tensors on different devices.
In particular, this operation will gather the inputs across different
devices and concatenates them along the specified dimension.
The result is then broadcasted back to the same devices that the inputs
came from.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* inputs ([Iterable](https://docs.python.org/3/library/collections.abc.html#collections.abc.Iterable)\[[TensorValue](TensorValue.md#max.graph.TensorValue)]) â€“ The input tensors to gather.
* signal\_buffers ([Iterable](https://docs.python.org/3/library/collections.abc.html#collections.abc.Iterable)\[[BufferValue](BufferValue.md#max.graph.BufferValue)]) â€“ Device buffer values used for synchronization.
* axis ([int](https://docs.python.org/3/library/functions.html#int)) â€“ Dimension to concatenate the input tensors. Defaults to 0.

</dd><dt>

**Returns:**

</dt><dd>

An iterable outputs which all hold the gathered output. Each output
tensor contains the concatenation of all inputs along the specified dimension.

</dd><dt>

**Return type:**

</dt><dd>

[list](https://docs.python.org/3/library/stdtypes.html#list)\[[TensorValue](TensorValue.md#max.graph.TensorValue)]

</dd></dl>

### `argmax()` {#max.graph.ops.argmax}

> max.graph.ops.argmax(x, axis=-1)

Reduces a symbolic tensor using an argmax operation.

When provided with a tensor with all identical elements,
on CPU this will return the first element index in the tensor,
on GPU this will return an arbitrary index.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* x (Value\[TensorType] | [TensorValue](TensorValue.md#max.graph.TensorValue) | [Shape](shape.md#max.graph.shape.Shape) | [Dim](dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]]) â€“ The input tensor for the operation.
* axis ([int](https://docs.python.org/3/library/functions.html#int)) â€“ The axis along which to compute the reduction. If negative,
  indexes from the last dimension. For example, a value of -1 will
  compute the reduction along the last dimension.

</dd><dt>

**Returns:**

</dt><dd>

A symbolic tensor representing the result of the argmax operation.
The tensor will have the same rank as the input tensor, and the same
shape except along the `axis` dimension which will have size 1.

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](TensorValue.md#max.graph.TensorValue)

</dd></dl>

### `argmin()` {#max.graph.ops.argmin}

> max.graph.ops.argmin(x, axis=-1)

Reduces a symbolic tensor using an argmin operation.

When provided with a tensor with all identical elements,
on CPU this will return the first element index in the tensor,
on GPU this will return an arbitrary index.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* x (Value\[TensorType] | [TensorValue](TensorValue.md#max.graph.TensorValue) | [Shape](shape.md#max.graph.shape.Shape) | [Dim](dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]]) â€“ The input tensor for the operation.
* axis ([int](https://docs.python.org/3/library/functions.html#int)) â€“ The axis along which to compute the reduction. If negative,
  indexes from the last dimension. For example, a value of -1 will
  compute the reduction along the last dimension.

</dd><dt>

**Returns:**

</dt><dd>

A symbolic tensor representing the result of the argmin operation.
The tensor will have the same rank as the input tensor, and the same
shape except along the `axis` dimension which will have size 1.

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](TensorValue.md#max.graph.TensorValue)

</dd></dl>

### `argsort()` {#max.graph.ops.argsort}

> max.graph.ops.argsort(x, ascending=True)

Returns the indices that would sort a tensor.

This function returns the indices that would sort the input tensor along
its first dimension. The returned indices are of type int64.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* x (Value\[TensorType] | [TensorValue](TensorValue.md#max.graph.TensorValue) | [Shape](shape.md#max.graph.shape.Shape) | [Dim](dim.md#max.graph.dim.Dim) | HasTensorValue) â€“ Input tensor to be sorted.
* ascending ([bool](https://docs.python.org/3/library/functions.html#bool)) â€“ If True (default), sort in ascending order. If False, sort in
  descending order.

</dd><dt>

**Returns:**

</dt><dd>

A tensor of indices of the same shape as the input tensor.

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](TensorValue.md#max.graph.TensorValue)

</dd></dl>

### `as_interleaved_complex()` {#max.graph.ops.as_interleaved_complex}

> max.graph.ops.as\_interleaved\_complex(x)

Reshapes the input symbolic tensor as complex from alternating (real, imag).

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* interleaved â€“ A symbolic tensor representing complex numbers as
  alternating pairs of (real, imag) real-valued numbers. Its last
  dimension must have an even size.
* x (Value\[TensorType] | [TensorValue](TensorValue.md#max.graph.TensorValue) | [Shape](shape.md#max.graph.shape.Shape) | [Dim](dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])

</dd><dt>

**Returns:**

</dt><dd>

A symbolic tensor representing the complex-valued tensor, but with the
values pulled out as complex numbers. The result has the same dimensions
for all dimensions except the last dimension, which is halved,
and then a final dimension of size 2 representing the complex value.

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](TensorValue.md#max.graph.TensorValue)

</dd></dl>

### `atanh()` {#max.graph.ops.atanh}

> max.graph.ops.atanh(x)

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

x (Value\[TensorType] | [TensorValue](TensorValue.md#max.graph.TensorValue) | [Shape](shape.md#max.graph.shape.Shape) | [Dim](dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](TensorValue.md#max.graph.TensorValue)

</dd></dl>

### `avg_pool2d()` {#max.graph.ops.avg_pool2d}

> max.graph.ops.avg\_pool2d(input, kernel\_size, stride=1, dilation=1, padding=0, ceil\_mode=False, count\_boundary=True)

Perform a 2D average pooling operation on the input tensor.

This function applies a 2D average pooling operation to the input tensor \[N, H, W, C].
The pooling operation slides a window of size kernel\_size over the input
tensor, and computes the average value within each window.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* input (Value\[TensorType] | [TensorValue](TensorValue.md#max.graph.TensorValue) | [Shape](shape.md#max.graph.shape.Shape) | [Dim](dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]]) â€“ The input tensor to perform the pooling operation on.
* kernel\_size ([tuple](https://docs.python.org/3/library/stdtypes.html#tuple)\[[int](https://docs.python.org/3/library/functions.html#int) | [str](https://docs.python.org/3/library/stdtypes.html#str) | [Dim](dim.md#max.graph.dim.Dim) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)], [int](https://docs.python.org/3/library/functions.html#int) | [str](https://docs.python.org/3/library/stdtypes.html#str) | [Dim](dim.md#max.graph.dim.Dim) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]) â€“ The size of the sliding blocks.
* stride ([int](https://docs.python.org/3/library/functions.html#int) | [tuple](https://docs.python.org/3/library/stdtypes.html#tuple)\[[int](https://docs.python.org/3/library/functions.html#int), [int](https://docs.python.org/3/library/functions.html#int)]) â€“ The stride of the sliding blocks in the input dimension.
* dilation ([int](https://docs.python.org/3/library/functions.html#int) | [tuple](https://docs.python.org/3/library/stdtypes.html#tuple)\[[int](https://docs.python.org/3/library/functions.html#int), [int](https://docs.python.org/3/library/functions.html#int)]) â€“ The spacing between the kernel elements.
* padding ([int](https://docs.python.org/3/library/functions.html#int) | [tuple](https://docs.python.org/3/library/stdtypes.html#tuple)\[[int](https://docs.python.org/3/library/functions.html#int), [int](https://docs.python.org/3/library/functions.html#int)]) â€“ 0-paddings to be added on both sides of the inputs.
* ceil\_mode ([bool](https://docs.python.org/3/library/functions.html#bool)) â€“ If true, use ceil instead of floor to compute the output shape.
* count\_boundary ([bool](https://docs.python.org/3/library/functions.html#bool)) â€“ If true, count the padding elements when computing the average.

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](TensorValue.md#max.graph.TensorValue)

</dd></dl>

### `band_part()` {#max.graph.ops.band_part}

> max.graph.ops.band\_part(x, num\_lower=None, num\_upper=None, exclude=False)

Masks out everything except a diagonal band of an input matrix.

Copies a tensor setting everything outside the central diagonal band of the
matrices to zero, where all but the last two axes are effectively batches,
and the last two axes define sub matrices.

Assumes the input has dimensions \[I, J, â€¦, M, N], then the output tensor
has the same shape as the input, and the values are given by

```python
out[i, j, ..., m, n] = in_band(m, n) * input[i, j,  ..., m, n].
```

with the indicator function:

```python
in_band(m, n) = ((num_lower is None || (m - n) <= num_lower)) &&
                (num_upper is None || (n - m) <= num_upper))
```

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* input â€“ The input to mask out.
* num\_lower ([int](https://docs.python.org/3/library/functions.html#int) | None) â€“ The number of diagonal bands to include below the central
  diagonal. If None, include the entire lower triangle.
* num\_upper ([int](https://docs.python.org/3/library/functions.html#int) | None) â€“ The number of diagonal bands to include above the central
  diagonal. If None, include the entire upper triangle.
* exclude ([bool](https://docs.python.org/3/library/functions.html#bool)) â€“ If true, invert the selection of elements to mask. Elements
  in the band are set to zero.
* x (Value\[TensorType] | [TensorValue](TensorValue.md#max.graph.TensorValue) | [Shape](shape.md#max.graph.shape.Shape) | [Dim](dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])

</dd><dt>

**Returns:**

</dt><dd>

A symbolic tensor value with the configured selection masked out
to 0 values, and the remaining values copied from the input tensor.

</dd><dt>

**Raises:**

</dt><dd>

[ValueError](https://docs.python.org/3/library/exceptions.html#ValueError) â€“ If the input tensor rank is less than 2, or if num\_lower/num\_upper
are out of bounds for statically known dimensions.

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](TensorValue.md#max.graph.TensorValue)

</dd></dl>

### `broadcast_to()` {#max.graph.ops.broadcast_to}

> max.graph.ops.broadcast\_to(x, shape, out\_dims=None)

Broadcasts a symbolic tensor.

Broadcasts the input tensor to the specified shape.
Dimensions in the input must be one or match the target dimension.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* x (Value\[TensorType] | [TensorValue](TensorValue.md#max.graph.TensorValue) | [Shape](shape.md#max.graph.shape.Shape) | [Dim](dim.md#max.graph.dim.Dim) | HasTensorValue) â€“ The input symbolic tensor to broadcast.
  This tensor may not contain any dynamic dimensions.
* shape ([TensorValue](TensorValue.md#max.graph.TensorValue) | [Iterable](https://docs.python.org/3/library/collections.abc.html#collections.abc.Iterable)\[[int](https://docs.python.org/3/library/functions.html#int) | [str](https://docs.python.org/3/library/stdtypes.html#str) | [Dim](dim.md#max.graph.dim.Dim) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]) â€“ The new shape as a list of dimensions.
  Dynamic dimensions are not allowed.
* out\_dims ([Iterable](https://docs.python.org/3/library/collections.abc.html#collections.abc.Iterable)\[[int](https://docs.python.org/3/library/functions.html#int) | [str](https://docs.python.org/3/library/stdtypes.html#str) | [Dim](dim.md#max.graph.dim.Dim) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]] | None) â€“ Output dims used only for tensor-valued shape.

</dd><dt>

**Returns:**

</dt><dd>

A symbolic tensor with the same elements as the original tensor, but
in a new shape. Its symbolic shape is the same as `shape`.

</dd><dt>

**Raises:**

</dt><dd>

[ValueError](https://docs.python.org/3/library/exceptions.html#ValueError) â€“ if a tensor-valued shape is passed without out\_dims.

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](TensorValue.md#max.graph.TensorValue)

</dd></dl>

### `buffer_load()` {#max.graph.ops.buffer_load}

> max.graph.ops.buffer\_load(x)

Loads the input buffer into a tensor.

It loads the in-place mutable tensor to an immutable tensor graph value.
This is semantically equivalent to a copy from the mutable tensor x to the
mutable value-semantic tensor output.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

x ([BufferValue](BufferValue.md#max.graph.BufferValue)) â€“ The buffer to be loaded to a tensor.

</dd><dt>

**Returns:**

</dt><dd>

A tensor graph value representing a copy of the buffer loaded.

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](TensorValue.md#max.graph.TensorValue)

</dd></dl>

### `buffer_store()` {#max.graph.ops.buffer_store}

> max.graph.ops.buffer\_store(destination, source)

Stores the input tensor into the in-out buffer.

It stores the immutable input tensor x in the mutable tensor y.
This is semantically equivalent to a copy from x tensor to the y buffer.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* x â€“ The tensor to be stored in the buffer.
* y â€“ The buffer to store the tensor in.
* destination ([BufferValue](BufferValue.md#max.graph.BufferValue))
* source ([TensorValue](TensorValue.md#max.graph.TensorValue))

</dd><dt>

**Return type:**

</dt><dd>

None

</dd></dl>

### `buffer_store_slice()` {#max.graph.ops.buffer_store_slice}

> max.graph.ops.buffer\_store\_slice(destination, source, indices)

Stores the input tensor to into a slice in the input buffer.

It stores the immutable input tensor source in the mutable tensor destination.
This is semantically equivalent to a copy from source tensor to a slice in the
destination buffer at index specified by indices.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* destination ([BufferValue](BufferValue.md#max.graph.BufferValue)) â€“ The buffer to store the tensor in.
* source ([TensorValue](TensorValue.md#max.graph.TensorValue)) â€“ The tensor to be stored in the buffer.
* indices ([Sequence](https://docs.python.org/3/library/collections.abc.html#collections.abc.Sequence)\[[TensorValue](TensorValue.md#max.graph.TensorValue) | [int](https://docs.python.org/3/library/functions.html#int) | [slice](https://docs.python.org/3/library/functions.html#slice) | [tuple](https://docs.python.org/3/library/stdtypes.html#tuple)\[[slice](https://docs.python.org/3/library/functions.html#slice), [int](https://docs.python.org/3/library/functions.html#int) | [str](https://docs.python.org/3/library/stdtypes.html#str) | [Dim](dim.md#max.graph.dim.Dim) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]] | builtins.ellipsis]) â€“ The index in the buffer where the tensor should be stored

</dd><dt>

**Return type:**

</dt><dd>

None

</dd></dl>

### `call()` {#max.graph.ops.call}

> max.graph.ops.call(graph, \*args, prefix='')

Call a graph with the provided arguments and return its results.

This function invokes a previously defined graph, passing in the provided
arguments and the current chain value, and returns the results.

The body of the graph is ultimately inlined into the caller, so the chain
value is only used for serialization if the subgraphâ€™s body contains an
operation that makes use of it in the first place.

The current advantage of using subgraphs is that it offers a way to improve
compile times for operations that are used repeatedly in a model. As a
secondary benefit, it also makes the IR more readable by allowing control
flow to be expressed in a more natural way.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* graph ([Graph](Graph.md#max.graph.Graph)) â€“ The graph to call
* \*args ([Value](Value.md#max.graph.Value)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]) â€“ Arguments to pass to the called graph
* prefix ([str](https://docs.python.org/3/library/stdtypes.html#str)) â€“ Prefix to add to the names of any weights in the subgraph

</dd><dt>

**Returns:**

</dt><dd>

Either a single Value or a list of Values representing the graph outputs
(excluding the chain value which is handled internally)

</dd><dt>

**Return type:**

</dt><dd>

[list](https://docs.python.org/3/library/stdtypes.html#list)\[[Value](Value.md#max.graph.Value)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]

</dd></dl>

### `cast()` {#max.graph.ops.cast}

> max.graph.ops.cast(x, dtype)

Casts a symbolic tensor to a different data type.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* x (Value\[TensorType] | [TensorValue](TensorValue.md#max.graph.TensorValue) | [Shape](shape.md#max.graph.shape.Shape) | [Dim](dim.md#max.graph.dim.Dim) | HasTensorValue) â€“ The input tensor to cast.
* dtype ([DType](../dtype.md#max.dtype.DType)) â€“ The target dtype to which the tensor is cast.

</dd><dt>

**Returns:**

</dt><dd>

A new symbolic tensor with the same shape as the input and the
specified dtype.

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](TensorValue.md#max.graph.TensorValue)

</dd></dl>

### `chunk()` {#max.graph.ops.chunk}

> max.graph.ops.chunk(x, chunks, axis=0)

Chunk the tensor into an exact number of chunks along the specified dim.

**Example:**

```pycon
>>> a = TensorValue([1, 2, 3, 4, 5])
>>> chunk(a, 2, 0)
[TensorValue([1, 2]), TensorValue([3, 4])]
```

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* x (Value\[TensorType] | [TensorValue](TensorValue.md#max.graph.TensorValue) | [Shape](shape.md#max.graph.shape.Shape) | [Dim](dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]]) â€“ The tensor to chunk.
* chunks ([int](https://docs.python.org/3/library/functions.html#int)) â€“ The number of chunks to split the tensor into.
  chunks must statically evenly divide x.shape\[axis].
* axis ([int](https://docs.python.org/3/library/functions.html#int)) â€“ The axis to split the tensor along.

</dd><dt>

**Returns:**

</dt><dd>

A list of chunks tensors.

</dd><dt>

**Return type:**

</dt><dd>

[list](https://docs.python.org/3/library/stdtypes.html#list)\[[TensorValue](TensorValue.md#max.graph.TensorValue)]

</dd></dl>

### `concat()` {#max.graph.ops.concat}

> max.graph.ops.concat(original\_vals, axis=0)

Concatenates a list of symbolic tensors along an axis.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* original\_vals ([Iterable](https://docs.python.org/3/library/collections.abc.html#collections.abc.Iterable)\[Value\[TensorType] | [TensorValue](TensorValue.md#max.graph.TensorValue) | [Shape](shape.md#max.graph.shape.Shape) | [Dim](dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]]]) â€“ A list of symbolic tensor values. Each tensor must have the same
  dtype and rank, and must have the same dimension size for each
  dimension other than `axis`.
* axis ([int](https://docs.python.org/3/library/functions.html#int)) â€“ The axis to concatenate along. If negative, indexes relative
  to the end of the tensor shape. For instance, `concat(vs, -1)`
  will concat along the last dimension.

</dd><dt>

**Returns:**

</dt><dd>

A new symbolic tensor representing the concatenation result. It will
have the same rank as each input tensor, and its dimensions will be the same
as each input tensorâ€™s for each dimension other than axis, which will
have size equal to the sum of all tensorâ€™s size for that dimension.

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](TensorValue.md#max.graph.TensorValue)

</dd></dl>

### `cond()` {#max.graph.ops.cond}

> max.graph.ops.cond(pred, out\_types, then\_fn, else\_fn)

Conditionally execute one of two branches based on a boolean predicate.

Both branches must return the same number and types of values as specified
in `out_types`. Buffer mutations in branches are tracked automatically
through the chain mechanism.

Examples:

1. Basic conditional with return values:
   > ```python
   > def then_fn():
   >     return ops.constant(1, DType.int32, device=DeviceRef.CPU())
   > def else_fn():
   >     return ops.constant(0, DType.int32, device=DeviceRef.CPU())
   > â€‹
   > result = ops.cond(
   >     pred,
   >     [TensorType(DType.int32, [], device=device)],
   >     then_fn,
   >     else_fn
   > )
   > ```
2. Conditional with buffer mutations:
   > ```python
   > def then_fn():
   >     ops.inplace_custom("increment", device=buffer.device, values=[buffer])
   > def else_fn():
   >     ops.inplace_custom("decrement", device=buffer.device, values=[buffer])
   > â€‹
   > ops.cond(pred, None, then_fn, else_fn)
   > ```

::
:param pred: Boolean scalar tensor of type `DType.bool` determining branch execution
:param out\_types: Expected output types for both branches. Use [`None`](https://docs.python.org/3/library/constants.html#None) for branches that donâ€™t return values
:param then\_fn: Callable executed when `pred` is True. Must return values matching `out_types` if `out_types` is not [`None`](https://docs.python.org/3/library/constants.html#None)
:param else\_fn: Callable executed when `pred` is False. Must return values matching `out_types` if `out_types` is not [`None`](https://docs.python.org/3/library/constants.html#None)

<dl class='field-list'><dt>

**Returns:**

</dt><dd>

List of output values from executed branch. Returns empty list when `out_types`
is [`None`](https://docs.python.org/3/library/constants.html#None)

</dd><dt>

**Raises:**

</dt><dd>

[ValueError](https://docs.python.org/3/library/exceptions.html#ValueError) â€“ If branches return different numbers of results or result types
donâ€™t match `out_types`

</dd><dt>

**Parameters:**

</dt><dd>

* pred (Value\[TensorType] | [TensorValue](TensorValue.md#max.graph.TensorValue) | [Shape](shape.md#max.graph.shape.Shape) | [Dim](dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])
* out\_types ([Iterable](https://docs.python.org/3/library/collections.abc.html#collections.abc.Iterable)\[[Type](type.md#max.graph.type.Type)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]] | None)
* then\_fn ([Callable](https://docs.python.org/3/library/typing.html#typing.Callable)\[\[], [Iterable](https://docs.python.org/3/library/collections.abc.html#collections.abc.Iterable)\[[Value](Value.md#max.graph.Value)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]] | [Value](Value.md#max.graph.Value)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | None])
* else\_fn ([Callable](https://docs.python.org/3/library/typing.html#typing.Callable)\[\[], [Iterable](https://docs.python.org/3/library/collections.abc.html#collections.abc.Iterable)\[[Value](Value.md#max.graph.Value)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]] | [Value](Value.md#max.graph.Value)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | None])

</dd><dt>

**Return type:**

</dt><dd>

[list](https://docs.python.org/3/library/stdtypes.html#list)\[[TensorValue](TensorValue.md#max.graph.TensorValue)]

</dd></dl>

##### NOTE

Buffer operations in branches automatically update the global chain state to
maintain mutation ordering constraints

### `constant()` {#max.graph.ops.constant}

> max.graph.ops.constant(value, dtype, device)

Adds a node representing a constant operation.

The value of this constant will have the type TensorType with the
same shape as value. If value is a scalar type, it will create a TensorType with 0 dimensions.

The constant will be loaded with the specified dtype.
If the constant does not fit within the specified dtype, an error is raised.

Warning: Loading the constant could result in precision loss.
For example, loading 16777217 as a float32 will result in 16777216.0.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* value ([ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]] | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]) â€“ The constantâ€™s value.
* dtype ([DType](../dtype.md#max.dtype.DType)) â€“ The constant tensorâ€™s element type.
* device ([Device](../driver.md#max.driver.Device) | [DeviceRef](type.md#max.graph.type.DeviceRef)) â€“ The device the constant lives on.

</dd><dt>

**Returns:**

</dt><dd>

A graph value containing the constant data as an attribute.

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](TensorValue.md#max.graph.TensorValue)

</dd></dl>

### `constant_external()` {#max.graph.ops.constant_external}

> max.graph.ops.constant\_external(name, type)

Registers an external constant (weight) in the graph of a given type.

Two external constants with the same name and type refer to the same weight.

Two external constants with the same name and different types are
incompatible and will fail compilation.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* name ([str](https://docs.python.org/3/library/stdtypes.html#str)) â€“ The name of the external constant.
  This should be the fully-qualified weight name and must be unique.
* type ([TensorType](type.md#max.graph.type.TensorType)) â€“ The type of the constant value.

</dd><dt>

**Returns:**

</dt><dd>

A tensor value of the specified type, representing the weight value
associated with the name at compile time.

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](TensorValue.md#max.graph.TensorValue)

</dd></dl>

### `conv2d()` {#max.graph.ops.conv2d}

> max.graph.ops.conv2d(x, filter, stride=(1, 1), dilation=(1, 1), padding=(0, 0, 0, 0), groups=1, bias=None, input\_layout=ConvInputLayout.NHWC, filter\_layout=FilterLayout.RSCF)

Computes the 2-D convolution product of the input with the given filter, bias,
strides, dilations, paddings, and groups.

The op supports 2-D convolution, with the following layout assumptions:

* input x has NHWC layout, i.e.,
  (batch\_size, height, width, in\_channels)
* filter has layout RSCF, i.e.,
  (height, width, in\_channels / num\_groups, out\_channels)
* bias has shape (out\_channels,)

The padding values are expected to take the form (pad\_dim1\_before,
pad\_dim1\_after, pad\_dim2\_before, pad\_dim2\_afterâ€¦) and represent padding
0â€™s before and after the indicated spatial dimensions in input. In 2-D
convolution, dim1 here represents H and dim2 represents W. In Python like
syntax, padding a 2x3 spatial input with \[0, 1, 2, 1] would yield:

```python
input = [
  [1, 2, 3],
  [4, 5, 6]
]
## Shape is 2x3

padded_input = [
  [0, 0, 1, 2, 3, 0],
  [0, 0, 4, 5, 6, 0],
  [0, 0, 0, 0, 0, 0]
]
## Shape is 3x6
```

This op currently only supports strides and padding on the input.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* input â€“ An NHWC input tensor to perform the convolution upon.
* filter (Value\[TensorType] | [TensorValue](TensorValue.md#max.graph.TensorValue) | [Shape](shape.md#max.graph.shape.Shape) | [Dim](dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]]) â€“ The convolution filter in RSCF layout:
  (height, width, in\_channels / num\_groups, out\_channels).
* stride ([tuple](https://docs.python.org/3/library/stdtypes.html#tuple)\[[int](https://docs.python.org/3/library/functions.html#int), [int](https://docs.python.org/3/library/functions.html#int)]) â€“ The stride of the convolution operation.
* dilation ([tuple](https://docs.python.org/3/library/stdtypes.html#tuple)\[[int](https://docs.python.org/3/library/functions.html#int), [int](https://docs.python.org/3/library/functions.html#int)]) â€“ The spacing between the kernel points.
* padding ([tuple](https://docs.python.org/3/library/stdtypes.html#tuple)\[[int](https://docs.python.org/3/library/functions.html#int), [int](https://docs.python.org/3/library/functions.html#int), [int](https://docs.python.org/3/library/functions.html#int), [int](https://docs.python.org/3/library/functions.html#int)]) â€“ The amount of padding applied to the input.
* groups ([int](https://docs.python.org/3/library/functions.html#int)) â€“ When greater than 1, divides the convolution into multiple
  parallel convolutions. The number of input and output
  channels must both be divisible by the number of groups.
* x (Value\[TensorType] | [TensorValue](TensorValue.md#max.graph.TensorValue) | [Shape](shape.md#max.graph.shape.Shape) | [Dim](dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])
* bias (Value\[TensorType] | [TensorValue](TensorValue.md#max.graph.TensorValue) | [Shape](shape.md#max.graph.shape.Shape) | [Dim](dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]] | None)
* input\_layout ([ConvInputLayout](type.md#max.graph.type.ConvInputLayout))
* filter\_layout ([FilterLayout](type.md#max.graph.type.FilterLayout))

</dd><dt>

**Returns:**

</dt><dd>

A symbolic tensor value with the convolution applied.

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](TensorValue.md#max.graph.TensorValue)

</dd></dl>

### `conv2d_transpose()` {#max.graph.ops.conv2d_transpose}

> max.graph.ops.conv2d\_transpose(x, filter, stride=(1, 1), dilation=(1, 1), padding=(0, 0, 0, 0), output\_paddings=(0, 0), bias=None, input\_layout=ConvInputLayout.NHWC, filter\_layout=FilterLayout.RSCF)

Computes the 2-D deconvolution of the input with the given filter,
strides, dilations, paddings, and groups.

The op supports the transpose (gradient) of convolution, with the following layout assumptions:
(note the out\_channel is w\.r.t. the original convolution)

* input x has NHWC layout, i.e.,
  (batch\_size, height, width, in\_channels)
* filter has layout RSCF, i.e.,
  (kernel\_height, kernel\_width, out\_channels, in\_channels)
* bias has shape (out\_channels,)

The padding values are expected to take the form in the form \[\[0, 0], \[pad\_top, pad\_bottom],
\[pad\_left, pad\_right], \[0, 0]].

This op effectively computes the gradient of a convolution with
respect to its input (as if the original convolution operation had the same
filter and hyperparameters as this op). A visualization of the computation
can be found in <https://d2l.ai/chapter_computer-vision/transposed-conv.html>.

The padding values are expected to take the form (pad\_dim1\_before,
pad\_dim1\_after, pad\_dim2\_before, pad\_dim2\_afterâ€¦) and represent padding
0â€™s before and after the indicated spatial dimensions in input. In 2D
ConvTranspose, dim1 here represents H\_out and dim2 represents W\_out. In
python like syntax, padding a 2x4 spatial output with \[0, 1, 2, 1] would
yield:

```python
output = [
  [1, 2, 3, 4],
  [5, 6, 7, 8]
]
## Shape is 2x4

padded_input = [
  [3],
]
## Shape is 1x1
```

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* input â€“ An NHWC input tensor to perform the convolution upon.
* filter (Value\[TensorType] | [TensorValue](TensorValue.md#max.graph.TensorValue) | [Shape](shape.md#max.graph.shape.Shape) | [Dim](dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]]) â€“ The convolution filter in RSCF layout:
  (height, width, out\_channels, in\_channels).
* stride ([tuple](https://docs.python.org/3/library/stdtypes.html#tuple)\[[int](https://docs.python.org/3/library/functions.html#int), [int](https://docs.python.org/3/library/functions.html#int)]) â€“ The stride of the sliding window for each dimension of input.
  If a single value is given it is replicated in the H and W dimension.
  By default the N and C dimensions are set to 0.
* dilation ([tuple](https://docs.python.org/3/library/stdtypes.html#tuple)\[[int](https://docs.python.org/3/library/functions.html#int), [int](https://docs.python.org/3/library/functions.html#int)]) â€“ The spacing between the kernel points.
* padding ([tuple](https://docs.python.org/3/library/stdtypes.html#tuple)\[[int](https://docs.python.org/3/library/functions.html#int), [int](https://docs.python.org/3/library/functions.html#int), [int](https://docs.python.org/3/library/functions.html#int), [int](https://docs.python.org/3/library/functions.html#int)]) â€“ The amount of padding applied to the input.
* output\_paddings ([tuple](https://docs.python.org/3/library/stdtypes.html#tuple)\[[int](https://docs.python.org/3/library/functions.html#int), [int](https://docs.python.org/3/library/functions.html#int)]) â€“ this argument is meant to resolve the ambiguity of multiple
  potential output shapes when any stride is greater than 1. Basically,
  weâ€™ll add output\_paddings\[i] number of zeros at the end of outputâ€™s ith
  axis. We only support output\_paddings = 0.
* bias (Value\[TensorType] | [TensorValue](TensorValue.md#max.graph.TensorValue) | [Shape](shape.md#max.graph.shape.Shape) | [Dim](dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]] | None) â€“ tensor of shape (out\_channels,)
* x (Value\[TensorType] | [TensorValue](TensorValue.md#max.graph.TensorValue) | [Shape](shape.md#max.graph.shape.Shape) | [Dim](dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])
* input\_layout ([ConvInputLayout](type.md#max.graph.type.ConvInputLayout))
* filter\_layout ([FilterLayout](type.md#max.graph.type.FilterLayout))

</dd><dt>

**Returns:**

</dt><dd>

A symbolic tensor value with the convolution applied.

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](TensorValue.md#max.graph.TensorValue)

</dd></dl>

### `conv3d()` {#max.graph.ops.conv3d}

> max.graph.ops.conv3d(x, filter, stride=(1, 1, 1), dilation=(1, 1, 1), padding=(0, 0, 0, 0, 0, 0), groups=1, bias=None, input\_layout=ConvInputLayout.NHWC, filter\_layout=FilterLayout.QRSCF)

Computes the 3-D convolution product of the input with the given filter,
strides, dilations, paddings, and groups.

The op supports 3-D convolution, with the following layout assumptions:

* input has NDHWC layout, i.e.,
  (batch\_size, depth, height, width, in\_channels)
* filter has layout RSCF, i.e.,
  (depth, height, width, in\_channels / num\_groups, out\_channels)

The padding values are expected to take the form (pad\_dim1\_before,
pad\_dim1\_after, pad\_dim2\_before, pad\_dim2\_afterâ€¦) and represent padding
0â€™s before and after the indicated spatial dimensions in input. In 3-D
convolution, dim1 here represents D, dim2 represents H and dim3 represents W. In Python like
syntax, padding a 2x3 spatial input with \[0, 1, 2, 1] would yield:

```python
input = [
  [1, 2, 3],
  [4, 5, 6]
]
## Shape is 2x3

padded_input = [
  [0, 0, 1, 2, 3, 0],
  [0, 0, 4, 5, 6, 0],
  [0, 0, 0, 0, 0, 0]
]
## Shape is 3x6
```

This op currently only supports strides and padding on the input.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* x (Value\[TensorType] | [TensorValue](TensorValue.md#max.graph.TensorValue) | [Shape](shape.md#max.graph.shape.Shape) | [Dim](dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]]) â€“ An NDHWC input tensor to perform the convolution upon.
* filter (Value\[TensorType] | [TensorValue](TensorValue.md#max.graph.TensorValue) | [Shape](shape.md#max.graph.shape.Shape) | [Dim](dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]]) â€“ The convolution filter in RSCF layout:
  (depth, height, width, in\_channels / num\_groups, out\_channels).
* stride ([tuple](https://docs.python.org/3/library/stdtypes.html#tuple)\[[int](https://docs.python.org/3/library/functions.html#int), [int](https://docs.python.org/3/library/functions.html#int), [int](https://docs.python.org/3/library/functions.html#int)]) â€“ The stride of the convolution operation.
* dilation ([tuple](https://docs.python.org/3/library/stdtypes.html#tuple)\[[int](https://docs.python.org/3/library/functions.html#int), [int](https://docs.python.org/3/library/functions.html#int), [int](https://docs.python.org/3/library/functions.html#int)]) â€“ The spacing between the kernel points.
* padding ([tuple](https://docs.python.org/3/library/stdtypes.html#tuple)\[[int](https://docs.python.org/3/library/functions.html#int), [int](https://docs.python.org/3/library/functions.html#int), [int](https://docs.python.org/3/library/functions.html#int), [int](https://docs.python.org/3/library/functions.html#int), [int](https://docs.python.org/3/library/functions.html#int), [int](https://docs.python.org/3/library/functions.html#int)]) â€“ The amount of padding applied to the input.
* groups ([int](https://docs.python.org/3/library/functions.html#int)) â€“ When greater than 1, divides the convolution into multiple
  parallel convolutions. The number of input and output
  channels must both be divisible by the number of groups.
* bias (Value\[TensorType] | [TensorValue](TensorValue.md#max.graph.TensorValue) | [Shape](shape.md#max.graph.shape.Shape) | [Dim](dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]] | None)
* input\_layout ([ConvInputLayout](type.md#max.graph.type.ConvInputLayout))
* filter\_layout ([FilterLayout](type.md#max.graph.type.FilterLayout))

</dd><dt>

**Returns:**

</dt><dd>

A symbolic tensor value with the convolution applied.
Output shape = (batch\_size, depth, height, width, out\_channels).

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](TensorValue.md#max.graph.TensorValue)

</dd></dl>

### `cos()` {#max.graph.ops.cos}

> max.graph.ops.cos(x)

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

x (Value\[TensorType] | [TensorValue](TensorValue.md#max.graph.TensorValue) | [Shape](shape.md#max.graph.shape.Shape) | [Dim](dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](TensorValue.md#max.graph.TensorValue)

</dd></dl>

### `cumsum()` {#max.graph.ops.cumsum}

> max.graph.ops.cumsum(x, axis=-1, exclusive=False, reverse=False)

Computes the cumulative sum of the input tensor along the given axis.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* x (Value\[TensorType] | [TensorValue](TensorValue.md#max.graph.TensorValue) | [Shape](shape.md#max.graph.shape.Shape) | [Dim](dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]]) â€“ The input tensor to sum over.
* axis ([int](https://docs.python.org/3/library/functions.html#int)) â€“ The axis along which to compute the sum. If negative,
  indexes from the last dimension. For example, a value of -1 will
  compute the sum along the last dimension.
* exclusive ([bool](https://docs.python.org/3/library/functions.html#bool)) â€“ If set, start at 0 and exclude the final element.
  Otherwise, start with the first element. Said another way, cumsum
  computes \[sum(x\[â€¦, :i, â€¦]) for i in range(x.shape\[axis])].
  If exclusive is set, the bounds are instead range(1, x.shape\[axis]).
* reverse ([bool](https://docs.python.org/3/library/functions.html#bool)) â€“ If set, start from the end. In other words, the first element
  will be the total sum, with each element following counting
  downwards; or \[sum(x\[â€¦, i:, â€¦]) for i in range(x.shape\[axis])].

</dd><dt>

**Returns:**

</dt><dd>

A symbolic tensor representing the result of the cumsum operation.
The tensor will have the same type as the input tensor. The computed
values will be the cumulative sum of the values along the given axis,
according to the specified parameters:

* if exclusive is set, the first value will be 0, and the last
  value will be excluded from the sum
* if reverse is set, the sum will be computed starting at the
  back of the axis back to the front, rather than front-to-back

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](TensorValue.md#max.graph.TensorValue)

</dd></dl>

### `custom()` {#max.graph.ops.custom}

> max.graph.ops.custom(name, device, values, out\_types, parameters=None)

Creates a node to execute a custom graph operation in the graph.

The custom op should be registered by annotating a function with the
[@compiler.register](/mojo/manual/decorators/compiler-register/)
decorator.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* name ([str](https://docs.python.org/3/library/stdtypes.html#str)) â€“ The op name provided to `@compiler.register`.
* values ([Sequence](https://docs.python.org/3/library/collections.abc.html#collections.abc.Sequence)\[[Value](Value.md#max.graph.Value)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]) â€“ The op functionâ€™s arguments.
* out\_types ([Sequence](https://docs.python.org/3/library/collections.abc.html#collections.abc.Sequence)\[[Type](type.md#max.graph.type.Type)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]) â€“ The list of op functionâ€™s return type.
* parameters ([Mapping](https://docs.python.org/3/library/collections.abc.html#collections.abc.Mapping)\[[str](https://docs.python.org/3/library/stdtypes.html#str), [bool](https://docs.python.org/3/library/functions.html#bool) | [int](https://docs.python.org/3/library/functions.html#int) | [str](https://docs.python.org/3/library/stdtypes.html#str) | [DType](../dtype.md#max.dtype.DType)] | None) â€“ Dictionary of extra parameters expected by the kernel.
* device ([DeviceRef](type.md#max.graph.type.DeviceRef)) â€“ Device that the op is assigned to.
  This becomes a target parameter to the kernel.

</dd><dt>

**Returns:**

</dt><dd>

Symbolic values representing the outputs of the op in the graph.
These correspond 1:1 with the types passed as `out_types`.

</dd><dt>

**Return type:**

</dt><dd>

[list](https://docs.python.org/3/library/stdtypes.html#list)\[[Value](Value.md#max.graph.Value)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]

</dd></dl>

### `dequantize()` {#max.graph.ops.dequantize}

> max.graph.ops.dequantize(encoding, quantized)

Dequantizes a quantized tensor to floating point.

NOTE: Currently this supports Q4\_0, Q4\_K, and Q6\_K encodings only.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* encoding ([QuantizationEncoding](quantization.md#max.graph.quantization.QuantizationEncoding)) â€“ The quantization encoding to use.
* quantized ([TensorValue](TensorValue.md#max.graph.TensorValue)) â€“ The quantized tensor to dequantize.

</dd><dt>

**Returns:**

</dt><dd>

The dequantized result (a floating point tensor).

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](TensorValue.md#max.graph.TensorValue)

</dd></dl>

### `div()` {#max.graph.ops.div}

> max.graph.ops.div(lhs, rhs)

Divides two symbolic tensors using true division (Python operator /).

For integer operands, this performs true division by promoting to float,
matching Pythonâ€™s / operator behavior. For floating-point operands,
this performs standard floating-point division.

Creates a new op node to compute the division of two symbol tensor values
and adds it to the graph, returning the symbolic result.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* lhs (Value\[TensorType] | [TensorValue](TensorValue.md#max.graph.TensorValue) | [Shape](shape.md#max.graph.shape.Shape) | [Dim](dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]]) â€“ The symbol to use as left side of the division.
* rhs (Value\[TensorType] | [TensorValue](TensorValue.md#max.graph.TensorValue) | [Shape](shape.md#max.graph.shape.Shape) | [Dim](dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]]) â€“ The symbol to use as right side of the division.

</dd><dt>

**Returns:**

</dt><dd>

A symbolic tensor value representing the output of the division. The
result will have:
: - floating-point dtype for integer operands, promoted dtype for mixed types

* the same shape as the broadcast of the two input shapes.

</dd><dt>

**Raises:**

</dt><dd>

* Error â€“ If the input valuesâ€™ shapes are not compatible for broadcasting.
* Error â€“ If one of the input values has an unsupported dtype.
* Error â€“ If the two symbols are parts of different graphs.

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](TensorValue.md#max.graph.TensorValue)

</dd></dl>

### `equal()` {#max.graph.ops.equal}

> max.graph.ops.equal(lhs, rhs)

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* lhs (Value\[TensorType] | [TensorValue](TensorValue.md#max.graph.TensorValue) | [Shape](shape.md#max.graph.shape.Shape) | [Dim](dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])
* rhs (Value\[TensorType] | [TensorValue](TensorValue.md#max.graph.TensorValue) | [Shape](shape.md#max.graph.shape.Shape) | [Dim](dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](TensorValue.md#max.graph.TensorValue)

</dd></dl>

### `erf()` {#max.graph.ops.erf}

> max.graph.ops.erf(x)

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

x (Value\[TensorType] | [TensorValue](TensorValue.md#max.graph.TensorValue) | [Shape](shape.md#max.graph.shape.Shape) | [Dim](dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](TensorValue.md#max.graph.TensorValue)

</dd></dl>

### `exp()` {#max.graph.ops.exp}

> max.graph.ops.exp(x)

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

x (Value\[TensorType] | [TensorValue](TensorValue.md#max.graph.TensorValue) | [Shape](shape.md#max.graph.shape.Shape) | [Dim](dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](TensorValue.md#max.graph.TensorValue)

</dd></dl>

### `fence()` {#max.graph.ops.fence}

> max.graph.ops.fence(\*values)

Returns the input value(s) unchanged, serving as a scheduling barrier.

This operation is a pure identity on values but prevents the asynchronous
runtime from reordering operations across it. This is critical when dealing
with operations that have implicit cross-device synchronization
requirements.

The primary use case is preventing deadlocks with distributed operations
that are implemented as per-device ops with implicit synchronization:

```python
## Example: Per-device collective operations (illustrative).
## NOTE: ops.custom("allreduce", ...) is a hypothetical per-device
## user-defined allreduce op -- not a public API.
with Graph("distributed_example", input_types=input_types) as g:
    x0, x1, x2 = g.inputs  # Inputs on GPU(0), GPU(1), GPU(2)

#    # Each device runs its own allreduce operation instance.
#    # These ops implicitly synchronize with each other.
    result_gpu0 = ops.custom("allreduce", device=DeviceRef.GPU(0),
                            inputs=[x0, x1, x2])
    result_gpu1 = ops.custom("allreduce", device=DeviceRef.GPU(1),
                            inputs=[x0, x1, x2])
    result_gpu2 = ops.custom("allreduce", device=DeviceRef.GPU(2),
                            inputs=[x0, x1, x2])

#    # DANGER: Without fence, the async runtime might reorder the
#    # transfer to happen before all allreduce ops are enqueue'd.
#    # This causes deadlock:
#    # - GPU0's transfer waits for result_gpu1.
#    # - GPU1's allreduce waits for GPU0 to reach its allreduce.
#    # - But GPU0 can't reach its allreduce because it's blocked on
#    #   transfer.

#    # Solution: fence all results to prevent any reordering.
    [result_gpu0, result_gpu1, result_gpu2] = ops.fence(
        result_gpu0, result_gpu1, result_gpu2
    )

#    # Now safe - transfers cannot be reordered before the fence.
#    # NOTE: The following are each enqueue'd on GPU0's stream.
    y0 = ops.transfer_to(result_gpu1, DeviceRef.GPU(0))
    y1 = ops.transfer_to(result_gpu2, DeviceRef.GPU(0))
    g.output(result_gpu0, y0, y1)
```

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

values ([Value](Value.md#max.graph.Value)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]) â€“ One or more values to fence as variadic arguments.

</dd><dt>

**Returns:**

</dt><dd>

A list containing the same input value(s) unchanged, preserving order.

</dd><dt>

**Raises:**

</dt><dd>

[ValueError](https://docs.python.org/3/library/exceptions.html#ValueError) â€“ If no input values are provided.

</dd><dt>

**Return type:**

</dt><dd>

[list](https://docs.python.org/3/library/stdtypes.html#list)\[[Value](Value.md#max.graph.Value)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]

</dd></dl>

### `flatten()` {#max.graph.ops.flatten}

> max.graph.ops.flatten(x, start\_dim=0, end\_dim=-1)

Flattens the specified dims of a symbolic tensor.

The number and order of the elements in the tensor is unchanged.
All dimensions from start\_dim to end\_dim (inclusive) are merged into a single output dim.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* x (Value\[TensorType] | [TensorValue](TensorValue.md#max.graph.TensorValue) | [Shape](shape.md#max.graph.shape.Shape) | [Dim](dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])
* start\_dim ([int](https://docs.python.org/3/library/functions.html#int))
* end\_dim ([int](https://docs.python.org/3/library/functions.html#int))

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](TensorValue.md#max.graph.TensorValue)

</dd></dl>

### `floor()` {#max.graph.ops.floor}

> max.graph.ops.floor(x)

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

x (Value\[TensorType] | [TensorValue](TensorValue.md#max.graph.TensorValue) | [Shape](shape.md#max.graph.shape.Shape) | [Dim](dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](TensorValue.md#max.graph.TensorValue)

</dd></dl>

### `fold()` {#max.graph.ops.fold}

> max.graph.ops.fold(input, output\_size, kernel\_size, stride=1, dilation=1, padding=0)

Combines an array of sliding blocks into a larger containing tensor.

The input tensor must have shape `(N, C * kernel_sizes, L)` where `N` is
the batch dimension, `C` is the number of channels, `kernel_sizes` is
the product of the kernel sizes, and `L` is the number of local blocks.

The resulting output tensor will have shape
`(N, C, output_shape[0], output_shape[1])`.

`L`, the number of blocks, must be equivalent to:
`prod((output_size[d] + 2 * padding[d] - dilation[d] * (kernel_size[d] - 1) - 1) / stride[d] + 1)`

where `d` is over all spatial dimensions.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* input (Value\[TensorType] | [TensorValue](TensorValue.md#max.graph.TensorValue) | [Shape](shape.md#max.graph.shape.Shape) | [Dim](dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]]) â€“ The 3D tensor to fold with shape `(N, C * kernel sizes, L)`.
* output\_size ([tuple](https://docs.python.org/3/library/stdtypes.html#tuple)\[[int](https://docs.python.org/3/library/functions.html#int) | [str](https://docs.python.org/3/library/stdtypes.html#str) | [Dim](dim.md#max.graph.dim.Dim) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)], [int](https://docs.python.org/3/library/functions.html#int) | [str](https://docs.python.org/3/library/stdtypes.html#str) | [Dim](dim.md#max.graph.dim.Dim) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]) â€“ Spatial dimensions of the output tensor. Must be a tuple of two ints.
* kernel\_size ([tuple](https://docs.python.org/3/library/stdtypes.html#tuple)\[[int](https://docs.python.org/3/library/functions.html#int) | [str](https://docs.python.org/3/library/stdtypes.html#str) | [Dim](dim.md#max.graph.dim.Dim) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)], [int](https://docs.python.org/3/library/functions.html#int) | [str](https://docs.python.org/3/library/stdtypes.html#str) | [Dim](dim.md#max.graph.dim.Dim) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]) â€“ The size of the sliding blocks. Must be a tuple of two ints.
* stride ([int](https://docs.python.org/3/library/functions.html#int) | [tuple](https://docs.python.org/3/library/stdtypes.html#tuple)\[[int](https://docs.python.org/3/library/functions.html#int), [int](https://docs.python.org/3/library/functions.html#int)]) â€“ The stride of the sliding blocks in the input dimension
  (can be an int or a tuple of two ints).
* dilation ([int](https://docs.python.org/3/library/functions.html#int) | [tuple](https://docs.python.org/3/library/stdtypes.html#tuple)\[[int](https://docs.python.org/3/library/functions.html#int), [int](https://docs.python.org/3/library/functions.html#int)]) â€“ The spacing between the kernel elements.
  (can be an int or a tuple of two ints).
* padding ([int](https://docs.python.org/3/library/functions.html#int) | [tuple](https://docs.python.org/3/library/stdtypes.html#tuple)\[[int](https://docs.python.org/3/library/functions.html#int), [int](https://docs.python.org/3/library/functions.html#int)]) â€“ 0-paddings to be added on both sides of the inputs.
  (can be an int or a tuple of two ints).

</dd><dt>

**Returns:**

</dt><dd>

The folded 4D tensor with shape `(N, C, output_shape[0], output_shape[1])`.

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](TensorValue.md#max.graph.TensorValue)

</dd></dl>

### `gather()` {#max.graph.ops.gather}

> max.graph.ops.gather(input, indices, axis=-1)

Selects elements out of an input tensor by index.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* input (Value\[TensorType] | [TensorValue](TensorValue.md#max.graph.TensorValue) | [Shape](shape.md#max.graph.shape.Shape) | [Dim](dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]]) â€“ The input symbolic tensor to select elements from.
* indices (Value\[TensorType] | [TensorValue](TensorValue.md#max.graph.TensorValue) | [Shape](shape.md#max.graph.shape.Shape) | [Dim](dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]]) â€“ A symbolic tensor of index values to use for selection.
* axis ([int](https://docs.python.org/3/library/functions.html#int)) â€“ The dimension which `indices` indexes from `input`.
  If negative, indexes relative to the end of the input tensor.
  For instance, `gather(input, indices, axis=-1)` will index
  against the last dimension of `input`.

</dd><dt>

**Returns:**

</dt><dd>

A new symbolic tensor representing the result of the gather operation.

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](TensorValue.md#max.graph.TensorValue)

</dd></dl>

### `gather_nd()` {#max.graph.ops.gather_nd}

> max.graph.ops.gather\_nd(input, indices, batch\_dims=0)

Selects elements out of an input tensor by N-dimensional index.

This operation performs N-dimensional indexing into `input` using `indices`.
Unlike [`gather()`](#max.graph.ops.gather), which indexes along a single axis, `gather_nd()` allows
indexing along multiple dimensions simultaneously.

```python
input_shape = ["a", "b", "c", "d", "e"]
indices_shape = ["a", "f", 3]
input_type = TensorType(DType.bfloat16, input_shape)
indices_type = TensorType(DType.int32, indices_shape)
with Graph("gather_nd", input_types=[input_type, indices_type]) as graph:
    input, indices = graph.inputs
    gathered = ops.gather_nd(input, indices, batch_dims=1)
    print(gathered.type)
## Output: TensorType(dtype=DType.bfloat16, shape=["a", "f", "e"])
```

In this example:

* `batch_dims` is 1, so thereâ€™s 1 shared dimension at the beginning.
* `indices` has an additional dimension â€œfâ€ which becomes part of the output.
* The last dimension of `indices` is the index vector; values in this vector
  are interpreted to be indices into â€œbâ€, â€œcâ€, and â€œdâ€.
* Since `batch_dims (1) + index size (3) < input.rank (5)`, the remaining
  dimensions (in this case â€œeâ€) are sliced into the output as features.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* input (Value\[TensorType] | [TensorValue](TensorValue.md#max.graph.TensorValue) | [Shape](shape.md#max.graph.shape.Shape) | [Dim](dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]]) â€“ The input symbolic tensor to select elements from.
* indices (Value\[TensorType] | [TensorValue](TensorValue.md#max.graph.TensorValue) | [Shape](shape.md#max.graph.shape.Shape) | [Dim](dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]]) â€“ A symbolic tensor of index values to use for selection.
  The last dimension of this tensor must be static. This dimension
  will be used to index or slice into `input` immediately following
  `batch_dims` initial dimensions. The size of this index dimension
  is the number of dimensions it specifies.
* batch\_dims ([int](https://docs.python.org/3/library/functions.html#int)) â€“ The number of leading batch dimensions shared by
  `input` and `indices`; 0 by default. `input` and `indices` must
  exactly match up to their first `batch_dims` dimensions. This
  function does not broadcast.

</dd><dt>

**Returns:**

</dt><dd>

A new symbolic tensor representing the result of the gather operation.
The output will have the same dtype as `input`, and will have shape
depending on the inputs, in this order:

* `input.shape[:batch_dims]` â€“ The â€œbroadcastâ€ dimensions (though note
  that this function does not broadcast). These dimensions must be
  identical between `input` and `indices`.
* `indices.shape[batch_dims:-1]` â€“ The â€œgatherâ€ dimensions; this allows
  multi-dimensional tensors of indices. The last dimension is the index vector.
* `input.shape[batch_dims + indices.shape[-1]:]` â€“ The â€œsliceâ€ dimensions.
  If `batch_dims` < `input.rank - indices.shape[-1]` (again, this last
  is the index vector), then any following dimensions of the inputs are
  taken entirely as though slicing.

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](TensorValue.md#max.graph.TensorValue)

</dd></dl>

### `gelu()` {#max.graph.ops.gelu}

> max.graph.ops.gelu(x, approximate='none')

Computes the elementwise gelu of a symbolic tensor.

Creates a new op node to compute the elementwise gelu of a
symbolic tensor and adds it to the graph, returning the symbolic result.

For `approximate == "none"`, the exact gelu function is computed.

For `approximate == "tanh"`, the approximation:

$$
gelu(x) = 0.5 * x * (1.0 + tanh(0.7978845608028654 * (x + 0.044715 * x**3)))
$$

is used.

For `approximate == "quick"`, the approximation:

$$
gelu(x) = sigmoid(1.702 * x) * x
$$

is used.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* value â€“ The symbolic tensor to use as the input to the gelu
  computation.
* x ([TensorValue](TensorValue.md#max.graph.TensorValue))
* approximate ([str](https://docs.python.org/3/library/stdtypes.html#str))

</dd><dt>

**Returns:**

</dt><dd>

A new symbolic tensor value representing the output of the gelu
value computation.

</dd><dt>

**Raises:**

</dt><dd>

* Error â€“ If the symbol doesnâ€™t represent a tensor value.
* [ValueError](https://docs.python.org/3/library/exceptions.html#ValueError) â€“ If the approximation method is invalid.

</dd></dl>

### `greater()` {#max.graph.ops.greater}

> max.graph.ops.greater(lhs, rhs)

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* lhs (Value\[TensorType] | [TensorValue](TensorValue.md#max.graph.TensorValue) | [Shape](shape.md#max.graph.shape.Shape) | [Dim](dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])
* rhs (Value\[TensorType] | [TensorValue](TensorValue.md#max.graph.TensorValue) | [Shape](shape.md#max.graph.shape.Shape) | [Dim](dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](TensorValue.md#max.graph.TensorValue)

</dd></dl>

### `greater_equal()` {#max.graph.ops.greater_equal}

> max.graph.ops.greater\_equal(lhs, rhs)

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* lhs (Value\[TensorType] | [TensorValue](TensorValue.md#max.graph.TensorValue) | [Shape](shape.md#max.graph.shape.Shape) | [Dim](dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])
* rhs (Value\[TensorType] | [TensorValue](TensorValue.md#max.graph.TensorValue) | [Shape](shape.md#max.graph.shape.Shape) | [Dim](dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](TensorValue.md#max.graph.TensorValue)

</dd></dl>

### `hann_window()` {#max.graph.ops.hann_window}

> max.graph.ops.hann\_window(window\_length, device, periodic=True, dtype=float32)

Calculate a Hann window for a given length.

Hann window function:

$$
H[n] = 1/2 [1 - cos(2 * pi * n / (N - 1))]
$$

where N is window\_length.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* window\_length ([int](https://docs.python.org/3/library/functions.html#int)) â€“ The length of the window.
* device ([DeviceRef](type.md#max.graph.type.DeviceRef)) â€“ The device to run the operation on.
* periodic ([bool](https://docs.python.org/3/library/functions.html#bool)) â€“ bool
  flag determines whether the returned window trims off the last
  duplicate value from the symmetric window and is ready to be used
  as a periodic window with functions like stft().
  hann\_window(L, periodic=True) == hann\_window(L + 1, periodic=False)\[:-1])
* dtype ([DType](../dtype.md#max.dtype.DType)) â€“ The desired data type of the output tensor.

</dd><dt>

**Returns:**

</dt><dd>

A 1-D tensor of size (window\_length,) containing the window.

</dd><dt>

**Raises:**

</dt><dd>

* [ValueError](https://docs.python.org/3/library/exceptions.html#ValueError) â€“ If window\_length is negative.
* [TypeError](https://docs.python.org/3/library/exceptions.html#TypeError) â€“ If window\_length is not an integer.

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](TensorValue.md#max.graph.TensorValue)

</dd></dl>

### `inplace_custom()` {#max.graph.ops.inplace_custom}

> max.graph.ops.inplace\_custom(name, device, values, out\_types=None, parameters=None)

Creates a node to execute an in-place custom graph operation in the graph.

The custom op should be registered by annotating a function with the
[@compiler.register](/mojo/manual/decorators/compiler-register/)
decorator.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* name ([str](https://docs.python.org/3/library/stdtypes.html#str)) â€“ The op name provided to `@compiler.register`.
* device ([DeviceRef](type.md#max.graph.type.DeviceRef)) â€“ Device that the op is assigned to.
  This becomes a target parameter to the kernel.
* values ([Sequence](https://docs.python.org/3/library/collections.abc.html#collections.abc.Sequence)\[[Value](Value.md#max.graph.Value)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]) â€“ The op functionâ€™s arguments.
* parameters ([dict](https://docs.python.org/3/library/stdtypes.html#dict)\[[str](https://docs.python.org/3/library/stdtypes.html#str), [bool](https://docs.python.org/3/library/functions.html#bool) | [int](https://docs.python.org/3/library/functions.html#int) | [str](https://docs.python.org/3/library/stdtypes.html#str) | [DType](../dtype.md#max.dtype.DType)] | None) â€“ Dictionary of extra parameters expected by the kernel.
* out\_types ([Sequence](https://docs.python.org/3/library/collections.abc.html#collections.abc.Sequence)\[[Type](type.md#max.graph.type.Type)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]] | None)

</dd><dt>

**Return type:**

</dt><dd>

[list](https://docs.python.org/3/library/stdtypes.html#list)\[[Value](Value.md#max.graph.Value)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]

</dd></dl>

### `irfft()` {#max.graph.ops.irfft}

> max.graph.ops.irfft(input\_tensor, n=None, axis=-1, normalization=Normalization.BACKWARD, input\_is\_complex=False, buffer\_size\_mb=512)

Compute the inverse real FFT of the input tensor.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* input\_tensor (Value\[TensorType] | [TensorValue](TensorValue.md#max.graph.TensorValue) | [Shape](shape.md#max.graph.shape.Shape) | [Dim](dim.md#max.graph.dim.Dim) | HasTensorValue) â€“ The input tensor to compute the inverse real FFT of.
* n ([int](https://docs.python.org/3/library/functions.html#int) | None) â€“ The size of the output tensor. Must be an int, and cannot be a
  symbolic Tensor. The input tensor will be padded or truncated to
  n // 2 + 1 along the specified axis.
* axis ([int](https://docs.python.org/3/library/functions.html#int)) â€“ The axis to compute the inverse real FFT of.
* normalization (Normalization | [str](https://docs.python.org/3/library/stdtypes.html#str)) â€“ The normalization to apply to the output tensor.
  Can be â€œbackwardâ€, â€œorthoâ€, or â€œforwardâ€. When â€œbackwardâ€, the
  output is divided by n. When â€œorthoâ€, the output is divided by
  sqrt(n). When â€œforwardâ€, no normalization is applied.
* input\_is\_complex ([bool](https://docs.python.org/3/library/functions.html#bool)) â€“ Whether the input tensor is already interleaved
  complex. The last dimension of the input tensor must be 2, and is
  excluded from the dimension referred to by axis.
* buffer\_size\_mb ([int](https://docs.python.org/3/library/functions.html#int)) â€“ The estimated size of a persistent buffer to use for
  storage of intermediate results. Needs to be the same across multiple
  calls to irfft within the same graph. Otherwise, multiple buffers
  will be allocated.

</dd><dt>

**Returns:**

</dt><dd>

The inverse real FFT of the input tensor. The shape of the output tensor
is the same as the shape of the input tensor, except for the axis that
the inverse real FFT is computed over, which is replaced by n.

</dd></dl>

### `is_inf()` {#max.graph.ops.is_inf}

> max.graph.ops.is\_inf(x)

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

x (Value\[TensorType] | [TensorValue](TensorValue.md#max.graph.TensorValue) | [Shape](shape.md#max.graph.shape.Shape) | [Dim](dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](TensorValue.md#max.graph.TensorValue)

</dd></dl>

### `is_nan()` {#max.graph.ops.is_nan}

> max.graph.ops.is\_nan(x)

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

x (Value\[TensorType] | [TensorValue](TensorValue.md#max.graph.TensorValue) | [Shape](shape.md#max.graph.shape.Shape) | [Dim](dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](TensorValue.md#max.graph.TensorValue)

</dd></dl>

### `layer_norm()` {#max.graph.ops.layer_norm}

> max.graph.ops.layer\_norm(input, gamma, beta, epsilon)

Performs layer normalization.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* input ([TensorValue](TensorValue.md#max.graph.TensorValue)) â€“ The input tensor to normalize.
* gamma (Value\[TensorType] | [TensorValue](TensorValue.md#max.graph.TensorValue) | [Shape](shape.md#max.graph.shape.Shape) | [Dim](dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]]) â€“ The gamma parameter of the normalization.
* beta (Value\[TensorType] | [TensorValue](TensorValue.md#max.graph.TensorValue) | [Shape](shape.md#max.graph.shape.Shape) | [Dim](dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]]) â€“ The beta parameter of the normalization.
* epsilon ([float](https://docs.python.org/3/library/functions.html#float)) â€“ The epsilon parameter of the normalization.

</dd><dt>

**Returns:**

</dt><dd>

A graph tensor value with the normalization applied.

</dd><dt>

**Raises:**

</dt><dd>

* [ValueError](https://docs.python.org/3/library/exceptions.html#ValueError) â€“ If gamma size doesnâ€™t match the last dimension of input.
* [ValueError](https://docs.python.org/3/library/exceptions.html#ValueError) â€“ If beta size doesnâ€™t match the last dimension of input.
* [ValueError](https://docs.python.org/3/library/exceptions.html#ValueError) â€“ If epsilon is not positive.

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](TensorValue.md#max.graph.TensorValue)

</dd></dl>

### `log()` {#max.graph.ops.log}

> max.graph.ops.log(x)

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

x (Value\[TensorType] | [TensorValue](TensorValue.md#max.graph.TensorValue) | [Shape](shape.md#max.graph.shape.Shape) | [Dim](dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](TensorValue.md#max.graph.TensorValue)

</dd></dl>

### `log1p()` {#max.graph.ops.log1p}

> max.graph.ops.log1p(x)

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

x (Value\[TensorType] | [TensorValue](TensorValue.md#max.graph.TensorValue) | [Shape](shape.md#max.graph.shape.Shape) | [Dim](dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](TensorValue.md#max.graph.TensorValue)

</dd></dl>

### `logical_and()` {#max.graph.ops.logical_and}

> max.graph.ops.logical\_and(lhs, rhs)

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* lhs (Value\[TensorType] | [TensorValue](TensorValue.md#max.graph.TensorValue) | [Shape](shape.md#max.graph.shape.Shape) | [Dim](dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])
* rhs (Value\[TensorType] | [TensorValue](TensorValue.md#max.graph.TensorValue) | [Shape](shape.md#max.graph.shape.Shape) | [Dim](dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](TensorValue.md#max.graph.TensorValue)

</dd></dl>

### `logical_not()` {#max.graph.ops.logical_not}

> max.graph.ops.logical\_not(x)

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

x (Value\[TensorType] | [TensorValue](TensorValue.md#max.graph.TensorValue) | [Shape](shape.md#max.graph.shape.Shape) | [Dim](dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](TensorValue.md#max.graph.TensorValue)

</dd></dl>

### `logical_or()` {#max.graph.ops.logical_or}

> max.graph.ops.logical\_or(lhs, rhs)

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* lhs (Value\[TensorType] | [TensorValue](TensorValue.md#max.graph.TensorValue) | [Shape](shape.md#max.graph.shape.Shape) | [Dim](dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])
* rhs (Value\[TensorType] | [TensorValue](TensorValue.md#max.graph.TensorValue) | [Shape](shape.md#max.graph.shape.Shape) | [Dim](dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](TensorValue.md#max.graph.TensorValue)

</dd></dl>

### `logical_xor()` {#max.graph.ops.logical_xor}

> max.graph.ops.logical\_xor(lhs, rhs)

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* lhs (Value\[TensorType] | [TensorValue](TensorValue.md#max.graph.TensorValue) | [Shape](shape.md#max.graph.shape.Shape) | [Dim](dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])
* rhs (Value\[TensorType] | [TensorValue](TensorValue.md#max.graph.TensorValue) | [Shape](shape.md#max.graph.shape.Shape) | [Dim](dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](TensorValue.md#max.graph.TensorValue)

</dd></dl>

### `logsoftmax()` {#max.graph.ops.logsoftmax}

> max.graph.ops.logsoftmax(x)

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

x (Value\[TensorType] | [TensorValue](TensorValue.md#max.graph.TensorValue) | [Shape](shape.md#max.graph.shape.Shape) | [Dim](dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](TensorValue.md#max.graph.TensorValue)

</dd></dl>

### `masked_scatter()` {#max.graph.ops.masked_scatter}

> max.graph.ops.masked\_scatter(input, mask, updates, out\_dim)

Creates a new symbolic tensor where the updates are written to input where mask is true.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* input (Value\[TensorType] | [TensorValue](TensorValue.md#max.graph.TensorValue) | [Shape](shape.md#max.graph.shape.Shape) | [Dim](dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]]) â€“ The input symbolic tensor to write elements to.
* mask (Value\[TensorType] | [TensorValue](TensorValue.md#max.graph.TensorValue) | [Shape](shape.md#max.graph.shape.Shape) | [Dim](dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]]) â€“ A symbolic tensor of boolean values to update.
* updates (Value\[TensorType] | [TensorValue](TensorValue.md#max.graph.TensorValue) | [Shape](shape.md#max.graph.shape.Shape) | [Dim](dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]]) â€“ A symbolic tensor of elements to write to input.
* out\_dim ([int](https://docs.python.org/3/library/functions.html#int) | [str](https://docs.python.org/3/library/stdtypes.html#str) | [Dim](dim.md#max.graph.dim.Dim) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]) â€“ The new data-dependent dimension.

</dd><dt>

**Returns:**

</dt><dd>

A new symbolic tensor representing the result of the masked\_scatter operation.

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](TensorValue.md#max.graph.TensorValue)

</dd></dl>

### `matmul()` {#max.graph.ops.matmul}

> max.graph.ops.matmul(lhs, rhs)

Computes the matrix multiplication of two tensor graph values.

Performs general matrix multiplication with broadcasting.

If the lhs is 1D, it will be reshaped to `1xD`.
If the rhs is 1D, it will be reshaped to `Dx1`.
In both cases, the additional 1 dimensions will be removed from the
output shape.

For the multiplication, the innermost (rightmost) 2 dimensions are treated
as a matrix.
The lhs matrix will have the shape `MxK`.
The rhs matrix will have the shape `KxN`.
The output will have the shape MxN
The `K` dimensions must be equivalent in both matrices.

The remaining outer dimensions will be broadcasted.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* lhs (Value\[TensorType] | [TensorValue](TensorValue.md#max.graph.TensorValue) | [Shape](shape.md#max.graph.shape.Shape) | [Dim](dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]]) â€“ The left-hand-side of the matmul.
* rhs (Value\[TensorType] | [TensorValue](TensorValue.md#max.graph.TensorValue) | [Shape](shape.md#max.graph.shape.Shape) | [Dim](dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]]) â€“ The right-hand-side of the matmul.
* location â€“ An optional location for a more specific error message.

</dd><dt>

**Returns:**

</dt><dd>

A tensor graph value representing he result of broadcasting the two
matrices together and then performing a matrix multiply
along the innermost two dimension of each tensor.

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](TensorValue.md#max.graph.TensorValue)

</dd></dl>

### `max()` {#max.graph.ops.max}

> max.graph.ops.max(x, y=None, /, axis=None)

Overload for ops.elementwise.max and ops.reduction.max.

* If two tensors are provided, axis is ignored and returns an elementwise maximum.
* If one tensor is provided, compute ops.reduction.max on the tensor and axis.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* x (Value\[TensorType] | [TensorValue](TensorValue.md#max.graph.TensorValue) | [Shape](shape.md#max.graph.shape.Shape) | [Dim](dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])
* y (Value\[TensorType] | [TensorValue](TensorValue.md#max.graph.TensorValue) | [Shape](shape.md#max.graph.shape.Shape) | [Dim](dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]] | None)
* axis ([int](https://docs.python.org/3/library/functions.html#int) | None)

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](TensorValue.md#max.graph.TensorValue)

</dd></dl>

### `max_pool2d()` {#max.graph.ops.max_pool2d}

> max.graph.ops.max\_pool2d(input, kernel\_size, stride=1, dilation=1, padding=0, ceil\_mode=False)

Perform a 2D max pooling operation on the input tensor.

This function applies a 2D max pooling operation to the input tensor \[N, H, W, C].
The pooling operation slides a window of size kernel\_size over the input
tensor, and selects the maximum value within each window.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* input (Value\[TensorType] | [TensorValue](TensorValue.md#max.graph.TensorValue) | [Shape](shape.md#max.graph.shape.Shape) | [Dim](dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]]) â€“ The input tensor to perform the pooling operation on.
* kernel\_size ([tuple](https://docs.python.org/3/library/stdtypes.html#tuple)\[[int](https://docs.python.org/3/library/functions.html#int) | [str](https://docs.python.org/3/library/stdtypes.html#str) | [Dim](dim.md#max.graph.dim.Dim) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)], [int](https://docs.python.org/3/library/functions.html#int) | [str](https://docs.python.org/3/library/stdtypes.html#str) | [Dim](dim.md#max.graph.dim.Dim) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]) â€“ The size of the sliding blocks.
* stride ([int](https://docs.python.org/3/library/functions.html#int) | [tuple](https://docs.python.org/3/library/stdtypes.html#tuple)\[[int](https://docs.python.org/3/library/functions.html#int), [int](https://docs.python.org/3/library/functions.html#int)]) â€“ The stride of the sliding blocks in the input dimension.
* dilation ([int](https://docs.python.org/3/library/functions.html#int) | [tuple](https://docs.python.org/3/library/stdtypes.html#tuple)\[[int](https://docs.python.org/3/library/functions.html#int), [int](https://docs.python.org/3/library/functions.html#int)]) â€“ The spacing between the kernel elements.
* padding ([int](https://docs.python.org/3/library/functions.html#int) | [tuple](https://docs.python.org/3/library/stdtypes.html#tuple)\[[int](https://docs.python.org/3/library/functions.html#int), [int](https://docs.python.org/3/library/functions.html#int)]) â€“ 0-paddings to be added on both sides of the inputs.
* ceil\_mode ([bool](https://docs.python.org/3/library/functions.html#bool)) â€“ If true, use ceil instead of floor to compute the output shape.

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](TensorValue.md#max.graph.TensorValue)

</dd></dl>

### `mean()` {#max.graph.ops.mean}

> max.graph.ops.mean(x, axis=-1)

Reduces a symbolic tensor using a mean operation.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* x (Value\[TensorType] | [TensorValue](TensorValue.md#max.graph.TensorValue) | [Shape](shape.md#max.graph.shape.Shape) | [Dim](dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]]) â€“ The input tensor for the operation.
* axis ([int](https://docs.python.org/3/library/functions.html#int)) â€“ The axis along which to compute the reduction. If negative,
  indexes from the last dimension. For example, a value of -1 will
  compute the reduction along the last dimension.

</dd><dt>

**Returns:**

</dt><dd>

A symbolic tensor representing the result of the mean operation.
The tensor will have the same rank as the input tensor, and the same
shape except along the `axis` dimension which will have size 1.

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](TensorValue.md#max.graph.TensorValue)

</dd></dl>

### `min()` {#max.graph.ops.min}

> max.graph.ops.min(x, y=None, /, axis=None)

Overload for ops.elementwise.min and ops.reduction.min.

* If two tensors are provided, axis is ignored and returns an elementwise minimum.
* If one tensor is provided, compute ops.reduction.min on the tensor and axis.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* x (Value\[TensorType] | [TensorValue](TensorValue.md#max.graph.TensorValue) | [Shape](shape.md#max.graph.shape.Shape) | [Dim](dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])
* y (Value\[TensorType] | [TensorValue](TensorValue.md#max.graph.TensorValue) | [Shape](shape.md#max.graph.shape.Shape) | [Dim](dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]] | None)
* axis ([int](https://docs.python.org/3/library/functions.html#int) | None)

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](TensorValue.md#max.graph.TensorValue)

</dd></dl>

### `mod()` {#max.graph.ops.mod}

> max.graph.ops.mod(lhs, rhs)

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* lhs (Value\[TensorType] | [TensorValue](TensorValue.md#max.graph.TensorValue) | [Shape](shape.md#max.graph.shape.Shape) | [Dim](dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])
* rhs (Value\[TensorType] | [TensorValue](TensorValue.md#max.graph.TensorValue) | [Shape](shape.md#max.graph.shape.Shape) | [Dim](dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](TensorValue.md#max.graph.TensorValue)

</dd></dl>

### `mul()` {#max.graph.ops.mul}

> max.graph.ops.mul(lhs, rhs)

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* lhs (Value\[TensorType] | [TensorValue](TensorValue.md#max.graph.TensorValue) | [Shape](shape.md#max.graph.shape.Shape) | [Dim](dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])
* rhs (Value\[TensorType] | [TensorValue](TensorValue.md#max.graph.TensorValue) | [Shape](shape.md#max.graph.shape.Shape) | [Dim](dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](TensorValue.md#max.graph.TensorValue)

</dd></dl>

### `negate()` {#max.graph.ops.negate}

> max.graph.ops.negate(x)

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

x (Value\[TensorType] | [TensorValue](TensorValue.md#max.graph.TensorValue) | [Shape](shape.md#max.graph.shape.Shape) | [Dim](dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](TensorValue.md#max.graph.TensorValue)

</dd></dl>

### `nonzero()` {#max.graph.ops.nonzero}

> max.graph.ops.nonzero(x, out\_dim)

Returns the indices of all nozero elements in a tensor.

Returns a tensor of indices of the nonzero values in the given tensor. The
return value is a 2D tensor of shape `[out_dim x rank_in]`, where
out\_dim is the number of nonzero elements in the input tensor, and
rank\_in is the rank of the input tensor. Indices are generated in
row-major order.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* x (Value\[TensorType] | [TensorValue](TensorValue.md#max.graph.TensorValue) | [Shape](shape.md#max.graph.shape.Shape) | [Dim](dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]]) â€“ The input symbolic tensor.
* out\_dim ([int](https://docs.python.org/3/library/functions.html#int) | [str](https://docs.python.org/3/library/stdtypes.html#str) | [Dim](dim.md#max.graph.dim.Dim) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]) â€“ The newly generated dimension that is sized for the number of
  nonzero elements.

</dd><dt>

**Returns:**

</dt><dd>

A symbolic tensor of indices

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](TensorValue.md#max.graph.TensorValue)

</dd></dl>

### `not_equal()` {#max.graph.ops.not_equal}

> max.graph.ops.not\_equal(lhs, rhs)

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* lhs (Value\[TensorType] | [TensorValue](TensorValue.md#max.graph.TensorValue) | [Shape](shape.md#max.graph.shape.Shape) | [Dim](dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])
* rhs (Value\[TensorType] | [TensorValue](TensorValue.md#max.graph.TensorValue) | [Shape](shape.md#max.graph.shape.Shape) | [Dim](dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](TensorValue.md#max.graph.TensorValue)

</dd></dl>

### `outer()` {#max.graph.ops.outer}

> max.graph.ops.outer(lhs, rhs)

Computes the outer product of two symbolic vectors.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* lhs (Value\[TensorType] | [TensorValue](TensorValue.md#max.graph.TensorValue) | [Shape](shape.md#max.graph.shape.Shape) | [Dim](dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]]) â€“ The left side of the product. Whatever its shape,
  it will be flattened to a rank-1 vector.
* rhs (Value\[TensorType] | [TensorValue](TensorValue.md#max.graph.TensorValue) | [Shape](shape.md#max.graph.shape.Shape) | [Dim](dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]]) â€“ The right side of the product. Whatever its shape,
  it will be flattened to a rank-1 vector. Must have the
  same number of elements as lhs.

</dd><dt>

**Returns:**

</dt><dd>

A symbolic tensor representing the
[outer product](\[https://en.wikipedia.org/wiki/Outer_product]\(https://en.wikipedia.org/wiki/Outer_product\))
of the two input vectors. It will have rank 2, with the dimension
sizes being the number of elements of lhs and rhs respectively.

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](TensorValue.md#max.graph.TensorValue)

</dd></dl>

### `pad()` {#max.graph.ops.pad}

> max.graph.ops.pad(input, paddings, mode='constant', value=0)

Pads a tensor with constant values.

Adds padding to the input tensor using the specified padding values.
Currently only constant padding mode is supported.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* input (Value\[TensorType] | [TensorValue](TensorValue.md#max.graph.TensorValue) | [Shape](shape.md#max.graph.shape.Shape) | [Dim](dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]]) â€“ The input tensor to pad.
* paddings ([Iterable](https://docs.python.org/3/library/collections.abc.html#collections.abc.Iterable)\[[int](https://docs.python.org/3/library/functions.html#int)]) â€“ Sequence of padding values. The padding values are applied
  symmetrically to each dimension. For a tensor with rank N,
  paddings should contain 2\*N values: [pad\_before\_dim0, pad\_after\_dim0,
  pad\_before\_dim1, pad\_after\_dim1, â€¦].
* mode ([Literal](https://docs.python.org/3/library/typing.html#typing.Literal)\['constant']) â€“ The padding mode. Currently only â€œconstantâ€ is supported.
* value (Value\[TensorType] | [TensorValue](TensorValue.md#max.graph.TensorValue) | [Shape](shape.md#max.graph.shape.Shape) | [Dim](dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]]) â€“ The constant value to use for padding.

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](TensorValue.md#max.graph.TensorValue)

</dd></dl>

### `permute()` {#max.graph.ops.permute}

> max.graph.ops.permute(x, dims)

Permutes all dimensions of a symbolic tensor.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* input â€“ The input symbolic tensor to transpose.
* dims ([list](https://docs.python.org/3/library/stdtypes.html#list)\[[int](https://docs.python.org/3/library/functions.html#int)]) â€“ The desired ordering of the dimensions in the output tensor.
* x (Value\[TensorType] | [TensorValue](TensorValue.md#max.graph.TensorValue) | [Shape](shape.md#max.graph.shape.Shape) | [Dim](dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])

</dd><dt>

**Returns:**

</dt><dd>

A new symbolic tensor with the dimensions permuted to match the passed in order.
It has the same elements and dtype, but the order of the elements
is different according to the permutation.

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](TensorValue.md#max.graph.TensorValue)

</dd></dl>

### `pow()` {#max.graph.ops.pow}

> max.graph.ops.pow(lhs, rhs)

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* lhs (Value\[TensorType] | [TensorValue](TensorValue.md#max.graph.TensorValue) | [Shape](shape.md#max.graph.shape.Shape) | [Dim](dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])
* rhs (Value\[TensorType] | [TensorValue](TensorValue.md#max.graph.TensorValue) | [Shape](shape.md#max.graph.shape.Shape) | [Dim](dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](TensorValue.md#max.graph.TensorValue)

</dd></dl>

### `print()` {#max.graph.ops.print}

> max.graph.ops.print(value, label='debug\_tensor')

Prints the value of a tensor or a string during graph execution.

This function is used to output the current value of a tensor and is
primarily used for debugging purposes within the context of the Max
Engine and its graph execution framework. This is particularly useful to
verify the intermediate results of your computations are as expected.

By printing the tensor values, you can visualize the data flowing through the
graph, which helps in understanding how the operations are transforming
the data.

When labeling the function you can assign the output, making it easier to
identify which tensorâ€™s value is being printed, especially when there are
multiple print statements in a complex graph.

```python
def add_tensors(a: np.ndarray, b: np.ndarray) -> dict[str, Any]:
    input_type = TensorType(dtype=DType.float32, shape=(1,), device=DeviceRef.CPU())
    with Graph(
        "simple_add_graph", input_types=(input_type, input_type)
    ) as graph:
        lhs, rhs = graph.inputs
        out = ops.add(lhs, rhs)
        ops.print(out, label="addition_output")  # Pass the output tensor here

        graph.output(out)
        print("final graph:", graph)
```

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* value ([str](https://docs.python.org/3/library/stdtypes.html#str) | [TensorValue](TensorValue.md#max.graph.TensorValue)) â€“ The value to print. Can be either a string or a TensorValue.
* label ([str](https://docs.python.org/3/library/stdtypes.html#str)) â€“ A label to identify the printed value. Defaults to
  `debug_tensor`.

</dd><dt>

**Return type:**

</dt><dd>

None

</dd></dl>

### `qmatmul()` {#max.graph.ops.qmatmul}

> max.graph.ops.qmatmul(encoding, config, lhs, \*rhs)

Performs matrix multiplication between floating point and quantized
tensors.

This quantizes the `lhs` floating point value to match the encoding of the
`rhs` quantized value, performs matmul, and then dequantizes the result.
Beware that, compared to a regular matmul op, this one expects the `rhs`
value to be transposed. For example, if the `lhs` shape is \[32, 64], and
the quantized `rhs` shape is also `[32, 64]`, then the output shape is
`[32, 32]`.

That is, this function returns the result from:

> dequantize(quantize(lhs) @ transpose(rhs))

The last two dimensions in `lhs` are treated as matrices and multiplied
by `rhs` (which must be a 2D tensor). Any remaining dimensions in `lhs`
are broadcast dimensions.

NOTE: Currently this supports Q4\_0, Q4\_K, and Q6\_K encodings only.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* encoding ([QuantizationEncoding](quantization.md#max.graph.quantization.QuantizationEncoding)) â€“ The quantization encoding to use.
* lhs ([TensorValue](TensorValue.md#max.graph.TensorValue)) â€“ The non-quantized, left-hand-side of the matmul.
* \*rhs ([TensorValue](TensorValue.md#max.graph.TensorValue)) â€“ The transposed and quantized right-hand-side of the matmul and
  auxiliary tensor (if has). Must be rank 2 and in a supported
  \[quantization encoding] (/max/api/mojo/graph/quantization/).
* config ([QuantizationConfig](quantization.md#max.graph.quantization.QuantizationConfig) | None)

</dd><dt>

**Returns:**

</dt><dd>

The dequantized result (a floating point tensor).

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](TensorValue.md#max.graph.TensorValue)

</dd></dl>

### `range()` {#max.graph.ops.range}

> max.graph.ops.range(start, stop, step=1, out\_dim=None, \*, dtype, device)

Creates a sequence of numbers. The sequence goes from start with
increments of size step up to (but not including) stop. All arguments
are mandatory and must have the same element type.

Note the following restrictions on input values:

1. step must be non-zero
2. stop - start must be zero or have the same sign as step

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* start (Value\[TensorType] | [TensorValue](TensorValue.md#max.graph.TensorValue) | [Shape](shape.md#max.graph.shape.Shape) | [Dim](dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]]) â€“ The start of the range to generate.
* stop (Value\[TensorType] | [TensorValue](TensorValue.md#max.graph.TensorValue) | [Shape](shape.md#max.graph.shape.Shape) | [Dim](dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]]) â€“ The range will be generated up to, but not including, this value.
* step (Value\[TensorType] | [TensorValue](TensorValue.md#max.graph.TensorValue) | [Shape](shape.md#max.graph.shape.Shape) | [Dim](dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]]) â€“ The step size for the range.
* out\_dim ([int](https://docs.python.org/3/library/functions.html#int) | [str](https://docs.python.org/3/library/stdtypes.html#str) | [Dim](dim.md#max.graph.dim.Dim) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | None) â€“ The expected output dimensions returned by the range op.
  These will be assert at graph execution time to be correct.
* device ([Device](../driver.md#max.driver.Device) | [DeviceRef](type.md#max.graph.type.DeviceRef)) â€“ Device of the result tensor.
* dtype ([DType](../dtype.md#max.dtype.DType)) â€“ Data type of the result tensor. If not specified, defaults to
  float32 for numeric inputs or infers from tensor inputs.

</dd><dt>

**Returns:**

</dt><dd>

A symbolic tensor value containing the defined range of values.

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](TensorValue.md#max.graph.TensorValue)

</dd></dl>

### `rebind()` {#max.graph.ops.rebind}

> max.graph.ops.rebind(x, shape, message='', layout=None)

Rebinds a symbolic tensor to a specified set of dimensions.

This does not mutate the symbolic tensor passed in, but instead adds a
runtime assert that the input symbolic shape is equivalent to
`out_dims` shape. For example, if the input tensor shape has
dynamic/unknown sizes, this will assert a fixed sizes that may be required
for a subsequent operation.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* x (Value\[TensorType] | [TensorValue](TensorValue.md#max.graph.TensorValue) | [Shape](shape.md#max.graph.shape.Shape) | [Dim](dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]]) â€“ The input symbolic tensor to rebind.
* shape ([Iterable](https://docs.python.org/3/library/collections.abc.html#collections.abc.Iterable)\[[int](https://docs.python.org/3/library/functions.html#int) | [str](https://docs.python.org/3/library/stdtypes.html#str) | [Dim](dim.md#max.graph.dim.Dim) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]) â€“ The symbolic shape to assert for `x`, as a list of
  [`Dim`](/max/api/python/graph/type/Dim) values.
* message ([str](https://docs.python.org/3/library/stdtypes.html#str)) â€“ The message printed if the rebind fails at runtime.
* layout ([FilterLayout](type.md#max.graph.type.FilterLayout) | None) â€“ A layout of the weights used by some operations like conv.

</dd><dt>

**Returns:**

</dt><dd>

A symbolic tensor with the same elements and shape as the given tensor,
but with the symbolic shape asserted to `out_dims`.

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](TensorValue.md#max.graph.TensorValue)

</dd></dl>

### `relu()` {#max.graph.ops.relu}

> max.graph.ops.relu(x)

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

x (Value\[TensorType] | [TensorValue](TensorValue.md#max.graph.TensorValue) | [Shape](shape.md#max.graph.shape.Shape) | [Dim](dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](TensorValue.md#max.graph.TensorValue)

</dd></dl>

### `repeat_interleave()` {#max.graph.ops.repeat_interleave}

> max.graph.ops.repeat\_interleave(x, repeats, axis=None, out\_dim=None)

Repeats elements of a tensor along the given dimension.

Modeled after `torch.repeat_interleave`, with the constraint that

For example, given `repeats=2` and the following input:

```python
## Input tensor with shape (2, 2)
input = TensorValue(x)  # Contains [[1.0, 2.0], [3.0, 4.0]]
```

`repeat_interleave` with `axis=0`:

```python
## Output tensor with shape (4, 2)
output = repeat_interleave(input, repeats=2, axis=0)
## Contains [[1.0, 2.0], [1.0, 2.0], [3.0, 4.0], [3.0, 4.0]]
```

`repeat_interleave` with `axis=1`:

```python
## Output tensor with shape (2, 4)
output = repeat_interleave(input, repeats=2, axis=1)
## Contains [[1.0, 1.0, 2.0, 2.0], [3.0, 3.0, 4.0, 4.0]]
```

`repeat_interleave` with `axis=None` (the default):

`repeat_interleave` with `repeats=[2, 3]` and `axis=0`:

```python
repeat_value = TensorValue([2, 3])

## Output tensor with shape (5, 2)
output = repeat_interleave(input, repeats=repeat_value, axis=0)
## Contains [[1.0, 2.0], [1.0, 2.0], [3.0, 4.0], [3.0, 4.0], [3.0, 4.0]]
```

```python
## Output tensor with shape (8,)
output = repeat_interleave(input, repeats=2)  # axis = None
## Contains [1.0, 1.0, 2.0, 2.0, 3.0, 3.0, 4.0, 4.0]
```

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* x (Value\[TensorType] | [TensorValue](TensorValue.md#max.graph.TensorValue) | [Shape](shape.md#max.graph.shape.Shape) | [Dim](dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]]) â€“ The input tensor.
* repeats ([int](https://docs.python.org/3/library/functions.html#int) | [TensorValue](TensorValue.md#max.graph.TensorValue)) â€“ The number of repetitions for each element.
* axis ([int](https://docs.python.org/3/library/functions.html#int) | None) â€“ The dimension along which to repeat values. If axis is not
  specified or None (the default), flatten the input array
  and repeat the flattened values.
* out\_dim ([int](https://docs.python.org/3/library/functions.html#int) | [str](https://docs.python.org/3/library/stdtypes.html#str) | [Dim](dim.md#max.graph.dim.Dim) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | None)

</dd><dt>

**Returns:**

</dt><dd>

A symbolic tensor with the elements interleaved.

</dd><dt>

**Raises:**

</dt><dd>

[ValueError](https://docs.python.org/3/library/exceptions.html#ValueError) â€“ If `repeats` non-positive or if `axis` is out of range.

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](TensorValue.md#max.graph.TensorValue)

</dd></dl>

### `reshape()` {#max.graph.ops.reshape}

> max.graph.ops.reshape(x, shape)

Reshapes a symbolic tensor.

The number and order of the elements in the tensor is unchanged.
In other words, if you were to iterate over elements in the tensor
by major dimension to minor dimension, the iteration order would stay
the same.

If a value of -1 is present in the shape, that dimension becomes
an automatically calculated dimension collecting all unspecified dimensions.
Its length becomes the number of elements in the original tensor
divided by the product of elements of the reshape.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* x (Value\[TensorType] | [TensorValue](TensorValue.md#max.graph.TensorValue) | [Shape](shape.md#max.graph.shape.Shape) | [Dim](dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]]) â€“ The input symbolic tensor to reshape.
  This tensor may not contain any dynamic dimensions.
* shape ([Iterable](https://docs.python.org/3/library/collections.abc.html#collections.abc.Iterable)\[[int](https://docs.python.org/3/library/functions.html#int) | [str](https://docs.python.org/3/library/stdtypes.html#str) | [Dim](dim.md#max.graph.dim.Dim) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]) â€“ The new shape as a list of dimensions.
  Dynamic dimensions are not allowed.
  A single dimension may be -1.

</dd><dt>

**Returns:**

</dt><dd>

A symbolic tensor with the same elements as the original tensor, but
in a new shape. Its symbolic shape is the same as `shape`.

</dd><dt>

**Raises:**

</dt><dd>

[ValueError](https://docs.python.org/3/library/exceptions.html#ValueError) â€“ if input and target shapesâ€™ number of elements mismatch.

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](TensorValue.md#max.graph.TensorValue)

</dd></dl>

### `resize()` {#max.graph.ops.resize}

> max.graph.ops.resize(input, shape, interpolation=InterpolationMode.BILINEAR)

Resize the input tensor to the given shape.

This function resizes a tensor using the specified interpolation method.
The tensor is expected to have NCHW format (batch, channels, height, width).

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* input (Value\[TensorType] | [TensorValue](TensorValue.md#max.graph.TensorValue) | [Shape](shape.md#max.graph.shape.Shape) | [Dim](dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]]) â€“ The input tensor to resize. Must have rank 4 in NCHW format.
* shape ([Iterable](https://docs.python.org/3/library/collections.abc.html#collections.abc.Iterable)\[[int](https://docs.python.org/3/library/functions.html#int) | [str](https://docs.python.org/3/library/stdtypes.html#str) | [Dim](dim.md#max.graph.dim.Dim) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]) â€“ Desired output shape of length 4 corresponding to (N, C, H, W).
* interpolation ([InterpolationMode](#max.graph.ops.InterpolationMode)) â€“ Desired interpolation enum defined by InterpolationMode.
  Default is InterpolationMode.BILINEAR. Currently only BICUBIC is
  supported.

</dd><dt>

**Returns:**

</dt><dd>

A resized tensor with the shape specified by the shape argument.

</dd><dt>

**Raises:**

</dt><dd>

* [ValueError](https://docs.python.org/3/library/exceptions.html#ValueError) â€“ If the input doesnâ€™t have rank 4, shape has wrong number
  of elements, or unsupported interpolation mode is specified.
* [NotImplementedError](https://docs.python.org/3/library/exceptions.html#NotImplementedError) â€“ If single integer size or non-BICUBIC interpolation
  mode is specified.

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](TensorValue.md#max.graph.TensorValue)

</dd></dl>

### `round()` {#max.graph.ops.round}

> max.graph.ops.round(x)

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

x (Value\[TensorType] | [TensorValue](TensorValue.md#max.graph.TensorValue) | [Shape](shape.md#max.graph.shape.Shape) | [Dim](dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](TensorValue.md#max.graph.TensorValue)

</dd></dl>

### `rsqrt()` {#max.graph.ops.rsqrt}

> max.graph.ops.rsqrt(x)

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

x (Value\[TensorType] | [TensorValue](TensorValue.md#max.graph.TensorValue) | [Shape](shape.md#max.graph.shape.Shape) | [Dim](dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](TensorValue.md#max.graph.TensorValue)

</dd></dl>

### `scatter()` {#max.graph.ops.scatter}

> max.graph.ops.scatter(input, updates, indices, axis=-1)

Creates a new symbolic tensor where the updates are written to input according to indices.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* input (Value\[TensorType] | [TensorValue](TensorValue.md#max.graph.TensorValue) | [Shape](shape.md#max.graph.shape.Shape) | [Dim](dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]]) â€“ The input symbolic tensor to write elements to.
* updates (Value\[TensorType] | [TensorValue](TensorValue.md#max.graph.TensorValue) | [Shape](shape.md#max.graph.shape.Shape) | [Dim](dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]]) â€“ A symbolic tensor of elements to write to input.
* indices (Value\[TensorType] | [TensorValue](TensorValue.md#max.graph.TensorValue) | [Shape](shape.md#max.graph.shape.Shape) | [Dim](dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]]) â€“ The positions in input to update.
* axis ([int](https://docs.python.org/3/library/functions.html#int)) â€“ The axis along which indices indexes into.

</dd><dt>

**Returns:**

</dt><dd>

A new symbolic tensor representing the result of the scatter operation.

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](TensorValue.md#max.graph.TensorValue)

</dd></dl>

### `scatter_nd()` {#max.graph.ops.scatter_nd}

> max.graph.ops.scatter\_nd(input, updates, indices)

Creates a new symbolic tensor where the updates are scattered into input at specified indices.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* input (Value\[TensorType] | [TensorValue](TensorValue.md#max.graph.TensorValue) | [Shape](shape.md#max.graph.shape.Shape) | [Dim](dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]]) â€“ The input symbolic tensor to write elements to.
* updates (Value\[TensorType] | [TensorValue](TensorValue.md#max.graph.TensorValue) | [Shape](shape.md#max.graph.shape.Shape) | [Dim](dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]]) â€“ A symbolic tensor of elements to write to input.
* indices (Value\[TensorType] | [TensorValue](TensorValue.md#max.graph.TensorValue) | [Shape](shape.md#max.graph.shape.Shape) | [Dim](dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]]) â€“ A tensor of indices specifying where to write updates.
  Shape should be \[num\_updates, rank] for full indexing or
  \[num\_updates, k] for partial indexing where k < rank.

</dd><dt>

**Returns:**

</dt><dd>

A new symbolic tensor representing the result of the scatter\_nd operation.

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](TensorValue.md#max.graph.TensorValue)

</dd></dl>

### `shape_to_tensor()` {#max.graph.ops.shape_to_tensor}

> max.graph.ops.shape\_to\_tensor(shape)

Converts a shape to a tensor.

This is useful for using a shape attribute in an op that expects a tensor
value.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

shape ([Iterable](https://docs.python.org/3/library/collections.abc.html#collections.abc.Iterable)\[[int](https://docs.python.org/3/library/functions.html#int) | [str](https://docs.python.org/3/library/stdtypes.html#str) | [Dim](dim.md#max.graph.dim.Dim) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]) â€“ the shape attribute of a tensor value.

</dd><dt>

**Returns:**

</dt><dd>

The TensorValue containing the same value as shape.

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](TensorValue.md#max.graph.TensorValue)

</dd></dl>

**Example:**

```pycon
>>> x = ops.constant(np.zeros((1,)), DType.int64, device=DeviceRef.CPU())
>>> result = ops.stack([
...     x,
...     ops.shape_to_tensor(x.shape),
... ])
TensorValue(dtype=int64, shape=[StaticDim(dim=2), StaticDim(dim=1)])
```

### `sigmoid()` {#max.graph.ops.sigmoid}

> max.graph.ops.sigmoid(x)

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

x (Value\[TensorType] | [TensorValue](TensorValue.md#max.graph.TensorValue) | [Shape](shape.md#max.graph.shape.Shape) | [Dim](dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](TensorValue.md#max.graph.TensorValue)

</dd></dl>

### `silu()` {#max.graph.ops.silu}

> max.graph.ops.silu(x)

Computes the elementwise silu of a symbolic tensor.

Creates a new op node to compute the elementwise silu of a
symbolic tensor and adds it to the graph, returning the symbolic result.

`silu` is defined as `silu(x) = x * sigmoid(x)`.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* value â€“ The symbolic tensor to use as the input to the silu
  computation.
* x ([TensorValue](TensorValue.md#max.graph.TensorValue))

</dd><dt>

**Returns:**

</dt><dd>

A new symbolic tensor value representing the output of the silu
value computation.

</dd><dt>

**Raises:**

</dt><dd>

Error â€“ If the symbol doesnâ€™t represent a tensor value.

</dd></dl>

### `sin()` {#max.graph.ops.sin}

> max.graph.ops.sin(x)

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

x (Value\[TensorType] | [TensorValue](TensorValue.md#max.graph.TensorValue) | [Shape](shape.md#max.graph.shape.Shape) | [Dim](dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](TensorValue.md#max.graph.TensorValue)

</dd></dl>

### `slice_tensor()` {#max.graph.ops.slice_tensor}

> max.graph.ops.slice\_tensor(x, indices)

Slices out a subtensor view of the input tensor based on indices.

The semantics of [`slice_tensor()`](#max.graph.ops.slice_tensor) follow NumPy slicing semantics with the
following restrictions:

* Slice indices must not index out of `[-dim - 1, dim - 1]` for negative step,
  or `[-dim, dim]` for positive step.

```python
## Reverse a tensor.
slice_tensor(x, [slice(None, None, -1)])
## Unsqueeze the second last dimension of a tensor.
slice_tensor(x, [..., None, slice(None)])
```

<dl class='field-list'><dt>

**Returns:**

</dt><dd>

The sliced subtensor of x.

</dd><dt>

**Parameters:**

</dt><dd>

* x ([TensorValue](TensorValue.md#max.graph.TensorValue))
* indices (SliceIndices)

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](TensorValue.md#max.graph.TensorValue)

</dd></dl>

### `softmax()` {#max.graph.ops.softmax}

> max.graph.ops.softmax(x)

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

x (Value\[TensorType] | [TensorValue](TensorValue.md#max.graph.TensorValue) | [Shape](shape.md#max.graph.shape.Shape) | [Dim](dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](TensorValue.md#max.graph.TensorValue)

</dd></dl>

### `split()` {#max.graph.ops.split}

> max.graph.ops.split(x, split\_sizes, axis=0)

Splits the input tensor into multiple tensors along a given dimension.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* x (Value\[TensorType] | [TensorValue](TensorValue.md#max.graph.TensorValue) | [Shape](shape.md#max.graph.shape.Shape) | [Dim](dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]]) â€“ The input symbolic tensor to split.
* split\_sizes ([Sequence](https://docs.python.org/3/library/collections.abc.html#collections.abc.Sequence)\[[int](https://docs.python.org/3/library/functions.html#int) | [str](https://docs.python.org/3/library/stdtypes.html#str) | [Dim](dim.md#max.graph.dim.Dim) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]) â€“ Sizes of each output tensor. Must add up to the split
  dimension axis.
* axis ([int](https://docs.python.org/3/library/functions.html#int)) â€“ Dimension to split the input tensor. Must have a statically
  known dimension size.

</dd><dt>

**Returns:**

</dt><dd>

A list of tensors with the same length as split\_sizes, where each
tensor has the same shape as the input except along the split dimension
axis, where the size is given by the corresponding element in
split\_sizes.

</dd><dt>

**Return type:**

</dt><dd>

[list](https://docs.python.org/3/library/stdtypes.html#list)\[[TensorValue](TensorValue.md#max.graph.TensorValue)]

</dd></dl>

### `sqrt()` {#max.graph.ops.sqrt}

> max.graph.ops.sqrt(x)

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

x (Value\[TensorType] | [TensorValue](TensorValue.md#max.graph.TensorValue) | [Shape](shape.md#max.graph.shape.Shape) | [Dim](dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](TensorValue.md#max.graph.TensorValue)

</dd></dl>

### `squeeze()` {#max.graph.ops.squeeze}

> max.graph.ops.squeeze(x, axis)

Removes a size-1 dimension from a symbolic tensor.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* x (Value\[TensorType] | [TensorValue](TensorValue.md#max.graph.TensorValue) | [Shape](shape.md#max.graph.shape.Shape) | [Dim](dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]]) â€“ The input symbolic tensor to squeeze.
* axis ([int](https://docs.python.org/3/library/functions.html#int)) â€“ The dimension to remove from the inputâ€™s shape. If negative, this
  indexes from the end of the tensor. For example,
  `squeeze(v, -1)` squeezes the last dimension.

</dd><dt>

**Returns:**

</dt><dd>

A symbolic tensor with the same number of elements as the input tensor,
and whose rank is 1 less than the rank of the input tensor.

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](TensorValue.md#max.graph.TensorValue)

</dd></dl>

### `stack()` {#max.graph.ops.stack}

> max.graph.ops.stack(values, axis=0)

Stacks a list of tensors along a new axis.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* values ([Iterable](https://docs.python.org/3/library/collections.abc.html#collections.abc.Iterable)\[Value\[TensorType] | [TensorValue](TensorValue.md#max.graph.TensorValue) | [Shape](shape.md#max.graph.shape.Shape) | [Dim](dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]]]) â€“ A list of symbolic tensor values. Each tensor must have the same
  dtype and rank, and must have the same dimension size for each
  dimension.
* axis ([int](https://docs.python.org/3/library/functions.html#int)) â€“ The axis to concatenate along. If negative, indexes relative
  to the end of the tensor shape plus 1. For instance,
  `stack(vs, -1)` will create and stack along a new axis as the
  last dimension, aad `stack(vs, -2)` will create and stack along a new
  dimension which is inserted immediately before the last dimension.

</dd><dt>

**Returns:**

</dt><dd>

A new symbolic tensor representing the result of the stack. It will
have rank `n+1` where `n` is the rank of each input tensor. Its size
on each dimension other than `axis` will be the same as each input tensorsâ€™,
with the new axis inserted. Along the new dimension it will have size
`len(values)`.

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](TensorValue.md#max.graph.TensorValue)

</dd></dl>

### `sub()` {#max.graph.ops.sub}

> max.graph.ops.sub(lhs, rhs)

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* lhs (Value\[TensorType] | [TensorValue](TensorValue.md#max.graph.TensorValue) | [Shape](shape.md#max.graph.shape.Shape) | [Dim](dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])
* rhs (Value\[TensorType] | [TensorValue](TensorValue.md#max.graph.TensorValue) | [Shape](shape.md#max.graph.shape.Shape) | [Dim](dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](TensorValue.md#max.graph.TensorValue)

</dd></dl>

### `sum()` {#max.graph.ops.sum}

> max.graph.ops.sum(x, axis=-1)

Reduces a symbolic tensor using a sum operation.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* x (Value\[TensorType] | [TensorValue](TensorValue.md#max.graph.TensorValue) | [Shape](shape.md#max.graph.shape.Shape) | [Dim](dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]]) â€“ The input tensor for the operation.
* axis ([int](https://docs.python.org/3/library/functions.html#int)) â€“ The axis along which to compute the reduction. If negative,
  indexes from the last dimension. For example, a value of -1 will
  compute the reduction along the last dimension.

</dd><dt>

**Returns:**

</dt><dd>

A symbolic tensor representing the result of the sum operation.
The tensor will have the same rank as the input tensor, and the same
shape except along the `axis` dimension which will have size 1.

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](TensorValue.md#max.graph.TensorValue)

</dd></dl>

### `tanh()` {#max.graph.ops.tanh}

> max.graph.ops.tanh(x)

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

x (Value\[TensorType] | [TensorValue](TensorValue.md#max.graph.TensorValue) | [Shape](shape.md#max.graph.shape.Shape) | [Dim](dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](TensorValue.md#max.graph.TensorValue)

</dd></dl>

### `tile()` {#max.graph.ops.tile}

> max.graph.ops.tile(x, repeats)

Returns a new Tensor as the result of copying the input tensor N\_i times
on each dimension, where N\_i = repeats\[i].

The i-th dimension of output shape will be the ith dimension of input shape
multiplied by N\_i.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* x (Value\[TensorType] | [TensorValue](TensorValue.md#max.graph.TensorValue) | [Shape](shape.md#max.graph.shape.Shape) | [Dim](dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])
* repeats ([Iterable](https://docs.python.org/3/library/collections.abc.html#collections.abc.Iterable)\[[int](https://docs.python.org/3/library/functions.html#int) | [str](https://docs.python.org/3/library/stdtypes.html#str) | [Dim](dim.md#max.graph.dim.Dim) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]])

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](TensorValue.md#max.graph.TensorValue)

</dd></dl>

### `top_k()` {#max.graph.ops.top_k}

> max.graph.ops.top\_k(input, k, axis=-1)

Returns tensor with only top K values along given axis.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* input (Value\[TensorType] | [TensorValue](TensorValue.md#max.graph.TensorValue) | [Shape](shape.md#max.graph.shape.Shape) | [Dim](dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]]) â€“ The input tensor from which to select top k.
* k ([int](https://docs.python.org/3/library/functions.html#int)) â€“ The number of values to select from input.
* axis ([int](https://docs.python.org/3/library/functions.html#int)) â€“ The axis from which to select top k.

</dd><dt>

**Returns:**

</dt><dd>

Top K values, Top K indices

</dd><dt>

**Return type:**

</dt><dd>

[tuple](https://docs.python.org/3/library/stdtypes.html#tuple)\[[TensorValue](TensorValue.md#max.graph.TensorValue), [TensorValue](TensorValue.md#max.graph.TensorValue)]

</dd></dl>

### `transfer_to()` {#max.graph.ops.transfer_to}

> max.graph.ops.transfer\_to(x, device)

Device-to-Device transfer operation.

This op transfers the input tensor from its current device over to another. A device represents a
computation unit, like CPU, GPU, etc. This op is useful for instance when working with
accelerators, like GPU, where for instance one may need to move data from GPU to GPU, or
from one GPU to CPU.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* x (Value\[TensorType] | [TensorValue](TensorValue.md#max.graph.TensorValue) | [Shape](shape.md#max.graph.shape.Shape) | [Dim](dim.md#max.graph.dim.Dim) | HasTensorValue) â€“ The input tensor to transfer.
* device ([Device](../driver.md#max.driver.Device) | [DeviceRef](type.md#max.graph.type.DeviceRef)) â€“ The device to transfer to.

</dd><dt>

**Returns:**

</dt><dd>

A tensor transferred to device specified.

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](TensorValue.md#max.graph.TensorValue)

</dd></dl>

### `transpose()` {#max.graph.ops.transpose}

> max.graph.ops.transpose(x, axis\_1, axis\_2)

Transposes two axes of a symbolic tensor.
For more information, see [`transpose()`](TensorValue.md#max.graph.TensorValue.transpose).

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* x (Value\[TensorType] | [TensorValue](TensorValue.md#max.graph.TensorValue) | [Shape](shape.md#max.graph.shape.Shape) | [Dim](dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]]) â€“ The input symbolic tensor to transpose.
* axis\_1 ([int](https://docs.python.org/3/library/functions.html#int)) â€“ One of the two axes to transpose. If negative, this indexes
  from the end of the tensor. For example,
  `transpose(v, -1, -2)` transposes the last two axes.
* axis\_2 ([int](https://docs.python.org/3/library/functions.html#int)) â€“ The other axis to transpose. May also be negative to index from
  the end of the tensor.

</dd><dt>

**Returns:**

</dt><dd>

A new symbolic tensor with the two specified axes transposed.
It has the same elements and dtype, but the order of the elements
is different according to the transposition.

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](TensorValue.md#max.graph.TensorValue)

</dd></dl>

### `trunc()` {#max.graph.ops.trunc}

> max.graph.ops.trunc(x)

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

x (Value\[TensorType] | [TensorValue](TensorValue.md#max.graph.TensorValue) | [Shape](shape.md#max.graph.shape.Shape) | [Dim](dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](TensorValue.md#max.graph.TensorValue)

</dd></dl>

### `unsqueeze()` {#max.graph.ops.unsqueeze}

> max.graph.ops.unsqueeze(x, axis)

Inserts a size-1 dimension into a symbolic tensor.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* x (Value\[TensorType] | [TensorValue](TensorValue.md#max.graph.TensorValue) | [Shape](shape.md#max.graph.shape.Shape) | [Dim](dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]]) â€“ The input symbolic tensor to unsqueeze.
* axis ([int](https://docs.python.org/3/library/functions.html#int)) â€“ The index at which to insert a new dimension into the inputâ€™s
  shape. Elements at that index or higher are shifted back.
  If negative, it indexes relative 1 plus the rank of the tensor.
  For example, `unsqueeze(v, -1)` adds a new dimension at the
  end, and `unsqueeze(v, -2)` inserts the dimension immediately
  before the last dimension.

</dd><dt>

**Returns:**

</dt><dd>

A symbolic tensor with the same number of elements as the input tensor,
whose rank is 1 larger than the rank of the input tensor. The resultâ€™s
shape at the `axis` dimension is a static dimension of size 1.

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](TensorValue.md#max.graph.TensorValue)

</dd></dl>

### `where()` {#max.graph.ops.where}

> max.graph.ops.where(condition, x, y)

Returns `condition ? x : y` (element-wise), where `cond`, `x` and `y`
are input tensors.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* condition (Value\[TensorType] | [TensorValue](TensorValue.md#max.graph.TensorValue) | [Shape](shape.md#max.graph.shape.Shape) | [Dim](dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]]) â€“ The condition tensor to use for selecting elementwise
  values. This tensor must have a boolean dtype.
* x (Value\[TensorType] | [TensorValue](TensorValue.md#max.graph.TensorValue) | [Shape](shape.md#max.graph.shape.Shape) | [Dim](dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]]) â€“ If the condition is true at a position, the value from the same
  position in this tensor will be selected.
* y (Value\[TensorType] | [TensorValue](TensorValue.md#max.graph.TensorValue) | [Shape](shape.md#max.graph.shape.Shape) | [Dim](dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]]) â€“ If the condition is false at a position, the value from the same
  position in this tensor will be selected.

</dd><dt>

**Returns:**

</dt><dd>

A new symbolic tensor holding either values from either `x` or `y`,
based on the elements in condition.

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](TensorValue.md#max.graph.TensorValue)

</dd></dl>

### `while_loop()` {#max.graph.ops.while_loop}

> max.graph.ops.while\_loop(initial\_values, predicate, body)

Execute a loop until the predicate evaluates to false.

Both the predicate and body functions must take in as arguments the same
number and types of values as specified in the init\_args. The predication
function must return only a boolean scalar tensor of type `DType.bool`.
The body function must return a list of values matching the types of init\_args,
(or may return a value directly if there is only one).

The following example demonstrates a basic while loop with a single argument:

```python
from max.graph import Graph, ops
from max.dtype import DType

with Graph("while_loop_example") as g:
    x = ops.constant(0, dtype=DType.int32, device=DeviceRef.CPU())

    def pred(x):
        return x < 10

    def body(x):
        return x + 1

    result = ops.while_loop(x, pred, body)
    print(result)
```

The following example shows a while loop with multiple arguments:

```python
from max.graph import Graph, ops
from max.dtype import DType

with Graph("while_loop_example") as g:
    x = ops.constant(0, dtype=DType.int32, device=DeviceRef.CPU())
    y = ops.constant(5, dtype=DType.int32, device=DeviceRef.CPU())

    def pred(x, y):
        return ops.logical_and(x < 10, y < 15)

    def body(x, y):
        return [x + 1, y + 1]

    results = ops.while_loop((x, y), pred, body)
    print(results)
```

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* initial\_values ([Iterable](https://docs.python.org/3/library/collections.abc.html#collections.abc.Iterable)\[[Value](Value.md#max.graph.Value)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]] | [Value](Value.md#max.graph.Value)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]) â€“ Initial values for loop arguments. Must be non-empty.
* predicate ([Callable](https://docs.python.org/3/library/typing.html#typing.Callable)\[\[...], [TensorValue](TensorValue.md#max.graph.TensorValue)]) â€“ Callable that takes loop arguments and returns a boolean scalar tensor
  of type `DType.bool` determining loop continuation.
* body ([Callable](https://docs.python.org/3/library/typing.html#typing.Callable)\[\[...], [Value](Value.md#max.graph.Value)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [Iterable](https://docs.python.org/3/library/collections.abc.html#collections.abc.Iterable)\[[Value](Value.md#max.graph.Value)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]]) â€“ Callable that takes loop arguments and returns updated values matching
  the types of init\_args.

</dd><dt>

**Returns:**

</dt><dd>

List of output values from the final loop iteration.

</dd><dt>

**Raises:**

</dt><dd>

* [ValueError](https://docs.python.org/3/library/exceptions.html#ValueError) â€“ If init\_args is empty.
* [NotImplementedError](https://docs.python.org/3/library/exceptions.html#NotImplementedError) â€“ If any init\_arg is a `BufferValue`.

</dd><dt>

**Return type:**

</dt><dd>

[list](https://docs.python.org/3/library/stdtypes.html#list)\[[TensorValue](TensorValue.md#max.graph.TensorValue)]

</dd></dl>

##### NOTE

Buffer operations are currently not supported.

---

## quantization

APIs to quantize graph tensors.

This package includes a comprehensive set of tools for working with quantized
models in MAX Graph. It defines supported quantization encodings, configuration
parameters that control the quantization process, and block parameter
specifications for different quantization formats.

The module supports various quantization formats including 4-bit, 5-bit, and
6-bit precision with different encoding schemes. It also provides support for
GGUF-compatible formats for interoperability with other frameworks.

## `BlockParameters` {#max.graph.quantization.BlockParameters}

> class max.graph.quantization.BlockParameters(elements\_per\_block, block\_size)

Parameters describing the structure of a quantization block.

Block-based quantization stores elements in fixed-size blocks.
Each block contains a specific number of elements in a compressed format.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* elements\_per\_block ([int](https://docs.python.org/3/library/functions.html#int))
* block\_size ([int](https://docs.python.org/3/library/functions.html#int))

</dd></dl>

### `block_size` {#max.graph.quantization.BlockParameters.block_size}

> block\_size: [int](https://docs.python.org/3/library/functions.html#int)

### `elements_per_block` {#max.graph.quantization.BlockParameters.elements_per_block}

> elements\_per\_block: [int](https://docs.python.org/3/library/functions.html#int)

## `QuantizationConfig` {#max.graph.quantization.QuantizationConfig}

> class max.graph.quantization.QuantizationConfig(quant\_method, bits, group\_size, desc\_act=False, sym=False)

Configuration for specifying quantization parameters that affect inference.

These parameters control how tensor values are quantized, including the method,
bit precision, grouping, and other characteristics that affect the trade-off
between model size, inference speed, and accuracy.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* quant\_method ([str](https://docs.python.org/3/library/stdtypes.html#str))
* bits ([int](https://docs.python.org/3/library/functions.html#int))
* group\_size ([int](https://docs.python.org/3/library/functions.html#int))
* desc\_act ([bool](https://docs.python.org/3/library/functions.html#bool))
* sym ([bool](https://docs.python.org/3/library/functions.html#bool))

</dd></dl>

### `bits` {#max.graph.quantization.QuantizationConfig.bits}

> bits: [int](https://docs.python.org/3/library/functions.html#int)

### `desc_act` {#max.graph.quantization.QuantizationConfig.desc_act}

> desc\_act: [bool](https://docs.python.org/3/library/functions.html#bool) = False

### `group_size` {#max.graph.quantization.QuantizationConfig.group_size}

> group\_size: [int](https://docs.python.org/3/library/functions.html#int)

### `quant_method` {#max.graph.quantization.QuantizationConfig.quant_method}

> quant\_method: [str](https://docs.python.org/3/library/stdtypes.html#str)

### `sym` {#max.graph.quantization.QuantizationConfig.sym}

> sym: [bool](https://docs.python.org/3/library/functions.html#bool) = False

## `QuantizationEncoding` {#max.graph.quantization.QuantizationEncoding}

> class max.graph.quantization.QuantizationEncoding(value, names=\<not given>, \*values, module=None, qualname=None, type=None, start=1, boundary=None)

Quantization encodings supported by MAX Graph.

Quantization reduces the precision of neural network weights to decrease
memory usage and potentially improve inference speed. Each encoding represents
a different compression method with specific trade-offs between model size,
accuracy, and computational efficiency.
These encodings are commonly used with pre-quantized model checkpoints
(especially GGUF format) or can be applied during weight allocation.

The following example shows how to create a quantized weight using the Q4\_K encoding:

```python
from max.graph.quantization import QuantizationEncoding
from max.graph import Weight

encoding = QuantizationEncoding.Q4_K
quantized_weight = Weight(
    name="linear.weight",
    dtype=DType.uint8,
    shape=[4096, 4096],
    device=DeviceRef.GPU(0),
    quantization_encoding=encoding
)
```

MAX supports several quantization formats optimized for different use cases.

### `Q4_0` {#max.graph.quantization.QuantizationEncoding.Q4_0}

> Q4\_0

Basic 4-bit quantization with 32 elements per block.

### `Q4_K` {#max.graph.quantization.QuantizationEncoding.Q4_K}

> Q4\_K

4-bit K-quantization with 256 elements per block.

### `Q5_K` {#max.graph.quantization.QuantizationEncoding.Q5_K}

> Q5\_K

5-bit K-quantization with 256 elements per block.

### `Q6_K` {#max.graph.quantization.QuantizationEncoding.Q6_K}

> Q6\_K

6-bit K-quantization with 256 elements per block.

### `GPTQ` {#max.graph.quantization.QuantizationEncoding.GPTQ}

> GPTQ

Group-wise Post-Training Quantization for large language models.

### `block_parameters` {#max.graph.quantization.QuantizationEncoding.block_parameters}

> property block\_parameters: [BlockParameters](#max.graph.quantization.BlockParameters)

Gets the block parameters for this quantization encoding.

<dl class='field-list'><dt>

**Returns:**

</dt><dd>

The parameters describing how elements are organized
and encoded in blocks for this quantization encoding.

</dd><dt>

**Return type:**

</dt><dd>

[BlockParameters](#max.graph.quantization.BlockParameters)

</dd></dl>

### `block_size` {#max.graph.quantization.QuantizationEncoding.block_size}

> property block\_size: [int](https://docs.python.org/3/library/functions.html#int)

Number of bytes in encoded representation of block.

All quantization types currently supported by MAX Graph are
block-based: groups of a fixed number of elements are formed, and each
group is quantized together into a fixed-size output block.  This value
is the number of bytes resulting after encoding a single block.

<dl class='field-list'><dt>

**Returns:**

</dt><dd>

Size in bytes of each encoded quantization block.

</dd><dt>

**Return type:**

</dt><dd>

[int](https://docs.python.org/3/library/functions.html#int)

</dd></dl>

### `elements_per_block` {#max.graph.quantization.QuantizationEncoding.elements_per_block}

> property elements\_per\_block: [int](https://docs.python.org/3/library/functions.html#int)

Number of elements per block.

All quantization types currently supported by MAX Graph are
block-based: groups of a fixed number of elements are formed, and each
group is quantized together into a fixed-size output block.  This value
is the number of elements gathered into a block.

<dl class='field-list'><dt>

**Returns:**

</dt><dd>

Number of original tensor elements in each quantized block.

</dd><dt>

**Return type:**

</dt><dd>

[int](https://docs.python.org/3/library/functions.html#int)

</dd></dl>

### `is_gguf` {#max.graph.quantization.QuantizationEncoding.is_gguf}

> property is\_gguf: [bool](https://docs.python.org/3/library/functions.html#bool)

Checks if this quantization encoding is compatible with GGUF format.

GGUF is a format for storing large language models and compatible
quantized weights.

<dl class='field-list'><dt>

**Returns:**

</dt><dd>

True if this encoding is compatible with GGUF, False otherwise.

</dd><dt>

**Return type:**

</dt><dd>

[bool](https://docs.python.org/3/library/functions.html#bool)

</dd></dl>

### `name` {#max.graph.quantization.QuantizationEncoding.name}

> property name: [str](https://docs.python.org/3/library/stdtypes.html#str)

Gets the lowercase name of the quantization encoding.

<dl class='field-list'><dt>

**Returns:**

</dt><dd>

Lowercase string representation of the quantization encoding.

</dd><dt>

**Return type:**

</dt><dd>

[str](https://docs.python.org/3/library/stdtypes.html#str)

</dd></dl>

---

## shape

Library for graph shape types.

## `Shape` {#max.graph.shape.Shape}

> class max.graph.shape.Shape(dims=())

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

dims (ShapeLike)

</dd></dl>

### `from_mlir()` {#max.graph.shape.Shape.from_mlir}

> classmethod from\_mlir(attr)

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

attr (TypedAttr)

</dd><dt>

**Return type:**

</dt><dd>

[Shape](#max.graph.shape.Shape)

</dd></dl>

### `is_static()` {#max.graph.shape.Shape.is_static}

> static is\_static(shape)

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

shape ([Shape](#max.graph.shape.Shape))

</dd><dt>

**Return type:**

</dt><dd>

[TypeGuard](https://docs.python.org/3/library/typing.html#typing.TypeGuard)\[[list](https://docs.python.org/3/library/stdtypes.html#list)\[[StaticDim](dim.md#max.graph.dim.StaticDim)]]

</dd></dl>

### `parameters` {#max.graph.shape.Shape.parameters}

> property parameters: [Iterable](https://docs.python.org/3/library/collections.abc.html#collections.abc.Iterable)\[[SymbolicDim](dim.md#max.graph.dim.SymbolicDim)]

Lists the symbolic dimension names on which this shape depends.

### `rank` {#max.graph.shape.Shape.rank}

> property rank

### `static_dims` {#max.graph.shape.Shape.static_dims}

> property static\_dims: [list](https://docs.python.org/3/library/stdtypes.html#list)\[[int](https://docs.python.org/3/library/functions.html#int)]

Returns all static dims in the shape as a list of integers.

### `to_mlir()` {#max.graph.shape.Shape.to_mlir}

> to\_mlir()

<dl class='field-list'><dt>

**Return type:**

</dt><dd>

ShapeAttr

</dd></dl>

---

## type

Library for graph value types.

## `BufferType` {#max.graph.type.BufferType}

> class max.graph.type.BufferType(dtype, shape, device)

A symbolic buffer type.

This is a reference to a tensor that can be mutated in place.

Constructs a tensor type.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* dtype ([DType](../dtype.md#max.dtype.DType)) â€“ The element type of the tensor data.
* dims â€“ The shape dimensions of the tensor. The number of dims
  is the rank of the tensor.
* shape ([Shape](shape.md#max.graph.shape.Shape))
* device ([DeviceRef](#max.graph.type.DeviceRef))

</dd></dl>

### `as_tensor()` {#max.graph.type.BufferType.as_tensor}

> as\_tensor()

Returns the analogous tensor type.

<dl class='field-list'><dt>

**Return type:**

</dt><dd>

[TensorType](#max.graph.type.TensorType)

</dd></dl>

### `from_mlir()` {#max.graph.type.BufferType.from_mlir}

> classmethod from\_mlir(type)

Constructs a buffer type from an MLIR type.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* t â€“ The MLIR Type object to parse into a buffer type.
* type (BufferType)

</dd><dt>

**Returns:**

</dt><dd>

The buffer type represented by the MLIR Type value.

</dd><dt>

**Return type:**

</dt><dd>

[BufferType](#max.graph.type.BufferType)

</dd></dl>

### `to_mlir()` {#max.graph.type.BufferType.to_mlir}

> to\_mlir()

Converts to an `mlir.Type` instance.

<dl class='field-list'><dt>

**Returns:**

</dt><dd>

An `mlir.Type` in the specified Context.

</dd><dt>

**Return type:**

</dt><dd>

BufferType

</dd></dl>

## `ConvInputLayout` {#max.graph.type.ConvInputLayout}

> class max.graph.type.ConvInputLayout(value, names=\<not given>, \*values, module=None, qualname=None, type=None, start=1, boundary=None)

### `NCHW` {#max.graph.type.ConvInputLayout.NCHW}

> NCHW = 'NCHW'

### `NHWC` {#max.graph.type.ConvInputLayout.NHWC}

> NHWC = 'NHWC'

### `from_mlir()` {#max.graph.type.ConvInputLayout.from_mlir}

> static from\_mlir(attr)

Constructs a layout from an attribute.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

attr (StringAttr) â€“ The MLIR Attribute object to parse into a layout.

</dd><dt>

**Returns:**

</dt><dd>

The FilterLayout represented by the Attribute value.

</dd><dt>

**Return type:**

</dt><dd>

[ConvInputLayout](#max.graph.type.ConvInputLayout)

</dd></dl>

### `to_mlir()` {#max.graph.type.ConvInputLayout.to_mlir}

> to\_mlir()

Returns an mlir Attribute representing this Layout.
This attribute is used for certain convolution ops.

<dl class='field-list'><dt>

**Returns:**

</dt><dd>

An Attribute representing the layout.

</dd><dt>

**Return type:**

</dt><dd>

StringAttr

</dd></dl>

## `DeviceKind` {#max.graph.type.DeviceKind}

> class max.graph.type.DeviceKind(value, names=\<not given>, \*values, module=None, qualname=None, type=None, start=1, boundary=None)

A device type representation.

### `CPU` {#max.graph.type.DeviceKind.CPU}

> CPU = 'cpu'

### `GPU` {#max.graph.type.DeviceKind.GPU}

> GPU = 'gpu'

### `from_string()` {#max.graph.type.DeviceKind.from_string}

> static from\_string(txt)

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

txt ([str](https://docs.python.org/3/library/stdtypes.html#str))

</dd><dt>

**Return type:**

</dt><dd>

[DeviceKind](#max.graph.type.DeviceKind)

</dd></dl>

## `DeviceRef` {#max.graph.type.DeviceRef}

> class max.graph.type.DeviceRef(device\_type, id=0)

A symbolic device representation.

DeviceRef type representation consists of a DeviceKind and an id. This is a direct
representation of the device attribute in mlir.

The following example demonstrates how to create and use device references:

```python
from max.graph import DeviceRef
gpu_device = DeviceRef.GPU()
print(gpu_device)  # Outputs: gpu:0
# Create a CPU device with specific id
cpu_device = DeviceRef.CPU(id=1)
print(cpu_device)  # Outputs: cpu:1
```

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* device\_type ([DeviceKind](#max.graph.type.DeviceKind))
* id ([int](https://docs.python.org/3/library/functions.html#int))

</dd></dl>

### `CPU()` {#max.graph.type.DeviceRef.CPU}

> static CPU(id=0)

Static Method for creating a CPU device.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

id ([int](https://docs.python.org/3/library/functions.html#int))

</dd><dt>

**Return type:**

</dt><dd>

[DeviceRef](#max.graph.type.DeviceRef)

</dd></dl>

### `GPU()` {#max.graph.type.DeviceRef.GPU}

> static GPU(id=0)

Static Method for creating a GPU device.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

id ([int](https://docs.python.org/3/library/functions.html#int))

</dd><dt>

**Return type:**

</dt><dd>

[DeviceRef](#max.graph.type.DeviceRef)

</dd></dl>

### `device_type` {#max.graph.type.DeviceRef.device_type}

> device\_type: [DeviceKind](#max.graph.type.DeviceKind)

### `from_device()` {#max.graph.type.DeviceRef.from_device}

> static from\_device(device)

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

device ([Device](../driver.md#max.driver.Device) | [DeviceRef](#max.graph.type.DeviceRef))

</dd><dt>

**Return type:**

</dt><dd>

[DeviceRef](#max.graph.type.DeviceRef)

</dd></dl>

### `from_mlir()` {#max.graph.type.DeviceRef.from_mlir}

> static from\_mlir(attr)

Returns a device from mlir attribute

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

attr (DeviceRefAttr)

</dd><dt>

**Return type:**

</dt><dd>

[DeviceRef](#max.graph.type.DeviceRef)

</dd></dl>

### `id` {#max.graph.type.DeviceRef.id}

> id: [int](https://docs.python.org/3/library/functions.html#int)

### `is_cpu()` {#max.graph.type.DeviceRef.is_cpu}

> is\_cpu()

Returns true if the device is a CPU device.

<dl class='field-list'><dt>

**Return type:**

</dt><dd>

[bool](https://docs.python.org/3/library/functions.html#bool)

</dd></dl>

### `is_gpu()` {#max.graph.type.DeviceRef.is_gpu}

> is\_gpu()

Returns true if the device is a GPU device.

<dl class='field-list'><dt>

**Return type:**

</dt><dd>

[bool](https://docs.python.org/3/library/functions.html#bool)

</dd></dl>

### `to_device()` {#max.graph.type.DeviceRef.to_device}

> to\_device()

Convert device reference to a concrete driver Device.

<dl class='field-list'><dt>

**Return type:**

</dt><dd>

[Device](../driver.md#max.driver.Device)

</dd></dl>

### `to_mlir()` {#max.graph.type.DeviceRef.to_mlir}

> to\_mlir()

Returns a mlir attribute representing device.

<dl class='field-list'><dt>

**Return type:**

</dt><dd>

DeviceRefAttr

</dd></dl>

## `FilterLayout` {#max.graph.type.FilterLayout}

> class max.graph.type.FilterLayout(value, names=\<not given>, \*values, module=None, qualname=None, type=None, start=1, boundary=None)

### `CFRS` {#max.graph.type.FilterLayout.CFRS}

> CFRS = 'CFRS'

### `FCQRS` {#max.graph.type.FilterLayout.FCQRS}

> FCQRS = 'FCQRS'

### `FCRS` {#max.graph.type.FilterLayout.FCRS}

> FCRS = 'FCRS'

### `QRSCF` {#max.graph.type.FilterLayout.QRSCF}

> QRSCF = 'QRSCF'

### `RSCF` {#max.graph.type.FilterLayout.RSCF}

> RSCF = 'RSCF'

### `from_mlir()` {#max.graph.type.FilterLayout.from_mlir}

> static from\_mlir(attr)

Constructs a layout from an attribute.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

attr (LayoutAttr) â€“ The MLIR Attribute object to parse into a layout.

</dd><dt>

**Returns:**

</dt><dd>

The FilterLayout represented by the Attribute value.

</dd><dt>

**Return type:**

</dt><dd>

[FilterLayout](#max.graph.type.FilterLayout)

</dd></dl>

### `to_mlir()` {#max.graph.type.FilterLayout.to_mlir}

> to\_mlir()

Returns an mlir Attribute representing this Layout.
This attribute is used in tensor type metadata for certain ops.

<dl class='field-list'><dt>

**Returns:**

</dt><dd>

An Attribute representing the layout.

</dd><dt>

**Return type:**

</dt><dd>

LayoutAttr

</dd></dl>

## `TensorType` {#max.graph.type.TensorType}

> class max.graph.type.TensorType(dtype, shape, device, \_layout=None)

A symbolic [`TensorType`](#max.graph.type.TensorType).

This is not an eager tensor type! This contains no actual data, but
instead represents the type of a value at some point in time during model
execution.

Most internal values in a model will be tensors. This type represents
their element type (`dtype`) and dimensions (`dims`) at a specific point during
model computation. It allows us to do some optimistic optimizations and
shape inference during graph construction, and to provide more detailed
shape information to the compiler for further optimization passes.

The following example shows how to create a tensor type with static dimensions and access its properties:

```python
from max.graph import TensorType
from max.dtype import DType
# Create a tensor type with float32 elements and static dimensions 2x3
tensor_type = TensorType(DType.float32, (2, 3))
print(tensor_type.dtype)  # Outputs: DType.float32
print(tensor_type.shape)  # Outputs: [2, 3]
```

It can also represent a fully dynamic rank tensor. The presence of dynamic
rank tensors in a graph will often degrade performance dramatically and
prevents many classes of optimizations.

An optional device (`device`) can also be provided to indicate the explicit
device the tensor is associated with.

Constructs a tensor type.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* dtype ([DType](../dtype.md#max.dtype.DType)) â€“ The element type of the tensor data.
* dims â€“ The shape dimensions of the tensor. The number of dims
  is the rank of the tensor.
* shape ([Shape](shape.md#max.graph.shape.Shape))
* device ([DeviceRef](#max.graph.type.DeviceRef))
* \_layout ([FilterLayout](#max.graph.type.FilterLayout) | None)

</dd></dl>

### `as_buffer()` {#max.graph.type.TensorType.as_buffer}

> as\_buffer()

Returns the analogous buffer type.

<dl class='field-list'><dt>

**Return type:**

</dt><dd>

[BufferType](#max.graph.type.BufferType)

</dd></dl>

### `from_mlir()` {#max.graph.type.TensorType.from_mlir}

> classmethod from\_mlir(type)

Constructs a tensor type from an MLIR type.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* t â€“ The MLIR Type object to parse into a tensor type.
* type (TensorType)

</dd><dt>

**Returns:**

</dt><dd>

The tensor type represented by the MLIR Type value.

</dd><dt>

**Return type:**

</dt><dd>

[TensorType](#max.graph.type.TensorType)

</dd></dl>

### `to_mlir()` {#max.graph.type.TensorType.to_mlir}

> to\_mlir()

Converts to an `mlir.Type` instance.

<dl class='field-list'><dt>

**Returns:**

</dt><dd>

An `mlir.Type` in the specified Context.

</dd><dt>

**Return type:**

</dt><dd>

TensorType

</dd></dl>

## `Type` {#max.graph.type.Type}

> class max.graph.type.Type

Represents any possible type for Graph values.

Every Value in the Graph has a Type, and that type is represented by an Type.
This type may be inspected to get finer-grained types and learn more
about an individual Value.

The following example shows how to work with types in a graph:

```python
from max.graph import Graph, TensorType
from max.dtype import DType
with Graph() as g:
    # Create a tensor constant with a specific type
    tensor_type = TensorType(DType.float32, [2, 3])
    # The type can be inspected to get information about the value
    print(f"Tensor element type: {tensor_type.dtype}")  # Outputs: DType.float32
    print(f"Tensor shape: {tensor_type.shape}")  # Outputs: [2, 3]
```

### `from_mlir()` {#max.graph.type.Type.from_mlir}

> static from\_mlir(t)

Constructs a type from an MLIR type.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

t (MlirType) â€“ The MLIR Type object to parse into a type.

</dd><dt>

**Returns:**

</dt><dd>

The type represented by the MLIR Type value.

</dd><dt>

**Return type:**

</dt><dd>

[Type](#max.graph.type.Type)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]

</dd></dl>

### `to_mlir()` {#max.graph.type.Type.to_mlir}

> to\_mlir()

Converts to an `mlir.Type` instance.

<dl class='field-list'><dt>

**Returns:**

</dt><dd>

An `mlir.Type` in the specified Context.

</dd><dt>

**Return type:**

</dt><dd>

MlirType

</dd></dl>

---

## weights

Weights are the learned parameters that store a neural networkâ€™s knowledge.
Theyâ€™re multi-dimensional arrays (tensors) of numerical values that determine how
the model transforms inputs into outputs. These weights contain all the
information needed for a model to perform its task - whether thatâ€™s text
generation, image classification, or any other capability.

## `GGUFWeights` {#max.graph.weights.GGUFWeights}

> class max.graph.weights.GGUFWeights(source, tensors=None, prefix='', allocated=None)

Implementation for loading weights from GGUF (GPT-Generated Unified Format) files.

`GGUFWeights` provides an interface to load model weights from GGUF files,
which are optimized for quantized large language models. GGUF is the
successor to GGML format and is commonly used in the `llama.cpp` ecosystem
for efficient storage and loading of quantized models.

```python
from pathlib import Path
from max.graph.weights import GGUFWeights
from max.dtype import DType
from max.graph.quantization import QuantizationEncoding

gguf_path = Path("model-q4_k.gguf")
weights = GGUFWeights(gguf_path)

# Check if a weight exists
if weights.model.layers[0].attention.wq.exists():
    # Allocate quantized attention weight
    wq_weight = weights.model.layers[0].attention.wq.allocate(
        dtype=DType.uint8,  # GGUF quantized weights use uint8
        device=DeviceRef.CPU()
    )

# Access weight data with quantization info
weight_data = weights.model.layers[0].attention.wq.data()
print(f"Quantization: {weight_data.quantization_encoding}")
print(f"Shape: {weight_data.shape}")

# Allocate with quantization validation
ffn_weight = weights.model.layers[0].feed_forward.w1.allocate(
    quantization_encoding=QuantizationEncoding.Q4_K,
    device=DeviceRef.GPU(0)
)

# Iterate through all weights in a layer
for name, weight in weights.model.layers[0].items():
    if weight.exists():
        print(f"Found weight: {name}")
```

Creates a GGUF weights reader.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* source (Union\[PathLike\[[str](https://docs.python.org/3/library/stdtypes.html#str)], gguf.GGUFReader]) â€“ Path to a GGUF file or a GGUFReader object.
* tensors (Optional\[[dict](https://docs.python.org/3/library/stdtypes.html#dict)\[[str](https://docs.python.org/3/library/stdtypes.html#str), gguf.ReaderTensor]]) â€“ List of tensors in the GGUF checkpoint.
* prefix ([str](https://docs.python.org/3/library/stdtypes.html#str)) â€“ Weight name or prefix.
* allocated (Optional\[[dict](https://docs.python.org/3/library/stdtypes.html#dict)\[[str](https://docs.python.org/3/library/stdtypes.html#str), [DLPackArray](../driver.md#max.driver.DLPackArray)]]) â€“ Dictionary of allocated values.

</dd></dl>

### `allocate()` {#max.graph.weights.GGUFWeights.allocate}

> allocate(dtype=None, shape=None, quantization\_encoding=None, device=cpu:0)

Creates and optionally validates a new Weight.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* dtype ([DType](../dtype.md#max.dtype.DType) | None)
* shape ([Iterable](https://docs.python.org/3/library/collections.abc.html#collections.abc.Iterable)\[[int](https://docs.python.org/3/library/functions.html#int) | [str](https://docs.python.org/3/library/stdtypes.html#str) | [Dim](dim.md#max.graph.dim.Dim) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]] | None)
* quantization\_encoding ([QuantizationEncoding](quantization.md#max.graph.quantization.QuantizationEncoding) | None)
* device ([DeviceRef](type.md#max.graph.type.DeviceRef))

</dd><dt>

**Return type:**

</dt><dd>

[Weight](Weight.md#max.graph.Weight)

</dd></dl>

### `allocated_weights` {#max.graph.weights.GGUFWeights.allocated_weights}

> property allocated\_weights: [dict](https://docs.python.org/3/library/stdtypes.html#dict)\[[str](https://docs.python.org/3/library/stdtypes.html#str), [DLPackArray](../driver.md#max.driver.DLPackArray)]

Gets the values of all weights that were allocated previously.

### `data()` {#max.graph.weights.GGUFWeights.data}

> data()

Get weight data with metadata.

```python
weight_data = weights.model.embeddings.weight.data()
print(f"Shape: {weight_data.shape}")
print(f"Dtype: {weight_data.dtype}")

# Convert to different dtype
fp16_data = weight_data.astype(DType.float16)
```

<dl class='field-list'><dt>

**Returns:**

</dt><dd>

A WeightData object containing the tensor data along with
metadata like name, dtype, shape, and quantization encoding.

</dd><dt>

**Raises:**

</dt><dd>

[KeyError](https://docs.python.org/3/library/exceptions.html#KeyError) â€“ If no weight exists at the current hierarchical name.

</dd><dt>

**Return type:**

</dt><dd>

[WeightData](#max.graph.weights.WeightData)

</dd></dl>

### `exists()` {#max.graph.weights.GGUFWeights.exists}

> exists()

Check if a weight with this exact name exists.

```python
if weights.model.classifier.weight.exists():
    classifier = weights.model.classifier.weight.allocate(...)
else:
    print("Classifier weight not found")
```

<dl class='field-list'><dt>

**Returns:**

</dt><dd>

True if a weight with the current hierarchical name exists
in the loaded weights, False otherwise.

</dd><dt>

**Return type:**

</dt><dd>

[bool](https://docs.python.org/3/library/functions.html#bool)

</dd></dl>

### `items()` {#max.graph.weights.GGUFWeights.items}

> items()

Iterate through all allocable weights that start with the prefix.

### `name` {#max.graph.weights.GGUFWeights.name}

> property name: [str](https://docs.python.org/3/library/stdtypes.html#str)

The current weight name or prefix.

## `PytorchWeights` {#max.graph.weights.PytorchWeights}

> class max.graph.weights.PytorchWeights(filepath, tensor\_infos=None, prefix='', allocated=None)

Implementation for loading weights from PyTorch checkpoint files.

`PytorchWeights` provides an interface to load model weights from PyTorch
checkpoint files (.bin or .pt format). These files contain serialized
PyTorch tensors using Pythonâ€™s pickle protocol, making them widely compatible
with the PyTorch ecosystem.

```python
from pathlib import Path
from max.graph.weights import PytorchWeights
from max.dtype import DType

# Load weights from PyTorch checkpoint
checkpoint_path = Path("pytorch_model.bin")
weights = PytorchWeights(checkpoint_path)

# Check if a weight exists before allocation
if weights.model.decoder.layers[0].self_attn.q_proj.weight.exists():
    # Allocate the attention weight
    q_weight = weights.model.decoder.layers[0].self_attn.q_proj.weight.allocate(
        dtype=DType.float32,
        device=DeviceRef.CPU()
    )

# Access weight properties
if weights.embeddings.weight.exists():
    print(f"Embedding shape: {weights.embeddings.weight.shape}")
    print(f"Embedding dtype: {weights.embeddings.weight.dtype}")

# Allocate with validation
embedding_weight = weights.embeddings.weight.allocate(
    dtype=DType.float16,
    shape=(50257, 768)  # Validate expected shape
)
```

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* filepath (PathLike\[[str](https://docs.python.org/3/library/stdtypes.html#str)])
* tensor\_infos (Optional\[[dict](https://docs.python.org/3/library/stdtypes.html#dict)\[[str](https://docs.python.org/3/library/stdtypes.html#str), Any]])
* prefix ([str](https://docs.python.org/3/library/stdtypes.html#str))

</dd></dl>

### `allocate()` {#max.graph.weights.PytorchWeights.allocate}

> allocate(dtype=None, shape=None, quantization\_encoding=None, device=cpu:0)

Creates and optionally validates a new Weight.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* dtype ([DType](../dtype.md#max.dtype.DType) | None)
* shape ([Iterable](https://docs.python.org/3/library/collections.abc.html#collections.abc.Iterable)\[[int](https://docs.python.org/3/library/functions.html#int) | [str](https://docs.python.org/3/library/stdtypes.html#str) | [Dim](dim.md#max.graph.dim.Dim) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]] | None)
* quantization\_encoding ([QuantizationEncoding](quantization.md#max.graph.quantization.QuantizationEncoding) | None)
* device ([DeviceRef](type.md#max.graph.type.DeviceRef))

</dd><dt>

**Return type:**

</dt><dd>

[Weight](Weight.md#max.graph.Weight)

</dd></dl>

### `allocated_weights` {#max.graph.weights.PytorchWeights.allocated_weights}

> property allocated\_weights: [dict](https://docs.python.org/3/library/stdtypes.html#dict)\[[str](https://docs.python.org/3/library/stdtypes.html#str), [DLPackArray](../driver.md#max.driver.DLPackArray)]

Gets the values of all weights that were allocated previously.

### `data()` {#max.graph.weights.PytorchWeights.data}

> data()

<dl class='field-list'><dt>

**Return type:**

</dt><dd>

[WeightData](#max.graph.weights.WeightData)

</dd></dl>

### `dtype` {#max.graph.weights.PytorchWeights.dtype}

> property dtype: [DType](../dtype.md#max.dtype.DType)

The current weight dtype, if this weight exists.

### `exists()` {#max.graph.weights.PytorchWeights.exists}

> exists()

<dl class='field-list'><dt>

**Return type:**

</dt><dd>

[bool](https://docs.python.org/3/library/functions.html#bool)

</dd></dl>

### `items()` {#max.graph.weights.PytorchWeights.items}

> items()

Iterate through all allocable weights that start with the prefix.

### `name` {#max.graph.weights.PytorchWeights.name}

> property name: [str](https://docs.python.org/3/library/stdtypes.html#str)

The current weight name or prefix.

### `quantization_encoding` {#max.graph.weights.PytorchWeights.quantization_encoding}

> property quantization\_encoding: [QuantizationEncoding](quantization.md#max.graph.quantization.QuantizationEncoding) | [None](https://docs.python.org/3/library/constants.html#None)

The current weight quantization encoding, if this weight exists.

### `shape` {#max.graph.weights.PytorchWeights.shape}

> property shape: [Shape](shape.md#max.graph.shape.Shape)

The current weight shape, if this weight exists.

## `SafetensorWeights` {#max.graph.weights.SafetensorWeights}

> class max.graph.weights.SafetensorWeights(filepaths, \*, tensors=None, tensors\_to\_file\_idx=None, prefix='', allocated=None, \_st\_weight\_map=None, \_st\_file\_handles=None)

Implementation for loading weights from safetensors files.

SafetensorWeights provides a secure and efficient way to load model weights
from safetensors format files. Safetensors is designed by Hugging Face for
safe serialization that prevents arbitrary code execution and supports
memory-mapped loading for fast access.

```python
from pathlib import Path
from max.graph.weights import SafetensorWeights
from max.dtype import DType

# Load weights from safetensors files
weight_files = [Path("model.safetensors")]
weights = SafetensorWeights(weight_files)

# Check if a weight exists
if weights.model.embeddings.weight.exists():
    # Allocate the embedding weight
    embedding_weight = weights.model.embeddings.weight.allocate(
        dtype=DType.float32,
        device=DeviceRef.CPU()
    )

# Access weights with hierarchical naming
attn_weight = weights.transformer.layers[0].attention.weight.allocate(
    dtype=DType.float16
)
```

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* filepaths (Sequence\[PathLike\[[str](https://docs.python.org/3/library/stdtypes.html#str)]])
* tensors (Optional\[Set\[[str](https://docs.python.org/3/library/stdtypes.html#str)]])
* tensors\_to\_file\_idx (Mapping\[[str](https://docs.python.org/3/library/stdtypes.html#str), [int](https://docs.python.org/3/library/functions.html#int)] | None)
* prefix ([str](https://docs.python.org/3/library/stdtypes.html#str))
* allocated (Optional\[[dict](https://docs.python.org/3/library/stdtypes.html#dict)\[[str](https://docs.python.org/3/library/stdtypes.html#str), [DLPackArray](../driver.md#max.driver.DLPackArray)]])
* \_st\_weight\_map ([dict](https://docs.python.org/3/library/stdtypes.html#dict)\[[str](https://docs.python.org/3/library/stdtypes.html#str), [Tensor](../driver.md#max.driver.Tensor)])
* \_st\_file\_handles ([dict](https://docs.python.org/3/library/stdtypes.html#dict)\[[PathLike](https://docs.python.org/3/library/os.html#os.PathLike)\[[str](https://docs.python.org/3/library/stdtypes.html#str)], SafeTensor])

</dd></dl>

### `allocate()` {#max.graph.weights.SafetensorWeights.allocate}

> allocate(dtype=None, shape=None, quantization\_encoding=None, device=cpu:0)

Creates a Weight that can be added to a graph.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* dtype ([DType](../dtype.md#max.dtype.DType) | None)
* shape ([Iterable](https://docs.python.org/3/library/collections.abc.html#collections.abc.Iterable)\[[int](https://docs.python.org/3/library/functions.html#int) | [str](https://docs.python.org/3/library/stdtypes.html#str) | [Dim](dim.md#max.graph.dim.Dim) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]] | None)
* quantization\_encoding ([QuantizationEncoding](quantization.md#max.graph.quantization.QuantizationEncoding) | None)
* device ([DeviceRef](type.md#max.graph.type.DeviceRef))

</dd><dt>

**Return type:**

</dt><dd>

[Weight](Weight.md#max.graph.Weight)

</dd></dl>

### `allocate_as_bytes()` {#max.graph.weights.SafetensorWeights.allocate_as_bytes}

> allocate\_as\_bytes(dtype=None)

Create a Weight that can be added to the graph. Has a uint8
representation, instead of the original data type. Last dimension of
the scale gets scaled by number of bytes it takes to represent the
original data type. For example, \[512, 256] float32 weights become
\[512, 1024] uint8 weights. Scalar weights will be interpreted as
weights with shape \[1].

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

dtype ([DType](../dtype.md#max.dtype.DType) | None)

</dd><dt>

**Return type:**

</dt><dd>

[Weight](Weight.md#max.graph.Weight)

</dd></dl>

### `allocated_weights` {#max.graph.weights.SafetensorWeights.allocated_weights}

> property allocated\_weights: [dict](https://docs.python.org/3/library/stdtypes.html#dict)\[[str](https://docs.python.org/3/library/stdtypes.html#str), [DLPackArray](../driver.md#max.driver.DLPackArray)]

Gets the values of all weights that were allocated previously.

### `data()` {#max.graph.weights.SafetensorWeights.data}

> data()

Get weight data with metadata.

```python
weight_data = weights.model.embeddings.weight.data()
print(f"Shape: {weight_data.shape}")
print(f"Dtype: {weight_data.dtype}")

# Convert to different dtype
fp16_data = weight_data.astype(DType.float16)
```

<dl class='field-list'><dt>

**Returns:**

</dt><dd>

A WeightData object containing the tensor data along with
metadata like name, dtype, shape, and quantization encoding.

</dd><dt>

**Raises:**

</dt><dd>

[KeyError](https://docs.python.org/3/library/exceptions.html#KeyError) â€“ If no weight exists at the current hierarchical name.

</dd><dt>

**Return type:**

</dt><dd>

[WeightData](#max.graph.weights.WeightData)

</dd></dl>

### `exists()` {#max.graph.weights.SafetensorWeights.exists}

> exists()

Check if a weight with this exact name exists.

```python
if weights.model.classifier.weight.exists():
    classifier = weights.model.classifier.weight.allocate(...)
else:
    print("Classifier weight not found")
```

<dl class='field-list'><dt>

**Returns:**

</dt><dd>

True if a weight with the current hierarchical name exists
in the loaded weights, False otherwise.

</dd><dt>

**Return type:**

</dt><dd>

[bool](https://docs.python.org/3/library/functions.html#bool)

</dd></dl>

### `items()` {#max.graph.weights.SafetensorWeights.items}

> items()

Iterate through all allocable weights that start with the prefix.

### `name` {#max.graph.weights.SafetensorWeights.name}

> property name: [str](https://docs.python.org/3/library/stdtypes.html#str)

The current weight name or prefix.

## `WeightData` {#max.graph.weights.WeightData}

> class max.graph.weights.WeightData(data, name, dtype, shape, quantization\_encoding=None)

Container for weight tensor data with metadata.

`WeightData` encapsulates a weight tensor along with its metadata,
providing utilities for type conversion and format compatibility.
It supports the DLPack protocol for efficient tensor sharing between
frameworks.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* data ([DLPackArray](../driver.md#max.driver.DLPackArray))
* name ([str](https://docs.python.org/3/library/stdtypes.html#str))
* dtype ([DType](../dtype.md#max.dtype.DType))
* shape ([Shape](shape.md#max.graph.shape.Shape))
* quantization\_encoding ([QuantizationEncoding](quantization.md#max.graph.quantization.QuantizationEncoding) | None)

</dd></dl>

### `astype()` {#max.graph.weights.WeightData.astype}

> astype(dtype)

Convert the weight data to a different dtype.

This method performs actual data conversion, unlike `view()` which
reinterprets the underlying bytes. Special handling is provided for
bfloat16 conversions using PyTorch when available.

```python
# Convert float32 weights to float16 for reduced memory
weight_data = weights.model.layer.weight.data()
fp16_data = weight_data.astype(DType.float16)
```

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

dtype ([DType](../dtype.md#max.dtype.DType)) â€“ Target data type for conversion.

</dd><dt>

**Returns:**

</dt><dd>

A new WeightData instance with the converted data.

</dd><dt>

**Return type:**

</dt><dd>

[WeightData](#max.graph.weights.WeightData)

</dd></dl>

### `data` {#max.graph.weights.WeightData.data}

> data: [DLPackArray](../driver.md#max.driver.DLPackArray)

The weight tensor as a DLPack array.

### `dtype` {#max.graph.weights.WeightData.dtype}

> dtype: [DType](../dtype.md#max.dtype.DType)

Data type of the tensor (for example, `DType.float32`, `DType.uint8`).

### `from_numpy()` {#max.graph.weights.WeightData.from_numpy}

> classmethod from\_numpy(arr, name)

Create WeightData from a numpy array.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* arr ([ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]) â€“ Numpy array containing the weight data.
* name ([str](https://docs.python.org/3/library/stdtypes.html#str)) â€“ Name to assign to this weight.

</dd><dt>

**Returns:**

</dt><dd>

A new WeightData instance with dtype and shape inferred
from the numpy array.

</dd><dt>

**Return type:**

</dt><dd>

[WeightData](#max.graph.weights.WeightData)

</dd></dl>

### `name` {#max.graph.weights.WeightData.name}

> name: [str](https://docs.python.org/3/library/stdtypes.html#str)

Hierarchical name of the weight (for example, `"model.layers.0.weight"`).

### `quantization_encoding` {#max.graph.weights.WeightData.quantization_encoding}

> quantization\_encoding: [QuantizationEncoding](quantization.md#max.graph.quantization.QuantizationEncoding) | [None](https://docs.python.org/3/library/constants.html#None) = None

Optional quantization scheme applied to the weight.

### `shape` {#max.graph.weights.WeightData.shape}

> shape: [Shape](shape.md#max.graph.shape.Shape)

Shape of the tensor as a Shape object.

## `Weights` {#max.graph.weights.Weights}

> class max.graph.weights.Weights(\*args, \*\*kwargs)

Protocol for managing and accessing model weights hierarchically.

The Weights protocol provides a convenient interface for loading and organizing
neural network weights. It supports hierarchical naming through attribute and
index access, making it easy to work with complex model architectures.

Weights in MAX are tensors backed by external memory (buffers or memory-mapped
files) that remain separate from the compiled graph.

```python
from max.graph import Graph
from max.dtype import DType

# Create a graph and get its weights interface
graph = Graph("my_model")
weights = graph.weights()

# Allocate weights with hierarchical naming
attn_weight = weights.transformer.layers[0].attention.weight.allocate(
    dtype=DType.float32,
    shape=(768, 768)
)
# Creates weight named "transformer.layers.0.attention.weight"

# Check if a weight exists before allocating
if weights.transformer.layers[0].mlp.weight.exists():
    mlp_weight = weights.transformer.layers[0].mlp.weight.allocate(
        dtype=DType.float16,
        shape=(768, 3072)
    )
```

### `allocate()` {#max.graph.weights.Weights.allocate}

> allocate(dtype=None, shape=None, quantization\_encoding=None, device=cpu:0)

Create a Weight object for this tensor.

```python
# Allocate a weight with specific configuration
weight = weights.model.layers[0].weight.allocate(
    dtype=DType.float16,  # Convert to half precision
    shape=(768, 768),
    device=DeviceRef.GPU(0)  # Place on first GPU
)

# Add to graph
with graph:
    weight_tensor = graph.add_weight(weight)
```

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* dtype ([DType](../dtype.md#max.dtype.DType) | None) â€“ Data type for the weight. If `None`, uses the original dtype.
* shape ([Iterable](https://docs.python.org/3/library/collections.abc.html#collections.abc.Iterable)\[[int](https://docs.python.org/3/library/functions.html#int) | [str](https://docs.python.org/3/library/stdtypes.html#str) | [Dim](dim.md#max.graph.dim.Dim) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]] | None) â€“ Shape of the weight tensor. If `None`, uses the original shape.
* quantization\_encoding ([QuantizationEncoding](quantization.md#max.graph.quantization.QuantizationEncoding) | None) â€“ Quantization scheme to apply (for example, `Q4_K`, `Q8_0`).
* device ([DeviceRef](type.md#max.graph.type.DeviceRef)) â€“ Target device for the weight (CPU or GPU).

</dd><dt>

**Returns:**

</dt><dd>

A Weight object that can be added to a graph using
`graph.add_weight()`.

</dd><dt>

**Return type:**

</dt><dd>

[Weight](Weight.md#max.graph.Weight)

</dd></dl>

### `allocated_weights` {#max.graph.weights.Weights.allocated_weights}

> property allocated\_weights: [dict](https://docs.python.org/3/library/stdtypes.html#dict)\[[str](https://docs.python.org/3/library/stdtypes.html#str), [DLPackArray](../driver.md#max.driver.DLPackArray)]

Get all previously allocated weights. This only includes weights that were explicitly allocated
: using the [`allocate()`](#max.graph.weights.Weights.allocate) method, not all available weights.

<dl class='field-list'><dt>

**Returns:**

</dt><dd>

A dictionary mapping weight names to their numpy arrays for
all weights that have been allocated through this interface.

</dd></dl>

### `data()` {#max.graph.weights.Weights.data}

> data()

Get weight data with metadata.

```python
weight_data = weights.model.embeddings.weight.data()
print(f"Shape: {weight_data.shape}")
print(f"Dtype: {weight_data.dtype}")

# Convert to different dtype
fp16_data = weight_data.astype(DType.float16)
```

<dl class='field-list'><dt>

**Returns:**

</dt><dd>

A WeightData object containing the tensor data along with
metadata like name, dtype, shape, and quantization encoding.

</dd><dt>

**Raises:**

</dt><dd>

[KeyError](https://docs.python.org/3/library/exceptions.html#KeyError) â€“ If no weight exists at the current hierarchical name.

</dd><dt>

**Return type:**

</dt><dd>

[WeightData](#max.graph.weights.WeightData)

</dd></dl>

### `exists()` {#max.graph.weights.Weights.exists}

> exists()

Check if a weight with this exact name exists.

```python
if weights.model.classifier.weight.exists():
    classifier = weights.model.classifier.weight.allocate(...)
else:
    print("Classifier weight not found")
```

<dl class='field-list'><dt>

**Returns:**

</dt><dd>

True if a weight with the current hierarchical name exists
in the loaded weights, False otherwise.

</dd><dt>

**Return type:**

</dt><dd>

[bool](https://docs.python.org/3/library/functions.html#bool)

</dd></dl>

### `items()` {#max.graph.weights.Weights.items}

> items()

Iterate through all weights that start with the current prefix.

```python
# Iterate through all weights in a specific layer
for name, weight in weights.transformer.layers[0].items():
    print(f"Found weight: {name}")
```

<dl class='field-list'><dt>

**Yields:**

</dt><dd>

Tuples of (name, weight\_accessor) for each weight under the
current prefix. The name is relative to the current prefix.

</dd><dt>

**Parameters:**

</dt><dd>

self (\_Self)

</dd><dt>

**Return type:**

</dt><dd>

[Iterator](https://docs.python.org/3/library/collections.abc.html#collections.abc.Iterator)\[[tuple](https://docs.python.org/3/library/stdtypes.html#tuple)\[[str](https://docs.python.org/3/library/stdtypes.html#str), \_Self]]

</dd></dl>

### `name` {#max.graph.weights.Weights.name}

> property name: [str](https://docs.python.org/3/library/stdtypes.html#str)

Get the current weight name or prefix.

<dl class='field-list'><dt>

**Returns:**

</dt><dd>

The hierarchical name built from attribute and index access.
For example, if accessed as `weights.model.layers[0]`,
returns â€œmodel.layers.0â€.

</dd></dl>

## `WeightsFormat` {#max.graph.weights.WeightsFormat}

> class max.graph.weights.WeightsFormat(value, names=\<not given>, \*values, module=None, qualname=None, type=None, start=1, boundary=None)

Enumeration of supported weight file formats.

MAX supports multiple weight formats to accommodate different model sources
and use cases.

### `gguf` {#max.graph.weights.WeightsFormat.gguf}

> gguf = 'gguf'

GGUF (GPT-Generated Unified Format) for quantized models.

File extension: `.gguf`

Optimized for quantized large language models, particularly those from the
llama.cpp ecosystem. Supports multiple quantization schemes (`Q4_K`,
`Q5_K`, `Q8_0`, etc.) and includes model metadata in the file.

### `pytorch` {#max.graph.weights.WeightsFormat.pytorch}

> pytorch = 'pytorch'

PyTorch checkpoint format for model weights.

File extension: `.bin` | `.pt` | `.pth`

Standard PyTorch format using Pythonâ€™s pickle protocol. Widely
supported but requires caution as pickle files can execute arbitrary
code.

### `safetensors` {#max.graph.weights.WeightsFormat.safetensors}

> safetensors = 'safetensors'

Safetensors format for secure and efficient tensor storage.

File extension: `.safetensors`

Designed by Hugging Face for safe serialization that prevents
arbitrary code execution. Uses memory-mapped files for fast loading
and supports sharding across multiple files.

## `load_weights()` {#max.graph.weights.load_weights}

> max.graph.weights.load\_weights(paths)

Loads neural network weights from checkpoint files.

Automatically detects checkpoint formats based on file extensions and returns
the appropriate Weights implementation, creating a seamless interface for
loading weights from different formats.

Supported formats:

* Safetensors: .safetensors
* PyTorch: .bin, .pt, .pth
* GGUF: .gguf

The following example shows how to load weights from a Safetensors file:

```python
from pathlib import Path
from max.graph.weights import load_weights

# Load multi-file checkpoints
sharded_paths = [
    Path("model-00001-of-00003.safetensors"),
    Path("model-00002-of-00003.safetensors"),
    Path("model-00003-of-00003.safetensors")
]
weights = load_weights(sharded_paths)
layer_weight = weights.model.layers[23].mlp.gate_proj.weight.allocate(
    dtype=DType.float32,
    shape=[4096, 14336],
    device=DeviceRef.GPU(0)
)
```

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

paths ([list](https://docs.python.org/3/library/stdtypes.html#list)\[[Path](https://docs.python.org/3/library/pathlib.html#pathlib.Path)]) â€“ List of pathlib.Path objects pointing to checkpoint files.
For multi-file checkpoints (e.g., sharded Safetensors), provide
all file paths in the list. For single-file checkpoints, provide
a list with one path.

</dd><dt>

**Return type:**

</dt><dd>

[Weights](#max.graph.weights.Weights)

</dd></dl>

## `weights_format()` {#max.graph.weights.weights_format}

> max.graph.weights.weights\_format(weight\_paths)

Detect the format of weight files based on their extensions.

This function examines the file extensions of all provided paths to
determine the weight format. All files must have the same format;
mixed formats are not supported.

```python
from pathlib import Path

# Detect format for safetensor files
paths = [Path("model-00001.safetensors"), Path("model-00002.safetensors")]
format = weights_format(paths)
print(format)  # WeightsFormat.safetensors
```

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

weight\_paths ([list](https://docs.python.org/3/library/stdtypes.html#list)\[[Path](https://docs.python.org/3/library/pathlib.html#pathlib.Path)]) â€“ List of file paths containing model weights. All files
must have the same extension/format.

</dd><dt>

**Returns:**

</dt><dd>

The detected WeightsFormat enum value.

</dd><dt>

**Raises:**

</dt><dd>

[ValueError](https://docs.python.org/3/library/exceptions.html#ValueError) â€“ If weight\_paths is empty, contains mixed formats, or
has unsupported file extensions.

</dd><dt>

**Return type:**

</dt><dd>

[WeightsFormat](#max.graph.weights.WeightsFormat)

</dd></dl>

---

## max

The MAX Python API reference.

The MAX API provides a high-performance graph compiler and runtime library that
executes AI models with incredible speed on a wide range of hardware.

MAX offers a layered architecture that lets you work at the level of abstraction
that best fits your needs. From deploying production-ready models with a few
lines of code to building custom neural networks from scratch, each layer builds
upon the others so you can move between levels seamlessly as requirements evolve.

To install the MAX Python API, see the [`Quickstart`](/max/get-started) guide.

## Modules

* [`driver`](/max/api/python/driver): Low-level device management and tensor operations.
* [`dtype`](/max/api/python/dtype): Unified data type system supporting various numeric formats.
* [`engine`](/max/api/python/engine): Model execution runtime with automatic optimization.
* [`entrypoints`](/max/api/python/entrypoints): Command-line tools and serving infrastructure.
* [`experimental`](/max/api/python/experimental): Experimental features and APIs under active development.
* [`interfaces`](/max/api/python/interfaces): Universal interfaces for consistent API integration.
* [`torch`](/max/api/python/torch): PyTorch integration for custom operations and interoperability.

## Packages

* [`graph`](/max/api/python/graph): Computational graph construction with 100+ operations for complete model control.
* [`pipelines`](/max/api/python/pipelines): Pre-built, optimized model architectures for immediate deployment.
* [`nn`](/max/api/python/nn): High-level neural network building blocks with automatic graph compilation.
* [`experimental`](/max/api/python/experimental): Experimental APIs for advanced users and early adopters (subject to change).

---

## interfaces

Universal interfaces between all aspects of the MAX Inference Stack.

## `AudioGenerationMetadata` {#max.interfaces.AudioGenerationMetadata}

> class max.interfaces.AudioGenerationMetadata(\*, sample\_rate=None, duration=None, chunk\_id=None, timestamp=None, final\_chunk=None, model\_name=None, request\_id=None, tokens\_generated=None, processing\_time=None, echo=None)

Represents metadata associated with audio generation.

This class will eventually replace the metadata dictionary used throughout
the AudioGeneratorOutput object, providing a structured and type-safe
alternative for audio generation metadata.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* sample\_rate ([int](https://docs.python.org/3/library/functions.html#int) | None) â€“ The sample rate of the generated audio in Hz.
* duration ([float](https://docs.python.org/3/library/functions.html#float) | None) â€“ The duration of the generated audio in seconds.
* chunk\_id ([int](https://docs.python.org/3/library/functions.html#int) | None) â€“ Identifier for the audio chunk (useful for streaming).
* timestamp ([str](https://docs.python.org/3/library/stdtypes.html#str) | None) â€“ Timestamp when the audio was generated.
* final\_chunk ([bool](https://docs.python.org/3/library/functions.html#bool) | None) â€“ Whether this is the final chunk in a streaming sequence.
* model\_name ([str](https://docs.python.org/3/library/stdtypes.html#str) | None) â€“ Name of the model used for generation.
* request\_id ([str](https://docs.python.org/3/library/stdtypes.html#str) | None) â€“ Unique identifier for the generation request.
* tokens\_generated ([int](https://docs.python.org/3/library/functions.html#int) | None) â€“ Number of tokens generated for this audio.
* processing\_time ([float](https://docs.python.org/3/library/functions.html#float) | None) â€“ Time taken to process this audio chunk in seconds.
* echo ([str](https://docs.python.org/3/library/stdtypes.html#str) | None) â€“ Echo of the input prompt or identifier for verification.

</dd></dl>

### `chunk_id` {#max.interfaces.AudioGenerationMetadata.chunk_id}

> chunk\_id: [int](https://docs.python.org/3/library/functions.html#int) | [None](https://docs.python.org/3/library/constants.html#None)

### `duration` {#max.interfaces.AudioGenerationMetadata.duration}

> duration: [float](https://docs.python.org/3/library/functions.html#float) | [None](https://docs.python.org/3/library/constants.html#None)

### `echo` {#max.interfaces.AudioGenerationMetadata.echo}

> echo: [str](https://docs.python.org/3/library/stdtypes.html#str) | [None](https://docs.python.org/3/library/constants.html#None)

### `final_chunk` {#max.interfaces.AudioGenerationMetadata.final_chunk}

> final\_chunk: [bool](https://docs.python.org/3/library/functions.html#bool) | [None](https://docs.python.org/3/library/constants.html#None)

### `model_name` {#max.interfaces.AudioGenerationMetadata.model_name}

> model\_name: [str](https://docs.python.org/3/library/stdtypes.html#str) | [None](https://docs.python.org/3/library/constants.html#None)

### `processing_time` {#max.interfaces.AudioGenerationMetadata.processing_time}

> processing\_time: [float](https://docs.python.org/3/library/functions.html#float) | [None](https://docs.python.org/3/library/constants.html#None)

### `request_id` {#max.interfaces.AudioGenerationMetadata.request_id}

> request\_id: [str](https://docs.python.org/3/library/stdtypes.html#str) | [None](https://docs.python.org/3/library/constants.html#None)

### `sample_rate` {#max.interfaces.AudioGenerationMetadata.sample_rate}

> sample\_rate: [int](https://docs.python.org/3/library/functions.html#int) | [None](https://docs.python.org/3/library/constants.html#None)

### `timestamp` {#max.interfaces.AudioGenerationMetadata.timestamp}

> timestamp: [str](https://docs.python.org/3/library/stdtypes.html#str) | [None](https://docs.python.org/3/library/constants.html#None)

### `to_dict()` {#max.interfaces.AudioGenerationMetadata.to_dict}

> to\_dict()

Convert the metadata to a dictionary format.

<dl class='field-list'><dt>

**Returns:**

</dt><dd>

Dictionary representation of the metadata.

</dd><dt>

**Return type:**

</dt><dd>

[dict](https://docs.python.org/3/library/stdtypes.html#dict)\[[str](https://docs.python.org/3/library/stdtypes.html#str), any]

</dd></dl>

### `tokens_generated` {#max.interfaces.AudioGenerationMetadata.tokens_generated}

> tokens\_generated: [int](https://docs.python.org/3/library/functions.html#int) | [None](https://docs.python.org/3/library/constants.html#None)

## `AudioGenerationRequest` {#max.interfaces.AudioGenerationRequest}

> class max.interfaces.AudioGenerationRequest(request\_id: str, model: 'str', input: 'Optional\[str]' = None, audio\_prompt\_tokens: 'list\[int]' = \<factory>, audio\_prompt\_transcription: 'str' = '', sampling\_params: 'SamplingParams' = \<factory>, \_assistant\_message\_override: 'str | None' = None, prompt: 'Optional\[list\[int] | str]' = None, streaming: 'bool' = True, buffer\_speech\_tokens: 'npt.NDArray\[np.integer\[Any]] | None' = None)

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* request\_id ([str](https://docs.python.org/3/library/stdtypes.html#str))
* model ([str](https://docs.python.org/3/library/stdtypes.html#str))
* input ([str](https://docs.python.org/3/library/stdtypes.html#str) | None)
* audio\_prompt\_tokens ([list](https://docs.python.org/3/library/stdtypes.html#list)\[[int](https://docs.python.org/3/library/functions.html#int)])
* audio\_prompt\_transcription ([str](https://docs.python.org/3/library/stdtypes.html#str))
* sampling\_params ([SamplingParams](#max.interfaces.SamplingParams))
* \_assistant\_message\_override ([str](https://docs.python.org/3/library/stdtypes.html#str) | None)
* prompt ([list](https://docs.python.org/3/library/stdtypes.html#list)\[[int](https://docs.python.org/3/library/functions.html#int)] | [str](https://docs.python.org/3/library/stdtypes.html#str) | None)
* streaming ([bool](https://docs.python.org/3/library/functions.html#bool))
* buffer\_speech\_tokens ([ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]] | None)

</dd></dl>

### `audio_prompt_tokens` {#max.interfaces.AudioGenerationRequest.audio_prompt_tokens}

> audio\_prompt\_tokens: [list](https://docs.python.org/3/library/stdtypes.html#list)\[[int](https://docs.python.org/3/library/functions.html#int)]

The prompt speech IDs to use for audio generation.

### `audio_prompt_transcription` {#max.interfaces.AudioGenerationRequest.audio_prompt_transcription}

> audio\_prompt\_transcription: [str](https://docs.python.org/3/library/stdtypes.html#str) = ''

The audio prompt transcription to use for audio generation.

### `buffer_speech_tokens` {#max.interfaces.AudioGenerationRequest.buffer_speech_tokens}

> buffer\_speech\_tokens: [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]] | [None](https://docs.python.org/3/library/constants.html#None) = None

An optional field potentially containing the last N speech tokens
generated by the model from a previous request.

When this field is specified, this tensor is used to buffer the tokens sent
to the audio decoder.

### `input` {#max.interfaces.AudioGenerationRequest.input}

> input: [str](https://docs.python.org/3/library/stdtypes.html#str) | [None](https://docs.python.org/3/library/constants.html#None) = None

The text to generate audio for. The maximum length is 4096 characters.

### `model` {#max.interfaces.AudioGenerationRequest.model}

> model: [str](https://docs.python.org/3/library/stdtypes.html#str)

The name of the model to be used for generating audio chunks. This should match
the available models on the server and determines the behavior and
capabilities of the response generation.

### `prompt` {#max.interfaces.AudioGenerationRequest.prompt}

> prompt: [list](https://docs.python.org/3/library/stdtypes.html#list)\[[int](https://docs.python.org/3/library/functions.html#int)] | [str](https://docs.python.org/3/library/stdtypes.html#str) | [None](https://docs.python.org/3/library/constants.html#None) = None

Optionally provide a preprocessed list of token ids or a prompt string to pass as input directly into the model.
This replaces automatically generating TokenGeneratorRequestMessages given the input, audio prompt tokens,
audio prompt transcription fields.

### `sampling_params` {#max.interfaces.AudioGenerationRequest.sampling_params}

> sampling\_params: [SamplingParams](#max.interfaces.SamplingParams)

Request sampling configuration options.

### `streaming` {#max.interfaces.AudioGenerationRequest.streaming}

> streaming: [bool](https://docs.python.org/3/library/functions.html#bool) = True

Whether to stream the audio generation.

## `AudioGenerator` {#max.interfaces.AudioGenerator}

> class max.interfaces.AudioGenerator(\*args, \*\*kwargs)

Interface for audio generation models.

### `next_chunk()` {#max.interfaces.AudioGenerator.next_chunk}

> next\_chunk(batch)

Computes the next audio chunk for a single batch.

The new speech tokens are saved to the context. The most recently
generated audio is return through the AudioGeneratorOutput.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

batch ([dict](https://docs.python.org/3/library/stdtypes.html#dict)\[[str](https://docs.python.org/3/library/stdtypes.html#str), AudioGeneratorContext]) â€“ Batch of contexts.

</dd><dt>

**Returns:**

</dt><dd>

Dictionary mapping request IDs to
audio generation responses.

</dd><dt>

**Return type:**

</dt><dd>

[dict](https://docs.python.org/3/library/stdtypes.html#dict)\[[str](https://docs.python.org/3/library/stdtypes.html#str), [AudioGeneratorOutput](#max.interfaces.AudioGeneratorOutput)]

</dd></dl>

### `release()` {#max.interfaces.AudioGenerator.release}

> release(request\_id)

Release any resources or state associated with a specific request.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

request\_id (RequestID) â€“ The unique identifier of the request to
release resources for.

</dd><dt>

**Return type:**

</dt><dd>

None

</dd></dl>

## `AudioGeneratorOutput` {#max.interfaces.AudioGeneratorOutput}

> class max.interfaces.AudioGeneratorOutput(final\_status, steps\_executed=None, audio\_data=\<factory>, buffer\_speech\_tokens=None, metadata=\<factory>)

Represents a response from the audio generation API.

This class encapsulates the result of an audio generation request, including
the final status, generated audio data, and optional buffered speech tokens.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* final\_status ([GenerationStatus](#max.interfaces.GenerationStatus))
* steps\_executed ([int](https://docs.python.org/3/library/functions.html#int) | None)
* audio\_data ([ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[float32]])
* buffer\_speech\_tokens ([ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]] | None)
* metadata ([AudioGenerationMetadata](#max.interfaces.AudioGenerationMetadata))

</dd></dl>

### `audio_data` {#max.interfaces.AudioGeneratorOutput.audio_data}

> audio\_data: [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[float32]]

The generated audio data, if available.

### `buffer_speech_tokens` {#max.interfaces.AudioGeneratorOutput.buffer_speech_tokens}

> buffer\_speech\_tokens: [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]] | [None](https://docs.python.org/3/library/constants.html#None)

Buffered speech tokens, if available.

### `final_status` {#max.interfaces.AudioGeneratorOutput.final_status}

> final\_status: [GenerationStatus](#max.interfaces.GenerationStatus)

The final status of the generation process.

### `is_done` {#max.interfaces.AudioGeneratorOutput.is_done}

> property is\_done: [bool](https://docs.python.org/3/library/functions.html#bool)

Indicates whether the audio generation process is complete.

<dl class='field-list'><dt>

**Returns:**

</dt><dd>

`True` if generation is done, `False` otherwise.

</dd><dt>

**Return type:**

</dt><dd>

[`bool`](https://docs.python.org/3/library/functions.html#bool)

</dd></dl>

### `metadata` {#max.interfaces.AudioGeneratorOutput.metadata}

> metadata: [AudioGenerationMetadata](#max.interfaces.AudioGenerationMetadata)

Metadata associated with the audio generation, such as chunk information, prompt details, or other relevant context.

### `steps_executed` {#max.interfaces.AudioGeneratorOutput.steps_executed}

> steps\_executed: [int](https://docs.python.org/3/library/functions.html#int) | [None](https://docs.python.org/3/library/constants.html#None)

The number of steps previously executed.

## `BaseContext` {#max.interfaces.BaseContext}

> class max.interfaces.BaseContext(\*args, \*\*kwargs)

Core interface for request lifecycle management across all of MAX, including serving, scheduling, and pipelines.

This protocol is intended to provide a unified, minimal contract for request state and status handling throughout the MAX stack.
Over time, BaseContext is expected to supersede and replace InputContext as the canonical context interface, as we refactor and standardize context handling across the codebase.

### `is_done` {#max.interfaces.BaseContext.is_done}

> property is\_done: [bool](https://docs.python.org/3/library/functions.html#bool)

Whether the request has completed generation.

### `request_id` {#max.interfaces.BaseContext.request_id}

> property request\_id: [str](https://docs.python.org/3/library/stdtypes.html#str)

Unique identifier for the request.

### `status` {#max.interfaces.BaseContext.status}

> property status: [GenerationStatus](#max.interfaces.GenerationStatus)

Current generation status of the request.

## `BatchProcessorInputs` {#max.interfaces.BatchProcessorInputs}

> class max.interfaces.BatchProcessorInputs(logits, logit\_offsets, context\_batch)

Arguments for a batch logits processor.

* logits: The model logits, a float32 tensor with shape (N\_batch, vocab\_size).
  N\_batch is the number of logits returned by the model for each sequence in the batch.
* logit\_offsets: If the model returns multiple logits, this is a tensor with
  shape (batch\_size + 1, 1) that contains the offsets of each sequence in
  the batch. Otherwise, this is None.
* context\_batch: The batch of contexts containing the inputs to the model.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* logits (md.Tensor)
* logit\_offsets (md.Tensor | None)
* context\_batch (Sequence\[[InputContext](#max.interfaces.InputContext)])

</dd></dl>

### `context_batch` {#max.interfaces.BatchProcessorInputs.context_batch}

> context\_batch: Sequence\[[InputContext](#max.interfaces.InputContext)]

### `logit_offsets` {#max.interfaces.BatchProcessorInputs.logit_offsets}

> logit\_offsets: md.Tensor | [None](https://docs.python.org/3/library/constants.html#None)

### `logits` {#max.interfaces.BatchProcessorInputs.logits}

> logits: md.Tensor

## `EmbeddingsGenerationInputs` {#max.interfaces.EmbeddingsGenerationInputs}

> class max.interfaces.EmbeddingsGenerationInputs(batches: 'list\[dict\[RequestID, EmbeddingsGenerationContextType]]')

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

batches ([list](https://docs.python.org/3/library/stdtypes.html#list)\[[dict](https://docs.python.org/3/library/stdtypes.html#dict)\[[str](https://docs.python.org/3/library/stdtypes.html#str), EmbeddingsGenerationContextType]])

</dd></dl>

### `batch` {#max.interfaces.EmbeddingsGenerationInputs.batch}

> property batch: [dict](https://docs.python.org/3/library/stdtypes.html#dict)\[[str](https://docs.python.org/3/library/stdtypes.html#str), EmbeddingsGenerationContextType]

Returns merged batches.

### `batches` {#max.interfaces.EmbeddingsGenerationInputs.batches}

> batches: [list](https://docs.python.org/3/library/stdtypes.html#list)\[[dict](https://docs.python.org/3/library/stdtypes.html#dict)\[[str](https://docs.python.org/3/library/stdtypes.html#str), EmbeddingsGenerationContextType]]

## `EmbeddingsGenerationOutput` {#max.interfaces.EmbeddingsGenerationOutput}

> class max.interfaces.EmbeddingsGenerationOutput(embeddings)

Response structure for embedding generation.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

embeddings ([ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]]) â€“ The generated embeddings as a NumPy array.

</dd></dl>

### `embeddings` {#max.interfaces.EmbeddingsGenerationOutput.embeddings}

> embeddings: [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]]

The generated embeddings as a NumPy array.

### `is_done` {#max.interfaces.EmbeddingsGenerationOutput.is_done}

> property is\_done: [bool](https://docs.python.org/3/library/functions.html#bool)

Indicates whether the embedding generation process is complete.

<dl class='field-list'><dt>

**Returns:**

</dt><dd>

Always True, as embedding generation is a single-step operation.

</dd><dt>

**Return type:**

</dt><dd>

[bool](https://docs.python.org/3/library/functions.html#bool)

</dd></dl>

## `GenerationStatus` {#max.interfaces.GenerationStatus}

> class max.interfaces.GenerationStatus(value, names=\<not given>, \*values, module=None, qualname=None, type=None, start=1, boundary=None)

Enum representing the status of a generation process in the MAX API.

### `ACTIVE` {#max.interfaces.GenerationStatus.ACTIVE}

> ACTIVE = 'active'

The generation process is ongoing.

### `CANCELLED` {#max.interfaces.GenerationStatus.CANCELLED}

> CANCELLED = 'cancelled'

The generation process has been cancelled by the user.

### `END_OF_SEQUENCE` {#max.interfaces.GenerationStatus.END_OF_SEQUENCE}

> END\_OF\_SEQUENCE = 'end\_of\_sequence'

The generation process has reached the end of the sequence.

### `MAXIMUM_LENGTH` {#max.interfaces.GenerationStatus.MAXIMUM_LENGTH}

> MAXIMUM\_LENGTH = 'maximum\_length'

The generation process has reached the maximum allowed length.

### `is_done` {#max.interfaces.GenerationStatus.is_done}

> property is\_done: [bool](https://docs.python.org/3/library/functions.html#bool)

Returns True if the generation process is complete (not ACTIVE).

<dl class='field-list'><dt>

**Returns:**

</dt><dd>

True if the status is not ACTIVE, indicating completion.

</dd><dt>

**Return type:**

</dt><dd>

[bool](https://docs.python.org/3/library/functions.html#bool)

</dd></dl>

## `InputContext` {#max.interfaces.InputContext}

> class max.interfaces.InputContext(\*args, \*\*kwargs)

Protocol defining the interface for model input contexts in token generation.

An `InputContext` represents model inputs for `TokenGenerator` instances, managing
the state of tokens throughout the generation process. It handles token arrays,
generation status, sampling parameters, and various indices that track different
stages of token processing.

The context maintains a token array with the following layout:

```default
.                      +---------- full prompt ----------+   CHUNK_SIZE*N v
. +--------------------+---------------+-----------------+----------------+
. |     completed      |  next_tokens  |                 |  preallocated  |
. +--------------------+---------------+-----------------+----------------+
.            start_idx ^    active_idx ^         end_idx ^
```

Token Array Regions:
: - completed: Tokens that have already been processed and encoded.

* next\_tokens: Tokens that will be processed in the next iteration.
  This may be a subset of the full prompt due to chunked prefill.
* preallocated: Token slots that have been preallocated. The token array
  resizes to multiples of `CHUNK_SIZE` to accommodate new tokens.

Key Indices:
: - `start_idx`: Marks the beginning of completed tokens

* `active_idx`: Marks the start of next\_tokens within the array
* `end_idx`: Marks the end of all active tokens (one past the last token)

### `active_idx` {#max.interfaces.InputContext.active_idx}

> property active\_idx: [int](https://docs.python.org/3/library/functions.html#int)

The index marking the start of `next_tokens` within the token array.

This index separates completed tokens from tokens that will be processed
in the next iteration during chunked prefill or generation.

<dl class='field-list'><dt>

**Returns:**

</dt><dd>

The zero-based index where `next_tokens` begin in the token array.

</dd></dl>

### `active_length` {#max.interfaces.InputContext.active_length}

> property active\_length: [int](https://docs.python.org/3/library/functions.html#int)

The number of tokens being processed in the current iteration.

During context encoding (prompt processing), this equals the prompt size
or chunk size for chunked prefill. During token generation, this is
typically 1 (one new token per iteration).

<dl class='field-list'><dt>

**Returns:**

</dt><dd>

The number of tokens being processed in this iteration.

</dd></dl>

### `all_tokens` {#max.interfaces.InputContext.all_tokens}

> property all\_tokens: [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]]

All active tokens in the context (prompt and generated).

This property returns only the meaningful tokens, excluding any
preallocated but unused slots in the token array.

<dl class='field-list'><dt>

**Returns:**

</dt><dd>

A 1D NumPy array containing all prompt and generated tokens.

</dd></dl>

### `bump_token_indices()` {#max.interfaces.InputContext.bump_token_indices}

> bump\_token\_indices(start\_idx=0, active\_idx=0, end\_idx=0)

Increment token indices by the specified amounts.

This method provides fine-grained control over token index management,
allowing incremental updates to track token processing progress.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* start\_idx ([int](https://docs.python.org/3/library/functions.html#int)) â€“ Amount to increment the `start_idx` by.
* active\_idx ([int](https://docs.python.org/3/library/functions.html#int)) â€“ Amount to increment the `active_idx` by.
* end\_idx ([int](https://docs.python.org/3/library/functions.html#int)) â€“ Amount to increment the `end_idx` by.

</dd><dt>

**Return type:**

</dt><dd>

None

</dd></dl>

### `compute_num_available_steps()` {#max.interfaces.InputContext.compute_num_available_steps}

> compute\_num\_available\_steps(max\_seq\_len)

Compute the maximum number of generation steps available.

This method calculates how many tokens can be generated without
exceeding the specified maximum sequence length limit.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

max\_seq\_len ([int](https://docs.python.org/3/library/functions.html#int)) â€“ The maximum allowed sequence length for this context.

</dd><dt>

**Returns:**

</dt><dd>

The number of generation steps that can be executed before reaching
the sequence length limit.

</dd><dt>

**Return type:**

</dt><dd>

[int](https://docs.python.org/3/library/functions.html#int)

</dd></dl>

### `current_length` {#max.interfaces.InputContext.current_length}

> property current\_length: [int](https://docs.python.org/3/library/functions.html#int)

The current total length of the sequence.

This includes both completed tokens and tokens currently being processed,
representing the total number of tokens in the active sequence.

<dl class='field-list'><dt>

**Returns:**

</dt><dd>

The total number of tokens including completed and active tokens.

</dd></dl>

### `end_idx` {#max.interfaces.InputContext.end_idx}

> property end\_idx: [int](https://docs.python.org/3/library/functions.html#int)

The index marking the end of all active tokens in the token array.

This is an exclusive end index (one past the last active token), following
Pythonâ€™s standard slicing conventions.

<dl class='field-list'><dt>

**Returns:**

</dt><dd>

The zero-based index one position past the last active token.

</dd></dl>

### `eos_token_ids` {#max.interfaces.InputContext.eos_token_ids}

> property eos\_token\_ids: [set](https://docs.python.org/3/library/stdtypes.html#set)\[[int](https://docs.python.org/3/library/functions.html#int)]

The set of end-of-sequence token IDs that can terminate generation.

<dl class='field-list'><dt>

**Returns:**

</dt><dd>

A set of token IDs that, when generated, will signal the end of the
sequence and terminate the generation process.

</dd></dl>

### `generated_tokens` {#max.interfaces.InputContext.generated_tokens}

> property generated\_tokens: [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]]

All tokens generated by the model for this context.

This excludes the original prompt tokens and includes only tokens
that have been produced during the generation process.

<dl class='field-list'><dt>

**Returns:**

</dt><dd>

A 1D NumPy array containing generated token IDs.

</dd></dl>

### `get_min_token_logit_mask()` {#max.interfaces.InputContext.get_min_token_logit_mask}

> get\_min\_token\_logit\_mask(num\_steps)

Get token indices that should be masked in the output logits.

This method is primarily used to implement the `min_tokens` constraint,
where certain tokens (typically EOS tokens) are masked to prevent early
termination before the minimum token count is reached.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

num\_steps ([int](https://docs.python.org/3/library/functions.html#int)) â€“ The number of generation steps to compute masks for.

</dd><dt>

**Returns:**

</dt><dd>

A list of NumPy arrays, where each array contains token indices
that should be masked (set to negative infinity) in the logits
for the corresponding generation step.

</dd><dt>

**Return type:**

</dt><dd>

[list](https://docs.python.org/3/library/stdtypes.html#list)\[[ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[int32]]]

</dd></dl>

### `is_done` {#max.interfaces.InputContext.is_done}

> property is\_done: [bool](https://docs.python.org/3/library/functions.html#bool)

Whether the generation process for this context has completed.

<dl class='field-list'><dt>

**Returns:**

</dt><dd>

`True` if generation has finished successfully or been terminated,
`False` if generation is still in progress.

</dd></dl>

### `is_initial_prompt` {#max.interfaces.InputContext.is_initial_prompt}

> property is\_initial\_prompt: [bool](https://docs.python.org/3/library/functions.html#bool)

Whether this context contains only the initial prompt.

This property indicates if the context has not yet been updated with
any generated tokens and still contains only the original input.

<dl class='field-list'><dt>

**Returns:**

</dt><dd>

`True` if no tokens have been generated yet, `False` if generation
has begun and tokens have been added.

</dd></dl>

### `json_schema` {#max.interfaces.InputContext.json_schema}

> property json\_schema: [str](https://docs.python.org/3/library/stdtypes.html#str) | [None](https://docs.python.org/3/library/constants.html#None)

The JSON schema for constrained decoding, if configured.

When set, this schema constrains token generation to produce valid JSON
output that conforms to the specified structure.

<dl class='field-list'><dt>

**Returns:**

</dt><dd>

The JSON schema string, or `None` if no schema constraint is active.

</dd></dl>

### `jump_ahead()` {#max.interfaces.InputContext.jump_ahead}

> jump\_ahead(new\_token)

Jump ahead in generation by adding a token and updating indices.

This method is used in speculative decoding scenarios to quickly
advance the generation state when draft tokens are accepted.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

new\_token ([int](https://docs.python.org/3/library/functions.html#int)) â€“ The token ID to add when jumping ahead in the sequence.

</dd><dt>

**Return type:**

</dt><dd>

None

</dd></dl>

### `last_generated_token` {#max.interfaces.InputContext.last_generated_token}

> property last\_generated\_token: [int](https://docs.python.org/3/library/functions.html#int)

Returns the most recently generated token. If no tokens have been generated, raises an error.
:returns: The most recently generated token.
:rtype: int

### `log_probabilities` {#max.interfaces.InputContext.log_probabilities}

> property log\_probabilities: [int](https://docs.python.org/3/library/functions.html#int)

The number of top tokens to return log probabilities for.

When greater than 0, the system returns log probabilities for the top N
most likely tokens at each generation step.

<dl class='field-list'><dt>

**Returns:**

</dt><dd>

The number of top tokens to include in log probability output.
Returns 0 if log probabilities are disabled.

</dd></dl>

### `log_probabilities_echo` {#max.interfaces.InputContext.log_probabilities_echo}

> property log\_probabilities\_echo: [bool](https://docs.python.org/3/library/functions.html#bool)

Whether to include input tokens in the returned log probabilities.

When `True`, log probabilities will be computed and returned for input
(prompt) tokens in addition to generated tokens.

<dl class='field-list'><dt>

**Returns:**

</dt><dd>

`True` if input tokens should be included in log probability output,
`False` otherwise.

</dd></dl>

### `matcher` {#max.interfaces.InputContext.matcher}

> property matcher: [Any](https://docs.python.org/3/library/typing.html#typing.Any) | [None](https://docs.python.org/3/library/constants.html#None)

The grammar matcher for structured output generation, if configured.

The matcher enforces structural constraints (like JSON schema) during
generation to ensure valid formatted output.

<dl class='field-list'><dt>

**Returns:**

</dt><dd>

The grammar matcher instance, or `None` if no structured generation
is configured for this context.

</dd></dl>

### `max_length` {#max.interfaces.InputContext.max_length}

> property max\_length: [int](https://docs.python.org/3/library/functions.html#int) | [None](https://docs.python.org/3/library/constants.html#None)

The maximum allowed length for this sequence.

When set, generation will stop when this length is reached, regardless
of other stopping criteria.

<dl class='field-list'><dt>

**Returns:**

</dt><dd>

The maximum sequence length limit, or `None` if no limit is set.

</dd></dl>

### `min_tokens` {#max.interfaces.InputContext.min_tokens}

> property min\_tokens: [int](https://docs.python.org/3/library/functions.html#int)

The minimum number of new tokens that must be generated.

Generation will continue until at least this many new tokens have been
produced, even if other stopping criteria are met (e.g., EOS tokens).

<dl class='field-list'><dt>

**Returns:**

</dt><dd>

The minimum number of new tokens to generate.

</dd></dl>

### `needs_ce` {#max.interfaces.InputContext.needs_ce}

> property needs\_ce: [bool](https://docs.python.org/3/library/functions.html#bool)

Returns whether this context needs context encoding (CE).

CE mode indicates that the context has additional prompt tokens to encode.

<dl class='field-list'><dt>

**Returns:**

</dt><dd>

True if the context needs CE, False otherwise.

</dd><dt>

**Return type:**

</dt><dd>

[bool](https://docs.python.org/3/library/functions.html#bool)

</dd></dl>

### `next_tokens` {#max.interfaces.InputContext.next_tokens}

> property next\_tokens: [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]]

The tokens to be processed in the next model iteration.

This array contains the tokens that will be fed to the model in the
upcoming forward pass. The length should match `active_length`.

<dl class='field-list'><dt>

**Returns:**

</dt><dd>

A 1D NumPy array of token IDs with length equal to `active_length`.

</dd></dl>

### `prompt_tokens` {#max.interfaces.InputContext.prompt_tokens}

> property prompt\_tokens: [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]]

The original prompt tokens for this context.

These are the input tokens that were provided to start the generation
process, before any tokens were generated by the model.

<dl class='field-list'><dt>

**Returns:**

</dt><dd>

A 1D NumPy array containing the original prompt token IDs.

</dd></dl>

### `request_id` {#max.interfaces.InputContext.request_id}

> property request\_id: [str](https://docs.python.org/3/library/stdtypes.html#str)

The unique identifier for this generation request.

<dl class='field-list'><dt>

**Returns:**

</dt><dd>

A `RequestID` that uniquely identifies this request across the system.

</dd></dl>

### `reset()` {#max.interfaces.InputContext.reset}

> reset()

Reset the context state by consolidating all tokens into a new prompt.

This method is typically used when a request is evicted from cache,
requiring the context to be re-encoded in a subsequent context encoding
iteration. All generated tokens become part of the new prompt.

<dl class='field-list'><dt>

**Return type:**

</dt><dd>

None

</dd></dl>

### `sampling_params` {#max.interfaces.InputContext.sampling_params}

> property sampling\_params: [SamplingParams](#max.interfaces.SamplingParams)

The sampling parameters configured for this generation request.

These parameters control how tokens are selected during generation,
including temperature, top-k/top-p filtering, and stopping criteria.

<dl class='field-list'><dt>

**Returns:**

</dt><dd>

The `SamplingParams` instance containing all sampling configuration
for this context.

</dd></dl>

### `set_matcher()` {#max.interfaces.InputContext.set_matcher}

> set\_matcher(matcher)

Set a grammar matcher for constrained decoding.

This method configures structured output generation by installing a
grammar matcher that enforces format constraints during token generation.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

matcher ([Any](https://docs.python.org/3/library/typing.html#typing.Any)) â€“ The grammar matcher instance to use for constraining output.
The specific type depends on the structured generation backend.

</dd><dt>

**Return type:**

</dt><dd>

None

</dd></dl>

### `set_token_indices()` {#max.interfaces.InputContext.set_token_indices}

> set\_token\_indices(start\_idx=None, active\_idx=None, end\_idx=None)

Set token indices to specific absolute values.

This method provides direct control over token index positioning,
allowing precise management of the token array state.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* start\_idx ([int](https://docs.python.org/3/library/functions.html#int) | None) â€“ New absolute value for `start_idx`, if provided.
* active\_idx ([int](https://docs.python.org/3/library/functions.html#int) | None) â€“ New absolute value for `active_idx`, if provided.
* end\_idx ([int](https://docs.python.org/3/library/functions.html#int) | None) â€“ New absolute value for `end_idx`, if provided.

</dd><dt>

**Return type:**

</dt><dd>

None

</dd></dl>

### `start_idx` {#max.interfaces.InputContext.start_idx}

> property start\_idx: [int](https://docs.python.org/3/library/functions.html#int)

The index marking the start of completed tokens in the token array.

Completed tokens are those that have already been processed and encoded
by the model in previous iterations.

<dl class='field-list'><dt>

**Returns:**

</dt><dd>

The zero-based index where completed tokens begin in the token array.

</dd></dl>

### `status` {#max.interfaces.InputContext.status}

> property status: [GenerationStatus](#max.interfaces.GenerationStatus)

The current generation status of this context.

<dl class='field-list'><dt>

**Returns:**

</dt><dd>

The `GenerationStatus` indicating the current state of generation
(e.g., encoding, generating, completed, or error).

</dd></dl>

### `tokens` {#max.interfaces.InputContext.tokens}

> property tokens: [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]]

The complete token array including preallocated slots.

This includes all tokens (completed, active, and preallocated empty slots).
For most use cases, prefer `all_tokens` to get only the active tokens.

<dl class='field-list'><dt>

**Returns:**

</dt><dd>

A 1D NumPy array containing all tokens including padding.

</dd></dl>

### `update()` {#max.interfaces.InputContext.update}

> update(new\_token, log\_probabilities=None)

Update the context with a newly generated token.

This method adds a generated token to the context, updating the token
array and associated metadata. It also stores log probability information
if provided.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* new\_token ([int](https://docs.python.org/3/library/functions.html#int)) â€“ The token ID to add to the generation sequence.
* log\_probabilities ([LogProbabilities](#max.interfaces.LogProbabilities) | None) â€“ Optional log probability data for the new token
  and alternatives. Used for analysis and debugging.

</dd><dt>

**Return type:**

</dt><dd>

None

</dd></dl>

## `LoRAOperation` {#max.interfaces.LoRAOperation}

> class max.interfaces.LoRAOperation(value, names=\<not given>, \*values, module=None, qualname=None, type=None, start=1, boundary=None)

Enum for different LoRA operations.

### `LIST` {#max.interfaces.LoRAOperation.LIST}

> LIST = 'list'

### `LOAD` {#max.interfaces.LoRAOperation.LOAD}

> LOAD = 'load'

### `UNLOAD` {#max.interfaces.LoRAOperation.UNLOAD}

> UNLOAD = 'unload'

## `LoRARequest` {#max.interfaces.LoRARequest}

> class max.interfaces.LoRARequest(operation, lora\_name=None, lora\_path=None)

Container for LoRA adapter requests.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* operation ([LoRAOperation](#max.interfaces.LoRAOperation))
* lora\_name ([str](https://docs.python.org/3/library/stdtypes.html#str) | None)
* lora\_path ([str](https://docs.python.org/3/library/stdtypes.html#str) | None)

</dd></dl>

### `lora_name` {#max.interfaces.LoRARequest.lora_name}

> lora\_name: [str](https://docs.python.org/3/library/stdtypes.html#str) | [None](https://docs.python.org/3/library/constants.html#None)

### `lora_path` {#max.interfaces.LoRARequest.lora_path}

> lora\_path: [str](https://docs.python.org/3/library/stdtypes.html#str) | [None](https://docs.python.org/3/library/constants.html#None)

### `operation` {#max.interfaces.LoRARequest.operation}

> operation: [LoRAOperation](#max.interfaces.LoRAOperation)

## `LoRAResponse` {#max.interfaces.LoRAResponse}

> class max.interfaces.LoRAResponse(status, message)

Response from LoRA operations.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* status ([LoRAStatus](#max.interfaces.LoRAStatus))
* message ([str](https://docs.python.org/3/library/stdtypes.html#str) | [list](https://docs.python.org/3/library/stdtypes.html#list)\[[str](https://docs.python.org/3/library/stdtypes.html#str)])

</dd></dl>

### `message` {#max.interfaces.LoRAResponse.message}

> message: [str](https://docs.python.org/3/library/stdtypes.html#str) | [list](https://docs.python.org/3/library/stdtypes.html#list)\[[str](https://docs.python.org/3/library/stdtypes.html#str)]

### `status` {#max.interfaces.LoRAResponse.status}

> status: [LoRAStatus](#max.interfaces.LoRAStatus)

## `LoRAStatus` {#max.interfaces.LoRAStatus}

> class max.interfaces.LoRAStatus(value, names=\<not given>, \*values, module=None, qualname=None, type=None, start=1, boundary=None)

Enum for LoRA operation status.

### `LOAD_ERROR` {#max.interfaces.LoRAStatus.LOAD_ERROR}

> LOAD\_ERROR = 'load\_error'

### `LOAD_INVALID_ADAPTER` {#max.interfaces.LoRAStatus.LOAD_INVALID_ADAPTER}

> LOAD\_INVALID\_ADAPTER = 'load\_invalid\_adapter'

### `LOAD_INVALID_PATH` {#max.interfaces.LoRAStatus.LOAD_INVALID_PATH}

> LOAD\_INVALID\_PATH = 'load\_invalid\_path'

### `LOAD_NAME_EXISTS` {#max.interfaces.LoRAStatus.LOAD_NAME_EXISTS}

> LOAD\_NAME\_EXISTS = 'load\_name\_exists'

### `SUCCESS` {#max.interfaces.LoRAStatus.SUCCESS}

> SUCCESS = 'success'

### `UNLOAD_ERROR` {#max.interfaces.LoRAStatus.UNLOAD_ERROR}

> UNLOAD\_ERROR = 'unload\_error'

### `UNLOAD_NAME_NONEXISTENT` {#max.interfaces.LoRAStatus.UNLOAD_NAME_NONEXISTENT}

> UNLOAD\_NAME\_NONEXISTENT = 'unload\_name\_nonexistent'

## `LoRAType` {#max.interfaces.LoRAType}

> class max.interfaces.LoRAType(value, names=\<not given>, \*values, module=None, qualname=None, type=None, start=1, boundary=None)

Enumeration for LoRA Types.

### `A` {#max.interfaces.LoRAType.A}

> A = 'lora\_A'

Represents the LoRA A matrix (high rank tensor to low rank tensor).

### `B` {#max.interfaces.LoRAType.B}

> B = 'lora\_B'

Represents the LoRA B matrix. (low rank tensor to high rank tensor)

### `BIAS` {#max.interfaces.LoRAType.BIAS}

> BIAS = 'lora.bias'

Represents the LoRA bias matrix. (added to matrix B)

## `LogProbabilities` {#max.interfaces.LogProbabilities}

> class max.interfaces.LogProbabilities(token\_log\_probabilities, top\_log\_probabilities)

Log probabilities for an individual output token.

This is a data-only class that serves as a serializable data structure for
transferring log probability information. It does not provide any functionality
for calculating or manipulating log probabilities - it is purely for data storage
and serialization purposes.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* token\_log\_probabilities ([list](https://docs.python.org/3/library/stdtypes.html#list)\[[float](https://docs.python.org/3/library/functions.html#float)])
* top\_log\_probabilities ([list](https://docs.python.org/3/library/stdtypes.html#list)\[[dict](https://docs.python.org/3/library/stdtypes.html#dict)\[[int](https://docs.python.org/3/library/functions.html#int), [float](https://docs.python.org/3/library/functions.html#float)]])

</dd></dl>

### `token_log_probabilities` {#max.interfaces.LogProbabilities.token_log_probabilities}

> token\_log\_probabilities: [list](https://docs.python.org/3/library/stdtypes.html#list)\[[float](https://docs.python.org/3/library/functions.html#float)]

Probabilities of each token.

### `top_log_probabilities` {#max.interfaces.LogProbabilities.top_log_probabilities}

> top\_log\_probabilities: [list](https://docs.python.org/3/library/stdtypes.html#list)\[[dict](https://docs.python.org/3/library/stdtypes.html#dict)\[[int](https://docs.python.org/3/library/functions.html#int), [float](https://docs.python.org/3/library/functions.html#float)]]

Top tokens and their corresponding probabilities.

## `MAXPullQueue` {#max.interfaces.MAXPullQueue}

> class max.interfaces.MAXPullQueue(\*args, \*\*kwargs)

Protocol for a minimal, non-blocking pull queue interface in MAX.

This protocol defines the contract for a queue that supports non-blocking
get operations for retrieving items. It is generic over the item type and designed
for scenarios where the caller must be immediately notified if no items are available
rather than waiting for items to arrive.

The protocol is intended for consumer-side queue operations where immediate
feedback about queue state is critical for proper flow control and error handling.

### `get_nowait()` {#max.interfaces.MAXPullQueue.get_nowait}

> get\_nowait()

Remove and return an item from the queue without blocking.

This method is expected to raise queue.Empty if no item is available
to retrieve from the queue.

<dl class='field-list'><dt>

**Returns:**

</dt><dd>

The item removed from the queue.

</dd><dt>

**Return type:**

</dt><dd>

ItemType

</dd><dt>

**Raises:**

</dt><dd>

[queue.Empty](https://docs.python.org/3/library/queue.html#queue.Empty) â€“ If the queue is empty and no item can be retrieved.

</dd></dl>

## `MAXPushQueue` {#max.interfaces.MAXPushQueue}

> class max.interfaces.MAXPushQueue(\*args, \*\*kwargs)

Protocol for a minimal, non-blocking push queue interface in MAX.

This protocol defines the contract for a queue that supports non-blocking
put operations for adding items. It is generic over the item type and designed
for scenarios where the caller must be immediately notified of success or failure
rather than waiting for space to become available.

The protocol is intended for producer-side queue operations where immediate
feedback is critical for proper flow control and error handling.

### `put_nowait()` {#max.interfaces.MAXPushQueue.put_nowait}

> put\_nowait(item)

Attempt to put an item into the queue without blocking.

This method is designed to immediately fail (typically by raising an exception)
if the item cannot be added to the queue at the time of the call. Unlike the
traditional â€˜putâ€™ method in many queue implementationsâ€”which may block until
space becomes available or the transfer is completedâ€”this method never waits.
It is intended for use cases where the caller must be notified of failure to
enqueue immediately, rather than waiting for space.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

item (ItemType) â€“ The item to be added to the queue.

</dd><dt>

**Return type:**

</dt><dd>

None

</dd></dl>

## `Pipeline` {#max.interfaces.Pipeline}

> class max.interfaces.Pipeline

Abstract base class for pipeline operations.

This generic abstract class defines the interface for pipeline operations that
transform inputs of type PipelineInputsType into outputs of type PipelineOutputsDict\[PipelineOutputType].
All concrete pipeline implementations must inherit from this class and implement
the execute method.

Type Parameters:
: PipelineInputsType: The type of inputs this pipeline accepts, must inherit from PipelineInputs
PipelineOutputType: The type of outputs this pipeline produces, must be a subclass of PipelineOutput

```python
class MyPipeline(Pipeline[MyInputs, MyOutput]):
    def execute(self, inputs: MyInputs) -> dict[RequestID, MyOutput]:
        # Implementation here
        pass
```

### `execute()` {#max.interfaces.Pipeline.execute}

> abstract execute(inputs)

Execute the pipeline operation with the given inputs.

This method must be implemented by all concrete pipeline classes.
It takes inputs of the specified type and returns outputs according
to the pipelineâ€™s processing logic.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

inputs (PipelineInputsType) â€“ The input data for the pipeline operation, must be of type PipelineInputsType

</dd><dt>

**Returns:**

</dt><dd>

The results of the pipeline operation, as a dictionary mapping RequestID to PipelineOutputType

</dd><dt>

**Raises:**

</dt><dd>

[NotImplementedError](https://docs.python.org/3/library/exceptions.html#NotImplementedError) â€“ If not implemented by a concrete subclass

</dd><dt>

**Return type:**

</dt><dd>

[dict](https://docs.python.org/3/library/stdtypes.html#dict)\[[str](https://docs.python.org/3/library/stdtypes.html#str), PipelineOutputType]

</dd></dl>

### `release()` {#max.interfaces.Pipeline.release}

> abstract release(request\_id)

Release any resources or state associated with a specific request.

This method should be implemented by concrete pipeline classes to perform
cleanup or resource deallocation for the given request ID. It is typically
called when a request has completed processing and its associated resources
(such as memory, cache, or temporary files) are no longer needed.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

request\_id (RequestID) â€“ The unique identifier of the request to release resources for.

</dd><dt>

**Returns:**

</dt><dd>

None

</dd><dt>

**Raises:**

</dt><dd>

[NotImplementedError](https://docs.python.org/3/library/exceptions.html#NotImplementedError) â€“ If not implemented by a concrete subclass.

</dd><dt>

**Return type:**

</dt><dd>

None

</dd></dl>

## `PipelineOutput` {#max.interfaces.PipelineOutput}

> class max.interfaces.PipelineOutput(\*args, \*\*kwargs)

Protocol representing the output of a pipeline operation.

Subclasses must implement the is\_done property to indicate whether
the pipeline operation has completed.

### `is_done` {#max.interfaces.PipelineOutput.is_done}

> property is\_done: [bool](https://docs.python.org/3/library/functions.html#bool)

Indicates whether the pipeline operation has completed.

<dl class='field-list'><dt>

**Returns:**

</dt><dd>

True if the operation is done, False otherwise.

</dd><dt>

**Return type:**

</dt><dd>

[bool](https://docs.python.org/3/library/functions.html#bool)

</dd></dl>

## `PipelineTask` {#max.interfaces.PipelineTask}

> class max.interfaces.PipelineTask(value, names=\<not given>, \*values, module=None, qualname=None, type=None, start=1, boundary=None)

Enum representing the types of pipeline tasks supported.

### `AUDIO_GENERATION` {#max.interfaces.PipelineTask.AUDIO_GENERATION}

> AUDIO\_GENERATION = 'audio\_generation'

Task for generating audio.

### `EMBEDDINGS_GENERATION` {#max.interfaces.PipelineTask.EMBEDDINGS_GENERATION}

> EMBEDDINGS\_GENERATION = 'embeddings\_generation'

Task for generating embeddings.

### `SPEECH_TOKEN_GENERATION` {#max.interfaces.PipelineTask.SPEECH_TOKEN_GENERATION}

> SPEECH\_TOKEN\_GENERATION = 'speech\_token\_generation'

Task for generating speech tokens.

### `TEXT_GENERATION` {#max.interfaces.PipelineTask.TEXT_GENERATION}

> TEXT\_GENERATION = 'text\_generation'

Task for generating text.

### `output_type` {#max.interfaces.PipelineTask.output_type}

> property output\_type: [type](https://docs.python.org/3/library/functions.html#type)

Get the output type for the pipeline task.

<dl class='field-list'><dt>

**Returns:**

</dt><dd>

The output type for the pipeline task.

</dd><dt>

**Return type:**

</dt><dd>

[type](https://docs.python.org/3/library/functions.html#type)

</dd></dl>

## `PipelineTokenizer` {#max.interfaces.PipelineTokenizer}

> class max.interfaces.PipelineTokenizer(\*args, \*\*kwargs)

Interface for LLM tokenizers.

### `decode()` {#max.interfaces.PipelineTokenizer.decode}

> async decode(encoded, \*\*kwargs)

Decodes response tokens to text.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

encoded (TokenizerEncoded) â€“ Encoded response tokens.

</dd><dt>

**Returns:**

</dt><dd>

Un-encoded response text.

</dd><dt>

**Return type:**

</dt><dd>

[str](https://docs.python.org/3/library/stdtypes.html#str)

</dd></dl>

### `encode()` {#max.interfaces.PipelineTokenizer.encode}

> async encode(prompt, add\_special\_tokens)

Encodes text prompts as tokens.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* prompt ([str](https://docs.python.org/3/library/stdtypes.html#str)) â€“ Un-encoded prompt text.
* add\_special\_tokens ([bool](https://docs.python.org/3/library/functions.html#bool))

</dd><dt>

**Raises:**

</dt><dd>

[ValueError](https://docs.python.org/3/library/exceptions.html#ValueError) â€“ If the prompt exceeds the configured maximum length.

</dd><dt>

**Return type:**

</dt><dd>

TokenizerEncoded

</dd></dl>

### `eos` {#max.interfaces.PipelineTokenizer.eos}

> property eos: [int](https://docs.python.org/3/library/functions.html#int)

The end of sequence token for this tokenizer.

### `expects_content_wrapping` {#max.interfaces.PipelineTokenizer.expects_content_wrapping}

> property expects\_content\_wrapping: [bool](https://docs.python.org/3/library/functions.html#bool)

If true, this tokenizer expects messages to have a content property.

Text messages are formatted as:

```json
{ "type": "text", "content": "text content" }
```

instead of the OpenAI spec:

```json
{ "type": "text", "text": "text content" }
```

NOTE: Multimodal messages omit the content property.
Both `image_urls` and `image` content parts are converted to:

```json
{ "type": "image" }
```

Their content is provided as byte arrays through the top-level property
on the request object, i.e., `RequestType.images`.

### `new_context()` {#max.interfaces.PipelineTokenizer.new_context}

> async new\_context(request)

Creates a new context from a request object. This is sent to the
worker process once and then cached locally.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

request (RequestType) â€“ Incoming request.

</dd><dt>

**Returns:**

</dt><dd>

Initialized context.

</dd><dt>

**Return type:**

</dt><dd>

UnboundContextType

</dd></dl>

## `ProcessorInputs` {#max.interfaces.ProcessorInputs}

> class max.interfaces.ProcessorInputs(logits: 'md.Tensor', context: 'InputContext')

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* logits (md.Tensor)
* context ([InputContext](#max.interfaces.InputContext))

</dd></dl>

### `context` {#max.interfaces.ProcessorInputs.context}

> context: [InputContext](#max.interfaces.InputContext)

### `logits` {#max.interfaces.ProcessorInputs.logits}

> logits: md.Tensor

## `Request` {#max.interfaces.Request}

> class max.interfaces.Request(request\_id)

Base class representing a generic request within the MAX API.

This class provides a unique identifier for each request, ensuring that
all requests can be tracked and referenced consistently throughout the
system. Subclasses can extend this class to include additional fields
specific to their request types.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

request\_id ([str](https://docs.python.org/3/library/stdtypes.html#str))

</dd></dl>

### `request_id` {#max.interfaces.Request.request_id}

> request\_id: [str](https://docs.python.org/3/library/stdtypes.html#str)

## `RequestID` {#max.interfaces.RequestID}

> max.interfaces.RequestID

alias of [`str`](https://docs.python.org/3/library/stdtypes.html#str)

## `SamplingParams` {#max.interfaces.SamplingParams}

> class max.interfaces.SamplingParams(top\_k=-1, top\_p=1, min\_p=0.0, temperature=1, frequency\_penalty=0.0, presence\_penalty=0.0, repetition\_penalty=1.0, max\_new\_tokens=None, min\_new\_tokens=0, ignore\_eos=False, stop=None, stop\_token\_ids=None, detokenize=True, seed=\<factory>, logits\_processors=None)

Request specific sampling parameters that are only known at run time.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* top\_k ([int](https://docs.python.org/3/library/functions.html#int))
* top\_p ([float](https://docs.python.org/3/library/functions.html#float))
* min\_p ([float](https://docs.python.org/3/library/functions.html#float))
* temperature ([float](https://docs.python.org/3/library/functions.html#float))
* frequency\_penalty ([float](https://docs.python.org/3/library/functions.html#float))
* presence\_penalty ([float](https://docs.python.org/3/library/functions.html#float))
* repetition\_penalty ([float](https://docs.python.org/3/library/functions.html#float))
* max\_new\_tokens ([int](https://docs.python.org/3/library/functions.html#int) | None)
* min\_new\_tokens ([int](https://docs.python.org/3/library/functions.html#int))
* ignore\_eos ([bool](https://docs.python.org/3/library/functions.html#bool))
* stop ([list](https://docs.python.org/3/library/stdtypes.html#list)\[[str](https://docs.python.org/3/library/stdtypes.html#str)] | None)
* stop\_token\_ids ([list](https://docs.python.org/3/library/stdtypes.html#list)\[[int](https://docs.python.org/3/library/functions.html#int)] | None)
* detokenize ([bool](https://docs.python.org/3/library/functions.html#bool))
* seed ([int](https://docs.python.org/3/library/functions.html#int))
* logits\_processors ([Sequence](https://docs.python.org/3/library/collections.abc.html#collections.abc.Sequence)\[[Callable](https://docs.python.org/3/library/typing.html#typing.Callable)\[\[[ProcessorInputs](#max.interfaces.ProcessorInputs)], None]] | None)

</dd></dl>

### `detokenize` {#max.interfaces.SamplingParams.detokenize}

> detokenize: [bool](https://docs.python.org/3/library/functions.html#bool) = True

Whether to detokenize the output tokens into text.

### `frequency_penalty` {#max.interfaces.SamplingParams.frequency_penalty}

> frequency\_penalty: [float](https://docs.python.org/3/library/functions.html#float) = 0.0

The frequency penalty to apply to the modelâ€™s output. A positive value will penalize new tokens
based on their frequency in the generated text: tokens will receive a penalty proportional to the
count of appearances.

### `from_input()` {#max.interfaces.SamplingParams.from_input}

> classmethod from\_input(input\_params)

Create a SamplingParams instance from a dataclass input, using defaults for None values.

This method allows you to pass a dataclass with some parameters set to None,
and those None values will be replaced with the default values defined in the class.
The dataclass ensures static type checking for parameter names and types.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

input\_params ([SamplingParamsInput](#max.interfaces.SamplingParamsInput)) â€“ Dataclass containing parameter names and values. Values of None
will be replaced with the default values from the class definition.

</dd><dt>

**Returns:**

</dt><dd>

A new SamplingParams instance with the provided values and defaults for None.

</dd><dt>

**Return type:**

</dt><dd>

[SamplingParams](#max.interfaces.SamplingParams)

</dd></dl>

### `ignore_eos` {#max.interfaces.SamplingParams.ignore_eos}

> ignore\_eos: [bool](https://docs.python.org/3/library/functions.html#bool) = False

If True, the response will ignore the EOS token, and continue to
generate until the max tokens or a stop string is hit.

### `log_sampling_info()` {#max.interfaces.SamplingParams.log_sampling_info}

> log\_sampling\_info()

Log comprehensive sampling parameters information.

Displays all sampling parameters in a consistent visual format similar to
pipeline configuration logging.

<dl class='field-list'><dt>

**Return type:**

</dt><dd>

None

</dd></dl>

### `logits_processors` {#max.interfaces.SamplingParams.logits_processors}

> logits\_processors: [Sequence](https://docs.python.org/3/library/collections.abc.html#collections.abc.Sequence)\[[Callable](https://docs.python.org/3/library/typing.html#typing.Callable)\[\[[ProcessorInputs](#max.interfaces.ProcessorInputs)], [None](https://docs.python.org/3/library/constants.html#None)]] | [None](https://docs.python.org/3/library/constants.html#None) = None

Callables to post-process the model logits.
See `LogitsProcessor` for examples.

### `max_new_tokens` {#max.interfaces.SamplingParams.max_new_tokens}

> max\_new\_tokens: [int](https://docs.python.org/3/library/functions.html#int) | [None](https://docs.python.org/3/library/constants.html#None) = None

The maximum number of new tokens to generate in the response. If not set,
the model may generate tokens until it reaches its internal limits or based
on other stopping criteria.

### `min_new_tokens` {#max.interfaces.SamplingParams.min_new_tokens}

> min\_new\_tokens: [int](https://docs.python.org/3/library/functions.html#int) = 0

The minimum number of tokens to generate in the response.

### `min_p` {#max.interfaces.SamplingParams.min_p}

> min\_p: [float](https://docs.python.org/3/library/functions.html#float) = 0.0

Float that represents the minimum probability for a token to be considered, relative to the probability of the most likely token. Must be in \[0, 1]. Set to 0 to disable this.

### `presence_penalty` {#max.interfaces.SamplingParams.presence_penalty}

> presence\_penalty: [float](https://docs.python.org/3/library/functions.html#float) = 0.0

The presence penalty to apply to the modelâ€™s output. A positive value will penalize new tokens
that have already appeared in the generated text at least once by applying a constant penalty.

### `repetition_penalty` {#max.interfaces.SamplingParams.repetition_penalty}

> repetition\_penalty: [float](https://docs.python.org/3/library/functions.html#float) = 1.0

The repetition penalty to apply to the modelâ€™s output. Values > 1 will penalize new tokens
that have already appeared in the generated text at least once by dividing the logits by the
repetition penalty.

### `seed` {#max.interfaces.SamplingParams.seed}

> seed: [int](https://docs.python.org/3/library/functions.html#int)

The seed to use for the random number generator. Defaults to a cryptographically secure random value.

### `stop` {#max.interfaces.SamplingParams.stop}

> stop: [list](https://docs.python.org/3/library/stdtypes.html#list)\[[str](https://docs.python.org/3/library/stdtypes.html#str)] | [None](https://docs.python.org/3/library/constants.html#None) = None

A list of detokenized sequences that can be used as stop criteria when generating a new sequence.

### `stop_token_ids` {#max.interfaces.SamplingParams.stop_token_ids}

> stop\_token\_ids: [list](https://docs.python.org/3/library/stdtypes.html#list)\[[int](https://docs.python.org/3/library/functions.html#int)] | [None](https://docs.python.org/3/library/constants.html#None) = None

A list of token ids that are used as stopping criteria when generating a new sequence.

### `temperature` {#max.interfaces.SamplingParams.temperature}

> temperature: [float](https://docs.python.org/3/library/functions.html#float) = 1

Controls the randomness of the modelâ€™s output; higher values produce more diverse responses.
For greedy sampling, set to temperature to 0.

### `top_k` {#max.interfaces.SamplingParams.top_k}

> top\_k: [int](https://docs.python.org/3/library/functions.html#int) = -1

Limits the sampling to the K most probable tokens. This defaults to -1 (which evaluates the top 255 tokens).
For greedy sampling, set to 1.

### `top_p` {#max.interfaces.SamplingParams.top_p}

> top\_p: [float](https://docs.python.org/3/library/functions.html#float) = 1

Only use the tokens whose cumulative probability is within the top\_p threshold. This applies to the top\_k tokens.

## `SamplingParamsInput` {#max.interfaces.SamplingParamsInput}

> class max.interfaces.SamplingParamsInput(top\_k=None, top\_p=None, min\_p=None, temperature=None, frequency\_penalty=None, presence\_penalty=None, repetition\_penalty=None, max\_new\_tokens=None, min\_new\_tokens=None, ignore\_eos=None, stop=None, stop\_token\_ids=None, detokenize=None, seed=None, logits\_processors=None)

Input dataclass for creating SamplingParams instances.

All fields are optional, allowing partial specification with None values
indicating â€œuse defaultâ€. This enables static type checking while maintaining
the flexibility to specify only the parameters you want to override.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* top\_k ([int](https://docs.python.org/3/library/functions.html#int) | None)
* top\_p ([float](https://docs.python.org/3/library/functions.html#float) | None)
* min\_p ([float](https://docs.python.org/3/library/functions.html#float) | None)
* temperature ([float](https://docs.python.org/3/library/functions.html#float) | None)
* frequency\_penalty ([float](https://docs.python.org/3/library/functions.html#float) | None)
* presence\_penalty ([float](https://docs.python.org/3/library/functions.html#float) | None)
* repetition\_penalty ([float](https://docs.python.org/3/library/functions.html#float) | None)
* max\_new\_tokens ([int](https://docs.python.org/3/library/functions.html#int) | None)
* min\_new\_tokens ([int](https://docs.python.org/3/library/functions.html#int) | None)
* ignore\_eos ([bool](https://docs.python.org/3/library/functions.html#bool) | None)
* stop ([list](https://docs.python.org/3/library/stdtypes.html#list)\[[str](https://docs.python.org/3/library/stdtypes.html#str)] | None)
* stop\_token\_ids ([list](https://docs.python.org/3/library/stdtypes.html#list)\[[int](https://docs.python.org/3/library/functions.html#int)] | None)
* detokenize ([bool](https://docs.python.org/3/library/functions.html#bool) | None)
* seed ([int](https://docs.python.org/3/library/functions.html#int) | None)
* logits\_processors ([Sequence](https://docs.python.org/3/library/collections.abc.html#collections.abc.Sequence)\[[Callable](https://docs.python.org/3/library/typing.html#typing.Callable)\[\[[ProcessorInputs](#max.interfaces.ProcessorInputs)], None]] | None)

</dd></dl>

### `detokenize` {#max.interfaces.SamplingParamsInput.detokenize}

> detokenize: [bool](https://docs.python.org/3/library/functions.html#bool) | [None](https://docs.python.org/3/library/constants.html#None) = None

### `frequency_penalty` {#max.interfaces.SamplingParamsInput.frequency_penalty}

> frequency\_penalty: [float](https://docs.python.org/3/library/functions.html#float) | [None](https://docs.python.org/3/library/constants.html#None) = None

### `ignore_eos` {#max.interfaces.SamplingParamsInput.ignore_eos}

> ignore\_eos: [bool](https://docs.python.org/3/library/functions.html#bool) | [None](https://docs.python.org/3/library/constants.html#None) = None

### `logits_processors` {#max.interfaces.SamplingParamsInput.logits_processors}

> logits\_processors: [Sequence](https://docs.python.org/3/library/collections.abc.html#collections.abc.Sequence)\[[Callable](https://docs.python.org/3/library/typing.html#typing.Callable)\[\[[ProcessorInputs](#max.interfaces.ProcessorInputs)], [None](https://docs.python.org/3/library/constants.html#None)]] | [None](https://docs.python.org/3/library/constants.html#None) = None

### `max_new_tokens` {#max.interfaces.SamplingParamsInput.max_new_tokens}

> max\_new\_tokens: [int](https://docs.python.org/3/library/functions.html#int) | [None](https://docs.python.org/3/library/constants.html#None) = None

### `min_new_tokens` {#max.interfaces.SamplingParamsInput.min_new_tokens}

> min\_new\_tokens: [int](https://docs.python.org/3/library/functions.html#int) | [None](https://docs.python.org/3/library/constants.html#None) = None

### `min_p` {#max.interfaces.SamplingParamsInput.min_p}

> min\_p: [float](https://docs.python.org/3/library/functions.html#float) | [None](https://docs.python.org/3/library/constants.html#None) = None

### `presence_penalty` {#max.interfaces.SamplingParamsInput.presence_penalty}

> presence\_penalty: [float](https://docs.python.org/3/library/functions.html#float) | [None](https://docs.python.org/3/library/constants.html#None) = None

### `repetition_penalty` {#max.interfaces.SamplingParamsInput.repetition_penalty}

> repetition\_penalty: [float](https://docs.python.org/3/library/functions.html#float) | [None](https://docs.python.org/3/library/constants.html#None) = None

### `seed` {#max.interfaces.SamplingParamsInput.seed}

> seed: [int](https://docs.python.org/3/library/functions.html#int) | [None](https://docs.python.org/3/library/constants.html#None) = None

### `stop` {#max.interfaces.SamplingParamsInput.stop}

> stop: [list](https://docs.python.org/3/library/stdtypes.html#list)\[[str](https://docs.python.org/3/library/stdtypes.html#str)] | [None](https://docs.python.org/3/library/constants.html#None) = None

### `stop_token_ids` {#max.interfaces.SamplingParamsInput.stop_token_ids}

> stop\_token\_ids: [list](https://docs.python.org/3/library/stdtypes.html#list)\[[int](https://docs.python.org/3/library/functions.html#int)] | [None](https://docs.python.org/3/library/constants.html#None) = None

### `temperature` {#max.interfaces.SamplingParamsInput.temperature}

> temperature: [float](https://docs.python.org/3/library/functions.html#float) | [None](https://docs.python.org/3/library/constants.html#None) = None

### `top_k` {#max.interfaces.SamplingParamsInput.top_k}

> top\_k: [int](https://docs.python.org/3/library/functions.html#int) | [None](https://docs.python.org/3/library/constants.html#None) = None

### `top_p` {#max.interfaces.SamplingParamsInput.top_p}

> top\_p: [float](https://docs.python.org/3/library/functions.html#float) | [None](https://docs.python.org/3/library/constants.html#None) = None

## `Scheduler` {#max.interfaces.Scheduler}

> class max.interfaces.Scheduler

Abstract base class defining the interface for schedulers.

### `run_iteration()` {#max.interfaces.Scheduler.run_iteration}

> abstract run\_iteration()

The core scheduler routine that creates and executes batches.

This method should implement the core scheduling logic including:

* Batch creation and management
* Request scheduling

## `SchedulerResult` {#max.interfaces.SchedulerResult}

> class max.interfaces.SchedulerResult(is\_done, result)

Structure representing the result of a scheduler operation for a specific pipeline execution.

This class encapsulates the outcome of a pipeline operation as managed by the scheduler,
including both the execution status and any resulting data from the pipeline. The scheduler
uses this structure to communicate the state of pipeline operations back to clients,
whether the operation is still running, has completed successfully, or was cancelled.

The generic type parameter allows this result to work with different types of pipeline
outputs while maintaining type safety.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* is\_done ([bool](https://docs.python.org/3/library/functions.html#bool))
* result (PipelineOutputType | None)

</dd></dl>

### `cancelled()` {#max.interfaces.SchedulerResult.cancelled}

> classmethod cancelled()

Create a SchedulerResult representing a cancelled pipeline operation.

<dl class='field-list'><dt>

**Returns:**

</dt><dd>

A SchedulerResult that is done.

</dd><dt>

**Return type:**

</dt><dd>

[SchedulerResult](#max.interfaces.SchedulerResult)

</dd></dl>

### `create()` {#max.interfaces.SchedulerResult.create}

> classmethod create(result)

Create a SchedulerResult representing a pipeline operation with some result.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

result (PipelineOutputType) â€“ The pipeline output data.

</dd><dt>

**Returns:**

</dt><dd>

A SchedulerResult with a result.

</dd><dt>

**Return type:**

</dt><dd>

[SchedulerResult](#max.interfaces.SchedulerResult)

</dd></dl>

### `is_done` {#max.interfaces.SchedulerResult.is_done}

> is\_done: [bool](https://docs.python.org/3/library/functions.html#bool)

The current status of the pipeline operation from the schedulerâ€™s perspective.

### `result` {#max.interfaces.SchedulerResult.result}

> result: PipelineOutputType | [None](https://docs.python.org/3/library/constants.html#None)

The pipeline output data, if any. May be None for cancelled operations or during intermediate states of streaming operations.

## `SharedMemoryArray` {#max.interfaces.SharedMemoryArray}

> class max.interfaces.SharedMemoryArray(name, shape, dtype)

Wrapper for numpy array stored in shared memory.

This class is used as a placeholder in pixel\_values during serialization.
It will be encoded as a dict with \_\_shm\_\_ flag and decoded back to a numpy
array.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* name ([str](https://docs.python.org/3/library/stdtypes.html#str))
* shape ([tuple](https://docs.python.org/3/library/stdtypes.html#tuple)\[[int](https://docs.python.org/3/library/functions.html#int), ...])
* dtype ([str](https://docs.python.org/3/library/stdtypes.html#str))

</dd></dl>

## `TextGenerationInputs` {#max.interfaces.TextGenerationInputs}

> class max.interfaces.TextGenerationInputs(batches, num\_steps)

Input parameters for text generation pipeline operations.

This class encapsulates the batch of contexts and number of steps required
for token generation in a single input object, replacing the previous
pattern of passing batch and num\_steps as separate parameters.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* batches ([list](https://docs.python.org/3/library/stdtypes.html#list)\[[dict](https://docs.python.org/3/library/stdtypes.html#dict)\[[str](https://docs.python.org/3/library/stdtypes.html#str), TextGenerationContextType]])
* num\_steps ([int](https://docs.python.org/3/library/functions.html#int))

</dd></dl>

### `batch` {#max.interfaces.TextGenerationInputs.batch}

> property batch: [dict](https://docs.python.org/3/library/stdtypes.html#dict)\[[str](https://docs.python.org/3/library/stdtypes.html#str), TextGenerationContextType]

Returns merged batches.

### `batches` {#max.interfaces.TextGenerationInputs.batches}

> batches: [list](https://docs.python.org/3/library/stdtypes.html#list)\[[dict](https://docs.python.org/3/library/stdtypes.html#dict)\[[str](https://docs.python.org/3/library/stdtypes.html#str), TextGenerationContextType]]

Variable list of batches, with each batch being a dictionary mapping
request IDs to context objects.

There can be multiple batches when using data parallelism, in which each
batch is mapped to a different device.

### `num_steps` {#max.interfaces.TextGenerationInputs.num_steps}

> num\_steps: [int](https://docs.python.org/3/library/functions.html#int)

Number of tokens to generate.

## `TextGenerationOutput` {#max.interfaces.TextGenerationOutput}

> class max.interfaces.TextGenerationOutput(request\_id, tokens, final\_status, log\_probabilities=None)

Represents the output of a text generation operation, combining token IDs,
final generation status, request ID, and optional log probabilities for each token.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* request\_id ([str](https://docs.python.org/3/library/stdtypes.html#str))
* tokens ([list](https://docs.python.org/3/library/stdtypes.html#list)\[[int](https://docs.python.org/3/library/functions.html#int)])
* final\_status ([GenerationStatus](#max.interfaces.GenerationStatus))
* log\_probabilities ([list](https://docs.python.org/3/library/stdtypes.html#list)\[[LogProbabilities](#max.interfaces.LogProbabilities)] | None)

</dd></dl>

### `final_status` {#max.interfaces.TextGenerationOutput.final_status}

> final\_status: [GenerationStatus](#max.interfaces.GenerationStatus)

The final status of the generation process.

### `is_done` {#max.interfaces.TextGenerationOutput.is_done}

> property is\_done: [bool](https://docs.python.org/3/library/functions.html#bool)

Indicates whether the text generation process is complete.

<dl class='field-list'><dt>

**Returns:**

</dt><dd>

True if the generation is done, False otherwise.

</dd><dt>

**Return type:**

</dt><dd>

[bool](https://docs.python.org/3/library/functions.html#bool)

</dd></dl>

### `log_probabilities` {#max.interfaces.TextGenerationOutput.log_probabilities}

> log\_probabilities: [list](https://docs.python.org/3/library/stdtypes.html#list)\[[LogProbabilities](#max.interfaces.LogProbabilities)] | [None](https://docs.python.org/3/library/constants.html#None)

Optional list of log probabilities for each token.

### `request_id` {#max.interfaces.TextGenerationOutput.request_id}

> request\_id: [str](https://docs.python.org/3/library/stdtypes.html#str)

The unique identifier for the generation request.

### `tokens` {#max.interfaces.TextGenerationOutput.tokens}

> tokens: [list](https://docs.python.org/3/library/stdtypes.html#list)\[[int](https://docs.python.org/3/library/functions.html#int)]

List of generated token IDs.

## `TextGenerationRequest` {#max.interfaces.TextGenerationRequest}

> class max.interfaces.TextGenerationRequest(request\_id: str, model\_name: 'str', prompt: 'Union\[str, Sequence\[int], None]' = None, messages: 'Optional\[list\[TextGenerationRequestMessage]]' = None, images: 'Optional\[list\[bytes]]' = None, tools: 'Optional\[list\[TextGenerationRequestTool]]' = None, response\_format: 'Optional\[TextGenerationResponseFormat]' = None, timestamp\_ns: 'int' = 0, request\_path: 'str' = '/', logprobs: 'int' = 0, echo: 'bool' = False, stop: 'Optional\[Union\[str, list\[str]]]' = None, chat\_template\_options: 'Optional\[dict\[str, Any]]' = None, sampling\_params: 'SamplingParams' = \<factory>, target\_endpoint: 'Optional\[str]' = None)

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* request\_id ([str](https://docs.python.org/3/library/stdtypes.html#str))
* model\_name ([str](https://docs.python.org/3/library/stdtypes.html#str))
* prompt ([str](https://docs.python.org/3/library/stdtypes.html#str) | [Sequence](https://docs.python.org/3/library/collections.abc.html#collections.abc.Sequence)\[[int](https://docs.python.org/3/library/functions.html#int)] | None)
* messages ([list](https://docs.python.org/3/library/stdtypes.html#list)\[[TextGenerationRequestMessage](#max.interfaces.TextGenerationRequestMessage)] | None)
* images ([list](https://docs.python.org/3/library/stdtypes.html#list)\[[bytes](https://docs.python.org/3/library/stdtypes.html#bytes)] | None)
* tools ([list](https://docs.python.org/3/library/stdtypes.html#list)\[[TextGenerationRequestTool](#max.interfaces.TextGenerationRequestTool)] | None)
* response\_format ([TextGenerationResponseFormat](#max.interfaces.TextGenerationResponseFormat) | None)
* timestamp\_ns ([int](https://docs.python.org/3/library/functions.html#int))
* request\_path ([str](https://docs.python.org/3/library/stdtypes.html#str))
* logprobs ([int](https://docs.python.org/3/library/functions.html#int))
* echo ([bool](https://docs.python.org/3/library/functions.html#bool))
* stop ([str](https://docs.python.org/3/library/stdtypes.html#str) | [list](https://docs.python.org/3/library/stdtypes.html#list)\[[str](https://docs.python.org/3/library/stdtypes.html#str)] | None)
* chat\_template\_options ([dict](https://docs.python.org/3/library/stdtypes.html#dict)\[[str](https://docs.python.org/3/library/stdtypes.html#str), [Any](https://docs.python.org/3/library/typing.html#typing.Any)] | None)
* sampling\_params ([SamplingParams](#max.interfaces.SamplingParams))
* target\_endpoint ([str](https://docs.python.org/3/library/stdtypes.html#str) | None)

</dd></dl>

### `chat_template_options` {#max.interfaces.TextGenerationRequest.chat_template_options}

> chat\_template\_options: [dict](https://docs.python.org/3/library/stdtypes.html#dict)\[[str](https://docs.python.org/3/library/stdtypes.html#str), [Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [None](https://docs.python.org/3/library/constants.html#None) = None

Optional dictionary of options to pass when applying the chat template.

### `echo` {#max.interfaces.TextGenerationRequest.echo}

> echo: [bool](https://docs.python.org/3/library/functions.html#bool) = False

If set to True, the response will include the original prompt along with the
generated output. This can be useful for debugging or when you want to see how
the input relates to the output.

### `images` {#max.interfaces.TextGenerationRequest.images}

> images: [list](https://docs.python.org/3/library/stdtypes.html#list)\[[bytes](https://docs.python.org/3/library/stdtypes.html#bytes)] | [None](https://docs.python.org/3/library/constants.html#None) = None

A list of image byte arrays that can be included as part of the request.
This field is optional and may be used for multimodal inputs where images
are relevant to the prompt or task.

### `logprobs` {#max.interfaces.TextGenerationRequest.logprobs}

> logprobs: [int](https://docs.python.org/3/library/functions.html#int) = 0

The number of top log probabilities to return for each generated token. A value
of 0 means that log probabilities will not be returned. Useful for analyzing
model confidence in its predictions.

### `messages` {#max.interfaces.TextGenerationRequest.messages}

> messages: [list](https://docs.python.org/3/library/stdtypes.html#list)\[[TextGenerationRequestMessage](#max.interfaces.TextGenerationRequestMessage)] | [None](https://docs.python.org/3/library/constants.html#None) = None

A list of messages for chat-based interactions. This is used in chat
completion APIs, where each message represents a turn in the conversation.
If provided, the model will generate responses based on these messages.

### `model_name` {#max.interfaces.TextGenerationRequest.model_name}

> model\_name: [str](https://docs.python.org/3/library/stdtypes.html#str)

The name of the model to be used for generating tokens. This should match
the available models on the server and determines the behavior and
capabilities of the response generation.

### `prompt` {#max.interfaces.TextGenerationRequest.prompt}

> prompt: [str](https://docs.python.org/3/library/stdtypes.html#str) | [Sequence](https://docs.python.org/3/library/collections.abc.html#collections.abc.Sequence)\[[int](https://docs.python.org/3/library/functions.html#int)] | [None](https://docs.python.org/3/library/constants.html#None) = None

The prompt to be processed by the model. This field supports legacy
completion APIs and can accept either a string or a sequence of integers
representing token IDs. If not provided, the model may generate output
based on the messages field.

### `request_path` {#max.interfaces.TextGenerationRequest.request_path}

> request\_path: [str](https://docs.python.org/3/library/stdtypes.html#str) = '/'

The endpoint path for the request. This is typically used for routing and
logging requests within the server infrastructure.

### `response_format` {#max.interfaces.TextGenerationRequest.response_format}

> response\_format: [TextGenerationResponseFormat](#max.interfaces.TextGenerationResponseFormat) | [None](https://docs.python.org/3/library/constants.html#None) = None

Specifies the desired format for the modelâ€™s output. When set, it enables
structured generation, which adheres to the json\_schema provided.

### `sampling_params` {#max.interfaces.TextGenerationRequest.sampling_params}

> sampling\_params: [SamplingParams](#max.interfaces.SamplingParams)

Token sampling configuration parameters for the request.

### `stop` {#max.interfaces.TextGenerationRequest.stop}

> stop: [str](https://docs.python.org/3/library/stdtypes.html#str) | [list](https://docs.python.org/3/library/stdtypes.html#list)\[[str](https://docs.python.org/3/library/stdtypes.html#str)] | [None](https://docs.python.org/3/library/constants.html#None) = None

//platform.openai.com/docs/api-reference/chat/create#chat-create-stop)

<dl class='field-list'><dt>

**Type:**

</dt><dd>

Optional list of stop expressions (see

</dd><dt>

**Type:**

</dt><dd>

https

</dd></dl>

### `target_endpoint` {#max.interfaces.TextGenerationRequest.target_endpoint}

> target\_endpoint: [str](https://docs.python.org/3/library/stdtypes.html#str) | [None](https://docs.python.org/3/library/constants.html#None) = None

Optional target endpoint identifier for routing the request to a specific
service or model instance. This should be used in disaggregate serving
scenarios, when you want to dynamically route to a specific instance.
If not specified, the request will be routed to the default endpoint.

### `timestamp_ns` {#max.interfaces.TextGenerationRequest.timestamp_ns}

> timestamp\_ns: [int](https://docs.python.org/3/library/functions.html#int) = 0

The time (in nanoseconds) when the request was received by the server. This
can be useful for performance monitoring and logging purposes.

### `tools` {#max.interfaces.TextGenerationRequest.tools}

> tools: [list](https://docs.python.org/3/library/stdtypes.html#list)\[[TextGenerationRequestTool](#max.interfaces.TextGenerationRequestTool)] | [None](https://docs.python.org/3/library/constants.html#None) = None

A list of tools that can be invoked during the generation process. This
allows the model to utilize external functionalities or APIs to enhance its
responses.

## `TextGenerationRequestFunction` {#max.interfaces.TextGenerationRequestFunction}

> class max.interfaces.TextGenerationRequestFunction

Represents a function definition for a text generation request.

### `description` {#max.interfaces.TextGenerationRequestFunction.description}

> description: [str](https://docs.python.org/3/library/stdtypes.html#str) | [None](https://docs.python.org/3/library/constants.html#None)

A human-readable description of the functionâ€™s purpose.

### `name` {#max.interfaces.TextGenerationRequestFunction.name}

> name: [str](https://docs.python.org/3/library/stdtypes.html#str)

The name of the function to be invoked.

### `parameters` {#max.interfaces.TextGenerationRequestFunction.parameters}

> parameters: [dict](https://docs.python.org/3/library/stdtypes.html#dict)\[[str](https://docs.python.org/3/library/stdtypes.html#str), [Any](https://docs.python.org/3/library/typing.html#typing.Any)]

A dictionary describing the functionâ€™s parameters, typically following a JSON schema.

## `TextGenerationRequestMessage` {#max.interfaces.TextGenerationRequestMessage}

> class max.interfaces.TextGenerationRequestMessage

### `content` {#max.interfaces.TextGenerationRequestMessage.content}

> content: [str](https://docs.python.org/3/library/stdtypes.html#str) | [list](https://docs.python.org/3/library/stdtypes.html#list)\[[dict](https://docs.python.org/3/library/stdtypes.html#dict)\[[str](https://docs.python.org/3/library/stdtypes.html#str), [Any](https://docs.python.org/3/library/typing.html#typing.Any)]]

Content can be a simple string or a list of message parts of different modalities.

For example:

```json
{
  "role": "user",
  "content": "What's the weather like in Boston today?"
}
```

Or:

```json
{
  "role": "user",
  "content": [
    {
      "type": "text",
      "text": "What's in this image?"
    },
    {
      "type": "image_url",
      "image_url": {
          "url": "https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg"
      }
    }
  ]
}
```

### `role` {#max.interfaces.TextGenerationRequestMessage.role}

> role: [Literal](https://docs.python.org/3/library/typing.html#typing.Literal)\['system', 'user', 'assistant', 'tool', 'function']

The role of the message sender, indicating whether the message is from the system, user, or assistant.

## `TextGenerationRequestTool` {#max.interfaces.TextGenerationRequestTool}

> class max.interfaces.TextGenerationRequestTool

Represents a tool definition for a text generation request.

### `function` {#max.interfaces.TextGenerationRequestTool.function}

> function: [TextGenerationRequestFunction](#max.interfaces.TextGenerationRequestFunction)

The function definition associated with the tool, including its name, description, and parameters.

### `type` {#max.interfaces.TextGenerationRequestTool.type}

> type: [str](https://docs.python.org/3/library/stdtypes.html#str)

The type of the tool, typically indicating the toolâ€™s category or usage.

## `TextGenerationResponseFormat` {#max.interfaces.TextGenerationResponseFormat}

> class max.interfaces.TextGenerationResponseFormat

Represents the response format specification for a text generation request.

### `json_schema` {#max.interfaces.TextGenerationResponseFormat.json_schema}

> json\_schema: [dict](https://docs.python.org/3/library/stdtypes.html#dict)\[[str](https://docs.python.org/3/library/stdtypes.html#str), [Any](https://docs.python.org/3/library/typing.html#typing.Any)]

A JSON schema dictionary that defines the structure and validation rules for the generated response.

### `type` {#max.interfaces.TextGenerationResponseFormat.type}

> type: [str](https://docs.python.org/3/library/stdtypes.html#str)

The type of response format, e.g., â€œjson\_objectâ€.

## `drain_queue()` {#max.interfaces.drain_queue}

> max.interfaces.drain\_queue(pull\_queue)

Remove and return all items from the queue without blocking.

This method is expected to return an empty list if the queue is empty.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

pull\_queue ([MAXPullQueue](#max.interfaces.MAXPullQueue)\[PullItemType])

</dd><dt>

**Return type:**

</dt><dd>

[list](https://docs.python.org/3/library/stdtypes.html#list)\[PullItemType]

</dd></dl>

## `get_blocking()` {#max.interfaces.get_blocking}

> max.interfaces.get\_blocking(pull\_queue)

Get the next item from the queue.

If no item is available, this method will spin until one is.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

pull\_queue ([MAXPullQueue](#max.interfaces.MAXPullQueue)\[PullItemType])

</dd><dt>

**Return type:**

</dt><dd>

PullItemType

</dd></dl>

## `msgpack_eq()` {#max.interfaces.msgpack_eq}

> max.interfaces.msgpack\_eq(a, b)

Compare two msgpack-serializable objects for equality. This should really
only be used in tests.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* a ([Any](https://docs.python.org/3/library/typing.html#typing.Any)) â€“ The first object to compare
* b ([Any](https://docs.python.org/3/library/typing.html#typing.Any)) â€“ The second object to compare

</dd><dt>

**Return type:**

</dt><dd>

[bool](https://docs.python.org/3/library/functions.html#bool)

</dd></dl>

## `msgpack_numpy_decoder()` {#max.interfaces.msgpack_numpy_decoder}

> max.interfaces.msgpack\_numpy\_decoder(type\_, copy=True)

Create a decoder function for the specified type.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* type â€“ The type to decode into
* copy ([bool](https://docs.python.org/3/library/functions.html#bool)) â€“ Copy numpy arrays if true
* type\_ ([Any](https://docs.python.org/3/library/typing.html#typing.Any))

</dd><dt>

**Returns:**

</dt><dd>

A pickleable decoder instance that decodes bytes into the specified type

</dd><dt>

**Return type:**

</dt><dd>

MsgpackNumpyDecoder

</dd></dl>

## `msgpack_numpy_encoder()` {#max.interfaces.msgpack_numpy_encoder}

> max.interfaces.msgpack\_numpy\_encoder(use\_shared\_memory=False, shared\_memory\_threshold=0)

Create an encoder function that handles numpy arrays.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* use\_shared\_memory ([bool](https://docs.python.org/3/library/functions.html#bool)) â€“ Whether to attempt shared memory conversion for numpy arrays
* shared\_memory\_threshold ([int](https://docs.python.org/3/library/functions.html#int)) â€“ Minimum size in bytes for shared memory conversion.
  If 0, all arrays are candidates for conversion.

</dd><dt>

**Returns:**

</dt><dd>

A pickleable encoder instance that encodes objects into bytes

</dd><dt>

**Return type:**

</dt><dd>

MsgpackNumpyEncoder

</dd></dl>

---

## attention_with_rope

An opaque KV Cache optimized attention mechanism with Rope.

## `AttentionWithRope` {#max.nn.attention.attention_with_rope.AttentionWithRope}

> class max.nn.attention.attention\_with\_rope.AttentionWithRope(\*, rope, num\_attention\_heads, num\_key\_value\_heads, hidden\_size, kv\_params, devices=None, dtype=float32, linear\_cls=\<class 'max.nn.linear.Linear'>, stacked\_qkv=False, scale=None, has\_bias=False, float8\_config=None, clip\_qkv=None)

Implementation of attention that uses the rope frequency.

Initializes the attention layer.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* rope ([RotaryEmbedding](../rotary_embedding.md#max.nn.rotary_embedding.RotaryEmbedding)) â€“ The rope layer to borrow the freqs\_cis value from.
* num\_attention\_heads ([int](https://docs.python.org/3/library/functions.html#int)) â€“ The number of attention heads.
* num\_key\_value\_heads ([int](https://docs.python.org/3/library/functions.html#int)) â€“ Number of key/value heads.
* hidden\_size ([int](https://docs.python.org/3/library/functions.html#int)) â€“ The dimension of the hidden states.
* kv\_params ([KVCacheParams](../kv_cache/cache_params.md#max.nn.kv_cache.cache_params.KVCacheParams)) â€“ KV Cache Params, including the number of kv heads, the head dim, and data type.
* dtype ([DType](../../dtype.md#max.dtype.DType)) â€“ DType of the QKV and output projection weights.
* devices (Sequence\[[DeviceRef](../../graph/type.md#max.graph.type.DeviceRef)] | None) â€“ Device to place the weights and run the computation. If
  multiple are provided, the first device is used. Use
  DistributedAttentionWithRope to use all devices during
  attention computation.
* linear\_cls (Callable\[..., [Linear](../linear.md#max.nn.linear.Linear)]) â€“ Linear class to use for the outputs dense layer.
* stacked\_qkv ([bool](https://docs.python.org/3/library/functions.html#bool)) â€“ Whether the weights are stacked together.
* scale ([float](https://docs.python.org/3/library/functions.html#float) | None) â€“ Value used to scale the results of the attention output.
* has\_bias ([bool](https://docs.python.org/3/library/functions.html#bool)) â€“ Whether to use an attention bias.
* clip\_qkv ([float](https://docs.python.org/3/library/functions.html#float) | None) â€“ If provided, the QKV weights are clamped between
  \[-clip\_qkv, clip\_qkv]
* float8\_config (Float8Config | None)

</dd></dl>

### `qkv_input_scale` {#max.nn.attention.attention_with_rope.AttentionWithRope.qkv_input_scale}

> property qkv\_input\_scale: [TensorValue](../../graph/TensorValue.md#max.graph.TensorValue) | [None](https://docs.python.org/3/library/constants.html#None)

The max of q, k, and v scale input vectors.

### `qkv_weight_scale` {#max.nn.attention.attention_with_rope.AttentionWithRope.qkv_weight_scale}

> property qkv\_weight\_scale: [TensorValue](../../graph/TensorValue.md#max.graph.TensorValue)

The max of q, k, and v scale weight vectors.

### `rope` {#max.nn.attention.attention_with_rope.AttentionWithRope.rope}

> rope: [RotaryEmbedding](../rotary_embedding.md#max.nn.rotary_embedding.RotaryEmbedding)

### `wqkv` {#max.nn.attention.attention_with_rope.AttentionWithRope.wqkv}

> property wqkv: [TensorValue](../../graph/TensorValue.md#max.graph.TensorValue)

The concatenation of q, k, and v weight vectors.

### `wqkv_bias` {#max.nn.attention.attention_with_rope.AttentionWithRope.wqkv_bias}

> property wqkv\_bias: [TensorValue](../../graph/TensorValue.md#max.graph.TensorValue) | [None](https://docs.python.org/3/library/constants.html#None)

The concatenation of q, k, and v bias weight vectors.

## `AttentionWithRopeNoOpaque` {#max.nn.attention.attention_with_rope.AttentionWithRopeNoOpaque}

> class max.nn.attention.attention\_with\_rope.AttentionWithRopeNoOpaque(\*, rope, num\_attention\_heads, num\_key\_value\_heads, hidden\_size, kv\_params, devices=None, dtype=float32, linear\_cls=\<class 'max.nn.linear.Linear'>, scale=None)

Implementation of attention that uses the rope frequency without opaque cache.

Assumes:

* no float8
* no stacked qkv
* no bias
* no clip\_qkv
* no float8\_config

Initializes the attention layer.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* rope ([RotaryEmbedding](../rotary_embedding.md#max.nn.rotary_embedding.RotaryEmbedding)) â€“ The rope layer to borrow the freqs\_cis value from.
* num\_attention\_heads ([int](https://docs.python.org/3/library/functions.html#int)) â€“ The number of attention heads.
* num\_key\_value\_heads ([int](https://docs.python.org/3/library/functions.html#int)) â€“ Number of key/value heads.
* hidden\_size ([int](https://docs.python.org/3/library/functions.html#int)) â€“ The dimension of the hidden states.
* kv\_params ([KVCacheParams](../kv_cache/cache_params.md#max.nn.kv_cache.cache_params.KVCacheParams)) â€“ KV Cache Params, including the number of kv heads, the head dim, and data type.
* dtype ([DType](../../dtype.md#max.dtype.DType)) â€“ DType of the QKV and output projection weights.
* devices (Sequence\[[DeviceRef](../../graph/type.md#max.graph.type.DeviceRef)] | None) â€“ Device to place the weights and run the computation. If
  multiple are provided, the first device is used. Use
  DistributedAttentionWithRope to use all devices during
  attention computation.
* linear\_cls (Callable\[..., [Linear](../linear.md#max.nn.linear.Linear)]) â€“ Linear class to use for the outputs dense layer.
* scale ([float](https://docs.python.org/3/library/functions.html#float) | None) â€“ Value used to scale the results of the attention output.

</dd></dl>

### `rope` {#max.nn.attention.attention_with_rope.AttentionWithRopeNoOpaque.rope}

> rope: [RotaryEmbedding](../rotary_embedding.md#max.nn.rotary_embedding.RotaryEmbedding)

## `AttentionWithRopeQKV` {#max.nn.attention.attention_with_rope.AttentionWithRopeQKV}

> class max.nn.attention.attention\_with\_rope.AttentionWithRopeQKV(n\_heads: 'int', kv\_params: 'KVCacheParams', wq: 'TensorValueLike', wk: 'TensorValueLike', wv: 'TensorValueLike', wo: 'LinearV1', scale: 'float', rope: 'RotaryEmbedding')

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* n\_heads ([int](https://docs.python.org/3/library/functions.html#int))
* kv\_params ([KVCacheParams](../kv_cache/cache_params.md#max.nn.kv_cache.cache_params.KVCacheParams))
* wq (Value\[TensorType] | [TensorValue](../../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../../graph/shape.md#max.graph.shape.Shape) | [Dim](../../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])
* wk (Value\[TensorType] | [TensorValue](../../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../../graph/shape.md#max.graph.shape.Shape) | [Dim](../../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])
* wv (Value\[TensorType] | [TensorValue](../../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../../graph/shape.md#max.graph.shape.Shape) | [Dim](../../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])
* wo ([LinearV1](../linear.md#max.nn.linear.LinearV1))
* scale ([float](https://docs.python.org/3/library/functions.html#float))
* rope ([RotaryEmbedding](../rotary_embedding.md#max.nn.rotary_embedding.RotaryEmbedding))

</dd></dl>

### `rope` {#max.nn.attention.attention_with_rope.AttentionWithRopeQKV.rope}

> rope: [RotaryEmbedding](../rotary_embedding.md#max.nn.rotary_embedding.RotaryEmbedding)

## `AttentionWithRopeV1` {#max.nn.attention.attention_with_rope.AttentionWithRopeV1}

> class max.nn.attention.attention\_with\_rope.AttentionWithRopeV1(n\_heads, kv\_params, wqkv, wo, scale, rope, bias=None, perm\_idx=None, quantization\_config=None)

Implementation of attention that uses the rope frequency.

Deprecated: Use AttentionWithRope instead.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* n\_heads ([int](https://docs.python.org/3/library/functions.html#int))
* kv\_params ([KVCacheParams](../kv_cache/cache_params.md#max.nn.kv_cache.cache_params.KVCacheParams))
* wqkv ([TensorValue](../../graph/TensorValue.md#max.graph.TensorValue))
* wo ([LinearV1](../linear.md#max.nn.linear.LinearV1))
* scale ([float](https://docs.python.org/3/library/functions.html#float))
* rope ([RotaryEmbedding](../rotary_embedding.md#max.nn.rotary_embedding.RotaryEmbedding))
* bias ([TensorValue](../../graph/TensorValue.md#max.graph.TensorValue) | None)
* perm\_idx ([TensorValue](../../graph/TensorValue.md#max.graph.TensorValue) | None)
* quantization\_config ([QuantizationConfig](../../graph/quantization.md#max.graph.quantization.QuantizationConfig) | None)

</dd></dl>

### `bias` {#max.nn.attention.attention_with_rope.AttentionWithRopeV1.bias}

> bias: [TensorValue](../../graph/TensorValue.md#max.graph.TensorValue) | [None](https://docs.python.org/3/library/constants.html#None) = None

### `perm_idx` {#max.nn.attention.attention_with_rope.AttentionWithRopeV1.perm_idx}

> perm\_idx: [TensorValue](../../graph/TensorValue.md#max.graph.TensorValue) | [None](https://docs.python.org/3/library/constants.html#None) = None

### `quantization_config` {#max.nn.attention.attention_with_rope.AttentionWithRopeV1.quantization_config}

> quantization\_config: [QuantizationConfig](../../graph/quantization.md#max.graph.quantization.QuantizationConfig) | [None](https://docs.python.org/3/library/constants.html#None) = None

### `rope` {#max.nn.attention.attention_with_rope.AttentionWithRopeV1.rope}

> rope: [RotaryEmbedding](../rotary_embedding.md#max.nn.rotary_embedding.RotaryEmbedding)

## `DistributedAttentionWithRope` {#max.nn.attention.attention_with_rope.DistributedAttentionWithRope}

> class max.nn.attention.attention\_with\_rope.DistributedAttentionWithRope(\*, rope, num\_attention\_heads, num\_key\_value\_heads, hidden\_size, kv\_params, devices=None, dtype=float32, linear\_cls=\<class 'max.nn.linear.Linear'>, stacked\_qkv=False, scale=None, has\_bias=False, float8\_config=None, clip\_qkv=None)

Initializes the distributed attention layer.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* rope ([RotaryEmbedding](../rotary_embedding.md#max.nn.rotary_embedding.RotaryEmbedding)) â€“ The rope layer to borrow the freqs\_cis value from.
* num\_attention\_heads ([int](https://docs.python.org/3/library/functions.html#int)) â€“ The number of attention heads.
* num\_key\_value\_heads ([int](https://docs.python.org/3/library/functions.html#int)) â€“ Number of key/value heads.
* hidden\_size ([int](https://docs.python.org/3/library/functions.html#int)) â€“ The dimension of the hidden states.
* kv\_params ([KVCacheParams](../kv_cache/cache_params.md#max.nn.kv_cache.cache_params.KVCacheParams)) â€“ KV Cache Params, including the number of kv heads, the head dim, and data type.
* devices (Sequence\[[DeviceRef](../../graph/type.md#max.graph.type.DeviceRef)] | None) â€“ Device to place the weights and run the computation. Must
  provide at least 2 devices for distributed attention.
* dtype ([DType](../../dtype.md#max.dtype.DType)) â€“ DType of the QKV and output projection weights.
* linear\_cls (Callable\[..., [Linear](../linear.md#max.nn.linear.Linear)]) â€“ Linear class to use for the outputs dense layer.
* stacked\_qkv ([bool](https://docs.python.org/3/library/functions.html#bool)) â€“ Whether the weights are stacked together.
* scale ([float](https://docs.python.org/3/library/functions.html#float) | None) â€“ Value used to scale the results of the attention output.
* has\_bias ([bool](https://docs.python.org/3/library/functions.html#bool)) â€“ Whether to use an attention bias.
* float8\_config (Float8Config | None) â€“ Float8 configuration for quantization.
* clip\_qkv ([float](https://docs.python.org/3/library/functions.html#float) | None) â€“ If provided, the QKV weights are clamped between
  \[-clip\_qkv, clip\_qkv].

</dd></dl>

## `GGUFQAttentionWithRope` {#max.nn.attention.attention_with_rope.GGUFQAttentionWithRope}

> class max.nn.attention.attention\_with\_rope.GGUFQAttentionWithRope(\*, rope, num\_attention\_heads, num\_key\_value\_heads, hidden\_size, kv\_params, dtype, quantization\_encoding, devices=None, linear\_cls=\<class 'max.nn.linear.Linear'>, scale=None, has\_bias=False, clip\_qkv=None)

Implementation of attention with GGUF quantized weights.

Initializes the attention layer.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* rope ([RotaryEmbedding](../rotary_embedding.md#max.nn.rotary_embedding.RotaryEmbedding)) â€“ The rope layer to borrow the freqs\_cis value from.
* num\_attention\_heads ([int](https://docs.python.org/3/library/functions.html#int)) â€“ The number of attention heads.
* num\_key\_value\_heads ([int](https://docs.python.org/3/library/functions.html#int)) â€“ Number of key/value heads.
* hidden\_size ([int](https://docs.python.org/3/library/functions.html#int)) â€“ The dimension of the hidden states.
* kv\_params ([KVCacheParams](../kv_cache/cache_params.md#max.nn.kv_cache.cache_params.KVCacheParams)) â€“ KV Cache Params, including the number of kv heads, the head dim, and data type.
* layer\_idx â€“ The layer number associated with this Attention block.
* dtype ([DType](../../dtype.md#max.dtype.DType)) â€“ DType of the weights, should always be uint8.
* devices ([list](https://docs.python.org/3/library/stdtypes.html#list)\[[DeviceRef](../../graph/type.md#max.graph.type.DeviceRef)] | None) â€“ Device to place the weights and run the computation. If
  multiple are provided, the first device is used. Use
  DistributedAttentionWithRope to use all devices during
  attention computation.
* quantization\_encoding ([QuantizationEncoding](../../graph/quantization.md#max.graph.quantization.QuantizationEncoding)) â€“ Quantization encoding of the weights.
* linear\_cls (Callable\[..., [Linear](../linear.md#max.nn.linear.Linear)]) â€“ Linear class to use for the outputs dense layer.
* scale ([float](https://docs.python.org/3/library/functions.html#float) | None) â€“ Value used to scale the results of the attention output.
* has\_bias ([bool](https://docs.python.org/3/library/functions.html#bool)) â€“ Whether to use an attention bias.
* clip\_qkv ([float](https://docs.python.org/3/library/functions.html#float) | None) â€“ If provided, the QKV weights are clamped between
  \[-clip\_qkv, clip\_qkv]

</dd></dl>

### `rope` {#max.nn.attention.attention_with_rope.GGUFQAttentionWithRope.rope}

> rope: [RotaryEmbedding](../rotary_embedding.md#max.nn.rotary_embedding.RotaryEmbedding)

### `wqkv` {#max.nn.attention.attention_with_rope.GGUFQAttentionWithRope.wqkv}

> property wqkv: [TensorValue](../../graph/TensorValue.md#max.graph.TensorValue)

The concatenation of q, k, and v weight vectors.

### `wqkv_bias` {#max.nn.attention.attention_with_rope.GGUFQAttentionWithRope.wqkv_bias}

> property wqkv\_bias: [TensorValue](../../graph/TensorValue.md#max.graph.TensorValue) | [None](https://docs.python.org/3/library/constants.html#None)

The concatenation of q, k, and v bias weight vectors.

## `GPTQAttentionWithRope` {#max.nn.attention.attention_with_rope.GPTQAttentionWithRope}

> class max.nn.attention.attention\_with\_rope.GPTQAttentionWithRope(quantization\_config, rope, num\_attention\_heads, num\_key\_value\_heads, hidden\_size, kv\_params, devices=None, dtype=float32, scale=None, linear\_cls=\<class 'max.nn.linear.Linear'>)

Implementation of the GPT-Q attention layer.

Initializes the attention layer.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* rope ([RotaryEmbedding](../rotary_embedding.md#max.nn.rotary_embedding.RotaryEmbedding)) â€“ The rope layer to borrow the freqs\_cis value from.
* num\_attention\_heads ([int](https://docs.python.org/3/library/functions.html#int)) â€“ The number of attention heads.
* num\_key\_value\_heads ([int](https://docs.python.org/3/library/functions.html#int)) â€“ Number of key/value heads.
* hidden\_size ([int](https://docs.python.org/3/library/functions.html#int)) â€“ The dimension of the hidden states.
* kv\_params ([KVCacheParams](../kv_cache/cache_params.md#max.nn.kv_cache.cache_params.KVCacheParams)) â€“ KV Cache Params, including the number of kv heads, the head dim, and data type.
* dtype ([DType](../../dtype.md#max.dtype.DType)) â€“ DType of the QKV and output projection weights.
* devices ([list](https://docs.python.org/3/library/stdtypes.html#list)\[[DeviceRef](../../graph/type.md#max.graph.type.DeviceRef)] | None) â€“ Device to place the weights and run the computation. If
  multiple are provided, the first device is used. Use
  DistributedAttentionWithRope to use all devices during
  attention computation.
* linear\_cls (Callable\[..., [Linear](../linear.md#max.nn.linear.Linear)]) â€“ Linear class to use for the outputs dense layer.
* stacked\_qkv â€“ Whether the weights are stacked together.
* scale ([float](https://docs.python.org/3/library/functions.html#float) | None) â€“ Value used to scale the results of the attention output.
* has\_bias â€“ Whether to use an attention bias.
* clip\_qkv â€“ If provided, the QKV weights are clamped between
  \[-clip\_qkv, clip\_qkv]
* quantization\_config ([QuantizationConfig](../../graph/quantization.md#max.graph.quantization.QuantizationConfig))

</dd></dl>

### `wqkv` {#max.nn.attention.attention_with_rope.GPTQAttentionWithRope.wqkv}

> property wqkv: [TensorValue](../../graph/TensorValue.md#max.graph.TensorValue)

The concatenation of q, k, and v weight vectors.

## `distribute_value()` {#max.nn.attention.attention_with_rope.distribute_value}

> max.nn.attention.attention\_with\_rope.distribute\_value(v, devices)

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* v ([TensorValue](../../graph/TensorValue.md#max.graph.TensorValue))
* devices ([list](https://docs.python.org/3/library/stdtypes.html#list)\[[DeviceRef](../../graph/type.md#max.graph.type.DeviceRef)])

</dd><dt>

**Return type:**

</dt><dd>

[list](https://docs.python.org/3/library/stdtypes.html#list)\[[TensorValue](../../graph/TensorValue.md#max.graph.TensorValue)]

</dd></dl>

---

## attention

## Modules

* [`attention_with_rope`](/max/api/python/nn/attention/attention_with_rope)
* [`ragged_attention`](/max/api/python/nn/attention/ragged_attention)
* [`interfaces`](/max/api/python/nn/attention/interfaces)

---

## interfaces (Attention)

General interface for Attention.

## `AttentionImpl` {#max.nn.attention.interfaces.AttentionImpl}

> class max.nn.attention.interfaces.AttentionImpl(n\_heads, kv\_params, wqkv, wo, scale)

A generalized attention interface, that will be used upstream by a general Transformer.
We would expect a separate subclass, articulating each variation of Attention:

* AttentionWithRope
* AttentionWithAlibi
* VanillaAttentionWithCausalMask
* â€¦

There are a series of shared attributes, however, more may be needed for each individual variant.
For example, we may introduce an RotaryEmbedding class for the AttentionWithRope class:

```python
@dataclass
class AttentionWithRope(AttentionImpl):
    rope: RotaryEmbedding
    ...
```

We expect the `__call__` abstractmethod to remain relatively consistent, however the `**kwargs`
argument is exposed, allowing you to leverage additional arguments for each particular variant.
For example, we may introduce an VanillaAttentionWithCausalMask class, which includes an attention
mask:

```python
@dataclass
class VanillaAttentionWithCausalMask(AttentionImpl):
    ...

    def __call__(
        self,
        x: TensorValueLike,
        kv_collection: PagedKVCacheCollection,
        valid_lengths: TensorValueLike,
        **kwargs,
    ) -> tuple[TensorValue, PagedKVCacheCollection]: ...

        if "attn_mask" not in kwargs:
            raise ValueError("attn_mask not provided to VanillaAttentionWithCausalMask")

        # Which we can then use the attention mask downstream like so:
        op(
            attn_mask = kwargs["attn_mask"]
        )
```

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* n\_heads ([int](https://docs.python.org/3/library/functions.html#int))
* kv\_params ([KVCacheParams](../kv_cache/cache_params.md#max.nn.kv_cache.cache_params.KVCacheParams))
* wqkv ([TensorValue](../../graph/TensorValue.md#max.graph.TensorValue))
* wo ([LinearV1](../linear.md#max.nn.linear.LinearV1))
* scale ([float](https://docs.python.org/3/library/functions.html#float))

</dd></dl>

### `kv_params` {#max.nn.attention.interfaces.AttentionImpl.kv_params}

> kv\_params: [KVCacheParams](../kv_cache/cache_params.md#max.nn.kv_cache.cache_params.KVCacheParams)

KV Cache Params, including the number of kv heads, the head dim, and data type.

### `n_heads` {#max.nn.attention.interfaces.AttentionImpl.n_heads}

> n\_heads: [int](https://docs.python.org/3/library/functions.html#int)

The number of attention heads.

### `scale` {#max.nn.attention.interfaces.AttentionImpl.scale}

> scale: [float](https://docs.python.org/3/library/functions.html#float)

The scale factor for the attention.

### `wo` {#max.nn.attention.interfaces.AttentionImpl.wo}

> wo: [LinearV1](../linear.md#max.nn.linear.LinearV1)

A linear layer for the output projection.

### `wqkv` {#max.nn.attention.interfaces.AttentionImpl.wqkv}

> wqkv: [TensorValue](../../graph/TensorValue.md#max.graph.TensorValue)

The concatenation of q, k, and v weight vectors.

## `AttentionImplQKV` {#max.nn.attention.interfaces.AttentionImplQKV}

> class max.nn.attention.interfaces.AttentionImplQKV(n\_heads, kv\_params, wq, wk, wv, wo, scale)

A generalized attention interface, that will be used upstream by a general Transformer.
We would expect a separate subclass, articulating each variation of Attention:

* AttentionWithRope
* AttentionWithAlibi
* VanillaAttentionWithCausalMask
* â€¦

There are a series of shared attributes, however, more may be needed for each individual variant.
For example, we may introduce an RotaryEmbedding class for the AttentionWithRope class:

```python
@dataclass
class AttentionWithRope(AttentionImpl):
    rope: RotaryEmbedding
    ...
```

We expect the `__call__` abstractmethod to remain relatively consistent, however the `**kwargs`
argument is exposed, allowing you to leverage additional arguments for each particular variant.
For example, we may introduce an VanillaAttentionWithCausalMask class, which includes an attention
mask:

```python
@dataclass
class VanillaAttentionWithCausalMask(AttentionImpl):
    ...

    def __call__(
        self,
        x: TensorValueLike,
        kv_collection: PagedKVCacheCollection,
        valid_lengths: TensorValueLike,
        **kwargs,
    ) -> tuple[TensorValue, PagedKVCacheCollection]: ...

        if "attn_mask" not in kwargs:
            raise ValueError("attn_mask not provided to VanillaAttentionWithCausalMask")

        # Which we can then use the attention mask downstream like so:
        op(
            attn_mask = kwargs["attn_mask"]
        )
```

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* n\_heads ([int](https://docs.python.org/3/library/functions.html#int))
* kv\_params ([KVCacheParams](../kv_cache/cache_params.md#max.nn.kv_cache.cache_params.KVCacheParams))
* wq (Value\[TensorType] | [TensorValue](../../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../../graph/shape.md#max.graph.shape.Shape) | [Dim](../../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])
* wk (Value\[TensorType] | [TensorValue](../../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../../graph/shape.md#max.graph.shape.Shape) | [Dim](../../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])
* wv (Value\[TensorType] | [TensorValue](../../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../../graph/shape.md#max.graph.shape.Shape) | [Dim](../../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])
* wo ([LinearV1](../linear.md#max.nn.linear.LinearV1))
* scale ([float](https://docs.python.org/3/library/functions.html#float))

</dd></dl>

### `kv_params` {#max.nn.attention.interfaces.AttentionImplQKV.kv_params}

> kv\_params: [KVCacheParams](../kv_cache/cache_params.md#max.nn.kv_cache.cache_params.KVCacheParams)

KV Cache Params, including the number of kv heads, the head dim, and data type.

### `n_heads` {#max.nn.attention.interfaces.AttentionImplQKV.n_heads}

> n\_heads: [int](https://docs.python.org/3/library/functions.html#int)

The number of attention heads.

### `scale` {#max.nn.attention.interfaces.AttentionImplQKV.scale}

> scale: [float](https://docs.python.org/3/library/functions.html#float)

The scale factor for the attention.

### `wk` {#max.nn.attention.interfaces.AttentionImplQKV.wk}

> wk: Value\[TensorType] | [TensorValue](../../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../../graph/shape.md#max.graph.shape.Shape) | [Dim](../../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]]

The k weight vector.

### `wo` {#max.nn.attention.interfaces.AttentionImplQKV.wo}

> wo: [LinearV1](../linear.md#max.nn.linear.LinearV1)

A linear layer for the output projection.

### `wq` {#max.nn.attention.interfaces.AttentionImplQKV.wq}

> wq: Value\[TensorType] | [TensorValue](../../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../../graph/shape.md#max.graph.shape.Shape) | [Dim](../../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]]

The q weight vector.

### `wv` {#max.nn.attention.interfaces.AttentionImplQKV.wv}

> wv: Value\[TensorType] | [TensorValue](../../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../../graph/shape.md#max.graph.shape.Shape) | [Dim](../../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]]

The v weight vector.

## `DistributedAttentionImpl` {#max.nn.attention.interfaces.DistributedAttentionImpl}

> class max.nn.attention.interfaces.DistributedAttentionImpl

A generalized Distributed attention interface.

---

## ragged_attention

An opaque KV Cache optimized vanilla attention mechanism, with Mask Variants provided inside the Kernel.

## `RaggedAttention` {#max.nn.attention.ragged_attention.RaggedAttention}

> class max.nn.attention.ragged\_attention.RaggedAttention(\*, mask\_variant, num\_attention\_heads, num\_key\_value\_heads, hidden\_size, kv\_params, devices=None, dtype=float32, linear\_cls=\<class 'max.nn.linear.Linear'>, stacked\_qkv=False, scale=None, has\_bias=False, clip\_qkv=None)

Layer that computes the self attention score for ragged inputs.

Initializes the attention layer.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* rope â€“ The rope layer to borrow the freqs\_cis value from.
* num\_attention\_heads ([int](https://docs.python.org/3/library/functions.html#int)) â€“ The number of attention heads.
* num\_key\_value\_heads ([int](https://docs.python.org/3/library/functions.html#int)) â€“ Number of key/value heads.
* hidden\_size ([int](https://docs.python.org/3/library/functions.html#int)) â€“ The dimension of the hidden states.
* kv\_params ([KVCacheParams](../kv_cache/cache_params.md#max.nn.kv_cache.cache_params.KVCacheParams)) â€“ KV Cache Params, including the number of kv heads, the head dim, and data type.
* dtype ([DType](../../dtype.md#max.dtype.DType)) â€“ DType of the
* devices ([list](https://docs.python.org/3/library/stdtypes.html#list)\[[DeviceRef](../../graph/type.md#max.graph.type.DeviceRef)] | None) â€“ Device to place the weights and run the computation. If
  multiple are provided, the first device is used.
* linear\_cls (Callable\[..., [Linear](../linear.md#max.nn.linear.Linear)]) â€“ Linear class to use for the outputs dense layer.
* stacked\_qkv ([bool](https://docs.python.org/3/library/functions.html#bool)) â€“ Whether the weights are stacked together.
* scale ([float](https://docs.python.org/3/library/functions.html#float) | None) â€“ Value used to scale the results of the attention output.
* has\_bias ([bool](https://docs.python.org/3/library/functions.html#bool)) â€“ Whether to use an attention bias.
* clip\_qkv ([float](https://docs.python.org/3/library/functions.html#float) | None) â€“ If provided, the QKV weights are clamped between
  \[-clip\_qkv, clip\_qkv]
* mask\_variant (MHAMaskVariant)

</dd></dl>

### `wqkv` {#max.nn.attention.ragged_attention.RaggedAttention.wqkv}

> property wqkv: [TensorValue](../../graph/TensorValue.md#max.graph.TensorValue)

The concatenation of q, k, and v weight vectors.

---

## conv

The `conv` module provides classes for performing convolution operations in
various dimensions (1D, 2D, and 3D) on tensor inputs. These convolution
operations are core building blocks for neural networks, especially in computer
vision and sequence processing tasks.

Hereâ€™s an example demonstrating how to use a 1D convolution:

```python
import max.nn as nn
from max.graph import Graph, ops, Weight, DeviceRef
from max.dtype import DType
import numpy as np

with Graph(name="conv_example") as graph:
    # Define dimensions
    batch_size = 2
    seq_length = 10
    in_channels = 16
    out_channels = 32
    kernel_size = 3

    # Create input tensor [batch_size, sequence_length, channels]
    x_data = np.zeros((batch_size, seq_length, in_channels), dtype=np.float32)
    x = ops.constant(x_data, dtype=DType.float32, device=DeviceRef.CPU())

    # Create weights for convolution
    filter_1d = Weight(
        name="filter_weight",
        dtype=DType.float32,
        shape=[kernel_size, in_channels, out_channels]
        device=DeviceRef.CPU()
    )
    bias_1d = Weight(
        name="bias_weight",
        dtype=DType.float32,
        shape=[out_channels]
        device=DeviceRef.CPU()
    )

    # Create and apply Conv1D layer
    conv1d = nn.Conv1D(
        filter=filter_1d,
        bias=bias_1d,
        stride=1,
        padding=1
    )

    output_1d = conv1d(x)
    print(f"Conv1D output shape: {output_1d.shape}")
    # Output: Conv1D output shape: [Dim(2), Dim(10), Dim(32)]
```

## `Conv1D` {#max.nn.conv.Conv1D}

> class max.nn.conv.Conv1D(kernel\_size, in\_channels, out\_channels, dtype, stride=1, padding=0, dilation=1, num\_groups=1, device=None, has\_bias=False, permute=False, name=None)

A 1D convolution over an input signal composed of several input
planes.

**Example:**

```python
conv = nn.Conv1D(
    kernel_size=3,
    in_channels=64,
    out_channels=128,
    dtype=DType.float32,
    stride=1,
    padding=0,
    has_bias=False,
    name="conv1d_weight",
    device=DeviceRef.GPU(),
)
```

Initializes the Conv1D layer with weights and optional bias.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* kernel\_size ([int](https://docs.python.org/3/library/functions.html#int)) â€“ Size of the convolving kernel (width dimension).
* in\_channels ([int](https://docs.python.org/3/library/functions.html#int)) â€“ Number of channels in the input signal.
* out\_channels ([int](https://docs.python.org/3/library/functions.html#int)) â€“ Number of channels produced by the convolution.
* dtype ([DType](../dtype.md#max.dtype.DType)) â€“ The data type for both weights and bias.
* stride ([int](https://docs.python.org/3/library/functions.html#int)) â€“ Stride of the convolution. Controls the step size when sliding the kernel. Default: 1
* padding ([int](https://docs.python.org/3/library/functions.html#int)) â€“ Padding added to both sides of the input sequence. Default: 0
* dilation ([int](https://docs.python.org/3/library/functions.html#int)) â€“ Spacing between kernel elements. Controls the kernel dilation rate. Default: 1
* num\_groups ([int](https://docs.python.org/3/library/functions.html#int)) â€“ Number of blocked connections from input channels to output channels.
  Input channels and output channels are divided into groups. Default: 1
* device ([DeviceRef](../graph/type.md#max.graph.type.DeviceRef) | None) â€“ The target device for computation. If None, defaults to CPU.
  Weights are initially stored on CPU and moved to target device during computation.
* name (Union\[[str](https://docs.python.org/3/library/stdtypes.html#str), None]) â€“ Base name for weights. If provided, weights are named `{name}.weight` and
  `{name}.bias` (if bias is enabled). If None, uses â€œweightâ€ and â€œbiasâ€.
* has\_bias ([bool](https://docs.python.org/3/library/functions.html#bool)) â€“ If true, adds a learnable bias vector to the layer.
  Defaults to [`False`](https://docs.python.org/3/library/constants.html#False).
* permute ([bool](https://docs.python.org/3/library/functions.html#bool)) â€“ If true, permutes weights from PyTorch format to MAX format.
  PyTorch order: (out\_channels, in\_channels / num\_groups, kernel\_size).
  MAX API order: (kernel\_size, in\_channels / num\_groups, out\_channels).
  Defaults to [`False`](https://docs.python.org/3/library/constants.html#False).

</dd></dl>

### `bias` {#max.nn.conv.Conv1D.bias}

> bias: [Weight](../graph/Weight.md#max.graph.Weight) | [None](https://docs.python.org/3/library/constants.html#None) = None

The optional bias vector stored on CPU with shape (out\_channels,).
Model init moves the bias to [`device`](#max.nn.conv.Conv1D.device) if present.

### `device` {#max.nn.conv.Conv1D.device}

> device: [DeviceRef](../graph/type.md#max.graph.type.DeviceRef) | [None](https://docs.python.org/3/library/constants.html#None)

The device where matrix operations are performed.

### `dilation` {#max.nn.conv.Conv1D.dilation}

> dilation: [int](https://docs.python.org/3/library/functions.html#int)

Controls the dilation rate.

### `filter` {#max.nn.conv.Conv1D.filter}

> filter: [Weight](../graph/Weight.md#max.graph.Weight)

The weight matrix stored on CPU with shape (kernel\_size, in\_channels / num\_groups, out\_channels).
Model init moves the weight to [`device`](#max.nn.conv.Conv1D.device).

### `num_groups` {#max.nn.conv.Conv1D.num_groups}

> num\_groups: [int](https://docs.python.org/3/library/functions.html#int)

Number of blocked connections from input channels to output channels.

### `padding` {#max.nn.conv.Conv1D.padding}

> padding: [int](https://docs.python.org/3/library/functions.html#int)

Controls the amount of padding applied before and after the input.

### `permute` {#max.nn.conv.Conv1D.permute}

> permute: [bool](https://docs.python.org/3/library/functions.html#bool) = False

bool controls whether self.filter is permuted from PyTorch order to max order.
PyTorch order is: (out\_channels, in\_channels / num\_groups, kernel\_size)
Max API order: (kernel\_size, in\_channels / num\_groups, out\_channels).

### `stride` {#max.nn.conv.Conv1D.stride}

> stride: [int](https://docs.python.org/3/library/functions.html#int)

Controls the stride for the cross-correlation.

## `Conv1DV1` {#max.nn.conv.Conv1DV1}

> class max.nn.conv.Conv1DV1(filter, bias=None, stride=1, padding=0, dilation=1, groups=1)

A 1D convolution over an input signal composed of several input
planes.

DEPRECATED: Use [`Conv1D`](#max.nn.conv.Conv1D) instead.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* filter (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])
* bias (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]] | None)
* stride ([int](https://docs.python.org/3/library/functions.html#int))
* padding ([int](https://docs.python.org/3/library/functions.html#int))
* dilation ([int](https://docs.python.org/3/library/functions.html#int))
* groups ([int](https://docs.python.org/3/library/functions.html#int))

</dd></dl>

### `bias` {#max.nn.conv.Conv1DV1.bias}

> bias: Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]] | [None](https://docs.python.org/3/library/constants.html#None) = None

### `dilation` {#max.nn.conv.Conv1DV1.dilation}

> dilation: [int](https://docs.python.org/3/library/functions.html#int) = 1

### `filter` {#max.nn.conv.Conv1DV1.filter}

> filter: Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]]

### `groups` {#max.nn.conv.Conv1DV1.groups}

> groups: [int](https://docs.python.org/3/library/functions.html#int) = 1

### `padding` {#max.nn.conv.Conv1DV1.padding}

> padding: [int](https://docs.python.org/3/library/functions.html#int) = 0

### `stride` {#max.nn.conv.Conv1DV1.stride}

> stride: [int](https://docs.python.org/3/library/functions.html#int) = 1

## `Conv2d` {#max.nn.conv.Conv2d}

> class max.nn.conv.Conv2d(kernel\_size, in\_channels, out\_channels, dtype, stride=1, padding=0, dilation=1, num\_groups=1, device=None, has\_bias=False, permute=False, name=None)

A 2D convolution over an input signal composed of several input
planes.

**Example:**

```python
conv = nn.Conv2d(
    kernel_size=3,
    in_channels=64,
    out_channels=128,
    dtype=DType.float32,
    stride=1,
    padding=0,
    has_bias=False,
    name="conv2d_weight",
    device=DeviceRef.GPU(),
)
```

Initializes the Conv2d layer with weights and optional bias.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* kernel\_size (Union\[[int](https://docs.python.org/3/library/functions.html#int), [tuple](https://docs.python.org/3/library/stdtypes.html#tuple)\[[int](https://docs.python.org/3/library/functions.html#int), [int](https://docs.python.org/3/library/functions.html#int)]]) â€“ Size of the convolving kernel. Can be a single int (square kernel) or tuple (height, width).
* in\_channels ([int](https://docs.python.org/3/library/functions.html#int)) â€“ Number of channels in the input image.
* out\_channels ([int](https://docs.python.org/3/library/functions.html#int)) â€“ Number of channels produced by the convolution.
* dtype ([DType](../dtype.md#max.dtype.DType)) â€“ The data type for both weights and bias.
* stride ([tuple](https://docs.python.org/3/library/stdtypes.html#tuple)\[[int](https://docs.python.org/3/library/functions.html#int), [int](https://docs.python.org/3/library/functions.html#int)]) â€“ Stride of the convolution for height and width dimensions.
  Can be int (applied to both dimensions) or tuple (stride\_h, stride\_w). Default: 1
* padding ([tuple](https://docs.python.org/3/library/stdtypes.html#tuple)\[[int](https://docs.python.org/3/library/functions.html#int), [int](https://docs.python.org/3/library/functions.html#int), [int](https://docs.python.org/3/library/functions.html#int), [int](https://docs.python.org/3/library/functions.html#int)]) â€“ Padding added to input. Can be int (applied to all sides),
  tuple of 2 ints (pad\_h, pad\_w), or tuple of 4 ints (pad\_top, pad\_bottom, pad\_left, pad\_right). Default: 0
* dilation ([tuple](https://docs.python.org/3/library/stdtypes.html#tuple)\[[int](https://docs.python.org/3/library/functions.html#int), [int](https://docs.python.org/3/library/functions.html#int)]) â€“ Spacing between kernel elements for height and width dimensions.
  Can be int (applied to both dimensions) or tuple (dilation\_h, dilation\_w). Default: 1
* num\_groups ([int](https://docs.python.org/3/library/functions.html#int)) â€“ Number of blocked connections from input channels to output channels.
  Input channels and output channels are divided into groups. Default: 1
* device ([DeviceRef](../graph/type.md#max.graph.type.DeviceRef) | None) â€“ The target device for computation. If None, defaults to CPU.
  Weights are initially stored on CPU and moved to target device during computation.
* name (Union\[[str](https://docs.python.org/3/library/stdtypes.html#str), None]) â€“ Base name for weights. If provided, weights are named `{name}.weight` and
  `{name}.bias` (if bias is enabled). If None, uses â€œweightâ€ and â€œbiasâ€.
* has\_bias ([bool](https://docs.python.org/3/library/functions.html#bool)) â€“ If true, adds a learnable bias vector to the layer.
  Defaults to [`False`](https://docs.python.org/3/library/constants.html#False).
* permute ([bool](https://docs.python.org/3/library/functions.html#bool)) â€“ If true, permutes weights from PyTorch format to MAX format.
  PyTorch order: (out\_channels, in\_channels / num\_groups, height, width).
  MAX API order: (height, width, in\_channels / num\_groups, out\_channels).
  Defaults to [`False`](https://docs.python.org/3/library/constants.html#False).

</dd></dl>

### `bias` {#max.nn.conv.Conv2d.bias}

> bias: [Weight](../graph/Weight.md#max.graph.Weight) | [None](https://docs.python.org/3/library/constants.html#None) = None

The optional bias vector stored on CPU with shape (out\_channels,).
Model init moves the bias to [`device`](#max.nn.conv.Conv2d.device) if present.

### `device` {#max.nn.conv.Conv2d.device}

> device: [DeviceRef](../graph/type.md#max.graph.type.DeviceRef) | [None](https://docs.python.org/3/library/constants.html#None)

The device where matrix operations are performed.

### `dilation` {#max.nn.conv.Conv2d.dilation}

> dilation: [tuple](https://docs.python.org/3/library/stdtypes.html#tuple)\[[int](https://docs.python.org/3/library/functions.html#int), [int](https://docs.python.org/3/library/functions.html#int)]

Controls the dilation rate.

### `filter` {#max.nn.conv.Conv2d.filter}

> filter: [Weight](../graph/Weight.md#max.graph.Weight)

The weight matrix stored on CPU with shape (height, width, in\_channels / num\_groups, out\_channels).
Model init moves the weight to [`device`](#max.nn.conv.Conv2d.device).

### `num_groups` {#max.nn.conv.Conv2d.num_groups}

> num\_groups: [int](https://docs.python.org/3/library/functions.html#int)

Number of blocked connections from input channels to output channels.

### `padding` {#max.nn.conv.Conv2d.padding}

> padding: [tuple](https://docs.python.org/3/library/stdtypes.html#tuple)\[[int](https://docs.python.org/3/library/functions.html#int), [int](https://docs.python.org/3/library/functions.html#int), [int](https://docs.python.org/3/library/functions.html#int), [int](https://docs.python.org/3/library/functions.html#int)]

Controls the amount of padding applied before and after the input for height and width dimensions.

### `permute` {#max.nn.conv.Conv2d.permute}

> permute: [bool](https://docs.python.org/3/library/functions.html#bool) = False

bool controls whether self.filter is permuted from PyTorch order to max order.
PyTorch order is: (out\_channels, in\_channels / num\_groups, height, width)
Max API order: (height, width, in\_channels / num\_groups, out\_channels).

### `shard()` {#max.nn.conv.Conv2d.shard}

> shard(devices)

Creates sharded views of this Conv2d layer across multiple devices.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

devices ([Iterable](https://docs.python.org/3/library/collections.abc.html#collections.abc.Iterable)\[[DeviceRef](../graph/type.md#max.graph.type.DeviceRef)]) â€“ Iterable of devices to place the shards on.

</dd><dt>

**Returns:**

</dt><dd>

List of sharded Conv2d instances, one for each device.

</dd><dt>

**Return type:**

</dt><dd>

[list](https://docs.python.org/3/library/stdtypes.html#list)\[[Conv2d](#max.nn.conv.Conv2d)]

</dd></dl>

### `sharding_strategy` {#max.nn.conv.Conv2d.sharding_strategy}

> property sharding\_strategy: ShardingStrategy | [None](https://docs.python.org/3/library/constants.html#None)

Get the Conv2d sharding strategy.

### `stride` {#max.nn.conv.Conv2d.stride}

> stride: [tuple](https://docs.python.org/3/library/stdtypes.html#tuple)\[[int](https://docs.python.org/3/library/functions.html#int), [int](https://docs.python.org/3/library/functions.html#int)]

Controls the stride for the cross-correlation.

## `Conv2dV1` {#max.nn.conv.Conv2dV1}

> class max.nn.conv.Conv2dV1(filter, bias=None, stride=(1, 1), padding=(0, 0, 0, 0), dilation=(1, 1), groups=1)

A 2D convolution over an input signal composed of several input
planes.

DEPRECATED: Use [`Conv2d`](#max.nn.conv.Conv2d) instead.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* filter (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])
* bias (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]] | None)
* stride ([int](https://docs.python.org/3/library/functions.html#int) | [tuple](https://docs.python.org/3/library/stdtypes.html#tuple)\[[int](https://docs.python.org/3/library/functions.html#int), [int](https://docs.python.org/3/library/functions.html#int)])
* padding ([int](https://docs.python.org/3/library/functions.html#int) | [tuple](https://docs.python.org/3/library/stdtypes.html#tuple)\[[int](https://docs.python.org/3/library/functions.html#int), [int](https://docs.python.org/3/library/functions.html#int), [int](https://docs.python.org/3/library/functions.html#int), [int](https://docs.python.org/3/library/functions.html#int)])
* dilation ([int](https://docs.python.org/3/library/functions.html#int) | [tuple](https://docs.python.org/3/library/stdtypes.html#tuple)\[[int](https://docs.python.org/3/library/functions.html#int), [int](https://docs.python.org/3/library/functions.html#int)])
* groups ([int](https://docs.python.org/3/library/functions.html#int))

</dd></dl>

### `bias` {#max.nn.conv.Conv2dV1.bias}

> bias: Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]] | [None](https://docs.python.org/3/library/constants.html#None) = None

### `dilation` {#max.nn.conv.Conv2dV1.dilation}

> dilation: [int](https://docs.python.org/3/library/functions.html#int) | [tuple](https://docs.python.org/3/library/stdtypes.html#tuple)\[[int](https://docs.python.org/3/library/functions.html#int), [int](https://docs.python.org/3/library/functions.html#int)] = (1, 1)

### `filter` {#max.nn.conv.Conv2dV1.filter}

> filter: Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]]

### `groups` {#max.nn.conv.Conv2dV1.groups}

> groups: [int](https://docs.python.org/3/library/functions.html#int) = 1

### `padding` {#max.nn.conv.Conv2dV1.padding}

> padding: [int](https://docs.python.org/3/library/functions.html#int) | [tuple](https://docs.python.org/3/library/stdtypes.html#tuple)\[[int](https://docs.python.org/3/library/functions.html#int), [int](https://docs.python.org/3/library/functions.html#int), [int](https://docs.python.org/3/library/functions.html#int), [int](https://docs.python.org/3/library/functions.html#int)] = (0, 0, 0, 0)

### `stride` {#max.nn.conv.Conv2dV1.stride}

> stride: [int](https://docs.python.org/3/library/functions.html#int) | [tuple](https://docs.python.org/3/library/stdtypes.html#tuple)\[[int](https://docs.python.org/3/library/functions.html#int), [int](https://docs.python.org/3/library/functions.html#int)] = (1, 1)

## `Conv3D` {#max.nn.conv.Conv3D}

> class max.nn.conv.Conv3D(depth, height, width, in\_channels, out\_channels, dtype, stride=1, padding=0, dilation=1, num\_groups=1, device=None, has\_bias=False, permute=False, name=None)

A 3D convolution over an input signal composed of several input
planes.

**Example:**

```python
conv = nn.Conv3D(
    depth=,
    height=,
    width=,
    in_channels=,
    out_channels=,
    dtype=DType.float32,
    stride=1,
    padding=0,
    has_bias=False,
    name="conv3d_weight",
    device=DeviceRef.GPU(),
)
```

Initializes the Conv3D layer with weights and optional bias.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* depth ([int](https://docs.python.org/3/library/functions.html#int)) â€“ Depth dimension of the convolution kernel (kernel\_size\[0]).
* height ([int](https://docs.python.org/3/library/functions.html#int)) â€“ Height dimension of the convolution kernel (kernel\_size\[1]).
* width ([int](https://docs.python.org/3/library/functions.html#int)) â€“ Width dimension of the convolution kernel (kernel\_size\[2]).
* in\_channels ([int](https://docs.python.org/3/library/functions.html#int)) â€“ Number of channels in the input image.
* out\_channels ([int](https://docs.python.org/3/library/functions.html#int)) â€“ Number of channels produced by the convolution.
* dtype ([DType](../dtype.md#max.dtype.DType)) â€“ The data type for both weights and bias.
* stride ([tuple](https://docs.python.org/3/library/stdtypes.html#tuple)\[[int](https://docs.python.org/3/library/functions.html#int), [int](https://docs.python.org/3/library/functions.html#int), [int](https://docs.python.org/3/library/functions.html#int)]) â€“ Stride of the convolution for depth, height, and width dimensions.
  Can be int (applied to all dimensions) or tuple of 3 ints. Default: 1
* padding ([tuple](https://docs.python.org/3/library/stdtypes.html#tuple)\[[int](https://docs.python.org/3/library/functions.html#int), [int](https://docs.python.org/3/library/functions.html#int), [int](https://docs.python.org/3/library/functions.html#int), [int](https://docs.python.org/3/library/functions.html#int), [int](https://docs.python.org/3/library/functions.html#int), [int](https://docs.python.org/3/library/functions.html#int)]) â€“ Padding added to all six sides of the input in order:
  (pad\_front, pad\_back, pad\_top, pad\_bottom, pad\_left, pad\_right).
  Can be int (applied to all sides) or tuple of 6 ints. Default: 0
* dilation ([tuple](https://docs.python.org/3/library/stdtypes.html#tuple)\[[int](https://docs.python.org/3/library/functions.html#int), [int](https://docs.python.org/3/library/functions.html#int), [int](https://docs.python.org/3/library/functions.html#int)]) â€“ Spacing between kernel elements for depth, height, and width dimensions.
  Can be int (applied to all dimensions) or tuple of 3 ints. Default: 1
* num\_groups ([int](https://docs.python.org/3/library/functions.html#int)) â€“ Number of blocked connections from input channels to output channels.
  Input channels and output channels are divided into groups. Default: 1.
* device ([DeviceRef](../graph/type.md#max.graph.type.DeviceRef) | None) â€“ The target device for computation. If None, defaults to CPU.
  Weights are initially stored on CPU and moved to target device during computation.
* name (Union\[[str](https://docs.python.org/3/library/stdtypes.html#str), None]) â€“ Base name for weights. If provided, weights are named `{name}.weight` and
  `{name}.bias` (if bias is enabled). If None, uses â€œweightâ€ and â€œbiasâ€.
* has\_bias ([bool](https://docs.python.org/3/library/functions.html#bool)) â€“ If true, adds a learnable bias vector to the layer.
  Defaults to [`False`](https://docs.python.org/3/library/constants.html#False).
* permute ([bool](https://docs.python.org/3/library/functions.html#bool)) â€“ If true, permutes weights from PyTorch format to MAX format.
  PyTorch order: (out\_channels, in\_channels / num\_groups, depth, height, width).
  MAX API order: (depth, height, width, in\_channels / num\_groups, out\_channels).
  Defaults to [`False`](https://docs.python.org/3/library/constants.html#False).

</dd></dl>

### `bias` {#max.nn.conv.Conv3D.bias}

> bias: [Weight](../graph/Weight.md#max.graph.Weight) | [None](https://docs.python.org/3/library/constants.html#None) = None

The optional bias vector stored on CPU with shape (out\_channels,).
Model init moves the bias to [`device`](#max.nn.conv.Conv3D.device) if present.

### `device` {#max.nn.conv.Conv3D.device}

> device: [DeviceRef](../graph/type.md#max.graph.type.DeviceRef) | [None](https://docs.python.org/3/library/constants.html#None)

The device where matrix operations are performed.

### `dilation` {#max.nn.conv.Conv3D.dilation}

> dilation: [tuple](https://docs.python.org/3/library/stdtypes.html#tuple)\[[int](https://docs.python.org/3/library/functions.html#int), [int](https://docs.python.org/3/library/functions.html#int), [int](https://docs.python.org/3/library/functions.html#int)]

Controls the dilation rate for depth, height, and width dimensions.

### `filter` {#max.nn.conv.Conv3D.filter}

> filter: [Weight](../graph/Weight.md#max.graph.Weight)

The weight matrix stored on CPU with shape (depth, height, width, in\_channels / num\_groups, out\_channels).
Model init moves the weight to [`device`](#max.nn.conv.Conv3D.device).

### `num_groups` {#max.nn.conv.Conv3D.num_groups}

> num\_groups: [int](https://docs.python.org/3/library/functions.html#int)

Number of blocked connections from input channels to output channels.

### `padding` {#max.nn.conv.Conv3D.padding}

> padding: [tuple](https://docs.python.org/3/library/stdtypes.html#tuple)\[[int](https://docs.python.org/3/library/functions.html#int), [int](https://docs.python.org/3/library/functions.html#int), [int](https://docs.python.org/3/library/functions.html#int), [int](https://docs.python.org/3/library/functions.html#int), [int](https://docs.python.org/3/library/functions.html#int), [int](https://docs.python.org/3/library/functions.html#int)]

Controls the amount of padding applied before and after the input for depth, height, and width dimensions.

### `permute` {#max.nn.conv.Conv3D.permute}

> permute: [bool](https://docs.python.org/3/library/functions.html#bool) = False

bool controls whether self.filter is permuted from PyTorch order to max order.
PyTorch order is: (out\_channels, in\_channels / num\_groups, depth, height, width)
Max API order: (depth, height, width, in\_channels / num\_groups, out\_channels).

### `stride` {#max.nn.conv.Conv3D.stride}

> stride: [tuple](https://docs.python.org/3/library/stdtypes.html#tuple)\[[int](https://docs.python.org/3/library/functions.html#int), [int](https://docs.python.org/3/library/functions.html#int), [int](https://docs.python.org/3/library/functions.html#int)]

Controls the stride for the cross-correlation.

## `Conv3DV1` {#max.nn.conv.Conv3DV1}

> class max.nn.conv.Conv3DV1(filter, bias=None, stride=(1, 1, 1), padding=(0, 0, 0, 0, 0, 0), dilation=(1, 1, 1), groups=1)

A 3D convolution over an input signal composed of several input
planes.

DEPRECATED: Use [`Conv3D`](#max.nn.conv.Conv3D) instead.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* filter (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])
* bias (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]] | None)
* stride ([int](https://docs.python.org/3/library/functions.html#int) | [tuple](https://docs.python.org/3/library/stdtypes.html#tuple)\[[int](https://docs.python.org/3/library/functions.html#int), [int](https://docs.python.org/3/library/functions.html#int), [int](https://docs.python.org/3/library/functions.html#int)])
* padding ([int](https://docs.python.org/3/library/functions.html#int) | [tuple](https://docs.python.org/3/library/stdtypes.html#tuple)\[[int](https://docs.python.org/3/library/functions.html#int), [int](https://docs.python.org/3/library/functions.html#int), [int](https://docs.python.org/3/library/functions.html#int), [int](https://docs.python.org/3/library/functions.html#int), [int](https://docs.python.org/3/library/functions.html#int), [int](https://docs.python.org/3/library/functions.html#int)])
* dilation ([int](https://docs.python.org/3/library/functions.html#int) | [tuple](https://docs.python.org/3/library/stdtypes.html#tuple)\[[int](https://docs.python.org/3/library/functions.html#int), [int](https://docs.python.org/3/library/functions.html#int), [int](https://docs.python.org/3/library/functions.html#int)])
* groups ([int](https://docs.python.org/3/library/functions.html#int))

</dd></dl>

### `bias` {#max.nn.conv.Conv3DV1.bias}

> bias: Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]] | [None](https://docs.python.org/3/library/constants.html#None) = None

### `dilation` {#max.nn.conv.Conv3DV1.dilation}

> dilation: [int](https://docs.python.org/3/library/functions.html#int) | [tuple](https://docs.python.org/3/library/stdtypes.html#tuple)\[[int](https://docs.python.org/3/library/functions.html#int), [int](https://docs.python.org/3/library/functions.html#int), [int](https://docs.python.org/3/library/functions.html#int)] = (1, 1, 1)

### `filter` {#max.nn.conv.Conv3DV1.filter}

> filter: Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]]

### `groups` {#max.nn.conv.Conv3DV1.groups}

> groups: [int](https://docs.python.org/3/library/functions.html#int) = 1

### `padding` {#max.nn.conv.Conv3DV1.padding}

> padding: [int](https://docs.python.org/3/library/functions.html#int) | [tuple](https://docs.python.org/3/library/stdtypes.html#tuple)\[[int](https://docs.python.org/3/library/functions.html#int), [int](https://docs.python.org/3/library/functions.html#int), [int](https://docs.python.org/3/library/functions.html#int), [int](https://docs.python.org/3/library/functions.html#int), [int](https://docs.python.org/3/library/functions.html#int), [int](https://docs.python.org/3/library/functions.html#int)] = (0, 0, 0, 0, 0, 0)

### `stride` {#max.nn.conv.Conv3DV1.stride}

> stride: [int](https://docs.python.org/3/library/functions.html#int) | [tuple](https://docs.python.org/3/library/stdtypes.html#tuple)\[[int](https://docs.python.org/3/library/functions.html#int), [int](https://docs.python.org/3/library/functions.html#int), [int](https://docs.python.org/3/library/functions.html#int)] = (1, 1, 1)

---

## embedding

The `embedding` module provides classes for mapping integer indices (like
token IDs) to dense vector representations. These embedding operations are
fundamental building blocks for natural language processing, recommendation
systems, and other tasks involving discrete tokens.

* `Embedding`: Basic embedding lookup table for simple use cases
* `EmbeddingV2`: Enhanced embedding with device placement control and improved memory management
* `VocabParallelEmbedding`: Distributed embedding that shards the vocabulary across multiple devices for large embedding tables

Hereâ€™s an example demonstrating how to use embeddings:

```python
import max.nn as nn
from max.graph import Graph, ops, DeviceRef
from max.dtype import DType
import numpy as np

with Graph(name="embedding_example") as graph:
    # Define dimensions
    batch_size = 4
    seq_length = 16
    vocab_size = 10000
    hidden_dim = 256

    # Create input tensor of token indices
    input_data = np.random.randint(0, vocab_size, (batch_size, seq_length), dtype=np.int32)
    input_indices = ops.constant(input_data, dtype=DType.int32, device=DeviceRef.CPU())

    # Create embedding layer
    embedding = nn.EmbeddingV2(
        vocab_size=vocab_size,
        hidden_dim=hidden_dim,
        dtype=DType.float32,
        device=DeviceRef.GPU(),
        name="token_embeddings"
    )

    # Look up embeddings for input indices
    embeddings = embedding(input_indices)
    print(f"Embedding output shape: {embeddings.shape}")
    # Embedding output shape: [Dim(4), Dim(16), Dim(256)]
```

## `Embedding` {#max.nn.embedding.Embedding}

> class max.nn.embedding.Embedding(vocab\_size, hidden\_dim, dtype, device, quantization\_encoding=None, name=None)

A lookup table for embedding integer indices into dense vectors.

This layer maps each integer index to a dense vector of fixed size.
Embedding weights are stored on the CPU but are moved to the specified
device during the model init phase.

Example:

```python
embedding_layer = Embedding(
    vocab_size=1000,
    hidden_dim=256,
    dtype=DType.float32,
    device=DeviceRef.GPU(),
    name="embeddings",
)

token_indices: TensorValueLike
embeddings = embedding_layer(token_indices)
```

Initializes the embedding layer with the given arguments.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* vocab\_size ([int](https://docs.python.org/3/library/functions.html#int)) â€“ The number of unique items in the vocabulary.
  Indices must be in the range `[0, vocab_size)`.
* hidden\_dim ([int](https://docs.python.org/3/library/functions.html#int)) â€“ The dimensionality of each embedding vector.
* dtype ([DType](../dtype.md#max.dtype.DType)) â€“ The data type of the embedding weights.
* device ([DeviceRef](../graph/type.md#max.graph.type.DeviceRef)) â€“ The device where embedding lookups are executed.
  Model init transfers the initially CPU-resident weights to this
  device.
* name (Optional\[[str](https://docs.python.org/3/library/stdtypes.html#str)]) â€“ The name identifier for the embedding weight matrix.
* quantization\_encoding (Optional\[[QuantizationEncoding](../graph/quantization.md#max.graph.quantization.QuantizationEncoding)])

</dd></dl>

### `device` {#max.nn.embedding.Embedding.device}

> device: [DeviceRef](../graph/type.md#max.graph.type.DeviceRef)

The device on which embedding lookup is performed.

### `weight` {#max.nn.embedding.Embedding.weight}

> weight: [Weight](../graph/Weight.md#max.graph.Weight)

The embedding weight matrix stored on the CPU.
Model init moves weights to the device specified in [`device`](#max.nn.embedding.Embedding.device).

## `EmbeddingV1` {#max.nn.embedding.EmbeddingV1}

> class max.nn.embedding.EmbeddingV1(weights, device)

A lookup table for embedding integer indices into dense vectors.

Deprecated: Use Embedding instead.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* weights (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])
* device ([DeviceRef](../graph/type.md#max.graph.type.DeviceRef))

</dd></dl>

### `device` {#max.nn.embedding.EmbeddingV1.device}

> device: [DeviceRef](../graph/type.md#max.graph.type.DeviceRef)

### `weights` {#max.nn.embedding.EmbeddingV1.weights}

> weights: Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]]

## `VocabParallelEmbedding` {#max.nn.embedding.VocabParallelEmbedding}

> class max.nn.embedding.VocabParallelEmbedding(vocab\_size, hidden\_dim, dtype, devices, quantization\_encoding=None, name=None)

A lookup table for embedding integer indices into dense vectors.

This layer works like nn.Embedding except the embedding table is sharded
on the vocabulary dimension across all devices.

Example:

```python
embedding_layer = VocabParallelEmbedding(
    vocab_size=1000,
    hidden_dim=256,
    dtype=DType.float32,
    device=[DeviceRef.GPU(0), DeviceRef.GPU(1)],
    name="embeddings",
)

# Token indices of shape: [batch, ..., num_indices].
token_indices: TensorValueLike
embeddings = embedding_layer(token_indices)
```

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* vocab\_size ([int](https://docs.python.org/3/library/functions.html#int)) â€“ The number of unique items in the vocabulary.
  Indices must be in the range `[0, vocab_size)`.
* hidden\_dim ([int](https://docs.python.org/3/library/functions.html#int)) â€“ The dimensionality of each embedding vector.
* dtype ([DType](../dtype.md#max.dtype.DType)) â€“ The data type of the embedding weights.
* devices ([list](https://docs.python.org/3/library/stdtypes.html#list)\[[DeviceRef](../graph/type.md#max.graph.type.DeviceRef)]) â€“ The devices where embedding lookups are executed.
  Model init transfers the initially CPU-resident weights to this
  device.
* name (Optional\[[str](https://docs.python.org/3/library/stdtypes.html#str)]) â€“ The name identifier for the embedding weight matrix.
* quantization\_encoding (Optional\[[QuantizationEncoding](../graph/quantization.md#max.graph.quantization.QuantizationEncoding)])

</dd></dl>

---

## nn

APIs to build neural network components for deep learning models with Python.

## Modules

* [`conv`](/max/api/python/nn/conv)
* [`embedding`](/max/api/python/nn/embedding)
* [`kernels`](/max/api/python/nn/kernels)
* [`layer`](/max/api/python/nn/layer)
* [`linear`](/max/api/python/nn/linear)
* [`rotary_embedding`](/max/api/python/nn/rotary_embedding)
* [`sequential`](/max/api/python/nn/sequential)

## Packages

* [`attention`](/max/api/python/nn/attention)
* [`norm`](/max/api/python/nn/norm)
* [`transformer`](/max/api/python/nn/transformer)
* [`kv_cache`](/max/api/python/nn/kv_cache)

---

## kernels

Helper functions for wrapping custom kv cache/attention related ops.

## `apply_penalties_to_logits()` {#max.nn.kernels.apply_penalties_to_logits}

> max.nn.kernels.apply\_penalties\_to\_logits(logits\_buffer, frequency\_data, frequency\_offsets, \*, frequency\_penalty=0.0, presence\_penalty=0.0, repetition\_penalty=1.0)

Applies penalties to the logits.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* logits\_buffer ([BufferValue](../graph/BufferValue.md#max.graph.BufferValue)) â€“ The buffer to apply penalties to.
* frequency\_data ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue)) â€“ 2d tensor of shape \[unique\_tokens, 2], where
  the first column indicates the token id and the second column
  indicates the frequency of the token.
* frequency\_offsets ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue)) â€“ 1d tensor of shape \[batch\_size + 1], indicating
  start of each sequenceâ€™s data.
* frequency\_penalty (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]]) â€“ The frequency penalty to apply to the modelâ€™s output.
  A positive value will penalize new tokens based on their frequency
  in the generated text: tokens will receive a penalty proportional
  to the count of appearances.
* presence\_penalty (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]]) â€“ The presence penalty to apply to the modelâ€™s output
  A positive value will penalize new tokens that have already appeared
  in the generated text at least once by applying a constant penalty.
* repetition\_penalty (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]]) â€“ The repetition penalty to apply to the modelâ€™s
  output. Values > 1 will penalize new tokens that have already
  appeared in prompt and generated text at least once by dividing the
  logits by the repetition penalty.

</dd><dt>

**Return type:**

</dt><dd>

None

</dd></dl>

## `convert_weights_to_fp8_fnuz_if_needed()` {#max.nn.kernels.convert_weights_to_fp8_fnuz_if_needed}

> max.nn.kernels.convert\_weights\_to\_fp8\_fnuz\_if\_needed(weight, weight\_scale)

Convert weights and scales to FP8 FNUZ format if needed for AMD GPUs.

This utility function checks if FP8 FNUZ conversion is needed, currently onli AMD MI300 GPUs,
and performs the conversion if required. This centralizes the conversion logic
that was previously duplicated across multiple files.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* weight ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue)) â€“ The weight tensor to potentially convert.
* weight\_scale ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue)) â€“ The weight scale factor.

</dd><dt>

**Returns:**

</dt><dd>

Tuple of (weight, weight\_scale) - converted if needed, original otherwise.

</dd><dt>

**Return type:**

</dt><dd>

[tuple](https://docs.python.org/3/library/stdtypes.html#tuple)\[[TensorValue](../graph/TensorValue.md#max.graph.TensorValue), [TensorValue](../graph/TensorValue.md#max.graph.TensorValue)]

</dd></dl>

## `cross_attention_ragged()` {#max.nn.kernels.cross_attention_ragged}

> max.nn.kernels.cross\_attention\_ragged(kv\_params, input, input\_row\_offsets, kv\_collection, layer\_idx, mask\_variant, kv\_input\_row\_offsets, q\_max\_seq\_len, scale, local\_window\_size=-1)

Computes cross attention provided the !mo.opaque KV Cache.

Notably, this materializes the attention mask (dependent on MHAMaskVariant)
within the kernel.
input and input\_row\_offsets are used together to implement the ragged
tensor.
input\_row\_offsets indicates where each batch starts and ends in input

attention, kv\_input\_row\_offsets represents the KV sequence length.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* kv\_params ([KVCacheParams](kv_cache/cache_params.md#max.nn.kv_cache.cache_params.KVCacheParams))
* input ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue))
* input\_row\_offsets ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue))
* kv\_collection (PagedKVCacheCollection)
* layer\_idx ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue))
* mask\_variant (MHAMaskVariant)
* kv\_input\_row\_offsets ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue))
* q\_max\_seq\_len ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue))
* scale ([float](https://docs.python.org/3/library/functions.html#float))
* local\_window\_size ([int](https://docs.python.org/3/library/functions.html#int))

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](../graph/TensorValue.md#max.graph.TensorValue)

</dd></dl>

## `dynamic_scaled_matmul()` {#max.nn.kernels.dynamic_scaled_matmul}

> max.nn.kernels.dynamic\_scaled\_matmul(a, b, a\_scales, b\_scales, input\_scale\_spec, weight\_scale\_spec, out\_type=bfloat16)

Perform a matmul of two tensors with scaling factors. Currently only
supports channel-wise scaling for weights and per-token scaling for inputs.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* a ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue)) â€“ The first tensor to multiply.
* b ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue)) â€“ The second tensor to multiply, must be transposed.
* a\_scales ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue)) â€“ The scaling factors for the first tensor.
* b\_scales ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue)) â€“ The scaling factors for the second tensor.
* input\_scale\_spec (Float8InputScaleSpec)
* weight\_scale\_spec (Float8WeightScaleSpec)
* out\_type ([DType](../dtype.md#max.dtype.DType))

</dd><dt>

**Returns:**

</dt><dd>

The result of the matmul operation.

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](../graph/TensorValue.md#max.graph.TensorValue)

</dd></dl>

## `flare_mla_decode_ragged()` {#max.nn.kernels.flare_mla_decode_ragged}

> max.nn.kernels.flare\_mla\_decode\_ragged(kv\_params, input, input\_row\_offsets, kv\_collection, layer\_idx, mask\_variant, scale, qk\_rope\_dim=64)

Computes flash (self) attention provided the !mo.opaque KV Cache.

Notably, this materializes the attention mask (dependent on MHAMaskVariant)
within the kernel.
input and input\_row\_offsets are used together to implement the ragged
tensor.
input\_row\_offsets indicates where each batch starts and ends in input

Note that this is self attention and the KV sequence length is
assumed to be equal to the Q sequence length.
For KV sequence length != Q sequence length, use cross\_attention\_ragged.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* kv\_params ([KVCacheParams](kv_cache/cache_params.md#max.nn.kv_cache.cache_params.KVCacheParams))
* input ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue))
* input\_row\_offsets ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue))
* kv\_collection (PagedKVCacheCollection)
* layer\_idx ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue))
* mask\_variant (MHAMaskVariant)
* scale ([float](https://docs.python.org/3/library/functions.html#float))
* qk\_rope\_dim ([int](https://docs.python.org/3/library/functions.html#int))

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](../graph/TensorValue.md#max.graph.TensorValue)

</dd></dl>

## `flare_mla_decompress_k_cache()` {#max.nn.kernels.flare_mla_decompress_k_cache}

> max.nn.kernels.flare\_mla\_decompress\_k\_cache(kv\_params, buffer\_row\_offsets\_1d, cache\_offsets\_1d, buffer\_length, weight, kv\_collection, layer\_idx, buffer\_size)

This kernel decompresses the key cache by up-projecting latent representations
into the KV space using a weight matrix.

The process involves:
: 1. Copying buffer\_length latent vectors from the key cache into a contiguous
buffer (k\_latent)
2\. Computing k = k\_latent @ weight.T to obtain the decompressed keys

<dl class='field-list'><dt>

**Returns:**

</dt><dd>

A tensor of shape \[buffer\_size, weight.shape\[0]] containing the decompressed
keys. Note that only the first buffer\_length tokens are valid.

</dd><dt>

**Parameters:**

</dt><dd>

* kv\_params ([KVCacheParams](kv_cache/cache_params.md#max.nn.kv_cache.cache_params.KVCacheParams))
* buffer\_row\_offsets\_1d ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue))
* cache\_offsets\_1d ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue))
* buffer\_length ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue))
* weight ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue))
* kv\_collection (PagedKVCacheCollection)
* layer\_idx ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue))
* buffer\_size ([int](https://docs.python.org/3/library/functions.html#int))

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](../graph/TensorValue.md#max.graph.TensorValue)

</dd></dl>

## `flare_mla_prefill_plan()` {#max.nn.kernels.flare_mla_prefill_plan}

> max.nn.kernels.flare\_mla\_prefill\_plan(kv\_params, input\_row\_offsets, kv\_collection, layer\_idx, buffer\_size, max\_chunks=16)

This kernel plans how to process a batch of sequences with
varying lengths using a fixed-size buffer.

Each sequence in the batch has some existing cached tokens and new input
tokens. The kernel divides the total tokens into chunks of buffer\_size.

For each chunk (iteration), it calculates:
: 1. Buffer offsets for each sequence in each chunk
2\. Cache offsets for each sequence in each chunk
3\. Total buffer lengths for each processing iteration

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* kv\_params ([KVCacheParams](kv_cache/cache_params.md#max.nn.kv_cache.cache_params.KVCacheParams))
* input\_row\_offsets ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue))
* kv\_collection (PagedKVCacheCollection)
* layer\_idx ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue))
* buffer\_size ([int](https://docs.python.org/3/library/functions.html#int))
* max\_chunks ([int](https://docs.python.org/3/library/functions.html#int))

</dd><dt>

**Return type:**

</dt><dd>

[tuple](https://docs.python.org/3/library/stdtypes.html#tuple)\[[TensorValue](../graph/TensorValue.md#max.graph.TensorValue), [TensorValue](../graph/TensorValue.md#max.graph.TensorValue), [TensorValue](../graph/TensorValue.md#max.graph.TensorValue)]

</dd></dl>

## `flare_mla_prefill_ragged()` {#max.nn.kernels.flare_mla_prefill_ragged}

> max.nn.kernels.flare\_mla\_prefill\_ragged(kv\_params, input, k, v, input\_row\_offsets, buffer\_row\_offsets, cache\_offsets, kv\_collection, layer\_idx, mask\_variant, scale, qk\_rope\_dim=64, prev\_output=None, prev\_softmax\_info=None)

Performs MLA prefill. In the MLA prefill, we need to decompress
the KV tensors, as we store the latent representations in the KV cache.
We will decompress the KV tensors into a fixed size buffer to avoid
out-of-memory errors. In case the total cache length is greater than
the buffer size, we will process the attention calculation in chunks.

This MLA prefill kernel will return the output tensor for this iteration
and the softmax info tensor for this iteration. Such tensors will be used
by the next iteration of the MLA prefill kernel to continue the attention
calculation.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* kv\_params ([KVCacheParams](kv_cache/cache_params.md#max.nn.kv_cache.cache_params.KVCacheParams)) â€“ KVCacheParams
* input ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue)) â€“ Input tensor
* k ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue)) â€“ Key tensor
* v ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue)) â€“ Value tensor
* input\_row\_offsets ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue)) â€“ Indicates where each batch starts and ends in input
* buffer\_row\_offsets ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue)) â€“ Indicates where each batch starts and ends in the buffer
* cache\_offsets ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue)) â€“ Indicates where each batch starts and ends in the KV cache
* kv\_collection (PagedKVCacheCollection) â€“ KV collection
* layer\_idx ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue)) â€“ Layer index tensor
* mask\_variant (MHAMaskVariant) â€“ Mask variant
* scale ([float](https://docs.python.org/3/library/functions.html#float)) â€“ Scale
* qk\_rope\_dim ([int](https://docs.python.org/3/library/functions.html#int)) â€“ QK rope dimension
* prev\_output ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | None) â€“ Optional. Previous output tensor
* prev\_softmax\_info ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | None) â€“ Optional. Previous softmax info tensor

</dd><dt>

**Returns:**

</dt><dd>

* The first tensor is the output tensor for this iteration
* The second tensor is the softmax info tensor for this iteration

</dd><dt>

**Return type:**

</dt><dd>

A tuple of two tensors

</dd></dl>

## `flash_attention_gpu()` {#max.nn.kernels.flash_attention_gpu}

> max.nn.kernels.flash\_attention\_gpu(q, k, v, mask\_variant, scale, local\_window\_size=-1, valid\_length=None)

Computes flash attention using GPU-optimized kernel.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* q ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue)) â€“ Query tensor of shape \[batch, seq\_len, num\_heads, head\_dim]
* k ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue)) â€“ Key tensor of shape \[batch, seq\_len, num\_heads, head\_dim]
* v ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue)) â€“ Value tensor of shape \[batch, seq\_len, num\_heads, head\_dim]
* mask\_variant (MHAMaskVariant) â€“ The mask variant to use for attention
* scale ([float](https://docs.python.org/3/library/functions.html#float)) â€“ Scaling factor for attention scores
* local\_window\_size ([int](https://docs.python.org/3/library/functions.html#int)) â€“ Local window size for sliding window attention
* valid\_length ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | None) â€“ Optional tensor of shape \[batch] with dtype uint32.
  When provided, uses the padded kernel variant that respects
  the valid sequence lengths for each batch element.

</dd><dt>

**Returns:**

</dt><dd>

Output tensor of shape \[batch, seq\_len, num\_heads, head\_dim]

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](../graph/TensorValue.md#max.graph.TensorValue)

</dd></dl>

## `flash_attention_ragged()` {#max.nn.kernels.flash_attention_ragged}

> max.nn.kernels.flash\_attention\_ragged(kv\_params, input, input\_row\_offsets, kv\_collection, layer\_idx, mask\_variant, scale, local\_window\_size=-1, sink\_weights=None)

Computes flash (self) attention provided the !mo.opaque KV Cache.

Notably, this materializes the attention mask (dependent on MHAMaskVariant)
within the kernel.
input and input\_row\_offsets are used together to implement the ragged
tensor.
input\_row\_offsets indicates where each batch starts and ends in input

Note that this is self attention and the KV sequence length is
assumed to be equal to the Q sequence length.
For KV sequence length != Q sequence length, use cross\_attention\_ragged.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* kv\_params ([KVCacheParams](kv_cache/cache_params.md#max.nn.kv_cache.cache_params.KVCacheParams)) â€“ KVCacheParams object containing key-value cache parameters.
* input ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue)) â€“ TensorValue representing the input tensor with shape \[total\_seq\_len, hidden\_dim].
* input\_row\_offsets ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue)) â€“ TensorValue indicating the start and end of each batch in the input tensor with shape \[batch\_size + 1].
* kv\_collection (PagedKVCacheCollection) â€“ PagedKVCacheCollection object for managing key-value cache.
* layer\_idx ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue)) â€“ TensorValue representing the layer index, expected to have dtype uint32.
* mask\_variant (MHAMaskVariant) â€“ MHAMaskVariant specifying the type of attention mask to use.
* scale ([float](https://docs.python.org/3/library/functions.html#float)) â€“ float value used to scale the attention scores.
* local\_window\_size ([int](https://docs.python.org/3/library/functions.html#int)) â€“ int specifying the size of the local attention window, default is -1 for no local window.
* sink\_weights ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | None) â€“ Optional tensor of shape \[num\_heads] containing learnable sink weights for each attention head.

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](../graph/TensorValue.md#max.graph.TensorValue)

</dd></dl>

## `flash_attention_ragged_gpu()` {#max.nn.kernels.flash_attention_ragged_gpu}

> max.nn.kernels.flash\_attention\_ragged\_gpu(q, k, v, input\_row\_offsets, max\_seq\_len, mask\_variant, scale, local\_window\_size=-1)

Computes flash attention for ragged inputs using GPU-optimized kernel
without a KV cache.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* q ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue)) â€“ Query tensor of shape \[total\_seq\_len, num\_heads, head\_dim] (ragged)
* k ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue)) â€“ Key tensor of shape \[total\_seq\_len, num\_heads, head\_dim] (ragged)
* v ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue)) â€“ Value tensor of shape \[total\_seq\_len, num\_heads, head\_dim] (ragged)
* input\_row\_offsets ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue)) â€“ Tensor of shape \[batch\_size + 1] with dtype uint32.
  Indicates where each sequence starts and ends in the ragged tensors.
  The values should be a prefix sum (cumulative sum) of sequence lengths.
* mask\_variant (MHAMaskVariant) â€“ The mask variant to use for attention
* scale ([float](https://docs.python.org/3/library/functions.html#float)) â€“ Scaling factor for attention scores
* local\_window\_size ([int](https://docs.python.org/3/library/functions.html#int)) â€“ Local window size for sliding window attention
* max\_seq\_len ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue))

</dd><dt>

**Returns:**

</dt><dd>

Output tensor of shape \[total\_seq\_len, num\_heads, head\_dim]

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](../graph/TensorValue.md#max.graph.TensorValue)

</dd></dl>

## `fused_qk_ragged_rope()` {#max.nn.kernels.fused_qk_ragged_rope}

> max.nn.kernels.fused\_qk\_ragged\_rope(kv\_params, input, input\_row\_offsets, kv\_collection, freqs\_cis, layer\_idx, interleaved=True, position\_ids=None, mrope\_section=None)

Computes fused query-key attention with rotary positional encodings and ragged inputs.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* kv\_params ([KVCacheParams](kv_cache/cache_params.md#max.nn.kv_cache.cache_params.KVCacheParams)) â€“ KV cache parameters
* input ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue)) â€“ \[batch\_size \* seq\_len, n\_heads, head\_dim]
* input\_row\_offsets ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue)) â€“ Ragged tensor offsets indicating where each batch starts and ends
* kv\_collection (PagedKVCacheCollection) â€“ KV cache collection
* freqs\_cis ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue)) â€“ tensor of shape (max\_seq\_len \* 2, head\_dim)
* layer\_idx ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue)) â€“ Layer index for KV cache
* interleaved ([bool](https://docs.python.org/3/library/functions.html#bool)) â€“ Whether to use interleaved RoPE pattern
* position\_ids ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | None) â€“ Optional ragged 2D array of position IDs. If None, defaults to
  cache\_length + token\_idx for each token. When num\_sections > 1,
  mrope\_section must be provided to indicate each section of the head\_dim
  to apply RoPE to. Shape: [num\_sections, total\_seq\_len]
* mrope\_section ([list](https://docs.python.org/3/library/stdtypes.html#list)\[[int](https://docs.python.org/3/library/functions.html#int)] | None) â€“ Optional list of integers indicating the section of the head\_dim to
* position\_ids. (apply RoPE to. Must be used in conjunction with)

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](../graph/TensorValue.md#max.graph.TensorValue)

</dd></dl>

input and input\_row\_offsets are used together to implement the ragged tensor.
input\_row\_offsets indicates where each batch starts and ends in input. If input
is not of the same dtype as freqs\_cis, it will be cast to the dtype of freqs\_cis
for the computation, and cast back to the original dtype after the computation is
finished.

When position\_ids and mrope\_section are provided, it replaces the default position
calculation (cache\_length + token\_idx) with explicit position values. This is useful for
3D RoPE in models like Qwen2.5-VL that need custom position encoding.

## `fused_qkv_ragged_matmul()` {#max.nn.kernels.fused_qkv_ragged_matmul}

> max.nn.kernels.fused\_qkv\_ragged\_matmul(kv\_params, input, input\_row\_offsets, wqkv, kv\_collection, layer\_idx, n\_heads, bias=None)

Computes fused query, key, and value projections with ragged input.

input and input\_row\_offsets are used together to implement the ragged
tensor.
input\_row\_offsets indicates where each batch starts and ends in input

<dl class='field-list'><dt>

**Raises:**

</dt><dd>

[ValueError](https://docs.python.org/3/library/exceptions.html#ValueError) â€“ on input shapes/dtypes that are invalid for the kernel.

</dd><dt>

**Parameters:**

</dt><dd>

* kv\_params ([KVCacheParams](kv_cache/cache_params.md#max.nn.kv_cache.cache_params.KVCacheParams))
* input ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue))
* input\_row\_offsets ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue))
* wqkv ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue))
* kv\_collection (PagedKVCacheCollection)
* layer\_idx ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue))
* n\_heads ([int](https://docs.python.org/3/library/functions.html#int))
* bias ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | None)

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](../graph/TensorValue.md#max.graph.TensorValue)

</dd></dl>

## `fused_qkv_ragged_matmul_quantized()` {#max.nn.kernels.fused_qkv_ragged_matmul_quantized}

> max.nn.kernels.fused\_qkv\_ragged\_matmul\_quantized(kv\_params, input, input\_row\_offsets, wqkv, kv\_collection, layer\_idx, n\_heads, quantization\_config, perm\_idx=None, bias=None)

Computes fused query, key, and value projections with ragged input and
quantized weight matrices. A quantization\_config must be provided.

input and input\_row\_offsets are used together to implement the ragged
tensor.
input\_row\_offsets indicates where each batch starts and ends in input

<dl class='field-list'><dt>

**Raises:**

</dt><dd>

[ValueError](https://docs.python.org/3/library/exceptions.html#ValueError) â€“ on input shapes/dtypes that are invalid for the kernel.

</dd><dt>

**Parameters:**

</dt><dd>

* kv\_params ([KVCacheParams](kv_cache/cache_params.md#max.nn.kv_cache.cache_params.KVCacheParams))
* input ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue))
* input\_row\_offsets ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue))
* wqkv ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue))
* kv\_collection (PagedKVCacheCollection)
* layer\_idx ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue))
* n\_heads ([int](https://docs.python.org/3/library/functions.html#int))
* quantization\_config ([QuantizationConfig](../graph/quantization.md#max.graph.quantization.QuantizationConfig))
* perm\_idx ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | None)
* bias ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | None)

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](../graph/TensorValue.md#max.graph.TensorValue)

</dd></dl>

## `fused_qkv_ragged_matmul_scaled_float8()` {#max.nn.kernels.fused_qkv_ragged_matmul_scaled_float8}

> max.nn.kernels.fused\_qkv\_ragged\_matmul\_scaled\_float8(kv\_params, input, input\_row\_offsets, wqkv, kv\_collection, layer\_idx, n\_heads, input\_scale, weight\_scale, bias=None)

Computes fused query, key, and value projections with ragged input.

input and input\_row\_offsets are used together to implement the ragged
tensor.
input\_row\_offsets indicates where each batch starts and ends in input

<dl class='field-list'><dt>

**Raises:**

</dt><dd>

[ValueError](https://docs.python.org/3/library/exceptions.html#ValueError) â€“ on input shapes/dtypes that are invalid for the kernel.

</dd><dt>

**Parameters:**

</dt><dd>

* kv\_params ([KVCacheParams](kv_cache/cache_params.md#max.nn.kv_cache.cache_params.KVCacheParams))
* input ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue))
* input\_row\_offsets ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue))
* wqkv ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue))
* kv\_collection (PagedKVCacheCollection)
* layer\_idx ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue))
* n\_heads ([int](https://docs.python.org/3/library/functions.html#int))
* input\_scale ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue))
* weight\_scale ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue))
* bias ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | None)

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](../graph/TensorValue.md#max.graph.TensorValue)

</dd></dl>

## `grouped_matmul_ragged()` {#max.nn.kernels.grouped_matmul_ragged}

> max.nn.kernels.grouped\_matmul\_ragged(hidden\_states, weight, expert\_start\_indices, expert\_ids, expert\_usage\_stats\_host)

Grouped matmul used in MoE layer.

hidden\_states and expert\_start\_indices are used together to implement
the ragged tensor. expert\_start\_indices indicates where each group starts
and ends in hidden\_states

expert\_ids is the id of the expert for each group in hidden\_states

expert\_usage\_stats\_host is the maximum number of tokens assigned to any
expert, and the number of active experts.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* hidden\_states ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue))
* weight ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue))
* expert\_start\_indices ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue))
* expert\_ids ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue))
* expert\_usage\_stats\_host ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue))

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](../graph/TensorValue.md#max.graph.TensorValue)

</dd></dl>

## `kv_cache_get_max_seq_len()` {#max.nn.kernels.kv_cache_get_max_seq_len}

> max.nn.kernels.kv\_cache\_get\_max\_seq\_len(kv\_params, kv\_collection)

This kernel returns the maximum sequence length.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* kv\_params ([KVCacheParams](kv_cache/cache_params.md#max.nn.kv_cache.cache_params.KVCacheParams))
* kv\_collection (PagedKVCacheCollection)

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](../graph/TensorValue.md#max.graph.TensorValue)

</dd></dl>

## `kv_cache_ragged_radd()` {#max.nn.kernels.kv_cache_ragged_radd}

> max.nn.kernels.kv\_cache\_ragged\_radd(kv\_params, a, kv\_collection, input\_row\_offsets, batch\_offset, layer\_idx)

This function adds a tensor to a slice of the KVCache, sliced on the batch dimension.

This expects that the requests which should be sliced out are contiguous and
in the front of the tensor, and weâ€™re only adding to the last requests in the batch
:param a: The tensor to add to the KVCache.
:param kv\_collection: The KVCache collection to add to.
:param input\_row\_offsets: The offsets of the input tensor.
:param batch\_offset: The batch to start applying the r-add to.
:param layer\_idx: The layer index to add to.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* kv\_params ([KVCacheParams](kv_cache/cache_params.md#max.nn.kv_cache.cache_params.KVCacheParams))
* a ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue))
* kv\_collection (PagedKVCacheCollection)
* input\_row\_offsets ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue))
* batch\_offset ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue))
* layer\_idx ([int](https://docs.python.org/3/library/functions.html#int))

</dd><dt>

**Return type:**

</dt><dd>

None

</dd></dl>

## `matmul_k_cache_ragged()` {#max.nn.kernels.matmul_k_cache_ragged}

> max.nn.kernels.matmul\_k\_cache\_ragged(kv\_params, hidden\_states, input\_row\_offsets, weight, kv\_collection, layer\_idx)

Computes key projections with ragged input.

hidden\_states and input\_row\_offsets are used together to
implement the ragged tensor.
input\_row\_offsets indicates where each batch starts and ends in input

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* kv\_params ([KVCacheParams](kv_cache/cache_params.md#max.nn.kv_cache.cache_params.KVCacheParams))
* hidden\_states ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue))
* input\_row\_offsets ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue))
* weight ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue))
* kv\_collection (PagedKVCacheCollection)
* layer\_idx ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue))

</dd><dt>

**Return type:**

</dt><dd>

None

</dd></dl>

## `matmul_kv_cache_ragged()` {#max.nn.kernels.matmul_kv_cache_ragged}

> max.nn.kernels.matmul\_kv\_cache\_ragged(kv\_params, hidden\_states, input\_row\_offsets, weight, kv\_collection, layer\_idx)

Computes key and value projections with ragged input.

hidden\_states and input\_row\_offsets are used together to
implement the ragged tensor.
input\_row\_offsets indicates where each batch starts and ends in input

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* kv\_params ([KVCacheParams](kv_cache/cache_params.md#max.nn.kv_cache.cache_params.KVCacheParams))
* hidden\_states ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue))
* input\_row\_offsets ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue))
* weight ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue))
* kv\_collection (PagedKVCacheCollection)
* layer\_idx ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue))

</dd><dt>

**Return type:**

</dt><dd>

None

</dd></dl>

## `matmul_static_scaled_float8()` {#max.nn.kernels.matmul_static_scaled_float8}

> max.nn.kernels.matmul\_static\_scaled\_float8(input, weight, input\_scale, weight\_scale)

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* input ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue))
* weight ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue))
* input\_scale ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue))
* weight\_scale ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue))

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](../graph/TensorValue.md#max.graph.TensorValue)

</dd></dl>

## `merge_ragged_tensors()` {#max.nn.kernels.merge_ragged_tensors}

> max.nn.kernels.merge\_ragged\_tensors(a, a\_row\_offsets, b, b\_row\_offsets)

Merges two ragged tensors into a single ragged tensor.

Both ragged tensors must have the same batch size (same number of row
offsets). This function interleaves the rows from each tensor based on
their row offsets.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* a ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue)) â€“ The first ragged tensor of shape \[total\_a\_rows, â€¦].
* a\_row\_offsets ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue)) â€“ The row offsets of the first ragged tensor,indicating
  where each batch starts and ends in a.
* b ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue)) â€“ The second ragged tensor of shape \[total\_b\_rows, â€¦].
* b\_row\_offsets ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue)) â€“ The row offsets of the second ragged tensor, indicating
  where each batch starts and ends in b.

</dd><dt>

**Returns:**

</dt><dd>

* The merged ragged tensor with shape
  \[total\_a\_rows + total\_b\_rows, â€¦].
* The merged row offsets with the same shape as input row offsets.

</dd><dt>

**Return type:**

</dt><dd>

A tuple of two tensors

</dd></dl>

**Example:**

a = [1, 2, 3, 4, 5, 6]
a\_row\_offsets = [0, 2, 6]
b = [7, 8, 9, 10]
b\_row\_offsets = [0, 3, 4]

merged\_tensor, merged\_row\_offsets = merge\_ragged\_tensors(
: a, a\_row\_offsets, b, b\_row\_offsets)

merged\_tensor = [1, 2, 7, 8, 9, 3, 4, 5, 6, 10]
merged\_row\_offsets = [0, 5, 10]

## `moe_create_indices()` {#max.nn.kernels.moe_create_indices}

> max.nn.kernels.moe\_create\_indices(topk\_ids, num\_local\_experts)

Creates indices for the MoE layer.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* topk\_ids ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue)) â€“ The expert assignments for each token from the router.
* num\_local\_experts ([int](https://docs.python.org/3/library/functions.html#int)) â€“ The number of experts on this device.

</dd><dt>

**Returns:**

</dt><dd>

* token\_expert\_order: The reordered token indices, grouped by assigned expert.
* expert\_start\_indices: The starting index for each expertâ€™s token group in
  the reordered sequence.
* restore\_token\_order: The indices to restore original token ordering after
  expert computation.
* expert\_ids: ids of active experts selected for tokens
* expert\_usage\_stats: The maximum number of tokens assigned to any expert,
  and the number of active experts.

</dd><dt>

**Return type:**

</dt><dd>

A tuple of four tensors

</dd></dl>

## `needs_fp8_fnuz_conversion()` {#max.nn.kernels.needs_fp8_fnuz_conversion}

> max.nn.kernels.needs\_fp8\_fnuz\_conversion()

Check if we need to convert FP8 E4M3FN to FNUZ for AMD GPUs.

<dl class='field-list'><dt>

**Returns:**

</dt><dd>

True if running on AMD GPU with CDNA3 architecture, False otherwise.

</dd><dt>

**Return type:**

</dt><dd>

[bool](https://docs.python.org/3/library/functions.html#bool)

</dd></dl>

## `normalize_e4m3fn_to_e4m3fnuz()` {#max.nn.kernels.normalize_e4m3fn_to_e4m3fnuz}

> max.nn.kernels.normalize\_e4m3fn\_to\_e4m3fnuz(weight, weight\_scale)

Convert E4M3FN weights to E4M3FNUZ format for AMD GPUs.

This conversion is necessary because AMD GPUs use the E4M3FNUZ format
while NVIDIA GPUs use E4M3FN. The key differences are:

1. The bit pattern 10000000 (-128) represents zero in E4M3FN but NaN in E4M3FNUZ
2. For the same bit representation, E4M3FNUZ values are half of E4M3FN values

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* weight ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue)) â€“ The weight tensor in E4M3FN format.
* weight\_scale ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue)) â€“ The weight scale factor.

</dd><dt>

**Returns:**

</dt><dd>

Tuple of (converted\_weight, adjusted\_weight\_scale, adjusted\_input\_scale).

</dd><dt>

**Return type:**

</dt><dd>

[tuple](https://docs.python.org/3/library/stdtypes.html#tuple)\[[TensorValue](../graph/TensorValue.md#max.graph.TensorValue), [TensorValue](../graph/TensorValue.md#max.graph.TensorValue)]

</dd></dl>

## `quantize_dynamic_scaled_float8()` {#max.nn.kernels.quantize_dynamic_scaled_float8}

> max.nn.kernels.quantize\_dynamic\_scaled\_float8(input, input\_scale\_spec, weight\_scale\_spec, scale\_ub=1200.0, group\_size\_or\_per\_token=-1, out\_type=float8\_e4m3fn, scales\_type=bfloat16)

Dynamically quantize the input tensor to fp8.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* input ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue)) â€“ The input tensor to quantize.
* scale\_ub ([float](https://docs.python.org/3/library/functions.html#float)) â€“ The upper bound of the scale factor.
* group\_size\_or\_per\_token ([int](https://docs.python.org/3/library/functions.html#int)) â€“ The group size for quantization. When set to -1,
  the quantization is column-wise.
* out\_type ([DType](../dtype.md#max.dtype.DType)) â€“ The type of the output tensor.
* scales\_type ([DType](../dtype.md#max.dtype.DType)) â€“ The type of the scales tensor.
* input\_scale\_spec (Float8InputScaleSpec)
* weight\_scale\_spec (Float8WeightScaleSpec)

</dd><dt>

**Returns:**

</dt><dd>

The quantized tensor and the scales.

</dd><dt>

**Return type:**

</dt><dd>

[tuple](https://docs.python.org/3/library/stdtypes.html#tuple)\[[TensorValue](../graph/TensorValue.md#max.graph.TensorValue), [TensorValue](../graph/TensorValue.md#max.graph.TensorValue)]

</dd></dl>

## `quantize_static_scaled_float8()` {#max.nn.kernels.quantize_static_scaled_float8}

> max.nn.kernels.quantize\_static\_scaled\_float8(x, scale, scale\_is\_inverted=True, out\_type=float8\_e4m3fn)

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* x ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue))
* scale ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue))
* scale\_is\_inverted ([bool](https://docs.python.org/3/library/functions.html#bool))
* out\_type ([DType](../dtype.md#max.dtype.DType))

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](../graph/TensorValue.md#max.graph.TensorValue)

</dd></dl>

## `rms_norm_key_cache()` {#max.nn.kernels.rms_norm_key_cache}

> max.nn.kernels.rms\_norm\_key\_cache(kv\_params, kv\_collection, gamma, epsilon, layer\_idx, total\_seq\_len, input\_row\_offsets, weight\_offset, rms\_norm\_cols=None, multiply\_before\_cast=True, per\_head\_norm=True)

This function applies RMSNorm to the \_new\_ entries in the KVCache.

When per\_head\_norm=True (default), RMSNorm is applied separately to each head.
In this mode, gamma should have size \[head\_dim] and normalization occurs
across the head\_dim dimensions within each head.

When per\_head\_norm=False, RMSNorm is applied per token across all heads.
In this mode, gamma should have size \[n\_kv\_heads \* head\_dim] and normalization
occurs across all dimensions for each token.

The size of the gamma tensor determines how many dimensions will be normalized.
If gammaâ€™s size doesnâ€™t match the expected size based on per\_head\_norm setting,
rms\_norm\_cols must be explicitly specified to confirm the intention to normalize
only a subset of dimensions.

Currently, the KVCacheT class itself isnâ€™t aware of the new cache entries
until cache length increment, which happens after model forward.
So use input\_row\_offsets to do this bookkeeping.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* kv\_params ([KVCacheParams](kv_cache/cache_params.md#max.nn.kv_cache.cache_params.KVCacheParams))
* kv\_collection (PagedKVCacheCollection)
* gamma ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue))
* epsilon ([float](https://docs.python.org/3/library/functions.html#float) | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)])
* layer\_idx ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue))
* total\_seq\_len ([Dim](../graph/dim.md#max.graph.dim.Dim))
* input\_row\_offsets ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue))
* weight\_offset ([float](https://docs.python.org/3/library/functions.html#float) | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)])
* rms\_norm\_cols ([int](https://docs.python.org/3/library/functions.html#int) | None)
* multiply\_before\_cast ([bool](https://docs.python.org/3/library/functions.html#bool))
* per\_head\_norm ([bool](https://docs.python.org/3/library/functions.html#bool))

</dd><dt>

**Return type:**

</dt><dd>

None

</dd></dl>

## `scatter_set_constant()` {#max.nn.kernels.scatter_set_constant}

> max.nn.kernels.scatter\_set\_constant(data, indices, fill\_val)

Scatters values into a tensor at specified indices.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* data ([BufferValue](../graph/BufferValue.md#max.graph.BufferValue))
* indices ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue))
* fill\_val ([float](https://docs.python.org/3/library/functions.html#float))

</dd><dt>

**Return type:**

</dt><dd>

None

</dd></dl>

## `sgmv_kernel()` {#max.nn.kernels.sgmv_kernel}

> max.nn.kernels.sgmv\_kernel(input, lora, lora\_ids, lora\_ranks, input\_row\_offsets, max\_lora\_seq\_len, bias=None)

Performs the SGMV kernel for LoRA. This is LoRA agnostic, meaning that
we can perform LoRA A or B from this kernel call.
:param input: The input tensor
:param lora: The LoRA tensor
:param lora\_ids: Ids of the LoRAs used for each sequence
:param lora\_ranks: The ranks of the LoRAs ihn the batch
:param input\_row\_offsets: The sequence offsets that use LoRA
:param max\_lora\_seq\_len: The maximum sequence length of any given LoRA in the batch
:param bias: The LoRA bias

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* input ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue))
* lora ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue))
* lora\_ids ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue))
* lora\_ranks ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue))
* input\_row\_offsets ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue))
* max\_lora\_seq\_len ([int](https://docs.python.org/3/library/functions.html#int))
* bias ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | None)

</dd></dl>

## `sgmv_lora_kernel()` {#max.nn.kernels.sgmv_lora_kernel}

> max.nn.kernels.sgmv\_lora\_kernel(input, lora\_a, lora\_b, lora\_ids, lora\_ranks, grouped\_row\_offsets, max\_lora\_seq\_len, bias=None)

Computes the SGMV LoRA kernel for some number of LoRAs A and B given the input.

out = Wx + xAB

SGMV can be explained by two independent kernels:
: - shrink -> shrinks high-dimensional tensor to low-rank tensor

* expand -> expands low-rank tensor to high-dimensional tensor

where v = [0, â€¦] and y = (some output tensor)

SGMV-shrink:
: v += xA

SGMV-expand:
: y += vB

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* input ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue)) â€“ The input tensor
* lora\_a ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue)) â€“ The LoRA tensor for A
* lora\_b ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue)) â€“ The LoRA tensor for B
* lora\_ids ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue)) â€“ Ids of the LoRAs used for each sequence
* lora\_ranks ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue)) â€“ The ranks of the LoRAs ihn the batch
* grouped\_row\_offsets ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue)) â€“ The grouped sequence offsets that use LoRA
* max\_lora\_seq\_len ([int](https://docs.python.org/3/library/functions.html#int)) â€“ The maximum sequence length of any given LoRA in the batch
* bias ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | None) â€“ The LoRA bias

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](../graph/TensorValue.md#max.graph.TensorValue)

</dd></dl>

## `sgmv_qkv_lora_kernel()` {#max.nn.kernels.sgmv_qkv_lora_kernel}

> max.nn.kernels.sgmv\_qkv\_lora\_kernel(input, lora\_a, lora\_b, lora\_ids, lora\_ranks, input\_row\_offsets, lora\_grouped\_offsets, kv\_collection, kv\_params, layer\_idx, max\_lora\_seq\_len, max\_rank, q\_dim, kv\_dim, bias=None)

Computes the SGMV QKV LoRA kernel for Q, K, V projections with LoRA.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* input ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue)) â€“ The input tensor
* lora\_a ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue)) â€“ The LoRA tensor for A
* lora\_b ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue)) â€“ The LoRA tensor for B
* lora\_ids ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue)) â€“ Ids of the LoRAs used for each sequence
* lora\_ranks ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue)) â€“ The ranks of the LoRAs ihn the batch
* input\_row\_offsets ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue)) â€“ The sequence offsets that use LoRA
* kv\_collection (PagedKVCacheCollection) â€“ The KV cache
* kv\_params ([KVCacheParams](kv_cache/cache_params.md#max.nn.kv_cache.cache_params.KVCacheParams)) â€“ The KV params
* layer\_idx ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue)) â€“ The layer index to retrieve the KV cache
* max\_lora\_seq\_len ([int](https://docs.python.org/3/library/functions.html#int)) â€“ The maximum sequence length of any given LoRA in the batch
* max\_rank ([int](https://docs.python.org/3/library/functions.html#int)) â€“ The maximum rank for the LoRAs
* q\_dim ([int](https://docs.python.org/3/library/functions.html#int)) â€“ The q dimension
* kv\_dim ([int](https://docs.python.org/3/library/functions.html#int)) â€“ The kv dimension
* bias ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | None) â€“ Optional LoRA bias
* lora\_grouped\_offsets ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue))

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](../graph/TensorValue.md#max.graph.TensorValue)

</dd></dl>

## `swish_glu()` {#max.nn.kernels.swish_glu}

> max.nn.kernels.swish\_glu(a, b0, b1)

Computes swish(.t()) \* (.t())

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* a (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])
* b0 (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])
* b1 (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](../graph/TensorValue.md#max.graph.TensorValue)

</dd></dl>

## `topk_fused_sampling()` {#max.nn.kernels.topk_fused_sampling}

> max.nn.kernels.topk\_fused\_sampling(logits, top\_k, \*, temperature=1.0, max\_k=None, top\_p=1.0, seed=0)

Performs top-k sampling with temperature scaling.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* logits ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue)) â€“ Input logits tensor of shape \[batch\_size, vocab\_size].
* top\_k (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]]) â€“ Number of top tokens to consider for sampling. Can be a scalar
  (which will be expanded to batch\_size) or a tensor of shape \[batch\_size].
* temperature (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]]) â€“ Temperature for scaling logits before sampling.
* max\_k (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]] | None) â€“ Maximum value of k across the batch. Required when top\_k is a tensor.
* top\_p (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]]) â€“ Top-p (nucleus) sampling threshold. Can be a scalar or tensor.
* seed (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]]) â€“ Seed for the random number generator. Can be a scalar or tensor.

</dd><dt>

**Returns:**

</dt><dd>

Sampled tokens tensor of shape \[batch\_size, 1].

</dd><dt>

**Raises:**

</dt><dd>

[ValueError](https://docs.python.org/3/library/exceptions.html#ValueError) â€“ If input validation fails.

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](../graph/TensorValue.md#max.graph.TensorValue)

</dd></dl>

## `unfused_qkv_ragged_matmul_gguf_quantized()` {#max.nn.kernels.unfused_qkv_ragged_matmul_gguf_quantized}

> max.nn.kernels.unfused\_qkv\_ragged\_matmul\_gguf\_quantized(kv\_params, input, input\_row\_offsets, n\_heads, q\_weight, k\_weight, v\_weight, quantization\_encoding\_q, quantization\_encoding\_k, quantization\_encoding\_v, kv\_collection, layer\_idx)

Computes fused query, key, and value projections with ragged input and
quantized weight matrices. A quantization\_config must be provided.

input and input\_row\_offsets are used together to implement the ragged
tensor.
input\_row\_offsets indicates where each batch starts and ends in input

<dl class='field-list'><dt>

**Raises:**

</dt><dd>

[ValueError](https://docs.python.org/3/library/exceptions.html#ValueError) â€“ on input shapes/dtypes that are invalid for the kernel.

</dd><dt>

**Parameters:**

</dt><dd>

* kv\_params ([KVCacheParams](kv_cache/cache_params.md#max.nn.kv_cache.cache_params.KVCacheParams))
* input ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue))
* input\_row\_offsets ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue))
* n\_heads ([int](https://docs.python.org/3/library/functions.html#int))
* q\_weight ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue))
* k\_weight ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue))
* v\_weight ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue))
* quantization\_encoding\_q ([QuantizationEncoding](../graph/quantization.md#max.graph.quantization.QuantizationEncoding))
* quantization\_encoding\_k ([QuantizationEncoding](../graph/quantization.md#max.graph.quantization.QuantizationEncoding))
* quantization\_encoding\_v ([QuantizationEncoding](../graph/quantization.md#max.graph.quantization.QuantizationEncoding))
* kv\_collection (PagedKVCacheCollection)
* layer\_idx ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue))

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](../graph/TensorValue.md#max.graph.TensorValue)

</dd></dl>

## `update_frequency_data()` {#max.nn.kernels.update_frequency_data}

> max.nn.kernels.update\_frequency\_data(frequency\_data, frequency\_offsets, tokens)

Updates the frequency data.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* frequency\_data ([BufferValue](../graph/BufferValue.md#max.graph.BufferValue)) â€“ 2d tensor of shape \[unique\_tokens, 2], where
  the first column indicates the token id and the second column
  indicates the frequency of the token.
* frequency\_offsets ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue)) â€“ 1d tensor of shape \[batch\_size + 1], indicating
  start of each sequenceâ€™s data.
* tokens ([TensorValue](../graph/TensorValue.md#max.graph.TensorValue)) â€“ The tokens to update the frequency data with.

</dd><dt>

**Return type:**

</dt><dd>

None

</dd></dl>

---

## cache_params

## `KVCacheParams` {#max.nn.kv_cache.cache_params.KVCacheParams}

> class max.nn.kv\_cache.cache\_params.KVCacheParams(dtype: max.dtype.DType, n\_kv\_heads: int, head\_dim: int, enable\_prefix\_caching: bool = False, enable\_kvcache\_swapping\_to\_host: bool = False, host\_kvcache\_swap\_space\_gb: Optional\[float] = None, cache\_strategy: max.nn.kv_cache.cache_params.KVCacheStrategy = \<KVCacheStrategy.PAGED: 'paged'>, page\_size: Optional\[int] = None, n\_devices: int = 1, data\_parallel\_degree: int = 1, n\_kv\_heads\_per\_device: int = 0)

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* dtype ([DType](../../dtype.md#max.dtype.DType))
* n\_kv\_heads ([int](https://docs.python.org/3/library/functions.html#int))
* head\_dim ([int](https://docs.python.org/3/library/functions.html#int))
* enable\_prefix\_caching ([bool](https://docs.python.org/3/library/functions.html#bool))
* enable\_kvcache\_swapping\_to\_host ([bool](https://docs.python.org/3/library/functions.html#bool))
* host\_kvcache\_swap\_space\_gb ([float](https://docs.python.org/3/library/functions.html#float) | None)
* cache\_strategy ([KVCacheStrategy](#max.nn.kv_cache.cache_params.KVCacheStrategy))
* page\_size ([int](https://docs.python.org/3/library/functions.html#int) | None)
* n\_devices ([int](https://docs.python.org/3/library/functions.html#int))
* data\_parallel\_degree ([int](https://docs.python.org/3/library/functions.html#int))
* n\_kv\_heads\_per\_device ([int](https://docs.python.org/3/library/functions.html#int))

</dd></dl>

### `cache_strategy` {#max.nn.kv_cache.cache_params.KVCacheParams.cache_strategy}

> cache\_strategy: [KVCacheStrategy](#max.nn.kv_cache.cache_params.KVCacheStrategy) = 'paged'

### `data_parallel_degree` {#max.nn.kv_cache.cache_params.KVCacheParams.data_parallel_degree}

> data\_parallel\_degree: [int](https://docs.python.org/3/library/functions.html#int) = 1

### `dtype` {#max.nn.kv_cache.cache_params.KVCacheParams.dtype}

> dtype: [DType](../../dtype.md#max.dtype.DType)

### `dtype_shorthand` {#max.nn.kv_cache.cache_params.KVCacheParams.dtype_shorthand}

> property dtype\_shorthand: [str](https://docs.python.org/3/library/stdtypes.html#str)

The textual representation in shorthand of the dtype.

### `enable_kvcache_swapping_to_host` {#max.nn.kv_cache.cache_params.KVCacheParams.enable_kvcache_swapping_to_host}

> enable\_kvcache\_swapping\_to\_host: [bool](https://docs.python.org/3/library/functions.html#bool) = False

### `enable_prefix_caching` {#max.nn.kv_cache.cache_params.KVCacheParams.enable_prefix_caching}

> enable\_prefix\_caching: [bool](https://docs.python.org/3/library/functions.html#bool) = False

### `head_dim` {#max.nn.kv_cache.cache_params.KVCacheParams.head_dim}

> head\_dim: [int](https://docs.python.org/3/library/functions.html#int)

### `host_kvcache_swap_space_gb` {#max.nn.kv_cache.cache_params.KVCacheParams.host_kvcache_swap_space_gb}

> host\_kvcache\_swap\_space\_gb: [float](https://docs.python.org/3/library/functions.html#float) | [None](https://docs.python.org/3/library/constants.html#None) = None

### `n_devices` {#max.nn.kv_cache.cache_params.KVCacheParams.n_devices}

> n\_devices: [int](https://docs.python.org/3/library/functions.html#int) = 1

### `n_kv_heads` {#max.nn.kv_cache.cache_params.KVCacheParams.n_kv_heads}

> n\_kv\_heads: [int](https://docs.python.org/3/library/functions.html#int)

### `n_kv_heads_per_device` {#max.nn.kv_cache.cache_params.KVCacheParams.n_kv_heads_per_device}

> n\_kv\_heads\_per\_device: [int](https://docs.python.org/3/library/functions.html#int) = 0

### `page_size` {#max.nn.kv_cache.cache_params.KVCacheParams.page_size}

> page\_size: [int](https://docs.python.org/3/library/functions.html#int) | [None](https://docs.python.org/3/library/constants.html#None) = None

### `static_cache_shape` {#max.nn.kv_cache.cache_params.KVCacheParams.static_cache_shape}

> property static\_cache\_shape: [tuple](https://docs.python.org/3/library/stdtypes.html#tuple)\[[str](https://docs.python.org/3/library/stdtypes.html#str), [str](https://docs.python.org/3/library/stdtypes.html#str), [str](https://docs.python.org/3/library/stdtypes.html#str), [str](https://docs.python.org/3/library/stdtypes.html#str), [str](https://docs.python.org/3/library/stdtypes.html#str)]

## `KVCacheStrategy` {#max.nn.kv\_cache.cache\_params.KVCacheStrategy}

> class max.nn.kv\_cache.cache\_params.KVCacheStrategy(value, names=\<not given>, \*values, module=None, qualname=None, type=None, start=1, boundary=None)

### `MODEL_DEFAULT` {#max.nn.kv_cache.cache_params.KVCacheStrategy.MODEL_DEFAULT}

> MODEL\_DEFAULT = 'model\_default'

### `PAGED` {#max.nn.kv_cache.cache_params.KVCacheStrategy.PAGED}

> PAGED = 'paged'

### `kernel_substring()` {#max.nn.kv_cache.cache_params.KVCacheStrategy.kernel_substring}

> kernel\_substring()

Returns the common substring that we include in the kernel name for this caching strategy.

<dl class='field-list'><dt>

**Return type:**

</dt><dd>

[str](https://docs.python.org/3/library/stdtypes.html#str)

</dd></dl>

### `uses_opaque()` {#max.nn.kv_cache.cache_params.KVCacheStrategy.uses_opaque}

> uses\_opaque()

<dl class='field-list'><dt>

**Return type:**

</dt><dd>

[bool](https://docs.python.org/3/library/functions.html#bool)

</dd></dl>

---

## context

## `KVCacheAwareContext` {#max.nn.kv_cache.context.KVCacheAwareContext}

> class max.nn.kv\_cache.context.KVCacheAwareContext(\*args, \*\*kwargs)

A Protocol identifying the minimum API necessary for interacting with a KV Cache.

### `active_idx` {#max.nn.kv_cache.context.KVCacheAwareContext.active_idx}

> property active\_idx: [int](https://docs.python.org/3/library/functions.html#int)

### `active_length` {#max.nn.kv_cache.context.KVCacheAwareContext.active_length}

> property active\_length: [int](https://docs.python.org/3/library/functions.html#int)

num tokens input this iteration.

This will be the prompt size for context encoding, and simply 1 for
token generation.

<dl class='field-list'><dt>

**Type:**

</dt><dd>

Current sequence length

</dd></dl>

### `bump_token_indices()` {#max.nn.kv_cache.context.KVCacheAwareContext.bump_token_indices}

> bump\_token\_indices(start\_idx=0, active\_idx=0, end\_idx=0)

Update the start\_idx, active\_idx and end\_idx without manipulating the token array.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* start\_idx ([int](https://docs.python.org/3/library/functions.html#int))
* active\_idx ([int](https://docs.python.org/3/library/functions.html#int))
* end\_idx ([int](https://docs.python.org/3/library/functions.html#int))

</dd><dt>

**Return type:**

</dt><dd>

None

</dd></dl>

### `compute_num_available_steps()` {#max.nn.kv_cache.context.KVCacheAwareContext.compute_num_available_steps}

> compute\_num\_available\_steps(max\_seq\_len)

Compute the max number of steps we can execute for a given context
without exceeding the max\_seq\_len.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

max\_seq\_len ([int](https://docs.python.org/3/library/functions.html#int))

</dd><dt>

**Return type:**

</dt><dd>

[int](https://docs.python.org/3/library/functions.html#int)

</dd></dl>

### `current_length` {#max.nn.kv_cache.context.KVCacheAwareContext.current_length}

> property current\_length: [int](https://docs.python.org/3/library/functions.html#int)

The current length of the sequence, including completed and active tokens.

### `end_idx` {#max.nn.kv_cache.context.KVCacheAwareContext.end_idx}

> property end\_idx: [int](https://docs.python.org/3/library/functions.html#int)

### `eos_token_ids` {#max.nn.kv_cache.context.KVCacheAwareContext.eos_token_ids}

> property eos\_token\_ids: [set](https://docs.python.org/3/library/stdtypes.html#set)\[[int](https://docs.python.org/3/library/functions.html#int)]

### `is_done` {#max.nn.kv_cache.context.KVCacheAwareContext.is_done}

> property is\_done: [bool](https://docs.python.org/3/library/functions.html#bool)

### `json_schema` {#max.nn.kv_cache.context.KVCacheAwareContext.json_schema}

> property json\_schema: [str](https://docs.python.org/3/library/stdtypes.html#str) | [None](https://docs.python.org/3/library/constants.html#None)

A json schema to use during constrained decoding.

### `matcher` {#max.nn.kv_cache.context.KVCacheAwareContext.matcher}

> property matcher: llguidance.LLMatcher | [None](https://docs.python.org/3/library/constants.html#None)

An optional Grammar Matcher provided when using structured output.

### `max_length` {#max.nn.kv_cache.context.KVCacheAwareContext.max_length}

> property max\_length: [int](https://docs.python.org/3/library/functions.html#int) | [None](https://docs.python.org/3/library/constants.html#None)

The maximum length of this sequence.

### `next_tokens` {#max.nn.kv_cache.context.KVCacheAwareContext.next_tokens}

> property next\_tokens: [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]]

The next prompt tokens to be input during this iteration.

This should be a 1D array of tokens of length active\_length.

### `request_id` {#max.nn.kv_cache.context.KVCacheAwareContext.request_id}

> property request\_id: [str](https://docs.python.org/3/library/stdtypes.html#str)

### `reset()` {#max.nn.kv_cache.context.KVCacheAwareContext.reset}

> reset()

Resets the contextâ€™s state by combining all tokens into a new prompt.
This method is used when a request is evicted, meaning that the context
needed to be re-encoded in the following CE iteration.

<dl class='field-list'><dt>

**Return type:**

</dt><dd>

None

</dd></dl>

### `set_matcher()` {#max.nn.kv_cache.context.KVCacheAwareContext.set_matcher}

> set\_matcher(matcher)

Set a grammar matcher for use during constrained decoding.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

matcher (llguidance.LLMatcher)

</dd><dt>

**Return type:**

</dt><dd>

None

</dd></dl>

### `set_token_indices()` {#max.nn.kv_cache.context.KVCacheAwareContext.set_token_indices}

> set\_token\_indices(start\_idx=None, active\_idx=None, end\_idx=None)

Set the token indices without manipulating the token array.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* start\_idx ([int](https://docs.python.org/3/library/functions.html#int) | None)
* active\_idx ([int](https://docs.python.org/3/library/functions.html#int) | None)
* end\_idx ([int](https://docs.python.org/3/library/functions.html#int) | None)

</dd><dt>

**Return type:**

</dt><dd>

None

</dd></dl>

### `start_idx` {#max.nn.kv_cache.context.KVCacheAwareContext.start_idx}

> property start\_idx: [int](https://docs.python.org/3/library/functions.html#int)

### `status` {#max.nn.kv_cache.context.KVCacheAwareContext.status}

> property status: [GenerationStatus](../../interfaces.md#max.interfaces.GenerationStatus)

### `tokens` {#max.nn.kv_cache.context.KVCacheAwareContext.tokens}

> property tokens: [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]]

All tokens in the context.

---

## kv_cache

## Modules

* [`cache_params`](/max/api/python/nn/kv_cache/cache_params)
* [`context`](/max/api/python/nn/kv_cache/context)
* [`manager`](/max/api/python/nn/kv_cache/manager)

---

## manager

Abstract base class for KVCacheManager for KV Cache.

## `KVCacheInputSymbols` {#max.nn.kv_cache.manager.KVCacheInputSymbols}

> class max.nn.kv\_cache.manager.KVCacheInputSymbols

Base class for input symbols for KV cache managers.

The derived class is responsible for defining the input symbols for the
specific KV cache manager.
For example, hereâ€™s a derived class for a text KV cache manager:

```python
@dataclass
class KVCacheInputSymbols(KVCacheInputSymbols):
    kv_blocks: TensorType
    cache_lengths: TensorType
    lookup_table: TensorType
    max_lengths: TensorType
```

## `KVCacheInputs` {#max.nn.kv_cache.manager.KVCacheInputs}

> class max.nn.kv\_cache.manager.KVCacheInputs

A base class that holds KV cache related (Tensor) inputs.

It is meant to be subclassed by concrete KV cache input types.
For example, hereâ€™s a derived class for a text KV cache manager:

```python
@dataclass
class RaggedKVCacheInputs(KVCacheInputs):
    blocks: Tensor
    cache_lengths: Tensor
    lookup_table: Tensor
    max_lengths: Tensor
```

## `KVCacheInputsSequence` {#max.nn.kv_cache.manager.KVCacheInputsSequence}

> class max.nn.kv\_cache.manager.KVCacheInputsSequence(kv\_cache\_inputs)

`KVCacheInputsSequence` is a sequence of [`KVCacheInputs`](#max.nn.kv_cache.manager.KVCacheInputs).

It is primarily used in our multistep execution to represent batched
KVCacheInputs.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

kv\_cache\_inputs ([Sequence](https://docs.python.org/3/library/collections.abc.html#collections.abc.Sequence)\[[KVCacheInputs](#max.nn.kv_cache.manager.KVCacheInputs)])

</dd></dl>

### `kv_cache_inputs` {#max.nn.kv_cache.manager.KVCacheInputsSequence.kv_cache_inputs}

> kv\_cache\_inputs: [Sequence](https://docs.python.org/3/library/collections.abc.html#collections.abc.Sequence)\[[KVCacheInputs](#max.nn.kv_cache.manager.KVCacheInputs)]

## `KVCacheManager` {#max.nn.kv_cache.manager.KVCacheManager}

> class max.nn.kv\_cache.manager.KVCacheManager(params, max\_batch\_size, max\_seq\_len, num\_layers, devices, session, is\_ragged=False)

The base class for KV cache managers.

It is responsible for managing the KV cache for a given model.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* params ([KVCacheParams](cache_params.md#max.nn.kv_cache.cache_params.KVCacheParams)) â€“ The parameters for the KV cache manager.
* max\_batch\_size ([int](https://docs.python.org/3/library/functions.html#int)) â€“ The maximum batch size. This should be the total overall
  maximum batch size, so if data parallelism is enabled, the sum of
  the batch size over all replicas will be equal to this value.
* max\_seq\_len ([int](https://docs.python.org/3/library/functions.html#int)) â€“ The maximum sequence length.
* num\_layers ([int](https://docs.python.org/3/library/functions.html#int)) â€“ The number of layers.
* devices (Sequence\[[Device](../../driver.md#max.driver.Device)]) â€“ The devices to use for the KV cache manager.
* session ([InferenceSession](../../engine.md#max.engine.InferenceSession)) â€“ The session to use for the KV cache manager.
* is\_ragged ([bool](https://docs.python.org/3/library/functions.html#bool)) â€“ Whether the KV cache manager is using ragged tensors.

</dd></dl>

### `params` {#max.nn.kv_cache.manager.KVCacheManager.params}

> params

The parameters for the KV cache manager.

### `max_batch_size` {#max.nn.kv_cache.manager.KVCacheManager.max_batch_size}

> max\_batch\_size

The maximum batch size.

### `max_seq_len` {#max.nn.kv_cache.manager.KVCacheManager.max_seq_len}

> max\_seq\_len

The maximum sequence length.

### `num_layers` {#max.nn.kv_cache.manager.KVCacheManager.num_layers}

> num\_layers

The number of layers.

### `contains()` {#max.nn.kv_cache.manager.KVCacheManager.contains}

> contains(request\_id)

Check if the given request ID is currently active in the cache.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

request\_id ([str](https://docs.python.org/3/library/stdtypes.html#str)) â€“ The request ID to check for.

</dd><dt>

**Returns:**

</dt><dd>

True if the request ID is active in the cache, False otherwise.

</dd><dt>

**Return type:**

</dt><dd>

[bool](https://docs.python.org/3/library/functions.html#bool)

</dd></dl>

### `estimated_memory_size()` {#max.nn.kv_cache.manager.KVCacheManager.estimated_memory_size}

> abstract classmethod estimated\_memory\_size(params, max\_batch\_size, max\_seq\_len, num\_layers, available\_cache\_memory, devices, \*\*kwargs)

Returns the estimated total memory usage of the kv cache.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* params ([KVCacheParams](cache_params.md#max.nn.kv_cache.cache_params.KVCacheParams))
* max\_batch\_size ([int](https://docs.python.org/3/library/functions.html#int))
* max\_seq\_len ([int](https://docs.python.org/3/library/functions.html#int))
* num\_layers ([int](https://docs.python.org/3/library/functions.html#int))
* available\_cache\_memory ([int](https://docs.python.org/3/library/functions.html#int))
* devices ([Sequence](https://docs.python.org/3/library/collections.abc.html#collections.abc.Sequence)\[[Device](../../driver.md#max.driver.Device)])
* kwargs ([Any](https://docs.python.org/3/library/typing.html#typing.Any))

</dd><dt>

**Return type:**

</dt><dd>

[int](https://docs.python.org/3/library/functions.html#int)

</dd></dl>

### `external_claim()` {#max.nn.kv_cache.manager.KVCacheManager.external_claim}

> external\_claim(request\_id)

Reserve a sequence ID for the given request ID.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

request\_id ([str](https://docs.python.org/3/library/stdtypes.html#str))

</dd><dt>

**Return type:**

</dt><dd>

None

</dd></dl>

### `fetch()` {#max.nn.kv_cache.manager.KVCacheManager.fetch}

> abstract fetch(batch, num\_steps=1)

Returns blocks and other inputs to kv cache kernel for given
sequence ids and prompts.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* batch ([Sequence](https://docs.python.org/3/library/collections.abc.html#collections.abc.Sequence)\[T])
* num\_steps ([int](https://docs.python.org/3/library/functions.html#int))

</dd><dt>

**Return type:**

</dt><dd>

[Sequence](https://docs.python.org/3/library/collections.abc.html#collections.abc.Sequence)\[[KVCacheInputs](#max.nn.kv_cache.manager.KVCacheInputs)]

</dd></dl>

### `increment_cache_lengths()` {#max.nn.kv_cache.manager.KVCacheManager.increment_cache_lengths}

> increment\_cache\_lengths(kv\_cache\_inputs, prev\_model\_inputs)

Prepare the inputs for a multistep execution, generally by incrementing
the cache lengths. This should not require a device synchronization,
as this would defeat the purpose of multistep execution.

This should also not update the cache lengths in our manager, this batch is
still considered in-progress.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* kv\_cache\_inputs ([list](https://docs.python.org/3/library/stdtypes.html#list)\[[RaggedKVCacheInputs](#max.nn.kv_cache.manager.RaggedKVCacheInputs)] | [list](https://docs.python.org/3/library/stdtypes.html#list)\[[PaddedKVCacheInputs](#max.nn.kv_cache.manager.PaddedKVCacheInputs)])
* prev\_model\_inputs ([Any](https://docs.python.org/3/library/typing.html#typing.Any))

</dd><dt>

**Return type:**

</dt><dd>

[list](https://docs.python.org/3/library/stdtypes.html#list)\[[RaggedKVCacheInputs](#max.nn.kv_cache.manager.RaggedKVCacheInputs)] | [list](https://docs.python.org/3/library/stdtypes.html#list)\[[PaddedKVCacheInputs](#max.nn.kv_cache.manager.PaddedKVCacheInputs)]

</dd></dl>

### `increment_cache_lengths_model` {#max.nn.kv_cache.manager.KVCacheManager.increment_cache_lengths_model}

> property increment\_cache\_lengths\_model: [Model](../../engine.md#max.engine.Model)

### `infer_optimal_batch_size()` {#max.nn.kv_cache.manager.KVCacheManager.infer_optimal_batch_size}

> abstract classmethod infer\_optimal\_batch\_size(params, max\_seq\_len, num\_layers, available\_cache\_memory, devices, \*\*kwargs)

Returns the estimated optimal batch size for the kv cache.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* params ([KVCacheParams](cache_params.md#max.nn.kv_cache.cache_params.KVCacheParams))
* max\_seq\_len ([int](https://docs.python.org/3/library/functions.html#int))
* num\_layers ([int](https://docs.python.org/3/library/functions.html#int))
* available\_cache\_memory ([int](https://docs.python.org/3/library/functions.html#int))
* devices ([Sequence](https://docs.python.org/3/library/collections.abc.html#collections.abc.Sequence)\[[Device](../../driver.md#max.driver.Device)])
* kwargs ([Any](https://docs.python.org/3/library/typing.html#typing.Any))

</dd><dt>

**Return type:**

</dt><dd>

[int](https://docs.python.org/3/library/functions.html#int)

</dd></dl>

### `input_symbols()` {#max.nn.kv_cache.manager.KVCacheManager.input_symbols}

> abstract input\_symbols(devices=None, num\_layers=None)

Returns the input symbols for the kv cache manager.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* devices ([Sequence](https://docs.python.org/3/library/collections.abc.html#collections.abc.Sequence)\[[Device](../../driver.md#max.driver.Device)] | None)
* num\_layers ([int](https://docs.python.org/3/library/functions.html#int) | None)

</dd><dt>

**Return type:**

</dt><dd>

[Sequence](https://docs.python.org/3/library/collections.abc.html#collections.abc.Sequence)\[[KVCacheInputSymbols](#max.nn.kv_cache.manager.KVCacheInputSymbols)]

</dd></dl>

### `release()` {#max.nn.kv_cache.manager.KVCacheManager.release}

> release(request\_id)

Release the sequence associated with `request_id`, marking this sequence as complete.
This returns the sequence ID back to the available pool of cache memory,
allowing it to be reused when a new sequence is claimed.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

request\_id ([str](https://docs.python.org/3/library/stdtypes.html#str))

</dd><dt>

**Return type:**

</dt><dd>

None

</dd></dl>

### `step()` {#max.nn.kv_cache.manager.KVCacheManager.step}

> step(batch)

Commit the new tokens into the prefix cache.

This is a no-op if prefix caching is disabled.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

batch ([Sequence](https://docs.python.org/3/library/collections.abc.html#collections.abc.Sequence)\[T])

</dd><dt>

**Return type:**

</dt><dd>

None

</dd></dl>

## `PaddedKVCacheInputs` {#max.nn.kv_cache.manager.PaddedKVCacheInputs}

> class max.nn.kv\_cache.manager.PaddedKVCacheInputs(k\_cache, v\_cache, start\_pos, null\_op)

`PaddedKVCacheInputs` is a class that holds the inputs for
KV cache when used together with padded tensors.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* k\_cache ([Tensor](../../driver.md#max.driver.Tensor))
* v\_cache ([Tensor](../../driver.md#max.driver.Tensor))
* start\_pos ([Tensor](../../driver.md#max.driver.Tensor))
* null\_op ([Tensor](../../driver.md#max.driver.Tensor))

</dd></dl>

### `k_cache` {#max.nn.kv_cache.manager.PaddedKVCacheInputs.k_cache}

> k\_cache: [Tensor](../../driver.md#max.driver.Tensor)

### `null_op` {#max.nn.kv_cache.manager.PaddedKVCacheInputs.null_op}

> null\_op: [Tensor](../../driver.md#max.driver.Tensor)

### `start_pos` {#max.nn.kv_cache.manager.PaddedKVCacheInputs.start_pos}

> start\_pos: [Tensor](../../driver.md#max.driver.Tensor)

### `v_cache` {#max.nn.kv_cache.manager.PaddedKVCacheInputs.v_cache}

> v\_cache: [Tensor](../../driver.md#max.driver.Tensor)

## `RaggedKVCacheInputs` {#max.nn.kv_cache.manager.RaggedKVCacheInputs}

> class max.nn.kv\_cache.manager.RaggedKVCacheInputs(blocks, cache\_lengths, lookup\_table, max\_lengths)

`RaggedKVCacheInputs` is a class that holds the inputs for
KV cache when used together with ragged tensors.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* blocks ([Tensor](../../driver.md#max.driver.Tensor))
* cache\_lengths ([Tensor](../../driver.md#max.driver.Tensor))
* lookup\_table ([Tensor](../../driver.md#max.driver.Tensor))
* max\_lengths ([Tensor](../../driver.md#max.driver.Tensor))

</dd></dl>

### `blocks` {#max.nn.kv_cache.manager.RaggedKVCacheInputs.blocks}

> blocks: [Tensor](../../driver.md#max.driver.Tensor)

### `cache_lengths` {#max.nn.kv_cache.manager.RaggedKVCacheInputs.cache_lengths}

> cache\_lengths: [Tensor](../../driver.md#max.driver.Tensor)

### `lookup_table` {#max.nn.kv_cache.manager.RaggedKVCacheInputs.lookup_table}

> lookup\_table: [Tensor](../../driver.md#max.driver.Tensor)

### `max_lengths` {#max.nn.kv_cache.manager.RaggedKVCacheInputs.max_lengths}

> max\_lengths: [Tensor](../../driver.md#max.driver.Tensor)

---

## layer

## `Layer` {#max.nn.layer.Layer}

> class max.nn.layer.Layer

#### Deprecated

Deprecated since version 25.2..

Base class for neural network components.
Use [`Module`](#max.nn.layer.Module) instead.

Provides functionality for adding hooks to the call function of
each layer to support testing, debugging or profiling.

## `LayerList` {#max.nn.layer.LayerList}

> class max.nn.layer.LayerList(layers)

Stores a list of layers.

Can be used as a regular python list.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

layers ([Sequence](https://docs.python.org/3/library/collections.abc.html#collections.abc.Sequence)\[[Layer](#max.nn.layer.Layer)])

</dd></dl>

### `append()` {#max.nn.layer.LayerList.append}

> append(layer)

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

layer ([Layer](#max.nn.layer.Layer))

</dd><dt>

**Return type:**

</dt><dd>

None

</dd></dl>

### `extend()` {#max.nn.layer.LayerList.extend}

> extend(layer)

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

layer ([Layer](#max.nn.layer.Layer))

</dd><dt>

**Return type:**

</dt><dd>

None

</dd></dl>

### `insert()` {#max.nn.layer.LayerList.insert}

> insert(i, layer)

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* i ([int](https://docs.python.org/3/library/functions.html#int))
* layer ([Layer](#max.nn.layer.Layer))

</dd><dt>

**Return type:**

</dt><dd>

None

</dd></dl>

### `sublayers` {#max.nn.layer.LayerList.sublayers}

> property sublayers: [dict](https://docs.python.org/3/library/stdtypes.html#dict)\[[str](https://docs.python.org/3/library/stdtypes.html#str), [Module](#max.nn.layer.Module)]

## `Module` {#max.nn.layer.Module}

> class max.nn.layer.Module

Base class for model components with weight management.

Provides functionality to create custom layers and construct networks with automatic weight tracking.

The following example uses the [`Module`](#max.nn.layer.Module) class to create custom layers and build a neural network:

```python
from max import nn
from max.dtype import DType
from max.graph import Weight, ops, DeviceRef

class Linear(nn.Module):
    def __init__(self, in_dims, out_dims):
        super().__init__()
        self.weight = Weight("weight", DType.float32, (in_dim, out_dim), DeviceRef.CPU())

    def __call__(self, x):
        return x @ self.weight.T

class MLP(nn.Module):
    def __init__(self):
        self.up = Linear(5, 10)
        self.gate = Linear(5, 10)
        self.down = Linear(10, 5)

    def __call__(self, x):
        return self.down(ops.silu(self.gate(x)) + self.up(x))

model = MLP()
print(model.state_dict())  # {"up.weight": Tensor([5, 10]), ...}
```

Constructing a graph without [`Module`](#max.nn.layer.Module) can result in name collisions
with the weights (in this example, there would be three weights with the
name Weight). With [`Module`](#max.nn.layer.Module), you can use [`state_dict()`](#max.nn.layer.Module.state_dict) or
[`load_state_dict()`](#max.nn.layer.Module.load_state_dict) to initialize or set the weights values, and finalize
the weight names to be unique within the model.

### `build_subgraph()` {#max.nn.layer.Module.build_subgraph}

> build\_subgraph(name, input\_types, weight\_prefix='')

Builds a subgraph for this module.

This method creates a subgraph that encapsulates the moduleâ€™s logic,
handling input types, weights, and creating a graph with the moduleâ€™s
computation.

Once the subgraph is built, it can be called using the `ops.call`
op.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* name ([str](https://docs.python.org/3/library/stdtypes.html#str)) â€“ The name of the subgraph to create.
* input\_types ([Sequence](https://docs.python.org/3/library/collections.abc.html#collections.abc.Sequence)\[[Type](../graph/type.md#max.graph.type.Type)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [list](https://docs.python.org/3/library/stdtypes.html#list)\[[Type](../graph/type.md#max.graph.type.Type)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]]) â€“ A list of input types for the subgraph. Each element can be
  either a single `Type` or a list of `Type` objects.
* weight\_prefix ([str](https://docs.python.org/3/library/stdtypes.html#str)) â€“ Optional prefix for weight names in the subgraph. If provided,
  weights with names starting with this prefix will have their names
  modified by removing the prefix and will be marked as placeholders.

</dd><dt>

**Returns:**

</dt><dd>

The created subgraph containing the moduleâ€™s computation.

</dd><dt>

**Return type:**

</dt><dd>

`Graph`

</dd></dl>

#### NOTE

* Placeholder weights will require the `prefix` attribute of `ops.call` to be set.

### `layer_weights` {#max.nn.layer.Module.layer_weights}

> property layer\_weights: [dict](https://docs.python.org/3/library/stdtypes.html#dict)\[[str](https://docs.python.org/3/library/stdtypes.html#str), [Weight](../graph/Weight.md#max.graph.Weight)]

### `load_state_dict()` {#max.nn.layer.Module.load_state_dict}

> load\_state\_dict(state\_dict, \*, override\_quantization\_encoding=False, weight\_alignment=None, strict=True)

Sets the values of all weights in this model.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* state\_dict ([Mapping](https://docs.python.org/3/library/collections.abc.html#collections.abc.Mapping)\[[str](https://docs.python.org/3/library/stdtypes.html#str), [DLPackArray](../driver.md#max.driver.DLPackArray) | [WeightData](../graph/weights.md#max.graph.weights.WeightData)]) â€“ A map from weight name to a numpy array or
  [`max.driver.Tensor`](../driver.md#max.driver.Tensor).
* override\_quantization\_encoding ([bool](https://docs.python.org/3/library/functions.html#bool)) â€“ Whether to override the weight
  quantization based on the loaded value.
* weight\_alignment ([int](https://docs.python.org/3/library/functions.html#int) | None) â€“ If specified, overrides the alignment for each
  weight in the Module. If left as None, each value in
  state\_dict must be aligned by the default dtype alignment.
* strict ([bool](https://docs.python.org/3/library/functions.html#bool)) â€“ If True, raises an error if any weights required by the
  Module are missing from state\_dict, or if any keys in
  state\_dict were not used by the Module. If False, both
  missing and unexpected keys are tolerated and reported only
  via return values/logging by callers.

</dd><dt>

**Raises:**

</dt><dd>

[ValueError](https://docs.python.org/3/library/exceptions.html#ValueError) â€“ If strict is True and any required weight is missing
from state\_dict, or if state\_dict contains keys not used by
the Module.

</dd><dt>

**Return type:**

</dt><dd>

None

</dd></dl>

### `raw_state_dict()` {#max.nn.layer.Module.raw_state_dict}

> raw\_state\_dict()

Returns all weights objects in the model.
Unlike [`state_dict`](#max.nn.layer.Module.state_dict), this returns [`max.graph.Weight`](../graph/Weight.md#max.graph.Weight) objects instead of
the assigned values. Some parameters inside the `Weight` can be
configured before a graph is built. Do not change these attributes after
building a graph:

* [`align`](../graph/Weight.md#max.graph.Weight.align)
* [`dtype`](../graph/Weight.md#max.graph.Weight.dtype)
* [`quantization_encoding`](../graph/Weight.md#max.graph.Weight.quantization_encoding)
* [`shape`](../graph/Weight.md#max.graph.Weight.shape)

<dl class='field-list'><dt>

**Returns:**

</dt><dd>

Map from weight name to the [`max.graph.Weight`](../graph/Weight.md#max.graph.Weight) object.

</dd><dt>

**Return type:**

</dt><dd>

[dict](https://docs.python.org/3/library/stdtypes.html#dict)\[[str](https://docs.python.org/3/library/stdtypes.html#str), [Weight](../graph/Weight.md#max.graph.Weight)]

</dd></dl>

### `set_shared_weight()` {#max.nn.layer.Module.set_shared_weight}

> set\_shared\_weight(name, weight)

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* name ([str](https://docs.python.org/3/library/stdtypes.html#str))
* weight ([Weight](../graph/Weight.md#max.graph.Weight))

</dd><dt>

**Return type:**

</dt><dd>

None

</dd></dl>

### `state_dict()` {#max.nn.layer.Module.state_dict}

> state\_dict(auto\_initialize=True)

Returns values of all weights in the model.

The values returned are the same as the values set in [`load_state_dict`](#max.nn.layer.Module.load_state_dict).
If [`load_state_dict`](#max.nn.layer.Module.load_state_dict) has not been called and none of the weights have
values, then they are initialized to zero.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

auto\_initialize ([bool](https://docs.python.org/3/library/functions.html#bool)) â€“ Determines whether to initialize weights to zero if
the weight value has not been loaded. If this is False, a
ValueError is raised if an uninitialized weight is found.

</dd><dt>

**Returns:**

</dt><dd>

Map from weight name to the weight value (can be numpy array or
[`max.driver.Tensor`](../driver.md#max.driver.Tensor)).

</dd><dt>

**Return type:**

</dt><dd>

[dict](https://docs.python.org/3/library/stdtypes.html#dict)\[[str](https://docs.python.org/3/library/stdtypes.html#str), [DLPackArray](../driver.md#max.driver.DLPackArray)]

</dd></dl>

### `sublayers` {#max.nn.layer.Module.sublayers}

> property sublayers: [dict](https://docs.python.org/3/library/stdtypes.html#dict)\[[str](https://docs.python.org/3/library/stdtypes.html#str), [Module](#max.nn.layer.Module)]

## `Shardable` {#max.nn.layer.Shardable}

> class max.nn.layer.Shardable(\*args, \*\*kwargs)

Protocol for objects that support sharding across multiple devices.

This protocol defines the interface that all shardable components
(like Linear layers and Weight objects) must implement to participate
in distributed computation.

### `shard()` {#max.nn.layer.Shardable.shard}

> shard(devices)

Creates a sharded view of this object for a specific device.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* device â€“ The devices where this shard should reside.
* devices ([Iterable](https://docs.python.org/3/library/collections.abc.html#collections.abc.Iterable)\[[DeviceRef](../graph/type.md#max.graph.type.DeviceRef)])

</dd><dt>

**Returns:**

</dt><dd>

A sequence of sharded instances of this object.

</dd><dt>

**Return type:**

</dt><dd>

[Sequence](https://docs.python.org/3/library/collections.abc.html#collections.abc.Sequence)\[[Self](https://docs.python.org/3/library/typing.html#typing.Self)]

</dd></dl>

### `sharding_strategy` {#max.nn.layer.Shardable.sharding_strategy}

> property sharding\_strategy: ShardingStrategy | [None](https://docs.python.org/3/library/constants.html#None)

Gets the weight sharding strategy.

## `add_layer_hook()` {#max.nn.layer.add_layer_hook}

> max.nn.layer.add\_layer\_hook(fn)

Adds a hook to call a function after each layerâ€™s `__call__`.

The function will be passed four inputs:

* layer
* input\_args
* input\_kwargs
* outputs

The function can either return None or new
outputs that will replace the layer returned outputs.

Note that input and outputs contain graph Values, which show limited
information (like [`shape`](../graph/TensorValue.md#max.graph.TensorValue.shape) and [`dtype`](../graph/TensorValue.md#max.graph.TensorValue.dtype)). You can still see the computed values
if you include the Value in the `graph.ops.output` op, or call `graph.ops.print`.

Example of printing debug inputs:

```python
def print_info(layer, args, kwargs, outputs):
    print("Layer:", type(layer).__name__)
    print("Input args:", args)
    print("Input kwargs:", kwargs)
    print("Outputs:", outputs)
    return outputs

add_layer_hook(print_info)
```

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

fn ([Callable](https://docs.python.org/3/library/typing.html#typing.Callable)\[\[[Layer](#max.nn.layer.Layer), [tuple](https://docs.python.org/3/library/stdtypes.html#tuple)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), ...], [dict](https://docs.python.org/3/library/stdtypes.html#dict)\[[str](https://docs.python.org/3/library/stdtypes.html#str), [Any](https://docs.python.org/3/library/typing.html#typing.Any)], [Any](https://docs.python.org/3/library/typing.html#typing.Any)], [Any](https://docs.python.org/3/library/typing.html#typing.Any)])

</dd><dt>

**Return type:**

</dt><dd>

None

</dd></dl>

## `clear_hooks()` {#max.nn.layer.clear_hooks}

> max.nn.layer.clear\_hooks()

Remove all hooks.

<dl class='field-list'><dt>

**Return type:**

</dt><dd>

None

</dd></dl>

## `recursive_named_layers()` {#max.nn.layer.recursive_named_layers}

> max.nn.layer.recursive\_named\_layers(parent, prefix='')

Recursively walks through the layers and generates names.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* parent ([Module](#max.nn.layer.Module))
* prefix ([str](https://docs.python.org/3/library/stdtypes.html#str))

</dd><dt>

**Return type:**

</dt><dd>

[Iterable](https://docs.python.org/3/library/collections.abc.html#collections.abc.Iterable)\[[tuple](https://docs.python.org/3/library/stdtypes.html#tuple)\[[str](https://docs.python.org/3/library/stdtypes.html#str), [Module](#max.nn.layer.Module)]]

</dd></dl>

---

## linear

Multi-layer Perceptron.

## `ColumnParallelLinear` {#max.nn.linear.ColumnParallelLinear}

> class max.nn.linear.ColumnParallelLinear(in\_dim, out\_dim, dtype, devices, tied\_weight=None, \*\*kwargs)

A [`Linear`](#max.nn.linear.Linear) layer where the weight and bias are sharded onto multiple devices.

This layer first computes $y = xW_i^T + b_i$ for each device i in
\[0,â€¦, num\_devices]:

```default
+-----+       +-----+ T     +-----+       +-----+
|     |       | W_0 |       | b_0 |       | y_0 | GPU0
|     |       +-----+       +-----+       +-----+
|     |       | W_1 |       | b_1 |       | y_1 | GPU1
|  x  |   @   +-----+   +   +-----+   =   +-----+
|     |       | W_2 |       | b_2 |       | y_2 | GPU2
|     |       +-----+       +-----+       +-----+
|     |       | W_3 |       | b_3 |       | y_3 | GPU3
+-----+       +-----+       +-----+       +-----+
```

The values are then collected using an Allgather op, producing the same
output tensor $y = xW^T + b$ on each device:

```default
GPU0  GPU1  GPU2  GPU3                      GPU0  GPU1  GPU2  GPU3
+-----+-----+-----+-----+                   +-----+-----+-----+-----+
| y_0 |  -  |  -  |  -  |                   | y_0 | y_0 | y_0 | y_0 |
+-----+-----+-----+-----+                   +-----+-----+-----+-----+
|  -  | y_1 |  -  |  -  |                   | y_1 | y_1 | y_1 | y_1 |
+-----+-----+-----+-----+  -- Allgather --> +-----+-----+-----+-----+
|  -  |  -  | y_2 |  -  |                   | y_2 | y_2 | y_2 | y_2 |
+-----+-----+-----+-----+                   +-----+-----+-----+-----+
|  -  |  -  |  -  | y_3 |                   | y_3 | y_3 | y_3 | y_3 |
+-----+-----+-----+-----+                   +-----+-----+-----+-----+
```

Example usage:

```python
from max.dtype import DType
from max.graph import DeviceRef
from max.nn import ColumnParallelLinear

num_devices = 4
distributed_linear = ColumnParallelLinear(
    in_dim,
    out_dim,
    DType.float32,
    devices=[DeviceRef.GPU(i) for i in range(num_devices)],
)
```

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* in\_dim ([int](https://docs.python.org/3/library/functions.html#int)) â€“ The dimensionality of the input space.
* out\_dim ([int](https://docs.python.org/3/library/functions.html#int)) â€“ The dimensionality of the output space.
* dtype ([DType](../dtype.md#max.dtype.DType)) â€“ The `DType` for both weights and bias.
* devices (Sequence\[[DeviceRef](../graph/type.md#max.graph.type.DeviceRef)]) â€“ The target `DeviceRef` devices for computation.
  Weights remain on CPU until sharded and moved to device during
  computation.
* tied\_weight ([Weight](../graph/Weight.md#max.graph.Weight) | None) â€“ Optional `Weight` to tie with this layer.

</dd></dl>

## `DistributedGemmConfig` {#max.nn.linear.DistributedGemmConfig}

> class max.nn.linear.DistributedGemmConfig(enable\_matmul\_allreduce)

Configure how distributed GEMM is executed.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

enable\_matmul\_allreduce ([bool](https://docs.python.org/3/library/functions.html#bool))

</dd></dl>

### `enable_matmul_allreduce` {#max.nn.linear.DistributedGemmConfig.enable_matmul_allreduce}

> enable\_matmul\_allreduce: [bool](https://docs.python.org/3/library/functions.html#bool)

If `True`, use the matmul + all\_reduce kernel.

### `generate()` {#max.nn.linear.DistributedGemmConfig.generate}

> static generate()

Returns the default [`DistributedGemmConfig`](#max.nn.linear.DistributedGemmConfig).

<dl class='field-list'><dt>

**Returns:**

</dt><dd>

A [`DistributedGemmConfig`](#max.nn.linear.DistributedGemmConfig) instance with default settings.

</dd><dt>

**Return type:**

</dt><dd>

[DistributedGemmConfig](#max.nn.linear.DistributedGemmConfig) | None

</dd></dl>

## `GPTQLinear` {#max.nn.linear.GPTQLinear}

> class max.nn.linear.GPTQLinear(in\_dim, out\_dim, dtype, device, has\_bias=False, quantization\_encoding=None, quantization\_config=None, float8\_config=None)

A [`Linear`](#max.nn.linear.Linear) layer for GPTQ encoding.

Initializes the linear layer with weights and optional bias with
GPTQ quantization.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* in\_dim ([int](https://docs.python.org/3/library/functions.html#int)) â€“ The dimensionality of the input space.
* out\_dim ([int](https://docs.python.org/3/library/functions.html#int)) â€“ The dimensionality of the output space.
* dtype ([DType](../dtype.md#max.dtype.DType)) â€“ The `DType` for both weights and bias.
* device ([DeviceRef](../graph/type.md#max.graph.type.DeviceRef)) â€“ The target `DeviceRef` for computation.
  Weights remain on CPU until moved during computation.
* has\_bias ([bool](https://docs.python.org/3/library/functions.html#bool)) â€“ When `True`, adds a bias vector to the layer.
  Defaults to `False`.
* quantization\_encoding ([QuantizationEncoding](../graph/quantization.md#max.graph.quantization.QuantizationEncoding) | None) â€“ The `QuantizationEncoding` of the weights.
* quantization\_config ([QuantizationConfig](../graph/quantization.md#max.graph.quantization.QuantizationConfig) | None) â€“ Extra `QuantizationConfig` for the weight quantization.
* float8\_config (Float8Config | None) â€“ `Float8Config` for float8 quantization (not supported).

</dd></dl>

## `GPTQLinearV1` {#max.nn.linear.GPTQLinearV1}

> class max.nn.linear.GPTQLinearV1(weight, bias=None, quantization\_encoding=None, quantization\_config=None, perm\_idx=None)

A [`Linear`](#max.nn.linear.Linear) layer for GPTQ encoding.

#### Deprecated

Deprecated since version 25.5: Use [`GPTQLinear`](#max.nn.linear.GPTQLinear) instead.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* weight (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])
* bias (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]] | None)
* quantization\_encoding ([QuantizationEncoding](../graph/quantization.md#max.graph.quantization.QuantizationEncoding) | None)
* quantization\_config ([QuantizationConfig](../graph/quantization.md#max.graph.quantization.QuantizationConfig) | None)
* perm\_idx (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]] | None)

</dd></dl>

### `perm_idx` {#max.nn.linear.GPTQLinearV1.perm_idx}

> perm\_idx: Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]] | [None](https://docs.python.org/3/library/constants.html#None) = None

Optional permutation indices for GPTQ quantization.

### `quantization_config` {#max.nn.linear.GPTQLinearV1.quantization_config}

> quantization\_config: [QuantizationConfig](../graph/quantization.md#max.graph.quantization.QuantizationConfig) | [None](https://docs.python.org/3/library/constants.html#None) = None

The `QuantizationConfig` for GPTQ quantization.

## `Linear` {#max.nn.linear.Linear}

> class max.nn.linear.Linear(in\_dim, out\_dim, dtype, device, has\_bias=False, quantization\_encoding=None, float8\_config=None, name=None, clip\_weight=None)

Applies a linear transformation to incoming data: $y = xW^T + b$.

This layer implements a fully connected layer where inputs are multiplied
by a weight matrix and optionally added with a bias vector.
Both weights and bias initially reside on CPU, and the model init phase
moves them to the specified device.

Example:

```python
linear_layer = Linear(
    in_dim=256,
    out_dim=128,
    dtype=DType.float32,
    device=DeviceRef.GPU(),
    name="linear",
    has_bias=True
)

input_tensor: TensorValue
output = linear_layer(input_tensor)
```

Initializes the linear layer with weights and optional bias.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* in\_dim ([int](https://docs.python.org/3/library/functions.html#int)) â€“ The dimensionality of the input space.
* out\_dim ([int](https://docs.python.org/3/library/functions.html#int)) â€“ The dimensionality of the output space.
* dtype ([DType](../dtype.md#max.dtype.DType)) â€“ The `DType` for both weights and bias.
* device ([DeviceRef](../graph/type.md#max.graph.type.DeviceRef)) â€“ The target `DeviceRef` for computation.
  Weights remain on CPU until moved during computation.
* name ([str](https://docs.python.org/3/library/stdtypes.html#str) | None) â€“ Base name for weights (appended with `.weight` and
  `.bias` if applicable).
* has\_bias ([bool](https://docs.python.org/3/library/functions.html#bool)) â€“ When `True`, adds a bias vector to the layer.
  Defaults to `False`.
* quantization\_encoding ([QuantizationEncoding](../graph/quantization.md#max.graph.quantization.QuantizationEncoding) | None) â€“ `QuantizationEncoding` for the weights.
* float8\_config (Float8Config | None) â€“ `Float8Config` for float8 quantization.
* clip\_weight ([float](https://docs.python.org/3/library/functions.html#float) | None) â€“ Optional weight clipping threshold.

</dd></dl>

### `bias` {#max.nn.linear.Linear.bias}

> bias: [Weight](../graph/Weight.md#max.graph.Weight) | [None](https://docs.python.org/3/library/constants.html#None) = None

The optional bias vector stored on CPU with shape (out\_dim,).
Model init moves the bias to the target device if present.

### `device` {#max.nn.linear.Linear.device}

> device: [DeviceRef](../graph/type.md#max.graph.type.DeviceRef)

The device where matrix operations are performed.

### `input_scale` {#max.nn.linear.Linear.input_scale}

> input\_scale: [Weight](../graph/Weight.md#max.graph.Weight) | [None](https://docs.python.org/3/library/constants.html#None) = None

The optional input scale stored on CPU with shape ().
Model init moves the input\_scale to the target device if present.

### `shard()` {#max.nn.linear.Linear.shard}

> shard(devices)

Creates sharded views of this Linear layer across multiple devices.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

devices ([Iterable](https://docs.python.org/3/library/collections.abc.html#collections.abc.Iterable)\[[DeviceRef](../graph/type.md#max.graph.type.DeviceRef)]) â€“ Iterable of `DeviceRef` devices to place the shards on.

</dd><dt>

**Returns:**

</dt><dd>

List of sharded [`Linear`](#max.nn.linear.Linear) instances, one for each device.

</dd><dt>

**Return type:**

</dt><dd>

[list](https://docs.python.org/3/library/stdtypes.html#list)\[[Linear](#max.nn.linear.Linear)]

</dd></dl>

### `sharding_strategy` {#max.nn.linear.Linear.sharding_strategy}

> property sharding\_strategy: ShardingStrategy | [None](https://docs.python.org/3/library/constants.html#None)

Get the weight sharding strategy.

### `weight` {#max.nn.linear.Linear.weight}

> weight: [Weight](../graph/Weight.md#max.graph.Weight)

The weight matrix stored on CPU with shape (out\_dim, in\_dim).
Model init transposes the weight and moves it to the target device.

### `weight_scale` {#max.nn.linear.Linear.weight_scale}

> weight\_scale: [Weight](../graph/Weight.md#max.graph.Weight) | [None](https://docs.python.org/3/library/constants.html#None) = None

The optional weight scale stored on CPU with shape () or (N,).
Model init moves the weight\_scale to the target device if present.

## `LinearV1` {#max.nn.linear.LinearV1}

> class max.nn.linear.LinearV1(weight, bias=None)

A unified linear layer that delegates to either regular or quantized implementation.

#### Deprecated

Deprecated since version 25.5: Use [`Linear`](#max.nn.linear.Linear) instead.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* weight (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])
* bias (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]] | None)

</dd></dl>

### `bias` {#max.nn.linear.LinearV1.bias}

> bias: Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]] | [None](https://docs.python.org/3/library/constants.html#None) = None

Optional bias tensor for the linear transformation.

### `create()` {#max.nn.linear.LinearV1.create}

> classmethod create(dtype, quantization\_encoding, in\_features, out\_features, weights, bias=None, quantization\_config=None)

Factory method to create a [`LinearV1`](#max.nn.linear.LinearV1) layer with appropriate implementation.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* dtype ([DType](../dtype.md#max.dtype.DType)) â€“ The `DType` for the layer.
* quantization\_encoding ([QuantizationEncoding](../graph/quantization.md#max.graph.quantization.QuantizationEncoding) | None) â€“ The `QuantizationEncoding` for the weights.
* in\_features ([int](https://docs.python.org/3/library/functions.html#int)) â€“ The input feature dimension.
* out\_features ([int](https://docs.python.org/3/library/functions.html#int)) â€“ The output feature dimension.
* weights ([Weights](../graph/weights.md#max.graph.weights.Weights) | [Weight](../graph/Weight.md#max.graph.Weight)) â€“ The `Weights` or `Weight` object for the layer.
* bias ([Weights](../graph/weights.md#max.graph.weights.Weights) | [Weight](../graph/Weight.md#max.graph.Weight) | None) â€“ Optional `Weights` or `Weight` object for bias.
* quantization\_config ([QuantizationConfig](../graph/quantization.md#max.graph.quantization.QuantizationConfig) | None) â€“ Optional `QuantizationConfig` for quantization.

</dd><dt>

**Returns:**

</dt><dd>

A [`LinearV1`](#max.nn.linear.LinearV1) instance.

</dd><dt>

**Return type:**

</dt><dd>

[LinearV1](#max.nn.linear.LinearV1)

</dd></dl>

### `weight` {#max.nn.linear.LinearV1.weight}

> weight: Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]]

The weight tensor for the linear transformation.

## `MLP` {#max.nn.linear.MLP}

> class max.nn.linear.MLP(dtype, quantization\_encoding, hidden\_dim, feed\_forward\_length, devices, linear\_cls=\<class 'max.nn.linear.Linear'>, has\_bias=False, activation\_function='silu', float8\_config=None, dist\_gemm\_config=None)

Simple multi-layer perceptron composed of three [`Linear`](#max.nn.linear.Linear) layers.
Defaults to SiLU activation function.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* dtype ([DType](../dtype.md#max.dtype.DType)) â€“ `DType` to use for the layer weights, which should match the
  input dtype.
* quantization\_encoding ([QuantizationEncoding](../graph/quantization.md#max.graph.quantization.QuantizationEncoding) | None) â€“ `QuantizationEncoding` of the layer weights.
* hidden\_dim ([int](https://docs.python.org/3/library/functions.html#int)) â€“ The last dimension of the layer input.
* feed\_forward\_length ([int](https://docs.python.org/3/library/functions.html#int)) â€“ Size of dimension used to project the inputs.
* linear\_cls (Callable\[..., [Linear](#max.nn.linear.Linear)]) â€“ [`Linear`](#max.nn.linear.Linear) class to use to create the projection layers.
* devices (Sequence\[[DeviceRef](../graph/type.md#max.graph.type.DeviceRef)]) â€“ `DeviceRef` devices to run the `MLP` layer. If multiple are provided,
  the first device is used instead. Use `DistributedMLP` to use
  all devices.
* has\_bias ([bool](https://docs.python.org/3/library/functions.html#bool)) â€“ Whether to include bias terms in the linear layers.
* activation\_function ([str](https://docs.python.org/3/library/stdtypes.html#str)) â€“

  Activation function to use. Options are:

  * `silu`
  * `gelu`
  * `gelu_tanh`
  * `relu`
  * `tanh`
  * `sigmoid`
* float8\_config (Float8Config | None) â€“ `Float8Config` for float8 quantization.
* dist\_gemm\_config ([DistributedGemmConfig](#max.nn.linear.DistributedGemmConfig) | None) â€“ [`DistributedGemmConfig`](#max.nn.linear.DistributedGemmConfig) for distributed GEMM configuration.

</dd></dl>

### `shard()` {#max.nn.linear.MLP.shard}

> shard(devices)

Creates sharded views of this MLP across multiple devices.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

devices ([Iterable](https://docs.python.org/3/library/collections.abc.html#collections.abc.Iterable)\[[DeviceRef](../graph/type.md#max.graph.type.DeviceRef)]) â€“ Iterable of devices to place the shards on.

</dd><dt>

**Returns:**

</dt><dd>

List of sharded MLP instances, one for each device.

</dd><dt>

**Return type:**

</dt><dd>

[list](https://docs.python.org/3/library/stdtypes.html#list)\[[MLP](#max.nn.linear.MLP)]

</dd></dl>

### `sharding_strategy` {#max.nn.linear.MLP.sharding_strategy}

> property sharding\_strategy: ShardingStrategy | [None](https://docs.python.org/3/library/constants.html#None)

Get the MLP sharding strategy.

## `MLPV1` {#max.nn.linear.MLPV1}

> class max.nn.linear.MLPV1(gate\_proj, down\_proj, up\_proj)

Simple multi-layer perceptron composed of three [`LinearV1`](#max.nn.linear.LinearV1) layers.
Uses SiLU activation function.

#### Deprecated

Deprecated since version 25.5: Use [`MLP`](#max.nn.linear.MLP) instead.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* gate\_proj ([LinearV1](#max.nn.linear.LinearV1))
* down\_proj ([LinearV1](#max.nn.linear.LinearV1))
* up\_proj ([LinearV1](#max.nn.linear.LinearV1))

</dd></dl>

### `down_proj` {#max.nn.linear.MLPV1.down_proj}

> down\_proj: [LinearV1](#max.nn.linear.LinearV1)

The down projection [`LinearV1`](#max.nn.linear.LinearV1) layer.

### `gate_proj` {#max.nn.linear.MLPV1.gate_proj}

> gate\_proj: [LinearV1](#max.nn.linear.LinearV1)

The gate projection [`LinearV1`](#max.nn.linear.LinearV1) layer.

### `up_proj` {#max.nn.linear.MLPV1.up_proj}

> up\_proj: [LinearV1](#max.nn.linear.LinearV1)

The up projection [`LinearV1`](#max.nn.linear.LinearV1) layer.

## `QLinearV1` {#max.nn.linear.QLinearV1}

> class max.nn.linear.QLinearV1(weight, bias=None, quantization\_encoding=None)

A quantized fully connected layer.

#### Deprecated

Deprecated since version 25.5: Use [`Linear`](#max.nn.linear.Linear) instead.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* weight (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])
* bias (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]] | None)
* quantization\_encoding ([QuantizationEncoding](../graph/quantization.md#max.graph.quantization.QuantizationEncoding) | None)

</dd></dl>

### `quantization_encoding` {#max.nn.linear.QLinearV1.quantization_encoding}

> quantization\_encoding: [QuantizationEncoding](../graph/quantization.md#max.graph.quantization.QuantizationEncoding) | [None](https://docs.python.org/3/library/constants.html#None) = None

The `QuantizationEncoding` for the quantized weights.

---

## group_norm

Group Normalization implementation using the graph API.

## `GroupNorm` {#max.nn.norm.group_norm.GroupNorm}

> class max.nn.norm.group\_norm.GroupNorm(num\_groups, num\_channels, eps=1e-05, affine=True, device=gpu:0)

Group normalization block.

Divides channels into groups and computes normalization stats per group.
Follows the implementation pattern from PyTorchâ€™s group\_norm.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* num\_groups ([int](https://docs.python.org/3/library/functions.html#int)) â€“ Number of groups to separate the channels into
* num\_channels ([int](https://docs.python.org/3/library/functions.html#int)) â€“ Number of input channels
* eps ([float](https://docs.python.org/3/library/functions.html#float)) â€“ Small constant added to denominator for numerical stability
* affine ([bool](https://docs.python.org/3/library/functions.html#bool)) â€“ If True, apply learnable affine transform parameters
* device ([DeviceRef](../../graph/type.md#max.graph.type.DeviceRef))

</dd></dl>

---

## norm

## Modules

* [`group_norm`](/max/api/python/nn/norm/group_norm)
* [`layer_norm`](/max/api/python/nn/norm/layer_norm)
* [`rms_norm`](/max/api/python/nn/norm/rms_norm)

---

## layer_norm

Layer Normalization layer.

## `LayerNorm` {#max.nn.norm.layer_norm.LayerNorm}

> class max.nn.norm.layer\_norm.LayerNorm(dims, device, dtype, eps=1e-05, use\_bias=True)

Layer normalization block.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* dims ([int](https://docs.python.org/3/library/functions.html#int))
* device ([DeviceRef](../../graph/type.md#max.graph.type.DeviceRef))
* dtype ([DType](../../dtype.md#max.dtype.DType))
* eps ([float](https://docs.python.org/3/library/functions.html#float))
* use\_bias ([bool](https://docs.python.org/3/library/functions.html#bool))

</dd></dl>

## `LayerNormV1` {#max.nn.norm.layer_norm.LayerNormV1}

> class max.nn.norm.layer\_norm.LayerNormV1(weight, bias=None, eps=1e-06)

Layer normalization block.

Deprecated: Use LayerNorm instead.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* weight ([TensorValue](../../graph/TensorValue.md#max.graph.TensorValue))
* bias ([TensorValue](../../graph/TensorValue.md#max.graph.TensorValue) | None)
* eps ([float](https://docs.python.org/3/library/functions.html#float))

</dd></dl>

### `bias` {#max.nn.norm.layer_norm.LayerNormV1.bias}

> bias: [TensorValue](../../graph/TensorValue.md#max.graph.TensorValue) | [None](https://docs.python.org/3/library/constants.html#None) = None

### `eps` {#max.nn.norm.layer_norm.LayerNormV1.eps}

> eps: [float](https://docs.python.org/3/library/functions.html#float) = 1e-06

### `weight` {#max.nn.norm.layer_norm.LayerNormV1.weight}

> weight: [TensorValue](../../graph/TensorValue.md#max.graph.TensorValue)

---

## rms_norm

Normalization layer.

## `RMSNorm` {#max.nn.norm.rms_norm.RMSNorm}

> class max.nn.norm.rms\_norm.RMSNorm(dim, dtype, eps=1e-06, weight\_offset=0.0, multiply\_before\_cast=True)

Computes the Root Mean Square normalization on inputs.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* dim ([int](https://docs.python.org/3/library/functions.html#int)) â€“ Size of last dimension of the expected input.
* eps ([float](https://docs.python.org/3/library/functions.html#float)) â€“ Value added to denominator for numerical stability.
* weight\_offset ([float](https://docs.python.org/3/library/functions.html#float)) â€“ Constant offset added to the learned weights at runtime.
  For Gemma-style RMSNorm, this should be set to 1.0.
* multiply\_before\_cast ([bool](https://docs.python.org/3/library/functions.html#bool)) â€“ True if we multiply the inputs by the learned
  weights before casting to the input type (Gemma3-style). False if we
  cast the inputs to the input type first, then multiply by the learned
  weights (Llama-style).
* dtype ([DType](../../dtype.md#max.dtype.DType))

</dd></dl>

### `shard()` {#max.nn.norm.rms_norm.RMSNorm.shard}

> shard(devices)

Creates sharded views of this RMSNorm across multiple devices.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

devices ([Iterable](https://docs.python.org/3/library/collections.abc.html#collections.abc.Iterable)\[[DeviceRef](../../graph/type.md#max.graph.type.DeviceRef)]) â€“ Iterable of devices to place the shards on.

</dd><dt>

**Returns:**

</dt><dd>

List of sharded RMSNorm instances, one for each device.

</dd><dt>

**Return type:**

</dt><dd>

[Sequence](https://docs.python.org/3/library/collections.abc.html#collections.abc.Sequence)\[[RMSNorm](#max.nn.norm.rms_norm.RMSNorm)]

</dd></dl>

### `sharding_strategy` {#max.nn.norm.rms_norm.RMSNorm.sharding_strategy}

> property sharding\_strategy: ShardingStrategy | [None](https://docs.python.org/3/library/constants.html#None)

Get the RMSNorm sharding strategy.

## `RMSNormV1` {#max.nn.norm.rms_norm.RMSNormV1}

> class max.nn.norm.rms\_norm.RMSNormV1(weight, eps=1e-06, weight\_offset=0.0, multiply\_before\_cast=True)

Computes the Root Mean Square normalization on inputs.

Deprecated: Use RMSNorm instead.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* weight (Value\[TensorType] | [TensorValue](../../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../../graph/shape.md#max.graph.shape.Shape) | [Dim](../../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])
* eps ([float](https://docs.python.org/3/library/functions.html#float))
* weight\_offset ([float](https://docs.python.org/3/library/functions.html#float))
* multiply\_before\_cast ([bool](https://docs.python.org/3/library/functions.html#bool))

</dd></dl>

### `eps` {#max.nn.norm.rms_norm.RMSNormV1.eps}

> eps: [float](https://docs.python.org/3/library/functions.html#float) = 1e-06

### `multiply_before_cast` {#max.nn.norm.rms_norm.RMSNormV1.multiply_before_cast}

> multiply\_before\_cast: [bool](https://docs.python.org/3/library/functions.html#bool) = True

### `weight` {#max.nn.norm.rms_norm.RMSNormV1.weight}

> weight: Value\[TensorType] | [TensorValue](../../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../../graph/shape.md#max.graph.shape.Shape) | [Dim](../../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]]

### `weight_offset` {#max.nn.norm.rms_norm.RMSNormV1.weight_offset}

> weight\_offset: [float](https://docs.python.org/3/library/functions.html#float) = 0.0

---

## rotary_embedding

The rope embedding used within the model.

## `DeepseekYarnRopeScalingParams` {#max.nn.rotary_embedding.DeepseekYarnRopeScalingParams}

> class max.nn.rotary\_embedding.DeepseekYarnRopeScalingParams(scaling\_factor: [float](https://docs.python.org/3/library/functions.html#float), original\_max\_position\_embeddings: [int](https://docs.python.org/3/library/functions.html#int), beta\_fast: [int](https://docs.python.org/3/library/functions.html#int), beta\_slow: [int](https://docs.python.org/3/library/functions.html#int), mscale: [float](https://docs.python.org/3/library/functions.html#float), mscale\_all\_dim: [float](https://docs.python.org/3/library/functions.html#float))

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* scaling\_factor ([float](https://docs.python.org/3/library/functions.html#float))
* original\_max\_position\_embeddings ([int](https://docs.python.org/3/library/functions.html#int))
* beta\_fast ([int](https://docs.python.org/3/library/functions.html#int))
* beta\_slow ([int](https://docs.python.org/3/library/functions.html#int))
* mscale ([float](https://docs.python.org/3/library/functions.html#float))
* mscale\_all\_dim ([float](https://docs.python.org/3/library/functions.html#float))

</dd></dl>

### `beta_fast` {#max.nn.rotary_embedding.DeepseekYarnRopeScalingParams.beta_fast}

> beta\_fast: [int](https://docs.python.org/3/library/functions.html#int)

Fast interpolation rate.

### `beta_slow` {#max.nn.rotary_embedding.DeepseekYarnRopeScalingParams.beta_slow}

> beta\_slow: [int](https://docs.python.org/3/library/functions.html#int)

Slow interpolation rate.

### `mscale` {#max.nn.rotary_embedding.DeepseekYarnRopeScalingParams.mscale}

> mscale: [float](https://docs.python.org/3/library/functions.html#float)

Scaling factor for middle frequencies.

### `mscale_all_dim` {#max.nn.rotary_embedding.DeepseekYarnRopeScalingParams.mscale_all_dim}

> mscale\_all\_dim: [float](https://docs.python.org/3/library/functions.html#float)

Scaling factor applied to all dimensions.

### `original_max_position_embeddings` {#max.nn.rotary_embedding.DeepseekYarnRopeScalingParams.original_max_position_embeddings}

> original\_max\_position\_embeddings: [int](https://docs.python.org/3/library/functions.html#int)

Original maximum sequence length during training.

### `scaling_factor` {#max.nn.rotary_embedding.DeepseekYarnRopeScalingParams.scaling_factor}

> scaling\_factor: [float](https://docs.python.org/3/library/functions.html#float)

Scaling factor for frequency interpolation.

## `DeepseekYarnRotaryEmbedding` {#max.nn.rotary_embedding.DeepseekYarnRotaryEmbedding}

> class max.nn.rotary\_embedding.DeepseekYarnRotaryEmbedding(dim, n\_heads, theta, max\_seq\_len, device, head\_dim=None, \_freqs\_cis=None, interleaved=True, scaling\_params=None)

Deepseekâ€™s YaRN (Yet another RoPE eNhancement) Rotary Position Embedding layer.

Unlike Llama3RotaryEmbedding, the dim argument here is the rope dimension
of the model, not the hidden dimension.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* dim ([int](https://docs.python.org/3/library/functions.html#int))
* n\_heads ([int](https://docs.python.org/3/library/functions.html#int))
* theta ([float](https://docs.python.org/3/library/functions.html#float))
* max\_seq\_len ([int](https://docs.python.org/3/library/functions.html#int))
* device ([DeviceRef](../graph/type.md#max.graph.type.DeviceRef))
* head\_dim ([int](https://docs.python.org/3/library/functions.html#int))
* \_freqs\_cis (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]] | None)
* interleaved ([bool](https://docs.python.org/3/library/functions.html#bool))
* scaling\_params ([DeepseekYarnRopeScalingParams](#max.nn.rotary_embedding.DeepseekYarnRopeScalingParams) | None)

</dd></dl>

### `compute_scale()` {#max.nn.rotary_embedding.DeepseekYarnRotaryEmbedding.compute_scale}

> compute\_scale(user\_scale=None)

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

user\_scale ([float](https://docs.python.org/3/library/functions.html#float) | None)

</dd><dt>

**Return type:**

</dt><dd>

[float](https://docs.python.org/3/library/functions.html#float)

</dd></dl>

### `freqs_cis_base()` {#max.nn.rotary_embedding.DeepseekYarnRotaryEmbedding.freqs_cis_base}

> freqs\_cis\_base()

Computes the frequency tensor for complex exponentials (cis)
for a given seq\_len. Tensor is scaled with theta parameter.
Required to apply Rotary Position Embedding (RoPE) to tensor.
See â€˜Roformer: Enhanced Transformer with Rotary Embeddingâ€™
(arxiv.org/pdf/2104.09864).

<dl class='field-list'><dt>

**Returns:**

</dt><dd>

The frequency tensor for complex exponentials with shape
(max\_seq\_len, rope\_dim // 2, 2)

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](../graph/TensorValue.md#max.graph.TensorValue)

</dd></dl>

### `scaling_params` {#max.nn.rotary_embedding.DeepseekYarnRotaryEmbedding.scaling_params}

> scaling\_params: [DeepseekYarnRopeScalingParams](#max.nn.rotary_embedding.DeepseekYarnRopeScalingParams) | [None](https://docs.python.org/3/library/constants.html#None) = None

## `DynamicRotaryEmbedding` {#max.nn.rotary_embedding.DynamicRotaryEmbedding}

> class max.nn.rotary\_embedding.DynamicRotaryEmbedding(dim, n\_heads, theta, max\_seq\_len, device, head\_dim=None, \_freqs\_cis=None, interleaved=True)

RotaryEmbedding with dynamic scaling support for long-context inference.

Dynamically updates the inv\_freq and corresponding freqs\_cis buffer if the
current sequence length exceeds the original max, or resets to the original
high-precision version for short sequences.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* dim ([int](https://docs.python.org/3/library/functions.html#int))
* n\_heads ([int](https://docs.python.org/3/library/functions.html#int))
* theta ([float](https://docs.python.org/3/library/functions.html#float))
* max\_seq\_len ([int](https://docs.python.org/3/library/functions.html#int))
* device ([DeviceRef](../graph/type.md#max.graph.type.DeviceRef))
* head\_dim ([int](https://docs.python.org/3/library/functions.html#int))
* \_freqs\_cis (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]] | None)
* interleaved ([bool](https://docs.python.org/3/library/functions.html#bool))

</dd></dl>

### `freqs_cis_base()` {#max.nn.rotary_embedding.DynamicRotaryEmbedding.freqs_cis_base}

> freqs\_cis\_base()

Computes freqs\_cis dynamically using the current self.inv\_freq.

<dl class='field-list'><dt>

**Return type:**

</dt><dd>

[TensorValue](../graph/TensorValue.md#max.graph.TensorValue)

</dd></dl>

### `maybe_update_freqs()` {#max.nn.rotary_embedding.DynamicRotaryEmbedding.maybe_update_freqs}

> maybe\_update\_freqs(position\_ids)

Update freqs\_cis if the sequence exceeds max\_seq\_len\_cached, or revert
to the original version if back below the threshold.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

position\_ids (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])

</dd><dt>

**Return type:**

</dt><dd>

None

</dd></dl>

## `LinearScalingParams` {#max.nn.rotary_embedding.LinearScalingParams}

> class max.nn.rotary\_embedding.LinearScalingParams(factor: [float](https://docs.python.org/3/library/functions.html#float))

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

factor ([float](https://docs.python.org/3/library/functions.html#float))

</dd></dl>

### `factor` {#max.nn.rotary_embedding.LinearScalingParams.factor}

> factor: [float](https://docs.python.org/3/library/functions.html#float)

Main scaling factor for the frequency components of the rope.

## `Llama3RopeScalingParams` {#max.nn.rotary_embedding.Llama3RopeScalingParams}

> class max.nn.rotary\_embedding.Llama3RopeScalingParams(factor: [float](https://docs.python.org/3/library/functions.html#float), low\_freq\_factor: [float](https://docs.python.org/3/library/functions.html#float), high\_freq\_factor: [float](https://docs.python.org/3/library/functions.html#float), orig\_max\_position: [int](https://docs.python.org/3/library/functions.html#int))

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* factor ([float](https://docs.python.org/3/library/functions.html#float))
* low\_freq\_factor ([float](https://docs.python.org/3/library/functions.html#float))
* high\_freq\_factor ([float](https://docs.python.org/3/library/functions.html#float))
* orig\_max\_position ([int](https://docs.python.org/3/library/functions.html#int))

</dd></dl>

### `factor` {#max.nn.rotary_embedding.Llama3RopeScalingParams.factor}

> factor: [float](https://docs.python.org/3/library/functions.html#float)

Main scaling factor for the frequency components of the rope.

### `high_freq_factor` {#max.nn.rotary_embedding.Llama3RopeScalingParams.high_freq_factor}

> high\_freq\_factor: [float](https://docs.python.org/3/library/functions.html#float)

Factor to scale the high frequency components of the rope.

### `low_freq_factor` {#max.nn.rotary_embedding.Llama3RopeScalingParams.low_freq_factor}

> low\_freq\_factor: [float](https://docs.python.org/3/library/functions.html#float)

Factor to scale the low frequency components of the rope.

### `orig_max_position` {#max.nn.rotary_embedding.Llama3RopeScalingParams.orig_max_position}

> orig\_max\_position: [int](https://docs.python.org/3/library/functions.html#int)

The original maximum position length supported by the model.

## `Llama3RotaryEmbedding` {#max.nn.rotary_embedding.Llama3RotaryEmbedding}

> class max.nn.rotary\_embedding.Llama3RotaryEmbedding(dim, n\_heads, theta, max\_seq\_len, device, head\_dim=None, \_freqs\_cis=None, interleaved=True, scaling\_params=None)

RotaryEmbedding for Llama3 that takes rope scaling into account.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* dim ([int](https://docs.python.org/3/library/functions.html#int))
* n\_heads ([int](https://docs.python.org/3/library/functions.html#int))
* theta ([float](https://docs.python.org/3/library/functions.html#float))
* max\_seq\_len ([int](https://docs.python.org/3/library/functions.html#int))
* device ([DeviceRef](../graph/type.md#max.graph.type.DeviceRef))
* head\_dim ([int](https://docs.python.org/3/library/functions.html#int))
* \_freqs\_cis (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]] | None)
* interleaved ([bool](https://docs.python.org/3/library/functions.html#bool))
* scaling\_params ([Llama3RopeScalingParams](#max.nn.rotary_embedding.Llama3RopeScalingParams) | None)

</dd></dl>

### `scaling_params` {#max.nn.rotary_embedding.Llama3RotaryEmbedding.scaling_params}

> scaling\_params: [Llama3RopeScalingParams](#max.nn.rotary_embedding.Llama3RopeScalingParams) | [None](https://docs.python.org/3/library/constants.html#None) = None

Scaling parameters to enable llama to function with a longer context length.

## `LongRoPERotaryEmbedding` {#max.nn.rotary_embedding.LongRoPERotaryEmbedding}

> class max.nn.rotary\_embedding.LongRoPERotaryEmbedding(dim, n\_heads, theta, max\_seq\_len, device, head\_dim=None, \_freqs\_cis=None, interleaved=True, scaling\_params=None)

Rotary position embedding with LongRoPE scaling for Phi-3.5 models.

Initialize LongRoPE rotary embeddings.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* dim ([int](https://docs.python.org/3/library/functions.html#int)) â€“ Model dimension
* n\_heads ([int](https://docs.python.org/3/library/functions.html#int)) â€“ Number of attention heads
* theta ([float](https://docs.python.org/3/library/functions.html#float)) â€“ Base for computing frequencies (usually 10000.0)
* max\_seq\_len ([int](https://docs.python.org/3/library/functions.html#int)) â€“ Maximum sequence length
* device ([DeviceRef](../graph/type.md#max.graph.type.DeviceRef)) â€“ Device to place tensors on
* head\_dim ([int](https://docs.python.org/3/library/functions.html#int)) â€“ Head dimension (if None, computed as dim // n\_heads)
* \_freqs\_cis (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]] | None) â€“ Pre-computed frequency tensor (optional)
* interleaved ([bool](https://docs.python.org/3/library/functions.html#bool)) â€“ Whether to use interleaved RoPE weights
* scaling\_params ([LongRoPEScalingParams](#max.nn.rotary_embedding.LongRoPEScalingParams) | None) â€“ LongRoPE scaling parameters

</dd></dl>

### `compute_scale()` {#max.nn.rotary_embedding.LongRoPERotaryEmbedding.compute_scale}

> compute\_scale(user\_scale=None)

Compute attention scale with LongRoPE adjustment.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

user\_scale ([float](https://docs.python.org/3/library/functions.html#float) | None)

</dd><dt>

**Return type:**

</dt><dd>

[float](https://docs.python.org/3/library/functions.html#float)

</dd></dl>

### `freqs_cis_base()` {#max.nn.rotary_embedding.LongRoPERotaryEmbedding.freqs_cis_base}

> freqs\_cis\_base()

Computes the frequency tensor for complex exponentials (cis)
with LongRoPE scaling. Creates a â€œstitchedâ€ table where:

* Positions 0 to original\_max\_position use short\_factor
* Positions from original\_max\_position onwards use long\_factor

<dl class='field-list'><dt>

**Returns:**

</dt><dd>

The frequency tensor for complex exponentials with shape (max\_seq\_len \* 2, head\_dim / 2, 2)

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](../graph/TensorValue.md#max.graph.TensorValue)

</dd></dl>

## `LongRoPEScalingParams` {#max.nn.rotary_embedding.LongRoPEScalingParams}

> class max.nn.rotary\_embedding.LongRoPEScalingParams(short\_factor, long\_factor, original\_max\_position, max\_position\_embeddings)

Parameters for LongRoPE scaling as used in Phi-3.5 models.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* short\_factor ([list](https://docs.python.org/3/library/stdtypes.html#list)\[[float](https://docs.python.org/3/library/functions.html#float)])
* long\_factor ([list](https://docs.python.org/3/library/stdtypes.html#list)\[[float](https://docs.python.org/3/library/functions.html#float)])
* original\_max\_position ([int](https://docs.python.org/3/library/functions.html#int))
* max\_position\_embeddings ([int](https://docs.python.org/3/library/functions.html#int))

</dd></dl>

### `long_factor` {#max.nn.rotary_embedding.LongRoPEScalingParams.long_factor}

> long\_factor: [list](https://docs.python.org/3/library/stdtypes.html#list)\[[float](https://docs.python.org/3/library/functions.html#float)]

Scaling factors for long sequences (can be much larger).

### `max_position_embeddings` {#max.nn.rotary_embedding.LongRoPEScalingParams.max_position_embeddings}

> max\_position\_embeddings: [int](https://docs.python.org/3/library/functions.html#int)

Current max position embeddings after scaling.

### `original_max_position` {#max.nn.rotary_embedding.LongRoPEScalingParams.original_max_position}

> original\_max\_position: [int](https://docs.python.org/3/library/functions.html#int)

Original max position embeddings the model was trained with.

### `short_factor` {#max.nn.rotary_embedding.LongRoPEScalingParams.short_factor}

> short\_factor: [list](https://docs.python.org/3/library/stdtypes.html#list)\[[float](https://docs.python.org/3/library/functions.html#float)]

Scaling factors for short sequences (typically close to 1.0).

## `RotaryEmbedding` {#max.nn.rotary_embedding.RotaryEmbedding}

> class max.nn.rotary\_embedding.RotaryEmbedding(dim, n\_heads, theta, max\_seq\_len, device, head\_dim=None, \_freqs\_cis=None, interleaved=True)

RotaryEmbedding layer to calculate and apply the frequency tensor for complex exponentials.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* dim ([int](https://docs.python.org/3/library/functions.html#int))
* n\_heads ([int](https://docs.python.org/3/library/functions.html#int))
* theta ([float](https://docs.python.org/3/library/functions.html#float))
* max\_seq\_len ([int](https://docs.python.org/3/library/functions.html#int))
* device ([DeviceRef](../graph/type.md#max.graph.type.DeviceRef))
* head\_dim ([int](https://docs.python.org/3/library/functions.html#int))
* \_freqs\_cis (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]] | None)
* interleaved ([bool](https://docs.python.org/3/library/functions.html#bool))

</dd></dl>

### `compute_scale()` {#max.nn.rotary_embedding.RotaryEmbedding.compute_scale}

> compute\_scale(user\_scale=None)

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

user\_scale ([float](https://docs.python.org/3/library/functions.html#float) | None)

</dd><dt>

**Return type:**

</dt><dd>

[float](https://docs.python.org/3/library/functions.html#float)

</dd></dl>

### `device` {#max.nn.rotary_embedding.RotaryEmbedding.device}

> device: [DeviceRef](../graph/type.md#max.graph.type.DeviceRef)

### `dim` {#max.nn.rotary_embedding.RotaryEmbedding.dim}

> dim: [int](https://docs.python.org/3/library/functions.html#int)

### `freqs_cis` {#max.nn.rotary_embedding.RotaryEmbedding.freqs_cis}

> property freqs\_cis: [TensorValue](../graph/TensorValue.md#max.graph.TensorValue)

### `freqs_cis_base()` {#max.nn.rotary_embedding.RotaryEmbedding.freqs_cis_base}

> freqs\_cis\_base()

Computes the frequency tensor for complex exponentials (cis)
for a given seq\_len. Tensor is scaled with theta parameter.
Required to apply Rotary Position Embedding (RoPE) to tensor.
See â€˜Roformer: Enhanced Transformer with Rotary Embeddingâ€™
(arxiv.org/pdf/2104.09864).

<dl class='field-list'><dt>

**Returns:**

</dt><dd>

The frequency tensor for complex exponentials with shape (max\_seq\_len \* 2, head\_dim / 2, 2)

</dd><dt>

**Return type:**

</dt><dd>

[TensorValue](../graph/TensorValue.md#max.graph.TensorValue)

</dd></dl>

### `head_dim` {#max.nn.rotary_embedding.RotaryEmbedding.head_dim}

> head\_dim: [int](https://docs.python.org/3/library/functions.html#int)

head\_dim = dim // n\_heads if not specified in the config.

### `interleaved` {#max.nn.rotary_embedding.RotaryEmbedding.interleaved}

> interleaved: [bool](https://docs.python.org/3/library/functions.html#bool) = True

### `max_seq_len` {#max.nn.rotary_embedding.RotaryEmbedding.max_seq_len}

> max\_seq\_len: [int](https://docs.python.org/3/library/functions.html#int)

The maximum sequence length for modelâ€™s input.

### `n_heads` {#max.nn.rotary_embedding.RotaryEmbedding.n_heads}

> n\_heads: [int](https://docs.python.org/3/library/functions.html#int)

### `theta` {#max.nn.rotary_embedding.RotaryEmbedding.theta}

> theta: [float](https://docs.python.org/3/library/functions.html#float)

Hyperparameter used to control the frequency scaling of the sinusoidal components of the embeddings.

## `YarnRotaryEmbedding` {#max.nn.rotary_embedding.YarnRotaryEmbedding}

> class max.nn.rotary\_embedding.YarnRotaryEmbedding(dim, n\_heads, theta, max\_seq\_len, device, head\_dim=None, \_freqs\_cis=None, interleaved=True, scaling\_params=None)

Generic YaRN (Yet another RoPE eNhancement) Rotary Position Embedding layer.

This implementation provides YARN scaling for models that require it,
with configurable parameters for beta\_fast, beta\_slow, and scaling factor.

Initialize YarnRotaryEmbedding.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* dim ([int](https://docs.python.org/3/library/functions.html#int)) â€“ The dimension of the rotary embedding (usually hidden\_size).
* n\_heads ([int](https://docs.python.org/3/library/functions.html#int)) â€“ Number of attention heads.
* theta ([float](https://docs.python.org/3/library/functions.html#float)) â€“ Base frequency for rotary embeddings.
* max\_seq\_len ([int](https://docs.python.org/3/library/functions.html#int)) â€“ Maximum sequence length.
* device ([DeviceRef](../graph/type.md#max.graph.type.DeviceRef)) â€“ Device to place the embeddings on.
* head\_dim ([int](https://docs.python.org/3/library/functions.html#int) | None) â€“ Optional head dimension override.
* \_freqs\_cis (Value\[TensorType] | [TensorValue](../graph/TensorValue.md#max.graph.TensorValue) | [Shape](../graph/shape.md#max.graph.shape.Shape) | [Dim](../graph/dim.md#max.graph.dim.Dim) | HasTensorValue | [int](https://docs.python.org/3/library/functions.html#int) | [float](https://docs.python.org/3/library/functions.html#float) | [integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[number](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.number)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]] | None) â€“ Optional precomputed frequencies.
* interleaved ([bool](https://docs.python.org/3/library/functions.html#bool)) â€“ Whether to use interleaved complex format.
* scaling\_params ([YarnScalingParams](#max.nn.rotary_embedding.YarnScalingParams) | None) â€“ YARN scaling parameters.

</dd></dl>

### `freqs_cis_base()` {#max.nn.rotary_embedding.YarnRotaryEmbedding.freqs_cis_base}

> freqs\_cis\_base()

Computes the frequency tensor for complex exponentials (cis)
with YARN scaling applied.

<dl class='field-list'><dt>

**Return type:**

</dt><dd>

[TensorValue](../graph/TensorValue.md#max.graph.TensorValue)

</dd></dl>

### `scaling_params` {#max.nn.rotary_embedding.YarnRotaryEmbedding.scaling_params}

> scaling\_params: [YarnScalingParams](#max.nn.rotary_embedding.YarnScalingParams) | [None](https://docs.python.org/3/library/constants.html#None) = None

## `YarnScalingParams` {#max.nn.rotary_embedding.YarnScalingParams}

> class max.nn.rotary\_embedding.YarnScalingParams(factor: [float](https://docs.python.org/3/library/functions.html#float), beta\_fast: [float](https://docs.python.org/3/library/functions.html#float), beta\_slow: [float](https://docs.python.org/3/library/functions.html#float), original\_max\_position\_embeddings: [int](https://docs.python.org/3/library/functions.html#int), truncate: [bool](https://docs.python.org/3/library/functions.html#bool))

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* factor ([float](https://docs.python.org/3/library/functions.html#float))
* beta\_fast ([float](https://docs.python.org/3/library/functions.html#float))
* beta\_slow ([float](https://docs.python.org/3/library/functions.html#float))
* original\_max\_position\_embeddings ([int](https://docs.python.org/3/library/functions.html#int))
* truncate ([bool](https://docs.python.org/3/library/functions.html#bool))

</dd></dl>

### `beta_fast` {#max.nn.rotary_embedding.YarnScalingParams.beta_fast}

> beta\_fast: [float](https://docs.python.org/3/library/functions.html#float)

Yarn parameter for fast frequencies.

### `beta_slow` {#max.nn.rotary_embedding.YarnScalingParams.beta_slow}

> beta\_slow: [float](https://docs.python.org/3/library/functions.html#float)

Yarn parameter for slow frequencies.

### `factor` {#max.nn.rotary_embedding.YarnScalingParams.factor}

> factor: [float](https://docs.python.org/3/library/functions.html#float)

Main scaling factor for the frequency components of the rope.

### `original_max_position_embeddings` {#max.nn.rotary_embedding.YarnScalingParams.original_max_position_embeddings}

> original\_max\_position\_embeddings: [int](https://docs.python.org/3/library/functions.html#int)

The original maximum position length supported by the model.

### `truncate` {#max.nn.rotary_embedding.YarnScalingParams.truncate}

> truncate: [bool](https://docs.python.org/3/library/functions.html#bool)

Whether to truncate the frequencies or not.

---

## sequential

A General sequential layer, each layer is executed with the outputs of the previous.

## `Sequential` {#max.nn.sequential.Sequential}

> class max.nn.sequential.Sequential(layers)

A sequential stack of layers where each layer is called by the outputs
of the previous layer.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

layers ([Sequence](https://docs.python.org/3/library/collections.abc.html#collections.abc.Sequence)\[[Layer](layer.md#max.nn.layer.Layer)])

</dd></dl>

---

## distributed_transformer

## `DistributedTransformer` {#max.nn.transformer.distributed_transformer.DistributedTransformer}

> class max.nn.transformer.distributed\_transformer.DistributedTransformer(dim, n\_heads, layers, norm, output, embedding, kv\_params, kv\_collection\_constructor, devices, rope, return\_logits=ReturnLogits.LAST\_TOKEN, use\_subgraphs=False, subgraph\_layer\_groups=None, logits\_scaling=1.0)

Transformer model consisting for TransformerBlock layers.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* dim ([int](https://docs.python.org/3/library/functions.html#int))
* n\_heads ([int](https://docs.python.org/3/library/functions.html#int))
* layers ([list](https://docs.python.org/3/library/stdtypes.html#list)\[[DistributedTransformerBlock](#max.nn.transformer.distributed_transformer.DistributedTransformerBlock)])
* norm ([ShardableCallable](#max.nn.transformer.distributed_transformer.ShardableCallable))
* output ([ColumnParallelLinear](../linear.md#max.nn.linear.ColumnParallelLinear))
* embedding ([VocabParallelEmbedding](../embedding.md#max.nn.embedding.VocabParallelEmbedding))
* kv\_params ([KVCacheParams](../kv_cache/cache_params.md#max.nn.kv_cache.cache_params.KVCacheParams))
* kv\_collection\_constructor (FetchPagedKVCacheCollection)
* devices ([list](https://docs.python.org/3/library/stdtypes.html#list)\[[DeviceRef](../../graph/type.md#max.graph.type.DeviceRef)])
* rope ([RotaryEmbedding](../rotary_embedding.md#max.nn.rotary_embedding.RotaryEmbedding))
* return\_logits ([ReturnLogits](transformer.md#max.nn.transformer.transformer.ReturnLogits))
* use\_subgraphs ([bool](https://docs.python.org/3/library/functions.html#bool))
* subgraph\_layer\_groups ([list](https://docs.python.org/3/library/stdtypes.html#list)\[[list](https://docs.python.org/3/library/stdtypes.html#list)\[[int](https://docs.python.org/3/library/functions.html#int)]] | None)
* logits\_scaling ([float](https://docs.python.org/3/library/functions.html#float))

</dd></dl>

## `DistributedTransformerBlock` {#max.nn.transformer.distributed_transformer.DistributedTransformerBlock}

> class max.nn.transformer.distributed\_transformer.DistributedTransformerBlock(attention, mlp, attention\_norm, mlp\_norm, devices, distributed\_gemm\_config=None)

Stack of Attention, FeedForward, and RMSNorm layers.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* attention ([Module](../layer.md#max.nn.layer.Module))
* mlp ([ShardableCallable](#max.nn.transformer.distributed_transformer.ShardableCallable))
* attention\_norm ([ShardableCallable](#max.nn.transformer.distributed_transformer.ShardableCallable))
* mlp\_norm ([ShardableCallable](#max.nn.transformer.distributed_transformer.ShardableCallable))
* devices ([list](https://docs.python.org/3/library/stdtypes.html#list)\[[DeviceRef](../../graph/type.md#max.graph.type.DeviceRef)])
* distributed\_gemm\_config ([DistributedGemmConfig](../linear.md#max.nn.linear.DistributedGemmConfig) | None)

</dd></dl>

## `ShardableCallable` {#max.nn.transformer.distributed_transformer.ShardableCallable}

> class max.nn.transformer.distributed\_transformer.ShardableCallable(\*args, \*\*kwargs)

## `distribute_value()` {#max.nn.transformer.distributed_transformer.distribute_value}

> max.nn.transformer.distributed\_transformer.distribute\_value(v, devices)

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* v ([TensorValue](../../graph/TensorValue.md#max.graph.TensorValue))
* devices ([list](https://docs.python.org/3/library/stdtypes.html#list)\[[DeviceRef](../../graph/type.md#max.graph.type.DeviceRef)])

</dd><dt>

**Return type:**

</dt><dd>

[list](https://docs.python.org/3/library/stdtypes.html#list)\[[TensorValue](../../graph/TensorValue.md#max.graph.TensorValue)]

</dd></dl>

## `forward_sharded_layers()` {#max.nn.transformer.distributed_transformer.forward_sharded_layers}

> max.nn.transformer.distributed\_transformer.forward\_sharded\_layers(layers, xs)

Forward pass through sharded layers.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* layers ([Sequence](https://docs.python.org/3/library/collections.abc.html#collections.abc.Sequence)\[[Callable](https://docs.python.org/3/library/typing.html#typing.Callable)\[\[[TensorValue](../../graph/TensorValue.md#max.graph.TensorValue)], [TensorValue](../../graph/TensorValue.md#max.graph.TensorValue)]]) â€“ Sequence of callable layers that return TensorValue
* xs ([Sequence](https://docs.python.org/3/library/collections.abc.html#collections.abc.Sequence)\[[TensorValue](../../graph/TensorValue.md#max.graph.TensorValue)]) â€“ Input tensors, one per layer

</dd><dt>

**Returns:**

</dt><dd>

List of output tensors from each layer

</dd><dt>

**Raises:**

</dt><dd>

[AssertionError](https://docs.python.org/3/library/exceptions.html#AssertionError) â€“ If the number of layers and input tensors donâ€™t match

</dd><dt>

**Return type:**

</dt><dd>

[list](https://docs.python.org/3/library/stdtypes.html#list)\[[TensorValue](../../graph/TensorValue.md#max.graph.TensorValue)]

</dd></dl>

## `take()` {#max.nn.transformer.distributed_transformer.take}

> max.nn.transformer.distributed\_transformer.take(it, n)

Return the next n items from it as a list.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* it ([Iterable](https://docs.python.org/3/library/collections.abc.html#collections.abc.Iterable)\[[Value](../../graph/Value.md#max.graph.Value)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]])
* n ([int](https://docs.python.org/3/library/functions.html#int))

</dd><dt>

**Return type:**

</dt><dd>

[list](https://docs.python.org/3/library/stdtypes.html#list)\[[Value](../../graph/Value.md#max.graph.Value)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]

</dd></dl>

---

## transformer

## Modules

* [`distributed_transformer`](/max/api/python/nn/transformer/distributed_transformer)
* [`transformer`](/max/api/python/nn/transformer/transformer)

---

## transformer (Transformer)

## `ReturnLogits` {#max.nn.transformer.transformer.ReturnLogits}

> class max.nn.transformer.transformer.ReturnLogits(value, names=\<not given>, \*values, module=None, qualname=None, type=None, start=1, boundary=None)

### `ALL` {#max.nn.transformer.transformer.ReturnLogits.ALL}

> ALL = 'all'

### `LAST_TOKEN` {#max.nn.transformer.transformer.ReturnLogits.LAST_TOKEN}

> LAST\_TOKEN = 'last\_token'

### `VARIABLE` {#max.nn.transformer.transformer.ReturnLogits.VARIABLE}

> VARIABLE = 'variable'

## `Transformer` {#max.nn.transformer.transformer.Transformer}

> class max.nn.transformer.transformer.Transformer(dim, n\_heads, layers, norm, output, embedding, kv\_params, kv\_collection\_constructor, rope, return\_logits=ReturnLogits.LAST\_TOKEN, embedding\_multiplier=1.0, logits\_scaling=1.0)

Transformer model consisting for TransformerBlock layers.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* dim ([int](https://docs.python.org/3/library/functions.html#int))
* n\_heads ([int](https://docs.python.org/3/library/functions.html#int))
* layers ([list](https://docs.python.org/3/library/stdtypes.html#list)\[Block])
* norm ([Layer](../layer.md#max.nn.layer.Layer))
* output ([LinearV1](../linear.md#max.nn.linear.LinearV1) | [Linear](../linear.md#max.nn.linear.Linear))
* embedding ([EmbeddingV1](../embedding.md#max.nn.embedding.EmbeddingV1) | [Embedding](../embedding.md#max.nn.embedding.Embedding))
* kv\_params ([KVCacheParams](../kv_cache/cache_params.md#max.nn.kv_cache.cache_params.KVCacheParams))
* kv\_collection\_constructor (FetchPagedKVCacheCollection)
* rope ([RotaryEmbedding](../rotary_embedding.md#max.nn.rotary_embedding.RotaryEmbedding))
* return\_logits ([ReturnLogits](#max.nn.transformer.transformer.ReturnLogits))
* embedding\_multiplier ([float](https://docs.python.org/3/library/functions.html#float))
* logits\_scaling ([float](https://docs.python.org/3/library/functions.html#float))

</dd></dl>

## `TransformerBlock` {#max.nn.transformer.transformer.TransformerBlock}

> class max.nn.transformer.transformer.TransformerBlock(attention, mlp, attention\_norm, mlp\_norm, residual\_multiplier=1.0)

Stack of Attention, FeedForward, and RMSNorm layers.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* attention ([AttentionImpl](../attention/interfaces.md#max.nn.attention.interfaces.AttentionImpl) | [AttentionImplQKV](../attention/interfaces.md#max.nn.attention.interfaces.AttentionImplQKV) | [Module](../layer.md#max.nn.layer.Module))
* mlp ([Layer](../layer.md#max.nn.layer.Layer))
* attention\_norm ([Layer](../layer.md#max.nn.layer.Layer))
* mlp\_norm ([Layer](../layer.md#max.nn.layer.Layer))
* residual\_multiplier ([float](https://docs.python.org/3/library/functions.html#float))

</dd></dl>

---

## architectures

## `register_all_models()` {#max.pipelines.architectures.register_all_models}

> max.pipelines.architectures.register\_all\_models()

Imports model architectures, thus registering the architecture in the shared `PipelineRegistry`.

<dl class='field-list'><dt>

**Return type:**

</dt><dd>

None

</dd></dl>

---

## config

Standardized configuration for Pipeline Inference.

## `AudioGenerationConfig` {#max.pipelines.lib.config.AudioGenerationConfig}

> class max.pipelines.lib.config.AudioGenerationConfig(audio\_decoder: 'str', audio\_decoder\_weights: 'str' = '', chunk\_size: 'list\[int] | None' = None, buffer: 'int' = 0, block\_causal: 'bool' = False, prepend\_prompt\_speech\_tokens: 'PrependPromptSpeechTokens' = \<PrependPromptSpeechTokens.NEVER: 'never'>, prepend\_prompt\_speech\_tokens\_causal: 'bool' = False, run\_model\_test\_mode: 'bool' = False, prometheus\_metrics\_mode: 'PrometheusMetricsMode' = \<PrometheusMetricsMode.INSTRUMENT\_ONLY: 'instrument\_only'>, \*\*kwargs: 'Any')

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* audio\_decoder ([str](https://docs.python.org/3/library/stdtypes.html#str))
* audio\_decoder\_weights ([str](https://docs.python.org/3/library/stdtypes.html#str))
* chunk\_size ([list](https://docs.python.org/3/library/stdtypes.html#list)\[[int](https://docs.python.org/3/library/functions.html#int)] | None)
* buffer ([int](https://docs.python.org/3/library/functions.html#int))
* block\_causal ([bool](https://docs.python.org/3/library/functions.html#bool))
* prepend\_prompt\_speech\_tokens ([PrependPromptSpeechTokens](#max.pipelines.lib.config.PrependPromptSpeechTokens))
* prepend\_prompt\_speech\_tokens\_causal ([bool](https://docs.python.org/3/library/functions.html#bool))
* run\_model\_test\_mode ([bool](https://docs.python.org/3/library/functions.html#bool))
* prometheus\_metrics\_mode ([PrometheusMetricsMode](#max.pipelines.lib.config.PrometheusMetricsMode))
* kwargs (Any)

</dd></dl>

### `audio_decoder` {#max.pipelines.lib.config.AudioGenerationConfig.audio_decoder}

> audio\_decoder: [str](https://docs.python.org/3/library/stdtypes.html#str) = ''

The name of the audio decoder model architecture.

### `audio_decoder_config` {#max.pipelines.lib.config.AudioGenerationConfig.audio_decoder_config}

> audio\_decoder\_config: [dict](https://docs.python.org/3/library/stdtypes.html#dict)\[[str](https://docs.python.org/3/library/stdtypes.html#str), [Any](https://docs.python.org/3/library/typing.html#typing.Any)]

Parameters to pass to the audio decoder model.

### `audio_decoder_weights` {#max.pipelines.lib.config.AudioGenerationConfig.audio_decoder_weights}

> audio\_decoder\_weights: [str](https://docs.python.org/3/library/stdtypes.html#str) = ''

The path to the audio decoder weights file.

### `block_causal` {#max.pipelines.lib.config.AudioGenerationConfig.block_causal}

> block\_causal: [bool](https://docs.python.org/3/library/functions.html#bool) = False

Whether prior buffered tokens should attend to tokens in the current block.
Has no effect if buffer is not set.

### `buffer` {#max.pipelines.lib.config.AudioGenerationConfig.buffer}

> buffer: [int](https://docs.python.org/3/library/functions.html#int) = 0

The number of previous speech tokens to pass to the audio decoder on
each generation step.

### `chunk_size` {#max.pipelines.lib.config.AudioGenerationConfig.chunk_size}

> chunk\_size: [list](https://docs.python.org/3/library/stdtypes.html#list)\[[int](https://docs.python.org/3/library/functions.html#int)] | [None](https://docs.python.org/3/library/constants.html#None) = None

The chunk sizes to use for streaming.
If this is an int, then fixed-size chunks of the given size are used
If this is a list, then variable chunk sizes are used.

### `from_flags()` {#max.pipelines.lib.config.AudioGenerationConfig.from_flags}

> classmethod from\_flags(audio\_flags, \*\*config\_flags)

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* audio\_flags ([dict](https://docs.python.org/3/library/stdtypes.html#dict)\[[str](https://docs.python.org/3/library/stdtypes.html#str), [str](https://docs.python.org/3/library/stdtypes.html#str)])
* config\_flags ([Any](https://docs.python.org/3/library/typing.html#typing.Any))

</dd><dt>

**Return type:**

</dt><dd>

[AudioGenerationConfig](#max.pipelines.lib.config.AudioGenerationConfig)

</dd></dl>

### `help()` {#max.pipelines.lib.config.AudioGenerationConfig.help}

> static help()

Documentation for this config class. Return a dictionary of config
options and their descriptions.

<dl class='field-list'><dt>

**Return type:**

</dt><dd>

[dict](https://docs.python.org/3/library/stdtypes.html#dict)\[[str](https://docs.python.org/3/library/stdtypes.html#str), [str](https://docs.python.org/3/library/stdtypes.html#str)]

</dd></dl>

### `prepend_prompt_speech_tokens` {#max.pipelines.lib.config.AudioGenerationConfig.prepend_prompt_speech_tokens}

> prepend\_prompt\_speech\_tokens: [PrependPromptSpeechTokens](#max.pipelines.lib.config.PrependPromptSpeechTokens) = 'once'

Whether the prompt speech tokens should be forwarded to the audio decoder.
If â€œneverâ€, the prompt tokens are not forwarded.
If â€œonceâ€, the prompt tokens are only forwarded on the first block.
If â€œalwaysâ€, the prompt tokens are forwarded on all blocks.

### `prepend_prompt_speech_tokens_causal` {#max.pipelines.lib.config.AudioGenerationConfig.prepend_prompt_speech_tokens_causal}

> prepend\_prompt\_speech\_tokens\_causal: [bool](https://docs.python.org/3/library/functions.html#bool) = False

Whether the prompt speech tokens should attend to tokens in the currently
generated audio block.
Has no effect if prepend\_prompt\_speech\_tokens is â€œneverâ€.
If False (default), the prompt tokens do not attend to the current block.
If True, the prompt tokens attend to the current block.

### `prometheus_metrics_mode` {#max.pipelines.lib.config.AudioGenerationConfig.prometheus_metrics_mode}

> prometheus\_metrics\_mode: [PrometheusMetricsMode](#max.pipelines.lib.config.PrometheusMetricsMode) = 'instrument\_only'

The mode to use for Prometheus metrics.

## `PipelineConfig` {#max.pipelines.lib.config.PipelineConfig}

> class max.pipelines.lib.config.PipelineConfig(\*\*kwargs)

Configuration for a pipeline.

WIP - Once a PipelineConfig is fully initialized, it should be as immutable
as possible (frozen=True). All underlying dataclass fields should have been
initialized to their default values, be it user specified via some CLI
flag, config file, environment variable, or internally set to a reasonable
default.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

kwargs (Any)

</dd></dl>

### `ce_delay_ms` {#max.pipelines.lib.config.PipelineConfig.ce_delay_ms}

> ce\_delay\_ms: [float](https://docs.python.org/3/library/functions.html#float) = 0.0

Duration of scheduler sleep prior to starting a prefill batch.

This is an experimental flag solely for the TTS scheduler. Do not use unless
you know what you are doing.

### `chat_template` {#max.pipelines.lib.config.PipelineConfig.chat_template}

> chat\_template: [Path](https://docs.python.org/3/library/pathlib.html#pathlib.Path) | [None](https://docs.python.org/3/library/constants.html#None) = None

Optional custom chat template to override the one shipped with the
HuggingFace model config. Can be either:

* A Path pointing to a file containing the template

If a Path is provided, the file will be read during config resolution and
the content will be stored as a string. This allows customizing the prompt
formatting for different use cases. If None, the modelâ€™s default chat
template will be used.

### `custom_architectures` {#max.pipelines.lib.config.PipelineConfig.custom_architectures}

> custom\_architectures: [list](https://docs.python.org/3/library/stdtypes.html#list)\[[str](https://docs.python.org/3/library/stdtypes.html#str)]

A list of custom architecture implementations to register.
Each input can either be a raw module name or an import path followed by a colon and the module name.
Ex:

* my\_module
* folder/path/to/import:my\_module

Each module must expose an ARCHITECTURES list of architectures to register.

### `draft_model_config` {#max.pipelines.lib.config.PipelineConfig.draft_model_config}

> property draft\_model\_config: MAXModelConfig | [None](https://docs.python.org/3/library/constants.html#None)

### `enable_chunked_prefill` {#max.pipelines.lib.config.PipelineConfig.enable_chunked_prefill}

> enable\_chunked\_prefill: [bool](https://docs.python.org/3/library/functions.html#bool) = True

Enable chunked prefill to split context encoding requests into multiple chunks
based on â€˜prefill\_chunk\_sizeâ€™.

### `enable_echo` {#max.pipelines.lib.config.PipelineConfig.enable_echo}

> enable\_echo: [bool](https://docs.python.org/3/library/functions.html#bool) = False

Whether the model should be built with echo capabilities.

### `enable_in_flight_batching` {#max.pipelines.lib.config.PipelineConfig.enable_in_flight_batching}

> enable\_in\_flight\_batching: [bool](https://docs.python.org/3/library/functions.html#bool) = False

When enabled, prioritizes token generation by batching it with context
encoding requests.

### `enable_prioritize_first_decode` {#max.pipelines.lib.config.PipelineConfig.enable_prioritize_first_decode}

> enable\_prioritize\_first\_decode: [bool](https://docs.python.org/3/library/functions.html#bool) = False

When enabled, the scheduler will always run a TG batch immediately after a CE batch,
with the same requests. This may be useful for decreasing time-to-first-chunk latency.

This is an experimental flag solely for the TTS scheduler. Do not use unless
you know what you are doing.

### `graph_quantization_encoding` {#max.pipelines.lib.config.PipelineConfig.graph_quantization_encoding}

> property graph\_quantization\_encoding: [QuantizationEncoding](../graph/quantization.md#max.graph.quantization.QuantizationEncoding) | [None](https://docs.python.org/3/library/constants.html#None)

Converts the CLI encoding to a MAX graph quantization encoding.

<dl class='field-list'><dt>

**Returns:**

</dt><dd>

The graph quantization encoding corresponding to the CLI encoding.

</dd></dl>

### `help()` {#max.pipelines.lib.config.PipelineConfig.help}

> static help()

Documentation for this config class. Return a dictionary of config
options and their descriptions.

<dl class='field-list'><dt>

**Return type:**

</dt><dd>

[dict](https://docs.python.org/3/library/stdtypes.html#dict)\[[str](https://docs.python.org/3/library/stdtypes.html#str), [str](https://docs.python.org/3/library/stdtypes.html#str)]

</dd></dl>

### `log_basic_config()` {#max.pipelines.lib.config.PipelineConfig.log_basic_config}

> log\_basic\_config()

Log minimal pipeline configuration information.

Logs basic PipelineConfig options including model name, pipeline task,
weight path, max\_batch\_size, max\_seq\_len, and reserved memory.

<dl class='field-list'><dt>

**Return type:**

</dt><dd>

None

</dd></dl>

### `log_pipeline_info()` {#max.pipelines.lib.config.PipelineConfig.log_pipeline_info}

> log\_pipeline\_info()

Log comprehensive pipeline and KVCache configuration information.

Retrieves all necessary information from self and the PIPELINE\_REGISTRY.
Raises an error if architecture is not found (which should not happen after config resolution).

<dl class='field-list'><dt>

**Return type:**

</dt><dd>

None

</dd></dl>

### `lora_config` {#max.pipelines.lib.config.PipelineConfig.lora_config}

> property lora\_config: LoRAConfig | [None](https://docs.python.org/3/library/constants.html#None)

### `max_batch_size` {#max.pipelines.lib.config.PipelineConfig.max_batch_size}

> max\_batch\_size: [int](https://docs.python.org/3/library/functions.html#int) | [None](https://docs.python.org/3/library/constants.html#None) = None

Maximum batch size to execute with the model.
When not specified (None), we determine this value dynamically. For users
launching in a server scenario, the expectation is that this value should be
set higher based on server capacity.

### `max_ce_batch_size` {#max.pipelines.lib.config.PipelineConfig.max_ce_batch_size}

> max\_ce\_batch\_size: [int](https://docs.python.org/3/library/functions.html#int) = 192

Maximum cache size to reserve for a single context encoding batch.
The actual limit is the lesser of this and max\_batch\_size.

### `max_length` {#max.pipelines.lib.config.PipelineConfig.max_length}

> max\_length: [int](https://docs.python.org/3/library/functions.html#int) | [None](https://docs.python.org/3/library/constants.html#None) = None

Maximum sequence length of the model.

### `max_num_steps` {#max.pipelines.lib.config.PipelineConfig.max_num_steps}

> max\_num\_steps: [int](https://docs.python.org/3/library/functions.html#int) = -1

The number of steps to run for multi-step scheduling. -1 specifies a default value based on
configuration and platform. Ignored for models which are not auto-regressive (e.g. embedding
models).

### `max_queue_size_tg` {#max.pipelines.lib.config.PipelineConfig.max_queue_size_tg}

> max\_queue\_size\_tg: [int](https://docs.python.org/3/library/functions.html#int) | [None](https://docs.python.org/3/library/constants.html#None) = None

Maximum number of requests in decode queue. By default, this is max-batch-size.

### `min_batch_size_tg` {#max.pipelines.lib.config.PipelineConfig.min_batch_size_tg}

> min\_batch\_size\_tg: [int](https://docs.python.org/3/library/functions.html#int) | [None](https://docs.python.org/3/library/constants.html#None) = None

Specifies a soft floor on the decode batch size.

If the TG batch size is larger than this value, the scheduler will continue to
run TG batches. If it falls below, the scheduler will prioritize CE. Note that
this is NOT a strict minimum! By default, this is max-queue-size-tg.

This is an experimental flag solely for the TTS scheduler. Do not use unless
you know what you are doing.

### `model_config` {#max.pipelines.lib.config.PipelineConfig.model_config}

> property model\_config: MAXModelConfig

### `pdl_level` {#max.pipelines.lib.config.PipelineConfig.pdl_level}

> pdl\_level: [str](https://docs.python.org/3/library/stdtypes.html#str) = '0'

Level of overlap of kernel launch via programmatic dependent grid control.

### `pipeline_role` {#max.pipelines.lib.config.PipelineConfig.pipeline_role}

> pipeline\_role: PipelineRole = 'prefill\_and\_decode'

Whether the pipeline should serve both a prefill or decode role or both.

### `pool_embeddings` {#max.pipelines.lib.config.PipelineConfig.pool_embeddings}

> pool\_embeddings: [bool](https://docs.python.org/3/library/functions.html#bool) = True

Whether to pool embedding outputs.

### `prefill_chunk_size` {#max.pipelines.lib.config.PipelineConfig.prefill_chunk_size}

> prefill\_chunk\_size: [int](https://docs.python.org/3/library/functions.html#int) = 8192

The target number of un-encoded tokens to include in each batch.
This value is used for chunked prefill and memory estimation.

### `profiling_config` {#max.pipelines.lib.config.PipelineConfig.profiling_config}

> property profiling\_config: ProfilingConfig

### `resolve()` {#max.pipelines.lib.config.PipelineConfig.resolve}

> resolve()

Validates and resolves the config.

This method is called after the config is initialized, to ensure that all
config fields have been initialized to a valid state.

<dl class='field-list'><dt>

**Return type:**

</dt><dd>

None

</dd></dl>

### `retrieve_chat_template()` {#max.pipelines.lib.config.PipelineConfig.retrieve_chat_template}

> retrieve\_chat\_template()

<dl class='field-list'><dt>

**Return type:**

</dt><dd>

[str](https://docs.python.org/3/library/stdtypes.html#str) | None

</dd></dl>

### `sampling_config` {#max.pipelines.lib.config.PipelineConfig.sampling_config}

> property sampling\_config: SamplingConfig

### `use_experimental_kernels` {#max.pipelines.lib.config.PipelineConfig.use_experimental_kernels}

> use\_experimental\_kernels: [str](https://docs.python.org/3/library/stdtypes.html#str) = 'false'

## `PrependPromptSpeechTokens` {#max.pipelines.lib.config.PrependPromptSpeechTokens}

> class max.pipelines.lib.config.PrependPromptSpeechTokens(value, names=\<not given>, \*values, module=None, qualname=None, type=None, start=1, boundary=None)

### `NEVER` {#max.pipelines.lib.config.PrependPromptSpeechTokens.NEVER}

> NEVER = 'never'

Never prepend the prompt speech tokens sent to the audio decoder.

### `ONCE` {#max.pipelines.lib.config.PrependPromptSpeechTokens.ONCE}

> ONCE = 'once'

Prepend the prompt speech tokens to the first block of the audio decoder.

### `ROLLING` {#max.pipelines.lib.config.PrependPromptSpeechTokens.ROLLING}

> ROLLING = 'rolling'

Prepend the prompt speech tokens to the first block of the audio decoder,
and to later blocks to reach the requested buffer size.

## `PrometheusMetricsMode` {#max.pipelines.lib.config.PrometheusMetricsMode}

> class max.pipelines.lib.config.PrometheusMetricsMode(value, names=\<not given>, \*values, module=None, qualname=None, type=None, start=1, boundary=None)

### `INSTRUMENT_ONLY` {#max.pipelines.lib.config.PrometheusMetricsMode.INSTRUMENT_ONLY}

> INSTRUMENT\_ONLY = 'instrument\_only'

Instrument metrics through the Prometheus client library, relying on the application to handle the metrics server.

### `LAUNCH_MULTIPROC_SERVER` {#max.pipelines.lib.config.PrometheusMetricsMode.LAUNCH_MULTIPROC_SERVER}

> LAUNCH\_MULTIPROC\_SERVER = 'launch\_multiproc\_server'

Launch a Prometheus server in multiprocess mode to report metrics.

### `LAUNCH_SERVER` {#max.pipelines.lib.config.PrometheusMetricsMode.LAUNCH_SERVER}

> LAUNCH\_SERVER = 'launch\_server'

Launch a Prometheus server to handle metrics requests.

---

## core

## `TTSContext` {#max.pipelines.core.TTSContext}

> class max.pipelines.core.TTSContext(audio\_prompt\_tokens=\<factory>, buffer\_speech\_tokens=None, audio\_buffer=None, prev\_samples\_beyond\_offset=0, streaming=False, \_speech\_token\_size=128, \_speech\_token\_end\_idx=0, \_speech\_tokens=\<factory>, decoded\_index=0, \_block\_counter=0, \_arrival\_time=\<factory>, audio\_generation\_status=GenerationStatus.ACTIVE, \*, request\_id=\<factory>, max\_length, tokens, eos\_token\_ids=\<factory>, eos\_sequences=\<factory>, log\_probabilities=0, log\_probabilities\_echo=False, ignore\_eos=False, json\_schema=None, sampling\_params=\<factory>, model\_name='', \_matcher=None, status=GenerationStatus.ACTIVE, \_size=-1, \_start\_idx=0, \_active\_idx=-1, \_end\_idx=-1, \_completion\_start\_idx=-1, \_completion\_end\_idx=-1, \_prompt\_len=-1, \_log\_probabilities\_data=\<factory>, \_is\_initial\_prompt=True, \_draft\_offset=0, target\_endpoint=None)

A context for Text-to-Speech (TTS) model inference.

This class extends TextContext to handle speech token generation and management.
It maintains buffers for audio prompt tokens and generated speech tokens, along
with tracking indices for decoding progress.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* audio\_prompt\_tokens ([ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]]) â€“ Array of input audio prompt tokens used for voice cloning
* buffer\_speech\_tokens ([ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]] | None)
* audio\_buffer ([ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]] | None)
* prev\_samples\_beyond\_offset ([int](https://docs.python.org/3/library/functions.html#int))
* streaming ([bool](https://docs.python.org/3/library/functions.html#bool)) â€“ Whether the request is streaming the audio to client
* \_speech\_token\_size ([int](https://docs.python.org/3/library/functions.html#int)) â€“ Size of the speech token buffer, defaults to SPEECH\_TOKEN\_audio\_chunk\_size
* \_speech\_token\_end\_idx ([int](https://docs.python.org/3/library/functions.html#int)) â€“ Index marking the end of valid speech tokens
* \_speech\_tokens ([ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]]) â€“ Buffer containing the generated speech tokens
* decoded\_index ([int](https://docs.python.org/3/library/functions.html#int))
* \_block\_counter ([int](https://docs.python.org/3/library/functions.html#int)) â€“ Counter tracking number of speech token blocks generated
* \_arrival\_time ([float](https://docs.python.org/3/library/functions.html#float))
* audio\_generation\_status ([GenerationStatus](../interfaces.md#max.interfaces.GenerationStatus))
* request\_id ([str](https://docs.python.org/3/library/stdtypes.html#str))
* max\_length ([int](https://docs.python.org/3/library/functions.html#int))
* tokens ([ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])
* eos\_token\_ids ([set](https://docs.python.org/3/library/stdtypes.html#set)\[[int](https://docs.python.org/3/library/functions.html#int)])
* eos\_sequences ([list](https://docs.python.org/3/library/stdtypes.html#list)\[[list](https://docs.python.org/3/library/stdtypes.html#list)\[[int](https://docs.python.org/3/library/functions.html#int)]])
* log\_probabilities ([int](https://docs.python.org/3/library/functions.html#int))
* log\_probabilities\_echo ([bool](https://docs.python.org/3/library/functions.html#bool))
* ignore\_eos ([bool](https://docs.python.org/3/library/functions.html#bool))
* json\_schema ([str](https://docs.python.org/3/library/stdtypes.html#str) | None)
* sampling\_params ([SamplingParams](../interfaces.md#max.interfaces.SamplingParams))
* model\_name ([str](https://docs.python.org/3/library/stdtypes.html#str))
* \_matcher ([Any](https://docs.python.org/3/library/typing.html#typing.Any) | None)
* status ([GenerationStatus](../interfaces.md#max.interfaces.GenerationStatus))
* \_size ([int](https://docs.python.org/3/library/functions.html#int))
* \_start\_idx ([int](https://docs.python.org/3/library/functions.html#int))
* \_active\_idx ([int](https://docs.python.org/3/library/functions.html#int))
* \_end\_idx ([int](https://docs.python.org/3/library/functions.html#int))
* \_completion\_start\_idx ([int](https://docs.python.org/3/library/functions.html#int))
* \_completion\_end\_idx ([int](https://docs.python.org/3/library/functions.html#int))
* \_prompt\_len ([int](https://docs.python.org/3/library/functions.html#int))
* \_log\_probabilities\_data ([dict](https://docs.python.org/3/library/stdtypes.html#dict)\[[int](https://docs.python.org/3/library/functions.html#int), [LogProbabilities](../interfaces.md#max.interfaces.LogProbabilities)])
* \_is\_initial\_prompt ([bool](https://docs.python.org/3/library/functions.html#bool))
* \_draft\_offset ([int](https://docs.python.org/3/library/functions.html#int))
* target\_endpoint ([str](https://docs.python.org/3/library/stdtypes.html#str) | None)

</dd></dl>

### `audio_buffer` {#max.pipelines.core.TTSContext.audio_buffer}

> audio\_buffer: [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]] | [None](https://docs.python.org/3/library/constants.html#None)

### `audio_generation_status` {#max.pipelines.core.TTSContext.audio_generation_status}

> audio\_generation\_status: [GenerationStatus](../interfaces.md#max.interfaces.GenerationStatus)

### `audio_prompt_tokens` {#max.pipelines.core.TTSContext.audio_prompt_tokens}

> audio\_prompt\_tokens: [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]]

### `block_counter` {#max.pipelines.core.TTSContext.block_counter}

> property block\_counter: [int](https://docs.python.org/3/library/functions.html#int)

### `buffer_speech_tokens` {#max.pipelines.core.TTSContext.buffer_speech_tokens}

> buffer\_speech\_tokens: [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]] | [None](https://docs.python.org/3/library/constants.html#None)

### `decoded_index` {#max.pipelines.core.TTSContext.decoded_index}

> decoded\_index: [int](https://docs.python.org/3/library/functions.html#int)

### `is_done` {#max.pipelines.core.TTSContext.is_done}

> property is\_done: [bool](https://docs.python.org/3/library/functions.html#bool)

### `next_speech_tokens()` {#max.pipelines.core.TTSContext.next_speech_tokens}

> next\_speech\_tokens(audio\_chunk\_size=None, buffer=None)

Returns a chunk of the next unseen speech tokens.

Calling this function will not update the index of the last seen
token. This must be done by setting decoded\_index after the chunk
is processed.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* audio\_chunk\_size ([int](https://docs.python.org/3/library/functions.html#int) | None) â€“ The number of speech tokens to return.
* buffer ([int](https://docs.python.org/3/library/functions.html#int) | None) â€“ The number of previous speech tokens to pass to the audio
  decoder on each generation step.

</dd><dt>

**Returns:**

</dt><dd>

A tuple of (chunk of speech tokens, buffer).

</dd><dt>

**Return type:**

</dt><dd>

[tuple](https://docs.python.org/3/library/stdtypes.html#tuple)\[[ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]], [int](https://docs.python.org/3/library/functions.html#int)]

</dd></dl>

### `prev_samples_beyond_offset` {#max.pipelines.core.TTSContext.prev_samples_beyond_offset}

> prev\_samples\_beyond\_offset: [int](https://docs.python.org/3/library/functions.html#int)

### `speech_tokens` {#max.pipelines.core.TTSContext.speech_tokens}

> property speech\_tokens: [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]]

### `streaming` {#max.pipelines.core.TTSContext.streaming}

> streaming: [bool](https://docs.python.org/3/library/functions.html#bool)

### `update_speech_tokens()` {#max.pipelines.core.TTSContext.update_speech_tokens}

> update\_speech\_tokens(new\_tokens)

Updates the next\_tokens

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

new\_tokens ([ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])

</dd><dt>

**Return type:**

</dt><dd>

None

</dd></dl>

## `TextAndVisionContext` {#max.pipelines.core.TextAndVisionContext}

> class max.pipelines.core.TextAndVisionContext(\*, request\_id=\<factory>, max\_length, tokens, eos\_token\_ids=\<factory>, eos\_sequences=\<factory>, log\_probabilities=0, log\_probabilities\_echo=False, ignore\_eos=False, json\_schema=None, sampling\_params=\<factory>, model\_name='', \_matcher=None, status=GenerationStatus.ACTIVE, \_size=-1, \_start\_idx=0, \_active\_idx=-1, \_end\_idx=-1, \_completion\_start\_idx=-1, \_completion\_end\_idx=-1, \_prompt\_len=-1, \_log\_probabilities\_data=\<factory>, \_is\_initial\_prompt=True, \_draft\_offset=0, target\_endpoint=None, pixel\_values=(), extra\_model\_args=\<factory>, \_needs\_vision\_encoding=True)

A base class for model context, specifically for Vision model variants.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* request\_id ([str](https://docs.python.org/3/library/stdtypes.html#str))
* max\_length ([int](https://docs.python.org/3/library/functions.html#int))
* tokens ([ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])
* eos\_token\_ids ([set](https://docs.python.org/3/library/stdtypes.html#set)\[[int](https://docs.python.org/3/library/functions.html#int)])
* eos\_sequences ([list](https://docs.python.org/3/library/stdtypes.html#list)\[[list](https://docs.python.org/3/library/stdtypes.html#list)\[[int](https://docs.python.org/3/library/functions.html#int)]])
* log\_probabilities ([int](https://docs.python.org/3/library/functions.html#int))
* log\_probabilities\_echo ([bool](https://docs.python.org/3/library/functions.html#bool))
* ignore\_eos ([bool](https://docs.python.org/3/library/functions.html#bool))
* json\_schema ([str](https://docs.python.org/3/library/stdtypes.html#str) | None)
* sampling\_params ([SamplingParams](../interfaces.md#max.interfaces.SamplingParams))
* model\_name ([str](https://docs.python.org/3/library/stdtypes.html#str))
* \_matcher ([Any](https://docs.python.org/3/library/typing.html#typing.Any) | None)
* status ([GenerationStatus](../interfaces.md#max.interfaces.GenerationStatus))
* \_size ([int](https://docs.python.org/3/library/functions.html#int))
* \_start\_idx ([int](https://docs.python.org/3/library/functions.html#int))
* \_active\_idx ([int](https://docs.python.org/3/library/functions.html#int))
* \_end\_idx ([int](https://docs.python.org/3/library/functions.html#int))
* \_completion\_start\_idx ([int](https://docs.python.org/3/library/functions.html#int))
* \_completion\_end\_idx ([int](https://docs.python.org/3/library/functions.html#int))
* \_prompt\_len ([int](https://docs.python.org/3/library/functions.html#int))
* \_log\_probabilities\_data ([dict](https://docs.python.org/3/library/stdtypes.html#dict)\[[int](https://docs.python.org/3/library/functions.html#int), [LogProbabilities](../interfaces.md#max.interfaces.LogProbabilities)])
* \_is\_initial\_prompt ([bool](https://docs.python.org/3/library/functions.html#bool))
* \_draft\_offset ([int](https://docs.python.org/3/library/functions.html#int))
* target\_endpoint ([str](https://docs.python.org/3/library/stdtypes.html#str) | None)
* pixel\_values ([tuple](https://docs.python.org/3/library/stdtypes.html#tuple)\[[ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]], ...])
* extra\_model\_args ([dict](https://docs.python.org/3/library/stdtypes.html#dict)\[[str](https://docs.python.org/3/library/stdtypes.html#str), [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])
* \_needs\_vision\_encoding ([bool](https://docs.python.org/3/library/functions.html#bool))

</dd></dl>

### `extra_model_args` {#max.pipelines.core.TextAndVisionContext.extra_model_args}

> extra\_model\_args: [dict](https://docs.python.org/3/library/stdtypes.html#dict)\[[str](https://docs.python.org/3/library/stdtypes.html#str), [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]]

### `needs_vision_encoding` {#max.pipelines.core.TextAndVisionContext.needs_vision_encoding}

> property needs\_vision\_encoding: [bool](https://docs.python.org/3/library/functions.html#bool)

Gets whether vision encoding is needed for this context.

### `pixel_values` {#max.pipelines.core.TextAndVisionContext.pixel_values}

> pixel\_values: [tuple](https://docs.python.org/3/library/stdtypes.html#tuple)\[[ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[floating](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.floating)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]], ...]

### `reset()` {#max.pipelines.core.TextAndVisionContext.reset}

> reset()

Resets the contextâ€™s state by combining all tokens into a new prompt.

<dl class='field-list'><dt>

**Return type:**

</dt><dd>

None

</dd></dl>

### `update()` {#max.pipelines.core.TextAndVisionContext.update}

> update(new\_token, log\_probabilities=None)

Updates the next\_tokens and extends existing tokens to include all generated tokens.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* new\_token ([int](https://docs.python.org/3/library/functions.html#int))
* log\_probabilities ([LogProbabilities](../interfaces.md#max.interfaces.LogProbabilities) | None)

</dd><dt>

**Return type:**

</dt><dd>

None

</dd></dl>

## `TextContext` {#max.pipelines.core.TextContext}

> class max.pipelines.core.TextContext(\*, request\_id=\<factory>, max\_length, tokens, eos\_token\_ids=\<factory>, eos\_sequences=\<factory>, log\_probabilities=0, log\_probabilities\_echo=False, ignore\_eos=False, json\_schema=None, sampling\_params=\<factory>, model\_name='', \_matcher=None, status=GenerationStatus.ACTIVE, \_size=-1, \_start\_idx=0, \_active\_idx=-1, \_end\_idx=-1, \_completion\_start\_idx=-1, \_completion\_end\_idx=-1, \_prompt\_len=-1, \_log\_probabilities\_data=\<factory>, \_is\_initial\_prompt=True, \_draft\_offset=0, target\_endpoint=None)

A base class for model context, specifically for Text model variants.

This class manages the state and processing of text generation, including token management,
caching, and generation parameters.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* request\_id ([str](https://docs.python.org/3/library/stdtypes.html#str)) â€“ A unique identifier for this sequence.
* max\_length ([int](https://docs.python.org/3/library/functions.html#int)) â€“ Maximum allowed length of the generated sequence
* tokens ([ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]]) â€“ NumPy array containing the token IDs
* eos\_token\_ids ([set](https://docs.python.org/3/library/stdtypes.html#set)\[[int](https://docs.python.org/3/library/functions.html#int)]) â€“ Set of token IDs that indicate end of sequence
* eos\_sequences ([list](https://docs.python.org/3/library/stdtypes.html#list)\[[list](https://docs.python.org/3/library/stdtypes.html#list)\[[int](https://docs.python.org/3/library/functions.html#int)]])
* log\_probabilities ([int](https://docs.python.org/3/library/functions.html#int)) â€“ Whether to return token log probabilities
* log\_probabilities\_echo ([bool](https://docs.python.org/3/library/functions.html#bool)) â€“ Whether to return log probabilities for prompt tokens
* ignore\_eos ([bool](https://docs.python.org/3/library/functions.html#bool)) â€“ Whether to ignore end of sequence tokens and continue generating
* json\_schema ([str](https://docs.python.org/3/library/stdtypes.html#str) | None) â€“ Optional JSON schema for structured output
* sampling\_params ([SamplingParams](../interfaces.md#max.interfaces.SamplingParams)) â€“ Parameters controlling the token sampling strategy
* model\_name ([str](https://docs.python.org/3/library/stdtypes.html#str))
* \_matcher ([Any](https://docs.python.org/3/library/typing.html#typing.Any) | None)
* status ([GenerationStatus](../interfaces.md#max.interfaces.GenerationStatus))
* \_size ([int](https://docs.python.org/3/library/functions.html#int)) â€“ Current allocated size of token array
* \_start\_idx ([int](https://docs.python.org/3/library/functions.html#int)) â€“ Start index of current generation window
* \_active\_idx ([int](https://docs.python.org/3/library/functions.html#int)) â€“ Current position in token sequence
* \_end\_idx ([int](https://docs.python.org/3/library/functions.html#int)) â€“ End index of valid tokens
* \_completion\_start\_idx ([int](https://docs.python.org/3/library/functions.html#int)) â€“ Start index of completion tokens
* \_completion\_end\_idx ([int](https://docs.python.org/3/library/functions.html#int)) â€“ End index of completion tokens
* \_prompt\_len ([int](https://docs.python.org/3/library/functions.html#int)) â€“ Length of original prompt
* \_log\_probabilities\_data ([dict](https://docs.python.org/3/library/stdtypes.html#dict)\[[int](https://docs.python.org/3/library/functions.html#int), [LogProbabilities](../interfaces.md#max.interfaces.LogProbabilities)]) â€“ Token log probabilities data
* \_is\_initial\_prompt ([bool](https://docs.python.org/3/library/functions.html#bool)) â€“ Whether this is the initial prompt encoding
* \_draft\_offset ([int](https://docs.python.org/3/library/functions.html#int)) â€“ Offset for draft decoding
* target\_endpoint ([str](https://docs.python.org/3/library/stdtypes.html#str) | None) â€“ Optional target endpoint identifier for routing requests

</dd></dl>

### `active_idx` {#max.pipelines.core.TextContext.active_idx}

> property active\_idx: [int](https://docs.python.org/3/library/functions.html#int)

### `active_length` {#max.pipelines.core.TextContext.active_length}

> property active\_length: [int](https://docs.python.org/3/library/functions.html#int)

num tokens input this iteration.

This will be the prompt size for context encoding, and simply 1 (or more) for
token generation.

<dl class='field-list'><dt>

**Type:**

</dt><dd>

Current sequence length

</dd></dl>

### `all_tokens` {#max.pipelines.core.TextContext.all_tokens}

> property all\_tokens: [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]]

### `bump_token_indices()` {#max.pipelines.core.TextContext.bump_token_indices}

> bump\_token\_indices(start\_idx=0, active\_idx=0, end\_idx=0)

Update the start\_idx, active\_idx and end\_idx without manipulating the token array.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* start\_idx ([int](https://docs.python.org/3/library/functions.html#int))
* active\_idx ([int](https://docs.python.org/3/library/functions.html#int))
* end\_idx ([int](https://docs.python.org/3/library/functions.html#int))

</dd><dt>

**Return type:**

</dt><dd>

None

</dd></dl>

### `compute_num_available_steps()` {#max.pipelines.core.TextContext.compute_num_available_steps}

> compute\_num\_available\_steps(max\_seq\_len)

Compute the max number of steps we can execute for a given context
without exceeding the max\_seq\_len.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

max\_seq\_len ([int](https://docs.python.org/3/library/functions.html#int))

</dd><dt>

**Return type:**

</dt><dd>

[int](https://docs.python.org/3/library/functions.html#int)

</dd></dl>

### `current_length` {#max.pipelines.core.TextContext.current_length}

> property current\_length: [int](https://docs.python.org/3/library/functions.html#int)

The current length of the sequence, including completed and active tokens.

### `end_idx` {#max.pipelines.core.TextContext.end_idx}

> property end\_idx: [int](https://docs.python.org/3/library/functions.html#int)

### `eos_sequences` {#max.pipelines.core.TextContext.eos_sequences}

> eos\_sequences: [list](https://docs.python.org/3/library/stdtypes.html#list)\[[list](https://docs.python.org/3/library/stdtypes.html#list)\[[int](https://docs.python.org/3/library/functions.html#int)]]

### `eos_token_ids` {#max.pipelines.core.TextContext.eos_token_ids}

> eos\_token\_ids: [set](https://docs.python.org/3/library/stdtypes.html#set)\[[int](https://docs.python.org/3/library/functions.html#int)]

### `generated_tokens` {#max.pipelines.core.TextContext.generated_tokens}

> property generated\_tokens: [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]]

Returns all tokens that have been generated after the prompt.

<dl class='field-list'><dt>

**Returns:**

</dt><dd>

Array of generated tokens from prompt\_len to end\_idx.

</dd><dt>

**Return type:**

</dt><dd>

np.ndarray

</dd></dl>

### `get_min_token_logit_mask()` {#max.pipelines.core.TextContext.get_min_token_logit_mask}

> get\_min\_token\_logit\_mask(num\_steps)

Returns a set of indices for the tokens in the output that should be masked.

This is primarily used for the min\_tokens setting, where we mask
eos tokens in the logits to avoid generating them before we reach
min\_tokens.

<dl class='field-list'><dt>

**Returns:**

</dt><dd>

A set of indices for the tokens in the output that should be masked.

</dd><dt>

**Parameters:**

</dt><dd>

num\_steps ([int](https://docs.python.org/3/library/functions.html#int))

</dd><dt>

**Return type:**

</dt><dd>

[list](https://docs.python.org/3/library/stdtypes.html#list)\[[ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[int32]]]

</dd></dl>

### `ignore_eos` {#max.pipelines.core.TextContext.ignore_eos}

> ignore\_eos: [bool](https://docs.python.org/3/library/functions.html#bool)

### `is_done` {#max.pipelines.core.TextContext.is_done}

> property is\_done: [bool](https://docs.python.org/3/library/functions.html#bool)

### `is_initial_prompt` {#max.pipelines.core.TextContext.is_initial_prompt}

> property is\_initial\_prompt: [bool](https://docs.python.org/3/library/functions.html#bool)

Returns true if the context has not been updated with tokens.

### `json_schema` {#max.pipelines.core.TextContext.json_schema}

> json\_schema: [str](https://docs.python.org/3/library/stdtypes.html#str) | [None](https://docs.python.org/3/library/constants.html#None)

### `jump_ahead()` {#max.pipelines.core.TextContext.jump_ahead}

> jump\_ahead(new\_token)

Updates the token array, while ensuring the new token is returned to the user.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

new\_token ([int](https://docs.python.org/3/library/functions.html#int))

</dd><dt>

**Return type:**

</dt><dd>

None

</dd></dl>

### `last_generated_token` {#max.pipelines.core.TextContext.last_generated_token}

> property last\_generated\_token: [int](https://docs.python.org/3/library/functions.html#int)

Returns the most recently generated token. If no tokens have been generated, raises an error.
:returns: The most recently generated token.
:rtype: int

### `log_probabilities` {#max.pipelines.core.TextContext.log_probabilities}

> log\_probabilities: [int](https://docs.python.org/3/library/functions.html#int)

### `log_probabilities_echo` {#max.pipelines.core.TextContext.log_probabilities_echo}

> log\_probabilities\_echo: [bool](https://docs.python.org/3/library/functions.html#bool)

### `matcher` {#max.pipelines.core.TextContext.matcher}

> property matcher: LLMatcher | [None](https://docs.python.org/3/library/constants.html#None)

### `max_length` {#max.pipelines.core.TextContext.max_length}

> max\_length: [int](https://docs.python.org/3/library/functions.html#int)

### `min_tokens` {#max.pipelines.core.TextContext.min_tokens}

> property min\_tokens: [int](https://docs.python.org/3/library/functions.html#int)

The minimum number of new tokens to generate.

### `model_name` {#max.pipelines.core.TextContext.model_name}

> model\_name: [str](https://docs.python.org/3/library/stdtypes.html#str)

### `needs_ce` {#max.pipelines.core.TextContext.needs_ce}

> property needs\_ce: [bool](https://docs.python.org/3/library/functions.html#bool)

Returns whether this context needs context encoding (CE).

CE mode indicates that the context has additional prompt tokens to encode.

<dl class='field-list'><dt>

**Returns:**

</dt><dd>

True if the context needs CE, False otherwise.

</dd><dt>

**Return type:**

</dt><dd>

[bool](https://docs.python.org/3/library/functions.html#bool)

</dd></dl>

### `next_tokens` {#max.pipelines.core.TextContext.next_tokens}

> property next\_tokens: [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]]

Returns the tokens between start\_idx and active\_idx.

<dl class='field-list'><dt>

**Returns:**

</dt><dd>

Array of tokens that have been generated but not yet processed.

</dd><dt>

**Return type:**

</dt><dd>

np.ndarray

</dd></dl>

### `prompt_tokens` {#max.pipelines.core.TextContext.prompt_tokens}

> property prompt\_tokens: [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]]

Returns the original prompt tokens.

<dl class='field-list'><dt>

**Returns:**

</dt><dd>

Array of tokens from the initial prompt.

</dd><dt>

**Return type:**

</dt><dd>

np.ndarray

</dd></dl>

### `request_id` {#max.pipelines.core.TextContext.request_id}

> request\_id: [str](https://docs.python.org/3/library/stdtypes.html#str)

### `reset()` {#max.pipelines.core.TextContext.reset}

> reset()

Resets the contextâ€™s state by combining all tokens into a new prompt.

<dl class='field-list'><dt>

**Return type:**

</dt><dd>

None

</dd></dl>

### `sampling_params` {#max.pipelines.core.TextContext.sampling_params}

> sampling\_params: [SamplingParams](../interfaces.md#max.interfaces.SamplingParams)

### `set_matcher()` {#max.pipelines.core.TextContext.set_matcher}

> set\_matcher(matcher)

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

matcher (LLMatcher)

</dd><dt>

**Return type:**

</dt><dd>

None

</dd></dl>

### `set_token_indices()` {#max.pipelines.core.TextContext.set_token_indices}

> set\_token\_indices(start\_idx=None, active\_idx=None, end\_idx=None)

Set the token indices without manipulating the token array.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* start\_idx ([int](https://docs.python.org/3/library/functions.html#int) | None)
* active\_idx ([int](https://docs.python.org/3/library/functions.html#int) | None)
* end\_idx ([int](https://docs.python.org/3/library/functions.html#int) | None)

</dd><dt>

**Return type:**

</dt><dd>

None

</dd></dl>

### `start_idx` {#max.pipelines.core.TextContext.start_idx}

> property start\_idx: [int](https://docs.python.org/3/library/functions.html#int)

### `status` {#max.pipelines.core.TextContext.status}

> status: [GenerationStatus](../interfaces.md#max.interfaces.GenerationStatus)

### `target_endpoint` {#max.pipelines.core.TextContext.target_endpoint}

> target\_endpoint: [str](https://docs.python.org/3/library/stdtypes.html#str) | [None](https://docs.python.org/3/library/constants.html#None)

### `to_generation_output()` {#max.pipelines.core.TextContext.to_generation_output}

> to\_generation\_output()

Get completion tokens that are ready to be returned to the user.

This method retrieves tokens that have been generated but not yet
delivered to the user, along with their associated log probability data.

<dl class='field-list'><dt>

**Returns:**

</dt><dd>

The completion tokens and their associated
log probabilities, if available.

</dd><dt>

**Return type:**

</dt><dd>

[TextGenerationOutput](../interfaces.md#max.interfaces.TextGenerationOutput)

</dd></dl>

### `tokens` {#max.pipelines.core.TextContext.tokens}

> tokens: [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]]

### `update()` {#max.pipelines.core.TextContext.update}

> update(new\_token, log\_probabilities=None)

Updates the next\_tokens and extends existing tokens to include all generated tokens.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* new\_token ([int](https://docs.python.org/3/library/functions.html#int))
* log\_probabilities ([LogProbabilities](../interfaces.md#max.interfaces.LogProbabilities) | None)

</dd><dt>

**Return type:**

</dt><dd>

None

</dd></dl>

## `get_request_payload_from_pipeline_task()` {#max.pipelines.core.get_request_payload_from_pipeline_task}

> max.pipelines.core.get\_request\_payload\_from\_pipeline\_task(pipeline\_task)

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

pipeline\_task ([PipelineTask](../interfaces.md#max.interfaces.PipelineTask))

</dd><dt>

**Return type:**

</dt><dd>

[type](https://docs.python.org/3/library/functions.html#type)\[[tuple](https://docs.python.org/3/library/stdtypes.html#tuple)\[[str](https://docs.python.org/3/library/stdtypes.html#str), [BaseContext](../interfaces.md#max.interfaces.BaseContext)]]

</dd></dl>

---

## hf_utils

Utilities for interacting with HuggingFace Files/Repos.

## `HuggingFaceRepo` {#max.pipelines.lib.hf_utils.HuggingFaceRepo}

> class max.pipelines.lib.hf\_utils.HuggingFaceRepo(repo\_id, revision='main', trust\_remote\_code=False, repo\_type=None)

A class for interacting with HuggingFace Repos.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* repo\_id ([str](https://docs.python.org/3/library/stdtypes.html#str))
* revision ([str](https://docs.python.org/3/library/stdtypes.html#str))
* trust\_remote\_code ([bool](https://docs.python.org/3/library/functions.html#bool))
* repo\_type (RepoType | None)

</dd></dl>

### `encoding_for_file()` {#max.pipelines.lib.hf_utils.HuggingFaceRepo.encoding_for_file}

> encoding\_for\_file(file)

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

file ([str](https://docs.python.org/3/library/stdtypes.html#str) | [Path](https://docs.python.org/3/library/pathlib.html#pathlib.Path))

</dd><dt>

**Return type:**

</dt><dd>

SupportedEncoding

</dd></dl>

### `file_exists()` {#max.pipelines.lib.hf_utils.HuggingFaceRepo.file_exists}

> file\_exists(filename)

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

filename ([str](https://docs.python.org/3/library/stdtypes.html#str))

</dd><dt>

**Return type:**

</dt><dd>

[bool](https://docs.python.org/3/library/functions.html#bool)

</dd></dl>

### `files_for_encoding()` {#max.pipelines.lib.hf_utils.HuggingFaceRepo.files_for_encoding}

> files\_for\_encoding(encoding, weights\_format=None)

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* encoding (SupportedEncoding)
* weights\_format ([WeightsFormat](../graph/weights.md#max.graph.weights.WeightsFormat) | None)

</dd><dt>

**Return type:**

</dt><dd>

[dict](https://docs.python.org/3/library/stdtypes.html#dict)\[[WeightsFormat](../graph/weights.md#max.graph.weights.WeightsFormat), [list](https://docs.python.org/3/library/stdtypes.html#list)\[[Path](https://docs.python.org/3/library/pathlib.html#pathlib.Path)]]

</dd></dl>

### `formats_available` {#max.pipelines.lib.hf_utils.HuggingFaceRepo.formats_available}

> property formats\_available: [list](https://docs.python.org/3/library/stdtypes.html#list)\[[WeightsFormat](../graph/weights.md#max.graph.weights.WeightsFormat)]

### `info` {#max.pipelines.lib.hf_utils.HuggingFaceRepo.info}

> property info: ModelInfo

### `repo_id` {#max.pipelines.lib.hf_utils.HuggingFaceRepo.repo_id}

> repo\_id: [str](https://docs.python.org/3/library/stdtypes.html#str)

The HuggingFace repo id. While itâ€™s called repo\_id, it can be a HF
remote or local path altogether.

### `repo_type` {#max.pipelines.lib.hf_utils.HuggingFaceRepo.repo_type}

> repo\_type: RepoType | [None](https://docs.python.org/3/library/constants.html#None) = None

The type of repo. This is inferred from the repo\_id.

### `revision` {#max.pipelines.lib.hf_utils.HuggingFaceRepo.revision}

> revision: [str](https://docs.python.org/3/library/stdtypes.html#str) = 'main'

The revision to use for the repo.

### `size_of()` {#max.pipelines.lib.hf_utils.HuggingFaceRepo.size_of}

> size\_of(filename)

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

filename ([str](https://docs.python.org/3/library/stdtypes.html#str))

</dd><dt>

**Return type:**

</dt><dd>

[int](https://docs.python.org/3/library/functions.html#int) | None

</dd></dl>

### `supported_encodings` {#max.pipelines.lib.hf_utils.HuggingFaceRepo.supported_encodings}

> property supported\_encodings: [list](https://docs.python.org/3/library/stdtypes.html#list)\[SupportedEncoding]

### `trust_remote_code` {#max.pipelines.lib.hf_utils.HuggingFaceRepo.trust_remote_code}

> trust\_remote\_code: [bool](https://docs.python.org/3/library/functions.html#bool) = False

Whether to trust remote code.

### `weight_files` {#max.pipelines.lib.hf_utils.HuggingFaceRepo.weight_files}

> property weight\_files: [dict](https://docs.python.org/3/library/stdtypes.html#dict)\[[WeightsFormat](../graph/weights.md#max.graph.weights.WeightsFormat), [list](https://docs.python.org/3/library/stdtypes.html#list)\[[str](https://docs.python.org/3/library/stdtypes.html#str)]]

## `download_weight_files()` {#max.pipelines.lib.hf_utils.download_weight_files}

> max.pipelines.lib.hf\_utils.download\_weight\_files(huggingface\_model\_id, filenames, revision=None, force\_download=False, max\_workers=8)

Provided a HuggingFace model id, and filenames, download weight files
: and return the list of local paths.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* huggingface\_model\_id ([str](https://docs.python.org/3/library/stdtypes.html#str)) â€“ The huggingface model identifier, ie. modularai/Llama-3.1-8B-Instruct-GGUF
* filenames ([list](https://docs.python.org/3/library/stdtypes.html#list)\[[str](https://docs.python.org/3/library/stdtypes.html#str)]) â€“ A list of file paths relative to the root of the HuggingFace repo.
  If files provided are available locally, download is skipped, and
  the local files are used.
* revision ([str](https://docs.python.org/3/library/stdtypes.html#str) | None) â€“ The HuggingFace revision to use. If provided, we check our cache
  directly without needing to go to HuggingFace directly, saving a
  network call.
* force\_download ([bool](https://docs.python.org/3/library/functions.html#bool)) â€“ A boolean, indicating whether we should force the files to be
  redownloaded, even if they are already available in our local cache,
  or a provided path.
* max\_workers ([int](https://docs.python.org/3/library/functions.html#int)) â€“ The number of worker threads to concurrently download files.

</dd><dt>

**Return type:**

</dt><dd>

[list](https://docs.python.org/3/library/stdtypes.html#list)\[[Path](https://docs.python.org/3/library/pathlib.html#pathlib.Path)]

</dd></dl>

## `generate_local_model_path()` {#max.pipelines.lib.hf_utils.generate_local_model_path}

> max.pipelines.lib.hf\_utils.generate\_local\_model\_path(repo\_id, revision)

Generate the local filesystem path where a HuggingFace model repo is cached.

This function takes a HuggingFace repository ID and revision hash and returns the full local
filesystem path where the model files are cached by the huggingface\_hub library. The path
follows the standard HuggingFace caching convention of:
\~/.cache/huggingface/hub/modelsâ€“{org}â€“{model}/snapshots/{revision}

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* repo\_id ([str](https://docs.python.org/3/library/stdtypes.html#str)) â€“ The HuggingFace repository ID in the format â€œorg/modelâ€
  (e.g. â€œHuggingFaceTB/SmolLM2-135Mâ€)
* revision ([str](https://docs.python.org/3/library/stdtypes.html#str)) â€“ The specific model revision hash to use, typically from a repo lock file

</dd><dt>

**Returns:**

</dt><dd>

The absolute path to the cached model files for the specified revision.
For example: â€œ\~/.cache/huggingface/hub/modelsâ€“HuggingFaceTBâ€“SmolLM2-135M/snapshots/abc123â€

</dd><dt>

**Return type:**

</dt><dd>

[str](https://docs.python.org/3/library/stdtypes.html#str)

</dd><dt>

**Raises:**

</dt><dd>

[FileNotFoundError](https://docs.python.org/3/library/exceptions.html#FileNotFoundError) â€“ If the model path does not exist locally

</dd></dl>

## `try_to_load_from_cache()` {#max.pipelines.lib.hf_utils.try_to_load_from_cache}

> max.pipelines.lib.hf\_utils.try\_to\_load\_from\_cache(repo\_id, filename, revision)

Wrapper around huggingface\_hub.try\_to\_load\_from\_cache. We also validate
that the repo exists.

validate\_hf\_repo\_access is called before this function to ensure the repo
exists.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* repo\_id ([str](https://docs.python.org/3/library/stdtypes.html#str))
* filename ([str](https://docs.python.org/3/library/stdtypes.html#str))
* revision ([str](https://docs.python.org/3/library/stdtypes.html#str))

</dd><dt>

**Return type:**

</dt><dd>

[str](https://docs.python.org/3/library/stdtypes.html#str) | [Any](https://docs.python.org/3/library/typing.html#typing.Any) | None

</dd></dl>

## `validate_hf_repo_access()` {#max.pipelines.lib.hf_utils.validate_hf_repo_access}

> max.pipelines.lib.hf\_utils.validate\_hf\_repo\_access(repo\_id, revision)

Validate repository access and raise clear, user-friendly errors.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* repo\_id ([str](https://docs.python.org/3/library/stdtypes.html#str)) â€“ The HuggingFace repository ID to validate
* revision ([str](https://docs.python.org/3/library/stdtypes.html#str)) â€“ The revision/branch to validate

</dd><dt>

**Raises:**

</dt><dd>

[ValueError](https://docs.python.org/3/library/exceptions.html#ValueError) â€“ With user-friendly error messages for various access issues

</dd><dt>

**Return type:**

</dt><dd>

None

</dd></dl>

---

## pipelines

The pipelines package provides end-to-end implementations for text
generation, embeddings, audio generation, and speech processing that
automatically convert Hugging Face models into performance-optimized MAX graphs.
Each pipeline can be served via OpenAI-compatible endpoints for production
deployment.

## Modules

* [`architectures`](/max/api/python/pipelines/architectures)
* [`config`](/max/api/python/pipelines/config)
* [`core`](/max/api/python/pipelines/core)
* [`hf_utils`](/max/api/python/pipelines/hf_utils)
* [`pipeline`](/max/api/python/pipelines/pipeline)
* [`registry`](/max/api/python/pipelines/registry)
* [`sampling`](/max/api/python/pipelines/sampling)
* [`tokenizer`](/max/api/python/pipelines/tokenizer)

---

## log_probabilities

## `compute_log_probabilities_ragged()` {#max.pipelines.lib.log_probabilities.compute_log_probabilities_ragged}

> max.pipelines.lib.log\_probabilities.compute\_log\_probabilities\_ragged(device, model, \*, input\_row\_offsets, logits, next\_token\_logits, tokens, sampled\_tokens, batch\_top\_n, batch\_echo)

Computes the log probabilities for ragged model outputs.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* device ([Device](../driver.md#max.driver.Device)) â€“ Device on which to do the bulk of the log probabilities
  computation.  A small amount of computation still occurs on the
  host regardless of this setting.
* model ([Model](../engine.md#max.engine.Model)) â€“ A compiled version of a graph from the
  â€˜log\_probabilities\_ragged\_graphâ€™ function.
* input\_row\_offsets ([ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]]) â€“ Token offsets into token-indexed buffers, by batch
  index.  Should have 1 more element than there are batches (batch n
  is token indices \[input\_row\_offsets\[n], input\_row\_offsets\[n+1])).
* logits ([Tensor](../driver.md#max.driver.Tensor) | None) â€“ (tokens, vocab\_dim) tensor full of tensor logits.  Token
  dimension mapped to batches using input\_row\_offsets.  May be
  omitted only if all â€˜batch\_echoâ€™ values are False.
* next\_token\_logits ([Tensor](../driver.md#max.driver.Tensor)) â€“ (batch\_dim, vocab\_dim) tensor full of tensor logits
  for the next token in each batch item.
* sampled\_tokens ([ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]]) â€“ (batch\_dim,) tensor of sampled token per batch
* batch\_top\_n ([Sequence](https://docs.python.org/3/library/collections.abc.html#collections.abc.Sequence)\[[int](https://docs.python.org/3/library/functions.html#int)]) â€“ Number of top log probabilities to return per input in
  the batch. For any element where top\_n == 0, the
  LogProbabilities is skipped.
* batch\_echo ([Sequence](https://docs.python.org/3/library/collections.abc.html#collections.abc.Sequence)\[[bool](https://docs.python.org/3/library/functions.html#bool)]) â€“ Whether to include input tokens in the returned log
  probabilities.
* tokens ([ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])

</dd><dt>

**Returns:**

</dt><dd>

Computed log probabilities for each item in the batch.

</dd><dt>

**Return type:**

</dt><dd>

[list](https://docs.python.org/3/library/stdtypes.html#list)\[[LogProbabilities](../interfaces.md#max.interfaces.LogProbabilities) | None]

</dd></dl>

## `log_probabilities_ragged_graph()` {#max.pipelines.lib.log_probabilities.log_probabilities_ragged_graph}

> max.pipelines.lib.log\_probabilities.log\_probabilities\_ragged\_graph(device, \*, levels)

Create a graph to compute log probabilities over ragged inputs.

A model obtained by this graph is a required input to
â€˜compute\_log\_probabilities\_raggedâ€™.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* device ([DeviceRef](../graph/type.md#max.graph.type.DeviceRef)) â€“ The type of device this graph will need to run on.
* levels ([int](https://docs.python.org/3/library/functions.html#int)) â€“ log2(max\_k+1) for the desired maximum top-k youâ€™d like to
  support.  To support the OpenAI API maximum of 5 logprobs, use
  levels=3.  Higher levels can be used to support higher k.

</dd><dt>

**Return type:**

</dt><dd>

[Graph](../graph/Graph.md#max.graph.Graph)

</dd></dl>

---

## pipeline

MAX pipeline for model inference and generation.

## `BatchInfo` {#max.pipelines.lib.pipeline.BatchInfo}

> class max.pipelines.lib.pipeline.BatchInfo(past\_seq\_lens, seq\_lens, num\_steps)

Information about a batch of requests passed to the pipeline

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* past\_seq\_lens ([list](https://docs.python.org/3/library/stdtypes.html#list)\[[int](https://docs.python.org/3/library/functions.html#int)])
* seq\_lens ([list](https://docs.python.org/3/library/stdtypes.html#list)\[[int](https://docs.python.org/3/library/functions.html#int)])
* num\_steps ([int](https://docs.python.org/3/library/functions.html#int))

</dd></dl>

### `num_steps` {#max.pipelines.lib.pipeline.BatchInfo.num_steps}

> num\_steps: [int](https://docs.python.org/3/library/functions.html#int)

Number of steps to do in the pipeline

### `past_seq_lens` {#max.pipelines.lib.pipeline.BatchInfo.past_seq_lens}

> past\_seq\_lens: [list](https://docs.python.org/3/library/stdtypes.html#list)\[[int](https://docs.python.org/3/library/functions.html#int)]

Coordinated list of past sequence lengths (i.e. context lengths)

### `seq_lens` {#max.pipelines.lib.pipeline.BatchInfo.seq_lens}

> seq\_lens: [list](https://docs.python.org/3/library/stdtypes.html#list)\[[int](https://docs.python.org/3/library/functions.html#int)]

Coordinated list of sequence lengths, i.e. prompt\_len or 1

## `GenerateMixin` {#max.pipelines.lib.pipeline.GenerateMixin}

> class max.pipelines.lib.pipeline.GenerateMixin(\*args, \*\*kwargs)

### `generate()` {#max.pipelines.lib.pipeline.GenerateMixin.generate}

> generate(prompts)

Generates outputs for the given prompts.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

prompts (RequestType | [list](https://docs.python.org/3/library/stdtypes.html#list)\[RequestType])

</dd><dt>

**Return type:**

</dt><dd>

[list](https://docs.python.org/3/library/stdtypes.html#list)\[[TextGenerationOutput](../interfaces.md#max.interfaces.TextGenerationOutput)]

</dd></dl>

### `generate_async()` {#max.pipelines.lib.pipeline.GenerateMixin.generate_async}

> async generate\_async(prompts)

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

prompts (RequestType | [list](https://docs.python.org/3/library/stdtypes.html#list)\[RequestType])

</dd><dt>

**Return type:**

</dt><dd>

[AsyncGenerator](https://docs.python.org/3/library/collections.abc.html#collections.abc.AsyncGenerator)\[[list](https://docs.python.org/3/library/stdtypes.html#list)\[[TextGenerationOutput](../interfaces.md#max.interfaces.TextGenerationOutput)], None]

</dd></dl>

## `KVCacheMixin` {#max.pipelines.lib.pipeline.KVCacheMixin}

> class max.pipelines.lib.pipeline.KVCacheMixin(\*args, \*\*kwargs)

### `estimate_kv_cache_size()` {#max.pipelines.lib.pipeline.KVCacheMixin.estimate_kv_cache_size}

> abstract classmethod estimate\_kv\_cache\_size(pipeline\_config, available\_cache\_memory, devices, huggingface\_config, kv\_cache\_config, cache\_dtype)

Estimates the size of the kv cache in bytes.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* pipeline\_config ([PipelineConfig](config.md#max.pipelines.lib.config.PipelineConfig))
* available\_cache\_memory ([int](https://docs.python.org/3/library/functions.html#int))
* devices ([list](https://docs.python.org/3/library/stdtypes.html#list)\[[Device](../driver.md#max.driver.Device)])
* huggingface\_config (AutoConfig)
* kv\_cache\_config (KVCacheConfig)
* cache\_dtype ([DType](../dtype.md#max.dtype.DType))

</dd><dt>

**Return type:**

</dt><dd>

[int](https://docs.python.org/3/library/functions.html#int)

</dd></dl>

### `get_kv_params()` {#max.pipelines.lib.pipeline.KVCacheMixin.get_kv_params}

> abstract classmethod get\_kv\_params(huggingface\_config, n\_devices, kv\_cache\_config, cache\_dtype)

Returns the KV cache params for the pipeline model.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* huggingface\_config (AutoConfig)
* n\_devices ([int](https://docs.python.org/3/library/functions.html#int))
* kv\_cache\_config (KVCacheConfig)
* cache\_dtype ([DType](../dtype.md#max.dtype.DType))

</dd><dt>

**Return type:**

</dt><dd>

[KVCacheParams](../nn/kv_cache/cache_params.md#max.nn.kv_cache.cache_params.KVCacheParams)

</dd></dl>

### `get_num_layers()` {#max.pipelines.lib.pipeline.KVCacheMixin.get_num_layers}

> abstract classmethod get\_num\_layers(huggingface\_config)

Returns the number of layers for the pipeline model.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

huggingface\_config (AutoConfig)

</dd><dt>

**Return type:**

</dt><dd>

[int](https://docs.python.org/3/library/functions.html#int)

</dd></dl>

### `load_kv_manager()` {#max.pipelines.lib.pipeline.KVCacheMixin.load_kv_manager}

> load\_kv\_manager(session, available\_cache\_memory)

Provided a PipelineConfig and InferenceSession, loads the KV manager.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* session ([InferenceSession](../engine.md#max.engine.InferenceSession)) â€“ Inference session to compile and init the KV cache.
* available\_cache\_memory ([int](https://docs.python.org/3/library/functions.html#int) | None) â€“ Amount of memory available to the KV cache,
  in bytes.

</dd><dt>

**Returns:**

</dt><dd>

one per input modality.

</dd><dt>

**Return type:**

</dt><dd>

Either a single KV cache manager or a tuple of KV cache managers

</dd></dl>

## `ModelInputs` {#max.pipelines.lib.pipeline.ModelInputs}

> class max.pipelines.lib.pipeline.ModelInputs

Base class for model inputs.
Use this class to encapsulate inputs for your model.
You may store any number of dataclass fields

The following example demonstrates how to create a custom inputs class for a model:

```python
class ReplitInputs(ModelInputs):
    tokens: Tensor
    input_row_offsets: Tensor

    def __init__(self, tokens: Tensor, input_row_offsets: Tensor):
        self.tokens = tokens
        self.input_row_offsets = input_row_offsets

tokens = Tensor.zeros((1, 2, 3), DType.int64)
input_row_offsets = Tensor.zeros((1, 1, 1), DType.int64)

# Initialize inputs
inputs = ReplitInputs(tokens=tokens, input_row_offsets=input_row_offsets)

# Access tensors
list(inputs) == [tokens, input_row_offsets]  # Output: True
```

### `kv_cache_inputs` {#max.pipelines.lib.pipeline.ModelInputs.kv_cache_inputs}

> kv\_cache\_inputs: [KVCacheInputs](../nn/kv_cache/manager.md#max.nn.kv_cache.manager.KVCacheInputs) | [None](https://docs.python.org/3/library/constants.html#None) = None

### `lora_ids` {#max.pipelines.lib.pipeline.ModelInputs.lora_ids}

> lora\_ids: [Tensor](../driver.md#max.driver.Tensor) | [None](https://docs.python.org/3/library/constants.html#None) = None

Tensor containing the LoRA ids.

### `lora_ranks` {#max.pipelines.lib.pipeline.ModelInputs.lora_ranks}

> lora\_ranks: [Tensor](../driver.md#max.driver.Tensor) | [None](https://docs.python.org/3/library/constants.html#None) = None

Tensor containing the LoRA ranks

### `update()` {#max.pipelines.lib.pipeline.ModelInputs.update}

> update(\*\*kwargs)

<dl class='field-list'><dt>

**Return type:**

</dt><dd>

None

</dd></dl>

## `ModelOutputs` {#max.pipelines.lib.pipeline.ModelOutputs}

> class max.pipelines.lib.pipeline.ModelOutputs(logits: 'Tensor', next\_token\_logits: 'Tensor | None' = None, logit\_offsets: 'Tensor | None' = None)

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* logits ([Tensor](../driver.md#max.driver.Tensor))
* next\_token\_logits ([Tensor](../driver.md#max.driver.Tensor) | None)
* logit\_offsets ([Tensor](../driver.md#max.driver.Tensor) | None)

</dd></dl>

### `logit_offsets` {#max.pipelines.lib.pipeline.ModelOutputs.logit_offsets}

> logit\_offsets: [Tensor](../driver.md#max.driver.Tensor) | [None](https://docs.python.org/3/library/constants.html#None) = None

Offsets to access variable length logits for each sequence.

### `logits` {#max.pipelines.lib.pipeline.ModelOutputs.logits}

> logits: [Tensor](../driver.md#max.driver.Tensor)

Logits for a variable number of tokens per sequence.

### `next_token_logits` {#max.pipelines.lib.pipeline.ModelOutputs.next_token_logits}

> next\_token\_logits: [Tensor](../driver.md#max.driver.Tensor) | [None](https://docs.python.org/3/library/constants.html#None) = None

Logits for just the next token.

## `PipelineModel` {#max.pipelines.lib.pipeline.PipelineModel}

> class max.pipelines.lib.pipeline.PipelineModel(pipeline\_config, session, huggingface\_config, encoding, devices, kv\_cache\_config, weights, adapter, return\_logits)

A pipeline model with setup, input preparation and execution methods.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* pipeline\_config ([PipelineConfig](config.md#max.pipelines.lib.config.PipelineConfig))
* session ([InferenceSession](../engine.md#max.engine.InferenceSession))
* huggingface\_config (AutoConfig)
* encoding (SupportedEncoding)
* devices ([list](https://docs.python.org/3/library/stdtypes.html#list)\[[Device](../driver.md#max.driver.Device)])
* kv\_cache\_config (KVCacheConfig)
* weights ([Weights](../graph/weights.md#max.graph.weights.Weights))
* adapter (Optional\[WeightsAdapter])
* return\_logits ([ReturnLogits](../nn/transformer/transformer.md#max.nn.transformer.transformer.ReturnLogits))

</dd></dl>

### `calculate_max_seq_len()` {#max.pipelines.lib.pipeline.PipelineModel.calculate_max_seq_len}

> abstract classmethod calculate\_max\_seq\_len(pipeline\_config, huggingface\_config)

Calculate the optimal max sequence length for the model.
Models are expected to implement this method.

The following example shows how to implement this method for a Mistral model:

```python
class MistralModel(PipelineModel):
    @classmethod
    def calculate_max_seq_len(cls, pipeline_config, huggingface_config) -> int:
        try:
            return upper_bounded_default(
                upper_bound=huggingface_config.max_seq_len,
                default=pipeline_config.max_length,
            )
        except ValueError as e:
            msg = (
                "Unable to infer max_length for Mistral, the provided "
                f"max_length ({pipeline_config.max_length}) exceeds the "
                f"model's max_seq_len ({huggingface_config.max_seq_len})."
            )
            raise ValueError(msg) from e
```

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* pipeline\_config ([PipelineConfig](config.md#max.pipelines.lib.config.PipelineConfig)) â€“ Configuration for the pipeline.
* huggingface\_config (AutoConfig) â€“ Hugging Face model configuration.

</dd><dt>

**Returns:**

</dt><dd>

The maximum sequence length to use.

</dd><dt>

**Return type:**

</dt><dd>

[int](https://docs.python.org/3/library/functions.html#int)

</dd></dl>

### `compute_log_probabilities()` {#max.pipelines.lib.pipeline.PipelineModel.compute_log_probabilities}

> compute\_log\_probabilities(session, model\_inputs, model\_outputs, next\_tokens, batch\_top\_n, batch\_echo)

Optional method that can be overridden to compute log probabilities.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* session ([InferenceSession](../engine.md#max.engine.InferenceSession)) â€“ Inference session to compute log probabilities within.
* model\_inputs ([ModelInputs](#max.pipelines.lib.pipeline.ModelInputs)) â€“ Inputs to the model returned by
  prepare\_\*\_token\_inputs().
* model\_outputs ([ModelOutputs](#max.pipelines.lib.pipeline.ModelOutputs)) â€“ Outputs returned by execute().
* next\_tokens ([Tensor](../driver.md#max.driver.Tensor)) â€“ Sampled tokens. Should have shape=\[batch size]
* batch\_top\_n ([list](https://docs.python.org/3/library/stdtypes.html#list)\[[int](https://docs.python.org/3/library/functions.html#int)]) â€“ Number of top log probabilities to return per input in
  the batch. For any element where top\_n == 0, the
  LogProbabilities is skipped.
* batch\_echo ([list](https://docs.python.org/3/library/stdtypes.html#list)\[[bool](https://docs.python.org/3/library/functions.html#bool)]) â€“ Whether to include input tokens in the returned log
  probabilities.

</dd><dt>

**Returns:**

</dt><dd>

List of log probabilities.

</dd><dt>

**Return type:**

</dt><dd>

[list](https://docs.python.org/3/library/stdtypes.html#list)\[[LogProbabilities](../interfaces.md#max.interfaces.LogProbabilities) | None] | None

</dd></dl>

### `dtype` {#max.pipelines.lib.pipeline.PipelineModel.dtype}

> property dtype: [DType](../dtype.md#max.dtype.DType)

### `estimate_activation_memory()` {#max.pipelines.lib.pipeline.PipelineModel.estimate_activation_memory}

> classmethod estimate\_activation\_memory(pipeline\_config, huggingface\_config)

Estimates the activation memory required for model execution.

This accounts for temporary memory buffers used during model execution,
such as intermediate activations and working buffers.

The default implementation returns 0 for backward compatibility.
Models with significant activation memory requirements should override
this method to provide accurate estimates.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* pipeline\_config ([PipelineConfig](config.md#max.pipelines.lib.config.PipelineConfig)) â€“ Pipeline configuration
* huggingface\_config (AutoConfig) â€“ HuggingFace model configuration

</dd><dt>

**Returns:**

</dt><dd>

Estimated activation memory in bytes

</dd><dt>

**Return type:**

</dt><dd>

[int](https://docs.python.org/3/library/functions.html#int)

</dd></dl>

### `estimate_weights_size()` {#max.pipelines.lib.pipeline.PipelineModel.estimate_weights_size}

> classmethod estimate\_weights\_size(pipeline\_config)

Calculates the estimated memory consumption of our model.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

pipeline\_config ([PipelineConfig](config.md#max.pipelines.lib.config.PipelineConfig))

</dd><dt>

**Return type:**

</dt><dd>

[int](https://docs.python.org/3/library/functions.html#int)

</dd></dl>

### `execute()` {#max.pipelines.lib.pipeline.PipelineModel.execute}

> abstract execute(model\_inputs)

Executes the graph with the given inputs.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

model\_inputs ([ModelInputs](#max.pipelines.lib.pipeline.ModelInputs)) â€“ The model inputs to execute, containing tensors and any other
required data for model execution.

</dd><dt>

**Returns:**

</dt><dd>

ModelOutputs containing the pipelineâ€™s output tensors.

</dd><dt>

**Return type:**

</dt><dd>

[ModelOutputs](#max.pipelines.lib.pipeline.ModelOutputs)

</dd></dl>

This is an abstract method that must be implemented by concrete PipelineModels
to define their specific execution logic.

### `infer_optimal_batch_size()` {#max.pipelines.lib.pipeline.PipelineModel.infer_optimal_batch_size}

> classmethod infer\_optimal\_batch\_size(pipeline\_config, available\_cache\_memory, huggingface\_config, devices, kv\_cache\_config, cache\_dtype)

Returns the estimated optimal batch size to run the model
given current memory constraints.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* pipeline\_config ([PipelineConfig](config.md#max.pipelines.lib.config.PipelineConfig))
* available\_cache\_memory ([int](https://docs.python.org/3/library/functions.html#int))
* huggingface\_config (AutoConfig)
* devices ([list](https://docs.python.org/3/library/stdtypes.html#list)\[[Device](../driver.md#max.driver.Device)])
* kv\_cache\_config (KVCacheConfig)
* cache\_dtype ([DType](../dtype.md#max.dtype.DType))

</dd><dt>

**Return type:**

</dt><dd>

[int](https://docs.python.org/3/library/functions.html#int)

</dd></dl>

### `lora_manager` {#max.pipelines.lib.pipeline.PipelineModel.lora_manager}

> property lora\_manager: LoRAManager | [None](https://docs.python.org/3/library/constants.html#None)

### `prepare_initial_token_inputs()` {#max.pipelines.lib.pipeline.PipelineModel.prepare_initial_token_inputs}

> abstract prepare\_initial\_token\_inputs(context\_batch, kv\_cache\_inputs=None, return\_n\_logits=1)

Prepares the initial inputs to be passed to .execute().

The inputs and functionality of this method can vary per model.
For example, the model inputs could include:

* Encoded tensors
* A unique IDs for each tensor if this model uses a KV Cache manager.
* kv\_cache\_inputs: The kv cache inputs required for the model. This
  should be None if the model does not use KV Cache.
  This function would batch the encoded tensors, claim a slot in the kv
  cache if the ID hasnâ€™t been seen before, and return the inputs and
  caches as a list of tensors.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* context\_batch ([Sequence](https://docs.python.org/3/library/collections.abc.html#collections.abc.Sequence)\[T])
* kv\_cache\_inputs ([KVCacheInputs](../nn/kv_cache/manager.md#max.nn.kv_cache.manager.KVCacheInputs) | None)
* return\_n\_logits ([int](https://docs.python.org/3/library/functions.html#int))

</dd><dt>

**Return type:**

</dt><dd>

[ModelInputs](#max.pipelines.lib.pipeline.ModelInputs)

</dd></dl>

### `prepare_next_token_inputs()` {#max.pipelines.lib.pipeline.PipelineModel.prepare_next_token_inputs}

> abstract prepare\_next\_token\_inputs(next\_tokens, prev\_model\_inputs)

Prepares the secondary inputs to be passed to .execute().

While prepare\_initial\_token\_inputs is responsible for managing the initial inputs.
This function is responsible for updating the inputs, for each step in a multi-step execution pattern.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* next\_tokens ([Tensor](../driver.md#max.driver.Tensor))
* prev\_model\_inputs ([ModelInputs](#max.pipelines.lib.pipeline.ModelInputs))

</dd><dt>

**Return type:**

</dt><dd>

[ModelInputs](#max.pipelines.lib.pipeline.ModelInputs)

</dd></dl>

## `TextGenerationPipeline` {#max.pipelines.lib.pipeline.TextGenerationPipeline}

> class max.pipelines.lib.pipeline.TextGenerationPipeline(pipeline\_config, pipeline\_model, eos\_token\_id, weight\_adapters, tokenizer)

Generalized token generator pipeline.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* pipeline\_config ([PipelineConfig](config.md#max.pipelines.lib.config.PipelineConfig))
* pipeline\_model ([type](https://docs.python.org/3/library/functions.html#type)\[[PipelineModel](#max.pipelines.lib.pipeline.PipelineModel)\[TextGenerationContextType]])
* eos\_token\_id ([int](https://docs.python.org/3/library/functions.html#int))
* weight\_adapters ([dict](https://docs.python.org/3/library/stdtypes.html#dict)\[[WeightsFormat](../graph/weights.md#max.graph.weights.WeightsFormat), WeightsAdapter])
* tokenizer ([PipelineTokenizer](../interfaces.md#max.interfaces.PipelineTokenizer)\[TextGenerationContextType, npt.NDArray\[np.integer\[Any]], [TextGenerationRequest](../interfaces.md#max.interfaces.TextGenerationRequest)])

</dd></dl>

### `calculate_num_steps()` {#max.pipelines.lib.pipeline.TextGenerationPipeline.calculate_num_steps}

> calculate\_num\_steps(num\_steps, context)

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* num\_steps ([int](https://docs.python.org/3/library/functions.html#int))
* context (TextGenerationContextType)

</dd><dt>

**Return type:**

</dt><dd>

[int](https://docs.python.org/3/library/functions.html#int)

</dd></dl>

### `execute()` {#max.pipelines.lib.pipeline.TextGenerationPipeline.execute}

> execute(inputs)

Provided a batch, process batch inputs, execute the graph for num\_steps in a multi-step scenario,
then decode the tokens holistically and return the list of decoded tokens.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

inputs ([TextGenerationInputs](../interfaces.md#max.interfaces.TextGenerationInputs)\[TextGenerationContextType])

</dd><dt>

**Return type:**

</dt><dd>

[dict](https://docs.python.org/3/library/stdtypes.html#dict)\[[str](https://docs.python.org/3/library/stdtypes.html#str), [TextGenerationOutput](../interfaces.md#max.interfaces.TextGenerationOutput)]

</dd></dl>

### `kv_managers` {#max.pipelines.lib.pipeline.TextGenerationPipeline.kv_managers}

> property kv\_managers: [list](https://docs.python.org/3/library/stdtypes.html#list)\[[KVCacheManager](../nn/kv_cache/manager.md#max.nn.kv_cache.manager.KVCacheManager)\[TextGenerationContextType]]

### `pipeline_config` {#max.pipelines.lib.pipeline.TextGenerationPipeline.pipeline_config}

> property pipeline\_config: [PipelineConfig](config.md#max.pipelines.lib.config.PipelineConfig)

### `prepare_batch()` {#max.pipelines.lib.pipeline.TextGenerationPipeline.prepare_batch}

> prepare\_batch(batches, num\_steps)

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* batches ([list](https://docs.python.org/3/library/stdtypes.html#list)\[[list](https://docs.python.org/3/library/stdtypes.html#list)\[TextGenerationContextType]])
* num\_steps ([int](https://docs.python.org/3/library/functions.html#int))

</dd><dt>

**Return type:**

</dt><dd>

[tuple](https://docs.python.org/3/library/stdtypes.html#tuple)\[[ModelInputs](#max.pipelines.lib.pipeline.ModelInputs), [int](https://docs.python.org/3/library/functions.html#int), [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[int32]] | None]

</dd></dl>

### `release()` {#max.pipelines.lib.pipeline.TextGenerationPipeline.release}

> release(request\_id)

Mark the context as complete, releasing the cache slot from the KV manager.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

request\_id ([str](https://docs.python.org/3/library/stdtypes.html#str))

</dd><dt>

**Return type:**

</dt><dd>

None

</dd></dl>

### `tokenizer` {#max.pipelines.lib.pipeline.TextGenerationPipeline.tokenizer}

> property tokenizer: [PipelineTokenizer](../interfaces.md#max.interfaces.PipelineTokenizer)\[TextGenerationContextType, [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]], [TextGenerationRequest](../interfaces.md#max.interfaces.TextGenerationRequest)]

## `get_paged_manager()` {#max.pipelines.lib.pipeline.get_paged_manager}

> max.pipelines.lib.pipeline.get\_paged\_manager(pipeline)

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

pipeline ([Pipeline](../interfaces.md#max.interfaces.Pipeline)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [Any](https://docs.python.org/3/library/typing.html#typing.Any)])

</dd><dt>

**Return type:**

</dt><dd>

PagedKVCacheManager\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | None

</dd></dl>

## `upper_bounded_default()` {#max.pipelines.lib.pipeline.upper_bounded_default}

> max.pipelines.lib.pipeline.upper\_bounded\_default(upper\_bound, default)

Given an upper bound and an optional default value, returns a final value
that cannot exceed the upper bound.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* default ([int](https://docs.python.org/3/library/functions.html#int) | None) â€“ The default value to use, or None to use the upper bound.
* upper\_bound ([int](https://docs.python.org/3/library/functions.html#int)) â€“ The upper bound to use.

</dd><dt>

**Raises:**

</dt><dd>

[ValueError](https://docs.python.org/3/library/exceptions.html#ValueError) â€“ If the provided default value exceeds the upper bound.

</dd><dt>

**Returns:**

</dt><dd>

The final value.

</dd><dt>

**Return type:**

</dt><dd>

[int](https://docs.python.org/3/library/functions.html#int)

</dd></dl>

## `SpeculativeDecodingTextGenerationPipeline` {#max.pipelines.lib.speculative_decoding.SpeculativeDecodingTextGenerationPipeline}

> final class max.pipelines.lib.speculative\_decoding.SpeculativeDecodingTextGenerationPipeline(pipeline\_config, pipeline\_model, eos\_token\_id, weight\_adapters, tokenizer)

Bases: [`Pipeline`](../interfaces.md#max.interfaces.Pipeline)\[[`TextGenerationInputs`](../interfaces.md#max.interfaces.TextGenerationInputs)\[[`TextContext`](core.md#max.pipelines.core.TextContext) | [`TextAndVisionContext`](core.md#max.pipelines.core.TextAndVisionContext)], [`TextGenerationOutput`](../interfaces.md#max.interfaces.TextGenerationOutput)], [`GenerateMixin`](#max.pipelines.lib.pipeline.GenerateMixin)\[[`TextContext`](core.md#max.pipelines.core.TextContext) | [`TextAndVisionContext`](core.md#max.pipelines.core.TextAndVisionContext), [`TextGenerationRequest`](../interfaces.md#max.interfaces.TextGenerationRequest)]

Generalized token generator pipeline with speculative decoding.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* pipeline\_config ([PipelineConfig](config.md#max.pipelines.lib.config.PipelineConfig))
* pipeline\_model ([type](https://docs.python.org/3/library/functions.html#type)\[[PipelineModel](#max.pipelines.lib.pipeline.PipelineModel)\[[TextContext](core.md#max.pipelines.core.TextContext) | [TextAndVisionContext](core.md#max.pipelines.core.TextAndVisionContext)]])
* eos\_token\_id ([int](https://docs.python.org/3/library/functions.html#int))
* weight\_adapters ([dict](https://docs.python.org/3/library/stdtypes.html#dict)\[[WeightsFormat](../graph/weights.md#max.graph.weights.WeightsFormat), WeightsAdapter])
* tokenizer ([PipelineTokenizer](../interfaces.md#max.interfaces.PipelineTokenizer)\[Union\[[TextContext](core.md#max.pipelines.core.TextContext), [TextAndVisionContext](core.md#max.pipelines.core.TextAndVisionContext)], npt.NDArray\[np.integer\[Any]], [TextGenerationRequest](../interfaces.md#max.interfaces.TextGenerationRequest)])

</dd></dl>

### `build_response()` {#max.pipelines.lib.speculative_decoding.SpeculativeDecodingTextGenerationPipeline.build_response}

> build\_response(context\_batch)

Build response from updated contexts.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* batch â€“ The input batch dictionary mapping request IDs to contexts
* context\_batch ([list](https://docs.python.org/3/library/stdtypes.html#list)\[[TextContext](core.md#max.pipelines.core.TextContext) | [TextAndVisionContext](core.md#max.pipelines.core.TextAndVisionContext)]) â€“ The list of context objects

</dd><dt>

**Returns:**

</dt><dd>

Dictionary mapping request IDs to TextGenerationOutput objects

</dd><dt>

**Return type:**

</dt><dd>

[dict](https://docs.python.org/3/library/stdtypes.html#dict)\[[str](https://docs.python.org/3/library/stdtypes.html#str), [TextGenerationOutput](../interfaces.md#max.interfaces.TextGenerationOutput)]

</dd></dl>

### `calculate_num_steps()` {#max.pipelines.lib.speculative_decoding.SpeculativeDecodingTextGenerationPipeline.calculate_num_steps}

> calculate\_num\_steps(model, huggingface\_config, num\_steps, context, is\_draft=False)

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* model ([PipelineModel](#max.pipelines.lib.pipeline.PipelineModel)\[[TextContext](core.md#max.pipelines.core.TextContext) | [TextAndVisionContext](core.md#max.pipelines.core.TextAndVisionContext)])
* huggingface\_config (AutoConfig)
* num\_steps ([int](https://docs.python.org/3/library/functions.html#int))
* context ([TextContext](core.md#max.pipelines.core.TextContext) | [TextAndVisionContext](core.md#max.pipelines.core.TextAndVisionContext))
* is\_draft ([bool](https://docs.python.org/3/library/functions.html#bool))

</dd><dt>

**Return type:**

</dt><dd>

[int](https://docs.python.org/3/library/functions.html#int)

</dd></dl>

### `execute()` {#max.pipelines.lib.speculative_decoding.SpeculativeDecodingTextGenerationPipeline.execute}

> execute(inputs)

Provided a batch, execute both the draft model for num\_steps and the target model for num\_steps + 1 tokens, accepting final tokens via rejection sampling, returning the variable list of token integers.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

inputs ([TextGenerationInputs](../interfaces.md#max.interfaces.TextGenerationInputs)\[[TextContext](core.md#max.pipelines.core.TextContext) | [TextAndVisionContext](core.md#max.pipelines.core.TextAndVisionContext)])

</dd><dt>

**Return type:**

</dt><dd>

[dict](https://docs.python.org/3/library/stdtypes.html#dict)\[[str](https://docs.python.org/3/library/stdtypes.html#str), [TextGenerationOutput](../interfaces.md#max.interfaces.TextGenerationOutput)]

</dd></dl>

### `generate_draft_tokens()` {#max.pipelines.lib.speculative_decoding.SpeculativeDecodingTextGenerationPipeline.generate_draft_tokens}

> generate\_draft\_tokens(batch, num\_steps, model\_inputs)

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* batch ([list](https://docs.python.org/3/library/stdtypes.html#list)\[[TextContext](core.md#max.pipelines.core.TextContext) | [TextAndVisionContext](core.md#max.pipelines.core.TextAndVisionContext)])
* num\_steps ([int](https://docs.python.org/3/library/functions.html#int))
* model\_inputs ([ModelInputs](#max.pipelines.lib.pipeline.ModelInputs))

</dd><dt>

**Return type:**

</dt><dd>

[tuple](https://docs.python.org/3/library/stdtypes.html#tuple)\[[int](https://docs.python.org/3/library/functions.html#int), [Tensor](../driver.md#max.driver.Tensor), [Tensor](../driver.md#max.driver.Tensor), [ModelInputs](#max.pipelines.lib.pipeline.ModelInputs), [Tensor](../driver.md#max.driver.Tensor)]

</dd></dl>

### `kv_managers` {#max.pipelines.lib.speculative_decoding.SpeculativeDecodingTextGenerationPipeline.kv_managers}

> property kv\_managers: [list](https://docs.python.org/3/library/stdtypes.html#list)\[[KVCacheManager](../nn/kv_cache/manager.md#max.nn.kv_cache.manager.KVCacheManager)\[[TextContext](core.md#max.pipelines.core.TextContext) | [TextAndVisionContext](core.md#max.pipelines.core.TextAndVisionContext)]]

### `metrics` {#max.pipelines.lib.speculative_decoding.SpeculativeDecodingTextGenerationPipeline.metrics}

> property metrics: SpeculativeDecodingMetrics

Get the current speculative decoding metrics.

<dl class='field-list'><dt>

**Returns:**

</dt><dd>

The SpeculativeDecodingMetrics instance with current statistics

</dd></dl>

### `pipeline_config` {#max.pipelines.lib.speculative_decoding.SpeculativeDecodingTextGenerationPipeline.pipeline_config}

> property pipeline\_config: [PipelineConfig](config.md#max.pipelines.lib.config.PipelineConfig)

### `prepare_batch()` {#max.pipelines.lib.speculative_decoding.SpeculativeDecodingTextGenerationPipeline.prepare_batch}

> prepare\_batch(model, batch, num\_steps, return\_n\_logits, is\_draft=False, draft\_inputs=None, merged\_draft\_tokens=None, merged\_draft\_offsets=None)

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* model ([PipelineModel](#max.pipelines.lib.pipeline.PipelineModel)\[[TextContext](core.md#max.pipelines.core.TextContext) | [TextAndVisionContext](core.md#max.pipelines.core.TextAndVisionContext)])
* batch ([list](https://docs.python.org/3/library/stdtypes.html#list)\[[TextContext](core.md#max.pipelines.core.TextContext) | [TextAndVisionContext](core.md#max.pipelines.core.TextAndVisionContext)])
* num\_steps ([int](https://docs.python.org/3/library/functions.html#int))
* return\_n\_logits ([int](https://docs.python.org/3/library/functions.html#int))
* is\_draft ([bool](https://docs.python.org/3/library/functions.html#bool))
* draft\_inputs ([ModelInputs](#max.pipelines.lib.pipeline.ModelInputs) | None)
* merged\_draft\_tokens ([Tensor](../driver.md#max.driver.Tensor) | None)
* merged\_draft\_offsets ([Tensor](../driver.md#max.driver.Tensor) | None)

</dd><dt>

**Return type:**

</dt><dd>

[tuple](https://docs.python.org/3/library/stdtypes.html#tuple)\[[ModelInputs](#max.pipelines.lib.pipeline.ModelInputs), [int](https://docs.python.org/3/library/functions.html#int)]

</dd></dl>

### `release()` {#max.pipelines.lib.speculative_decoding.SpeculativeDecodingTextGenerationPipeline.release}

> release(request\_id)

Releases resources associated with this request ID.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

request\_id ([str](https://docs.python.org/3/library/stdtypes.html#str)) â€“ Unique identifier for the finished request.

</dd><dt>

**Return type:**

</dt><dd>

None

</dd></dl>

### `sample_draft_logits()` {#max.pipelines.lib.speculative_decoding.SpeculativeDecodingTextGenerationPipeline.sample_draft_logits}

> sample\_draft\_logits(batch, model\_outputs, prev\_tokens, prev\_logits, top\_k, max\_k, temperature, top\_p, seed)

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* batch ([list](https://docs.python.org/3/library/stdtypes.html#list)\[[TextContext](core.md#max.pipelines.core.TextContext) | [TextAndVisionContext](core.md#max.pipelines.core.TextAndVisionContext)])
* model\_outputs ([ModelOutputs](#max.pipelines.lib.pipeline.ModelOutputs))
* prev\_tokens ([Tensor](../driver.md#max.driver.Tensor))
* prev\_logits ([Tensor](../driver.md#max.driver.Tensor))
* top\_k ([Tensor](../driver.md#max.driver.Tensor))
* max\_k ([Tensor](../driver.md#max.driver.Tensor))
* temperature ([Tensor](../driver.md#max.driver.Tensor))
* top\_p ([Tensor](../driver.md#max.driver.Tensor))
* seed ([Tensor](../driver.md#max.driver.Tensor))

</dd><dt>

**Return type:**

</dt><dd>

[tuple](https://docs.python.org/3/library/stdtypes.html#tuple)\[[Tensor](../driver.md#max.driver.Tensor), [Tensor](../driver.md#max.driver.Tensor), [Tensor](../driver.md#max.driver.Tensor)]

</dd></dl>

### `tokenizer` {#max.pipelines.lib.speculative_decoding.SpeculativeDecodingTextGenerationPipeline.tokenizer}

> property tokenizer: [PipelineTokenizer](../interfaces.md#max.interfaces.PipelineTokenizer)\[[TextContext](core.md#max.pipelines.core.TextContext) | [TextAndVisionContext](core.md#max.pipelines.core.TextAndVisionContext), [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]], [TextGenerationRequest](../interfaces.md#max.interfaces.TextGenerationRequest)]

### `update_contexts()` {#max.pipelines.lib.speculative_decoding.SpeculativeDecodingTextGenerationPipeline.update_contexts}

> update\_contexts(context\_batch, first\_rejected\_tokens, recovered\_tokens, bonus\_tokens, draft\_tokens, num\_draft\_tokens\_generated)

Update contexts with the results of token generation.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* context\_batch ([list](https://docs.python.org/3/library/stdtypes.html#list)\[[TextContext](core.md#max.pipelines.core.TextContext) | [TextAndVisionContext](core.md#max.pipelines.core.TextAndVisionContext)]) â€“ The list of context objects
* first\_rejected\_tokens ([ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]]) â€“ Array indicating the indices of first rejected tokens
* sampled\_target\_tokens â€“ Array of sampled tokens from the target model
* draft\_tokens ([ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]]) â€“ Array of draft tokens
* num\_draft\_tokens\_generated ([int](https://docs.python.org/3/library/functions.html#int)) â€“ Number of tokens generated by the draft model
* recovered\_tokens ([ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])
* bonus\_tokens ([ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])

</dd><dt>

**Return type:**

</dt><dd>

None

</dd></dl>

### `verify_draft_tokens_with_target_model()` {#max.pipelines.lib.speculative_decoding.SpeculativeDecodingTextGenerationPipeline.verify_draft_tokens_with_target_model}

> verify\_draft\_tokens\_with\_target\_model(draft\_inputs, context\_batch, num\_draft\_tokens\_generated, draft\_tokens, draft\_logits, merged\_draft\_tokens, merged\_draft\_offsets, all\_draft\_logits)

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* draft\_inputs ([ModelInputs](#max.pipelines.lib.pipeline.ModelInputs))
* context\_batch ([list](https://docs.python.org/3/library/stdtypes.html#list)\[[TextContext](core.md#max.pipelines.core.TextContext) | [TextAndVisionContext](core.md#max.pipelines.core.TextAndVisionContext)])
* num\_draft\_tokens\_generated ([int](https://docs.python.org/3/library/functions.html#int))
* draft\_tokens ([Tensor](../driver.md#max.driver.Tensor))
* draft\_logits ([Tensor](../driver.md#max.driver.Tensor))
* merged\_draft\_tokens ([Tensor](../driver.md#max.driver.Tensor))
* merged\_draft\_offsets ([Tensor](../driver.md#max.driver.Tensor))
* all\_draft\_logits ([Tensor](../driver.md#max.driver.Tensor))

</dd><dt>

**Return type:**

</dt><dd>

[tuple](https://docs.python.org/3/library/stdtypes.html#tuple)\[[Tensor](../driver.md#max.driver.Tensor), [Tensor](../driver.md#max.driver.Tensor), [Tensor](../driver.md#max.driver.Tensor)]

</dd></dl>

## `EmbeddingsPipeline` {#max.pipelines.lib.embeddings_pipeline.EmbeddingsPipeline}

> final class max.pipelines.lib.embeddings\_pipeline.EmbeddingsPipeline(pipeline\_config, pipeline\_model, eos\_token\_id, weight\_adapters, tokenizer)

Bases: [`Pipeline`](../interfaces.md#max.interfaces.Pipeline)\[[`EmbeddingsGenerationInputs`](../interfaces.md#max.interfaces.EmbeddingsGenerationInputs)\[`EmbeddingsGenerationContextType`], [`EmbeddingsGenerationOutput`](../interfaces.md#max.interfaces.EmbeddingsGenerationOutput)]

Generalized token generator pipeline.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* pipeline\_config ([PipelineConfig](config.md#max.pipelines.lib.config.PipelineConfig))
* pipeline\_model ([type](https://docs.python.org/3/library/functions.html#type)\[[PipelineModel](#max.pipelines.lib.pipeline.PipelineModel)\[EmbeddingsGenerationContextType]])
* eos\_token\_id ([int](https://docs.python.org/3/library/functions.html#int))
* weight\_adapters ([dict](https://docs.python.org/3/library/stdtypes.html#dict)\[[WeightsFormat](../graph/weights.md#max.graph.weights.WeightsFormat), WeightsAdapter])
* tokenizer ([PipelineTokenizer](../interfaces.md#max.interfaces.PipelineTokenizer)\[BaseContextType, npt.NDArray\[np.integer\[Any]], [TextGenerationRequest](../interfaces.md#max.interfaces.TextGenerationRequest)])

</dd></dl>

### `execute()` {#max.pipelines.lib.embeddings_pipeline.EmbeddingsPipeline.execute}

> execute(inputs)

Provided a batch, process batch inputs, execute the graph for num\_steps in a multi-step scenario,
then decode the tokens holistically and return the list of decoded tokens.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

inputs ([EmbeddingsGenerationInputs](../interfaces.md#max.interfaces.EmbeddingsGenerationInputs)\[EmbeddingsGenerationContextType])

</dd><dt>

**Return type:**

</dt><dd>

[dict](https://docs.python.org/3/library/stdtypes.html#dict)\[[str](https://docs.python.org/3/library/stdtypes.html#str), [EmbeddingsGenerationOutput](../interfaces.md#max.interfaces.EmbeddingsGenerationOutput)]

</dd></dl>

### `release()` {#max.pipelines.lib.embeddings_pipeline.EmbeddingsPipeline.release}

> release(request\_id)

Release any resources or state associated with a specific request.

This method should be implemented by concrete pipeline classes to perform
cleanup or resource deallocation for the given request ID. It is typically
called when a request has completed processing and its associated resources
(such as memory, cache, or temporary files) are no longer needed.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

request\_id (RequestID) â€“ The unique identifier of the request to release resources for.

</dd><dt>

**Returns:**

</dt><dd>

None

</dd><dt>

**Raises:**

</dt><dd>

[NotImplementedError](https://docs.python.org/3/library/exceptions.html#NotImplementedError) â€“ If not implemented by a concrete subclass.

</dd><dt>

**Return type:**

</dt><dd>

None

</dd></dl>

---

## registry

Model registry, for tracking various model variants.

## `PipelineRegistry` {#max.pipelines.lib.registry.PipelineRegistry}

> class max.pipelines.lib.registry.PipelineRegistry(architectures)

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

architectures ([list](https://docs.python.org/3/library/stdtypes.html#list)\[[SupportedArchitecture](#max.pipelines.lib.registry.SupportedArchitecture)])

</dd></dl>

### `get_active_huggingface_config()` {#max.pipelines.lib.registry.PipelineRegistry.get_active_huggingface_config}

> get\_active\_huggingface\_config(huggingface\_repo)

Retrieves or creates a cached HuggingFace AutoConfig for the given
model configuration.

This method maintains a cache of HuggingFace configurations to avoid
reloading them unnecessarily which incurs a huggingface hub API call.
If a config for the given model hasnâ€™t been loaded before, it will
create a new one using AutoConfig.from\_pretrained() with the modelâ€™s
settings.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

huggingface\_repo ([HuggingFaceRepo](hf_utils.md#max.pipelines.lib.hf_utils.HuggingFaceRepo)) â€“ The HuggingFaceRepo containing the model.

</dd><dt>

**Returns:**

</dt><dd>

The HuggingFace configuration object for the model.

</dd><dt>

**Return type:**

</dt><dd>

AutoConfig

</dd></dl>

### `get_active_tokenizer()` {#max.pipelines.lib.registry.PipelineRegistry.get_active_tokenizer}

> get\_active\_tokenizer(huggingface\_repo)

Retrieves or creates a cached HuggingFace AutoTokenizer for the given
model configuration.

This method maintains a cache of HuggingFace tokenizers to avoid
reloading them unnecessarily which incurs a huggingface hub API call.
If a tokenizer for the given model hasnâ€™t been loaded before, it will
create a new one using AutoTokenizer.from\_pretrained() with the modelâ€™s
settings.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

huggingface\_repo ([HuggingFaceRepo](hf_utils.md#max.pipelines.lib.hf_utils.HuggingFaceRepo)) â€“ The HuggingFaceRepo containing the model.

</dd><dt>

**Returns:**

</dt><dd>

The HuggingFace tokenizer for the model.

</dd><dt>

**Return type:**

</dt><dd>

PreTrainedTokenizer | PreTrainedTokenizerFast

</dd></dl>

### `register()` {#max.pipelines.lib.registry.PipelineRegistry.register}

> register(architecture, \*, allow\_override=False)

Add new architecture to registry.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* architecture ([SupportedArchitecture](#max.pipelines.lib.registry.SupportedArchitecture))
* allow\_override ([bool](https://docs.python.org/3/library/functions.html#bool))

</dd><dt>

**Return type:**

</dt><dd>

None

</dd></dl>

### `reset()` {#max.pipelines.lib.registry.PipelineRegistry.reset}

> reset()

<dl class='field-list'><dt>

**Return type:**

</dt><dd>

None

</dd></dl>

### `retrieve()` {#max.pipelines.lib.registry.PipelineRegistry.retrieve}

> retrieve(pipeline\_config, task=PipelineTask.TEXT\_GENERATION, override\_architecture=None)

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* pipeline\_config ([PipelineConfig](config.md#max.pipelines.lib.config.PipelineConfig))
* task ([PipelineTask](../interfaces.md#max.interfaces.PipelineTask))
* override\_architecture ([str](https://docs.python.org/3/library/stdtypes.html#str) | None)

</dd><dt>

**Return type:**

</dt><dd>

[tuple](https://docs.python.org/3/library/stdtypes.html#tuple)\[[PipelineTokenizer](../interfaces.md#max.interfaces.PipelineTokenizer)\[Any, Any, Any], PipelineTypes]

</dd></dl>

### `retrieve_architecture()` {#max.pipelines.lib.registry.PipelineRegistry.retrieve_architecture}

> retrieve\_architecture(huggingface\_repo)

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

huggingface\_repo ([HuggingFaceRepo](hf_utils.md#max.pipelines.lib.hf_utils.HuggingFaceRepo))

</dd><dt>

**Return type:**

</dt><dd>

[SupportedArchitecture](#max.pipelines.lib.registry.SupportedArchitecture) | None

</dd></dl>

### `retrieve_factory()` {#max.pipelines.lib.registry.PipelineRegistry.retrieve_factory}

> retrieve\_factory(pipeline\_config, task=PipelineTask.TEXT\_GENERATION, override\_architecture=None)

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* pipeline\_config ([PipelineConfig](config.md#max.pipelines.lib.config.PipelineConfig))
* task ([PipelineTask](../interfaces.md#max.interfaces.PipelineTask))
* override\_architecture ([str](https://docs.python.org/3/library/stdtypes.html#str) | None)

</dd><dt>

**Return type:**

</dt><dd>

[tuple](https://docs.python.org/3/library/stdtypes.html#tuple)\[[PipelineTokenizer](../interfaces.md#max.interfaces.PipelineTokenizer)\[Any, Any, Any], Callable\[\[], PipelineTypes]]

</dd></dl>

### `retrieve_pipeline_task()` {#max.pipelines.lib.registry.PipelineRegistry.retrieve_pipeline_task}

> retrieve\_pipeline\_task(pipeline\_config)

Retrieve the pipeline task associated with the architecture for the given pipeline configuration.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

pipeline\_config ([PipelineConfig](config.md#max.pipelines.lib.config.PipelineConfig)) â€“ The configuration for the pipeline.

</dd><dt>

**Returns:**

</dt><dd>

The task associated with the architecture.

</dd><dt>

**Return type:**

</dt><dd>

[PipelineTask](../interfaces.md#max.interfaces.PipelineTask)

</dd><dt>

**Raises:**

</dt><dd>

[ValueError](https://docs.python.org/3/library/exceptions.html#ValueError) â€“ If no supported architecture is found for the given model repository.

</dd></dl>

### `retrieve_tokenizer()` {#max.pipelines.lib.registry.PipelineRegistry.retrieve_tokenizer}

> retrieve\_tokenizer(pipeline\_config, override\_architecture=None)

Retrieves a tokenizer for the given pipeline configuration.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* pipeline\_config ([PipelineConfig](config.md#max.pipelines.lib.config.PipelineConfig)) â€“ Configuration for the pipeline
* override\_architecture ([str](https://docs.python.org/3/library/stdtypes.html#str) | None) â€“ Optional architecture override string

</dd><dt>

**Returns:**

</dt><dd>

The configured tokenizer

</dd><dt>

**Return type:**

</dt><dd>

[PipelineTokenizer](../interfaces.md#max.interfaces.PipelineTokenizer)

</dd><dt>

**Raises:**

</dt><dd>

[ValueError](https://docs.python.org/3/library/exceptions.html#ValueError) â€“ If no architecture is found

</dd></dl>

## `SupportedArchitecture` {#max.pipelines.lib.registry.SupportedArchitecture}

> class max.pipelines.lib.registry.SupportedArchitecture(name, example\_repo\_ids, default\_encoding, supported\_encodings, pipeline\_model, task, tokenizer, default\_weights\_format, rope\_type=RopeType.none, weight\_adapters=None, multi\_gpu\_supported=False, prefix\_caching\_supported=True)

Represents a model architecture configuration for MAX pipelines.

This class defines all the necessary components and settings required to
support a specific model architecture within the MAX pipeline system.
Each SupportedArchitecture instance encapsulates the model implementation,
tokenizer, supported encodings, and other architecture-specific configuration.

New architectures should be registered into the [`PipelineRegistry`](#max.pipelines.lib.registry.PipelineRegistry)
using the [`register()`](#max.pipelines.lib.registry.PipelineRegistry.register) method.

```python
my_architecture = SupportedArchitecture(
    name="MyModelForCausalLM",  # Must match your Hugging Face model class name
    example_repo_ids=[
        "your-org/your-model-name",  # Add example model repository IDs
    ],
    default_encoding=SupportedEncoding.q4_k,
    supported_encodings={
        SupportedEncoding.q4_k: [KVCacheStrategy.PAGED],
        SupportedEncoding.bfloat16: [KVCacheStrategy.PAGED],
        # Add other encodings your model supports
    },
    pipeline_model=MyModel,
    tokenizer=TextTokenizer,
    default_weights_format=WeightsFormat.safetensors,
    multi_gpu_supported=True,  # Set based on your implementation capabilities
    weight_adapters={
        WeightsFormat.safetensors: weight_adapters.convert_safetensor_state_dict,
        # Add other weight formats if needed
    },
    task=PipelineTask.TEXT_GENERATION,
)
```

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* name ([str](https://docs.python.org/3/library/stdtypes.html#str)) â€“ The name of the model architecture that must match the Hugging Face
  model class name.
* example\_repo\_ids ([list](https://docs.python.org/3/library/stdtypes.html#list)\[[str](https://docs.python.org/3/library/stdtypes.html#str)]) â€“ A list of Hugging Face repository IDs that use this
  architecture for testing and validation purposes.
* default\_encoding (SupportedEncoding) â€“ The default quantization encoding to use when no
  specific encoding is requested.
* supported\_encodings ([dict](https://docs.python.org/3/library/stdtypes.html#dict)\[SupportedEncoding, [list](https://docs.python.org/3/library/stdtypes.html#list)\[[KVCacheStrategy](../nn/kv_cache/cache_params.md#max.nn.kv_cache.cache_params.KVCacheStrategy)]]) â€“ A dictionary mapping supported quantization encodings
  to their compatible KV cache strategies.
* pipeline\_model ([type](https://docs.python.org/3/library/functions.html#type)\[[PipelineModel](pipeline.md#max.pipelines.lib.pipeline.PipelineModel)\[Any]]) â€“ The PipelineModel class that defines the model graph
  structure and execution logic.
* task ([PipelineTask](../interfaces.md#max.interfaces.PipelineTask)) â€“ The pipeline task type that this architecture supports.
* tokenizer (Callable\[..., [PipelineTokenizer](../interfaces.md#max.interfaces.PipelineTokenizer)\[Any, Any, Any]]) â€“ A callable that returns a PipelineTokenizer instance for
  preprocessing model inputs.
* default\_weights\_format ([WeightsFormat](../graph/weights.md#max.graph.weights.WeightsFormat)) â€“ The weights format expected by the pipeline\_model.
* rope\_type (RopeType) â€“ The type of RoPE (Rotary Position Embedding) used by the model.
* weight\_adapters ([dict](https://docs.python.org/3/library/stdtypes.html#dict)\[[WeightsFormat](../graph/weights.md#max.graph.weights.WeightsFormat), WeightsAdapter] | None) â€“ A dictionary of weight format adapters for converting
  checkpoints from different formats to the default format.
* multi\_gpu\_supported ([bool](https://docs.python.org/3/library/functions.html#bool)) â€“ Whether the architecture supports multi-GPU execution.
* prefix\_caching\_supported ([bool](https://docs.python.org/3/library/functions.html#bool)) â€“ Whether the architecture supports prefix caching.

</dd></dl>

### `tokenizer_cls` {#max.pipelines.lib.registry.SupportedArchitecture.tokenizer_cls}

> property tokenizer\_cls: [type](https://docs.python.org/3/library/functions.html#type)\[[PipelineTokenizer](../interfaces.md#max.interfaces.PipelineTokenizer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [Any](https://docs.python.org/3/library/typing.html#typing.Any), [Any](https://docs.python.org/3/library/typing.html#typing.Any)]]

## `get_pipeline_for_task()` {#max.pipelines.lib.registry.get_pipeline_for_task}

> max.pipelines.lib.registry.get\_pipeline\_for\_task(task, pipeline\_config)

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* task ([PipelineTask](../interfaces.md#max.interfaces.PipelineTask))
* pipeline\_config ([PipelineConfig](config.md#max.pipelines.lib.config.PipelineConfig))

</dd><dt>

**Return type:**

</dt><dd>

[type](https://docs.python.org/3/library/functions.html#type)\[[TextGenerationPipeline](pipeline.md#max.pipelines.lib.pipeline.TextGenerationPipeline)\[[TextContext](core.md#max.pipelines.core.TextContext) | [TextAndVisionContext](core.md#max.pipelines.core.TextAndVisionContext)]] | [type](https://docs.python.org/3/library/functions.html#type)\[[EmbeddingsPipeline](pipeline.md#max.pipelines.lib.embeddings_pipeline.EmbeddingsPipeline)\[[TextContext](core.md#max.pipelines.core.TextContext)]] | [type](https://docs.python.org/3/library/functions.html#type)\[[SpeculativeDecodingTextGenerationPipeline](pipeline.md#max.pipelines.lib.speculative_decoding.SpeculativeDecodingTextGenerationPipeline)] | [type](https://docs.python.org/3/library/functions.html#type)\[AudioGeneratorPipeline] | [type](https://docs.python.org/3/library/functions.html#type)\[SpeechTokenGenerationPipeline]

</dd></dl>

---

## sampling

## `rejection_sampler()` {#max.pipelines.lib.sampling.sampling.rejection_sampler}

> max.pipelines.lib.sampling.sampling.rejection\_sampler(device, \*, seed=0)

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* device ([DeviceRef](../graph/type.md#max.graph.type.DeviceRef))
* seed ([int](https://docs.python.org/3/library/functions.html#int))

</dd><dt>

**Return type:**

</dt><dd>

[Graph](../graph/Graph.md#max.graph.Graph)

</dd></dl>

## `rejection_sampler_with_residuals()` {#max.pipelines.lib.sampling.sampling.rejection_sampler_with_residuals}

> max.pipelines.lib.sampling.sampling.rejection\_sampler\_with\_residuals(device, \*, seed=0, debug=False)

Rejection sampler with residual sampling for speculative decoding.

Computes acceptance ratios for draft tokens, finds first rejection,
samples from residual distribution (target - draft), and generates bonus tokens.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* device ([DeviceRef](../graph/type.md#max.graph.type.DeviceRef))
* seed ([int](https://docs.python.org/3/library/functions.html#int))
* debug ([bool](https://docs.python.org/3/library/functions.html#bool))

</dd><dt>

**Return type:**

</dt><dd>

[Graph](../graph/Graph.md#max.graph.Graph)

</dd></dl>

## `token_sampler()` {#max.pipelines.lib.sampling.sampling.token_sampler}

> max.pipelines.lib.sampling.sampling.token\_sampler(sampling\_config, device, return\_logits=False)

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* sampling\_config (SamplingConfig)
* device ([DeviceRef](../graph/type.md#max.graph.type.DeviceRef))
* return\_logits ([bool](https://docs.python.org/3/library/functions.html#bool))

</dd><dt>

**Return type:**

</dt><dd>

[Graph](../graph/Graph.md#max.graph.Graph)

</dd></dl>

---

## tokenizer

Implementations of provided tokenizers.

## `IdentityPipelineTokenizer` {#max.pipelines.lib.tokenizer.IdentityPipelineTokenizer}

> class max.pipelines.lib.tokenizer.IdentityPipelineTokenizer(\*args, \*\*kwargs)

### `decode()` {#max.pipelines.lib.tokenizer.IdentityPipelineTokenizer.decode}

> async decode(encoded, \*\*kwargs)

Decodes response tokens to text.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

encoded (TokenizerEncoded) â€“ Encoded response tokens.

</dd><dt>

**Returns:**

</dt><dd>

Un-encoded response text.

</dd><dt>

**Return type:**

</dt><dd>

[str](https://docs.python.org/3/library/stdtypes.html#str)

</dd></dl>

### `encode()` {#max.pipelines.lib.tokenizer.IdentityPipelineTokenizer.encode}

> async encode(prompt, add\_special\_tokens=False)

Encodes text prompts as tokens.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* prompt ([str](https://docs.python.org/3/library/stdtypes.html#str)) â€“ Un-encoded prompt text.
* add\_special\_tokens ([bool](https://docs.python.org/3/library/functions.html#bool))

</dd><dt>

**Raises:**

</dt><dd>

[ValueError](https://docs.python.org/3/library/exceptions.html#ValueError) â€“ If the prompt exceeds the configured maximum length.

</dd><dt>

**Return type:**

</dt><dd>

[str](https://docs.python.org/3/library/stdtypes.html#str)

</dd></dl>

### `eos` {#max.pipelines.lib.tokenizer.IdentityPipelineTokenizer.eos}

> property eos: [int](https://docs.python.org/3/library/functions.html#int)

The end of sequence token for this tokenizer.

### `expects_content_wrapping` {#max.pipelines.lib.tokenizer.IdentityPipelineTokenizer.expects_content_wrapping}

> property expects\_content\_wrapping: [bool](https://docs.python.org/3/library/functions.html#bool)

If true, this tokenizer expects messages to have a content property.

Text messages are formatted as:

```json
{ "type": "text", "content": "text content" }
```

instead of the OpenAI spec:

```json
{ "type": "text", "text": "text content" }
```

NOTE: Multimodal messages omit the content property.
Both `image_urls` and `image` content parts are converted to:

```json
{ "type": "image" }
```

Their content is provided as byte arrays through the top-level property
on the request object, i.e., `RequestType.images`.

## `PreTrainedPipelineTokenizer` {#max.pipelines.lib.tokenizer.PreTrainedPipelineTokenizer}

> class max.pipelines.lib.tokenizer.PreTrainedPipelineTokenizer(delegate)

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

delegate (Union\[PreTrainedTokenizer, PreTrainedTokenizerFast])

</dd></dl>

### `apply_chat_template()` {#max.pipelines.lib.tokenizer.PreTrainedPipelineTokenizer.apply_chat_template}

> apply\_chat\_template(messages)

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

messages ([list](https://docs.python.org/3/library/stdtypes.html#list)\[[TextGenerationRequestMessage](../interfaces.md#max.interfaces.TextGenerationRequestMessage)])

</dd><dt>

**Return type:**

</dt><dd>

[str](https://docs.python.org/3/library/stdtypes.html#str)

</dd></dl>

### `decode()` {#max.pipelines.lib.tokenizer.PreTrainedPipelineTokenizer.decode}

> async decode(encoded, \*\*kwargs)

Decodes response tokens to text.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

encoded (TokenizerEncoded) â€“ Encoded response tokens.

</dd><dt>

**Returns:**

</dt><dd>

Un-encoded response text.

</dd><dt>

**Return type:**

</dt><dd>

[str](https://docs.python.org/3/library/stdtypes.html#str)

</dd></dl>

### `encode()` {#max.pipelines.lib.tokenizer.PreTrainedPipelineTokenizer.encode}

> async encode(prompt, add\_special\_tokens=False)

Encodes text prompts as tokens.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* prompt ([str](https://docs.python.org/3/library/stdtypes.html#str)) â€“ Un-encoded prompt text.
* add\_special\_tokens ([bool](https://docs.python.org/3/library/functions.html#bool))

</dd><dt>

**Raises:**

</dt><dd>

[ValueError](https://docs.python.org/3/library/exceptions.html#ValueError) â€“ If the prompt exceeds the configured maximum length.

</dd><dt>

**Return type:**

</dt><dd>

[ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]]

</dd></dl>

### `eos` {#max.pipelines.lib.tokenizer.PreTrainedPipelineTokenizer.eos}

> property eos: [int](https://docs.python.org/3/library/functions.html#int)

The end of sequence token for this tokenizer.

### `expects_content_wrapping` {#max.pipelines.lib.tokenizer.PreTrainedPipelineTokenizer.expects_content_wrapping}

> property expects\_content\_wrapping: [bool](https://docs.python.org/3/library/functions.html#bool)

If true, this tokenizer expects messages to have a content property.

Text messages are formatted as:

```json
{ "type": "text", "content": "text content" }
```

instead of the OpenAI spec:

```json
{ "type": "text", "text": "text content" }
```

NOTE: Multimodal messages omit the content property.
Both `image_urls` and `image` content parts are converted to:

```json
{ "type": "image" }
```

Their content is provided as byte arrays through the top-level property
on the request object, i.e., `RequestType.images`.

## `TextAndVisionTokenizer` {#max.pipelines.lib.tokenizer.TextAndVisionTokenizer}

> class max.pipelines.lib.tokenizer.TextAndVisionTokenizer(model\_path, \*, revision=None, max\_length=None, trust\_remote\_code=False, \*\*unused\_kwargs)

Encapsulates creation of TextContext and specific token encode/decode logic.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* model\_path ([str](https://docs.python.org/3/library/stdtypes.html#str))
* revision ([str](https://docs.python.org/3/library/stdtypes.html#str) | None)
* max\_length ([int](https://docs.python.org/3/library/functions.html#int) | None)
* trust\_remote\_code ([bool](https://docs.python.org/3/library/functions.html#bool))

</dd></dl>

### `apply_chat_template()` {#max.pipelines.lib.tokenizer.TextAndVisionTokenizer.apply_chat_template}

> apply\_chat\_template(messages)

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

messages ([list](https://docs.python.org/3/library/stdtypes.html#list)\[[TextGenerationRequestMessage](../interfaces.md#max.interfaces.TextGenerationRequestMessage)])

</dd><dt>

**Return type:**

</dt><dd>

[str](https://docs.python.org/3/library/stdtypes.html#str)

</dd></dl>

### `decode()` {#max.pipelines.lib.tokenizer.TextAndVisionTokenizer.decode}

> async decode(encoded, \*\*kwargs)

Transformer a provided encoded token array, back into readable text.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

encoded ([ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])

</dd><dt>

**Return type:**

</dt><dd>

[str](https://docs.python.org/3/library/stdtypes.html#str)

</dd></dl>

### `encode()` {#max.pipelines.lib.tokenizer.TextAndVisionTokenizer.encode}

> async encode(prompt, add\_special\_tokens=True)

Transform the provided prompt into a token array.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* prompt ([str](https://docs.python.org/3/library/stdtypes.html#str) | [Sequence](https://docs.python.org/3/library/collections.abc.html#collections.abc.Sequence)\[[int](https://docs.python.org/3/library/functions.html#int)])
* add\_special\_tokens ([bool](https://docs.python.org/3/library/functions.html#bool))

</dd><dt>

**Return type:**

</dt><dd>

[ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]]

</dd></dl>

### `eos` {#max.pipelines.lib.tokenizer.TextAndVisionTokenizer.eos}

> property eos: [int](https://docs.python.org/3/library/functions.html#int)

The end of sequence token for this tokenizer.

### `expects_content_wrapping` {#max.pipelines.lib.tokenizer.TextAndVisionTokenizer.expects_content_wrapping}

> property expects\_content\_wrapping: [bool](https://docs.python.org/3/library/functions.html#bool)

If true, this tokenizer expects messages to have a content property.

Text messages are formatted as:

```json
{ "type": "text", "content": "text content" }
```

instead of the OpenAI spec:

```json
{ "type": "text", "text": "text content" }
```

NOTE: Multimodal messages omit the content property.
Both `image_urls` and `image` content parts are converted to:

```json
{ "type": "image" }
```

Their content is provided as byte arrays through the top-level property
on the request object, i.e., `RequestType.images`.

### `new_context()` {#max.pipelines.lib.tokenizer.TextAndVisionTokenizer.new_context}

> async new\_context(request)

Create a new TextAndVisionContext object, leveraging necessary information from TextGenerationRequest.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

request ([TextGenerationRequest](../interfaces.md#max.interfaces.TextGenerationRequest))

</dd><dt>

**Return type:**

</dt><dd>

[TextAndVisionContext](core.md#max.pipelines.core.TextAndVisionContext)

</dd></dl>

## `TextTokenizer` {#max.pipelines.lib.tokenizer.TextTokenizer}

> class max.pipelines.lib.tokenizer.TextTokenizer(model\_path, \*, revision=None, max\_length=None, trust\_remote\_code=False, enable\_llama\_whitespace\_fix=False, pipeline\_config=None, chat\_template=None, \*\*unused\_kwargs)

Encapsulates creation of TextContext and specific token encode/decode logic.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* model\_path ([str](https://docs.python.org/3/library/stdtypes.html#str)) â€“ Path to the model/tokenizer
* revision ([str](https://docs.python.org/3/library/stdtypes.html#str) | None) â€“ Git revision/branch to use
* max\_length ([int](https://docs.python.org/3/library/functions.html#int) | None) â€“ Maximum sequence length
* trust\_remote\_code ([bool](https://docs.python.org/3/library/functions.html#bool)) â€“ Whether to trust remote code from the model
* enable\_llama\_whitespace\_fix ([bool](https://docs.python.org/3/library/functions.html#bool)) â€“ Enable whitespace fix for Llama tokenizers
* pipeline\_config ([PipelineConfig](config.md#max.pipelines.lib.config.PipelineConfig) | None) â€“ Optional pipeline configuration
* chat\_template ([str](https://docs.python.org/3/library/stdtypes.html#str) | None) â€“ Optional custom chat template string to override the one
  shipped with the HuggingFace model config. This allows
  customizing the prompt formatting for different use cases.

</dd></dl>

### `apply_chat_template()` {#max.pipelines.lib.tokenizer.TextTokenizer.apply_chat_template}

> apply\_chat\_template(messages, tools, chat\_template\_options=None)

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* messages ([list](https://docs.python.org/3/library/stdtypes.html#list)\[[TextGenerationRequestMessage](../interfaces.md#max.interfaces.TextGenerationRequestMessage)])
* tools ([list](https://docs.python.org/3/library/stdtypes.html#list)\[[TextGenerationRequestTool](../interfaces.md#max.interfaces.TextGenerationRequestTool)] | None)
* chat\_template\_options ([dict](https://docs.python.org/3/library/stdtypes.html#dict)\[[str](https://docs.python.org/3/library/stdtypes.html#str), [Any](https://docs.python.org/3/library/typing.html#typing.Any)] | None)

</dd><dt>

**Return type:**

</dt><dd>

[str](https://docs.python.org/3/library/stdtypes.html#str)

</dd></dl>

### `decode()` {#max.pipelines.lib.tokenizer.TextTokenizer.decode}

> async decode(encoded, \*\*kwargs)

Transformer a provided encoded token array, back into readable text.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

encoded ([ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]])

</dd><dt>

**Return type:**

</dt><dd>

[str](https://docs.python.org/3/library/stdtypes.html#str)

</dd></dl>

### `encode()` {#max.pipelines.lib.tokenizer.TextTokenizer.encode}

> async encode(prompt, add\_special\_tokens=True)

Transform the provided prompt into a token array.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* prompt ([str](https://docs.python.org/3/library/stdtypes.html#str) | [Sequence](https://docs.python.org/3/library/collections.abc.html#collections.abc.Sequence)\[[int](https://docs.python.org/3/library/functions.html#int)])
* add\_special\_tokens ([bool](https://docs.python.org/3/library/functions.html#bool))

</dd><dt>

**Return type:**

</dt><dd>

[ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any), [dtype](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype)\[[integer](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]]

</dd></dl>

### `eos` {#max.pipelines.lib.tokenizer.TextTokenizer.eos}

> property eos: [int](https://docs.python.org/3/library/functions.html#int)

The end of sequence token for this tokenizer.

### `expects_content_wrapping` {#max.pipelines.lib.tokenizer.TextTokenizer.expects_content_wrapping}

> property expects\_content\_wrapping: [bool](https://docs.python.org/3/library/functions.html#bool)

If true, this tokenizer expects messages to have a content property.

Text messages are formatted as:

```json
{ "type": "text", "content": "text content" }
```

instead of the OpenAI spec:

```json
{ "type": "text", "text": "text content" }
```

NOTE: Multimodal messages omit the content property.
Both `image_urls` and `image` content parts are converted to:

```json
{ "type": "image" }
```

Their content is provided as byte arrays through the top-level property
on the request object, i.e., `RequestType.images`.

### `new_context()` {#max.pipelines.lib.tokenizer.TextTokenizer.new_context}

> async new\_context(request)

Create a new TextContext object, leveraging necessary information from TextGenerationRequest.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

request ([TextGenerationRequest](../interfaces.md#max.interfaces.TextGenerationRequest))

</dd><dt>

**Return type:**

</dt><dd>

[TextContext](core.md#max.pipelines.core.TextContext)

</dd></dl>

## `max_tokens_to_generate()` {#max.pipelines.lib.tokenizer.max_tokens_to_generate}

> max.pipelines.lib.tokenizer.max\_tokens\_to\_generate(prompt\_size, max\_length, max\_new\_tokens=None)

Returns the max number of new tokens to generate.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* prompt\_size ([int](https://docs.python.org/3/library/functions.html#int))
* max\_length ([int](https://docs.python.org/3/library/functions.html#int) | None)
* max\_new\_tokens ([int](https://docs.python.org/3/library/functions.html#int) | None)

</dd><dt>

**Return type:**

</dt><dd>

[int](https://docs.python.org/3/library/functions.html#int) | None

</dd></dl>

## `run_with_default_executor()` {#max.pipelines.lib.tokenizer.run_with_default_executor}

> async max.pipelines.lib.tokenizer.run\_with\_default\_executor(fn, \*args, \*\*kwargs)

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* fn ([Callable](https://docs.python.org/3/library/typing.html#typing.Callable)\[\[\~\_P], \_R])
* args (\~\_P)
* kwargs (\~\_P)

</dd><dt>

**Return type:**

</dt><dd>

\_R

</dd></dl>

---

## torch

## `CustomOpLibrary` {#max.torch.CustomOpLibrary}

> class max.torch.CustomOpLibrary(kernel\_library)

A PyTorch interface to custom operations implemented in Mojo.

This API allows for easy passing of PyTorch data as
`torch.Tensor` values to the corresponding custom op. `CustomOpLibrary`
handles the compilation of the Mojo custom ops and marshalling of data between
PyTorch and the executable Mojo code.

For example, consider a grayscale operation implemented in Mojo:

```mojo title="my_library/grayscale.mojo"
 @register("grayscale")
 struct Grayscale:
     @staticmethod
     fn execute[
         # The kind of device this is running on: "cpu" or "gpu"
         target: StaticString,
     ](
         img_out: OutputTensor[dtype = DType.uint8, rank=2],
         img_in: InputTensor[dtype = DType.uint8, rank=3],
         ctx: DeviceContextPtr,
     ) raises:
         ...
```

You can then use `CustomOpLibrary` to invoke the Mojo operation like so:

```python
import torch
from max.torch import CustomOpLibrary

op_library = CustomOpLibrary("my_library")
grayscale_op = op_library.grayscale

def grayscale(pic: torch.Tensor) -> torch.Tensor:
    result = pic.new_empty(pic.shape[:-1])
    grayscale_op(result, pic)
    return result

img = (torch.rand(64, 64, 3) * 255).to(torch.uint8)
result = grayscale(img)
```

The custom operation produced by `op_library.<opname>` will have the
same interface as the backing Mojo operation. Each `InputTensor` or
`OutputTensor` argument corresponds to a
[`torch.Tensor`](https://docs.pytorch.org/docs/stable/tensors.html#tensor-class-reference)
value in Python. Each argument corresponding to an `OutputTensor` in the
Mojo operation will be modified in-place.

For more information, see the [custom ops for PyTorch](/max/tutorials/custom-kernels-pytorch) tutorial.

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

kernel\_library (Path | [KernelLibrary](graph/KernelLibrary.md#max.graph.KernelLibrary)) â€“ The path to a `.mojo` file or a `.mojopkg` with
your custom op kernels, or the corresponding library object.

</dd></dl>

## `graph_op()` {#max.torch.graph_op}

> max.torch.graph\_op(fn=None, name=None, kernel\_library=None, input\_types=None, output\_types=None, num\_outputs=None)

A decorator to create PyTorch custom operations using MAX graph operations.

This decorator allows you to define larger graphs using [MAX graph
ops](/max/api/python/graph/ops) or the MAX `nn` modules and
call them with PyTorch tensors, or integrate them into PyTorch modules.
These custom ops can be called eagerly, and support compilation with
`torch.compile` and the Inductor backend.

The resulting custom operation uses destination-passing style, where output
tensors are passed as the first arguments and modified in-place. This
allows PyTorch to manage the memory and streams of the output tensors.
Tensors internal to the computation are managed via MAXâ€™s graph compiler
and memory planning.

The default behavior is to JIT-compile for the specific input and output
shapes needed. If you are passing variable-sized inputs, for instance a
batch size or sequence length which may take on many different values
between calls, you should specify this dimension as a symbolic dimension
through `input_types` and `output_types`. Otherwise you will
end up compiling specialized graphs for each possible variation of
inputs, which may use a lot of memory.

If neither output\_types nor num\_outputs is specified, default to 1
output.

For example to create a functional-style PyTorch op backed by MAX:

```python title="grayscale.py"
import torch
import numpy as np
import max.torch
from max.dtype import DType
from max.graph import ops

@max.torch.graph_op
def max_grayscale(pic: max.graph.TensorValue):
    scaled = pic.cast(DType.float32) * np.array([0.21, 0.71, 0.07])
    grayscaled = ops.sum(scaled, axis=-1).cast(pic.dtype)
    # max reductions don't remove the dimension, need to squeeze
    return ops.squeeze(grayscaled, axis=-1)

@torch.compile
def grayscale(pic: torch.Tensor):
    output = pic.new_empty(pic.shape[:-1])  # Remove color channel dimension
    max_grayscale(output, pic)  # Call as destination-passing style
    return output

device = "cuda" if torch.cuda.is_available() else "cpu"
img = (torch.rand(64, 64, 3, device=device) * 255).to(torch.uint8)
result = grayscale(img)
print(f"Input shape: {img.shape}")
print(f"Output shape: {result.shape}")
print("Grayscale conversion completed successfully!")
```

<dl class='field-list'><dt>

**Parameters:**

</dt><dd>

* fn ([Callable](https://docs.python.org/3/library/typing.html#typing.Callable)\[\[...], None | [Value](graph/Value.md#max.graph.Value)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [Iterable](https://docs.python.org/3/library/collections.abc.html#collections.abc.Iterable)\[[Value](graph/Value.md#max.graph.Value)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]] | None) â€“ The function to decorate. If None, returns a decorator.
* name ([str](https://docs.python.org/3/library/stdtypes.html#str) | None) â€“ Optional name for the custom operation. Defaults to the function name.
* kernel\_library ([Path](https://docs.python.org/3/library/pathlib.html#pathlib.Path) | [KernelLibrary](graph/KernelLibrary.md#max.graph.KernelLibrary) | None) â€“ Optional kernel library to use for compilation. Useful
  for creating graphs with custom Mojo ops.
* input\_types ([Sequence](https://docs.python.org/3/library/collections.abc.html#collections.abc.Sequence)\[[TensorType](graph/type.md#max.graph.type.TensorType)] | None) â€“ Optional sequence of input tensor types for compilation.
  If None, types are inferred from runtime arguments.
* output\_types ([Sequence](https://docs.python.org/3/library/collections.abc.html#collections.abc.Sequence)\[[TensorType](graph/type.md#max.graph.type.TensorType)] | None) â€“ Optional sequence of output tensor types for compilation.
  If None, types are inferred from runtime arguments.
* num\_outputs ([int](https://docs.python.org/3/library/functions.html#int) | None) â€“ The number of outputs of the graph. We need to know this ahead
  of time to register with PyTorch before weâ€™ve compiled the final kernels.

</dd><dt>

**Returns:**

</dt><dd>

A PyTorch custom operation that can be called with torch.Tensor arguments.

</dd><dt>

**Return type:**

</dt><dd>

CustomOpDef | [Callable](https://docs.python.org/3/library/typing.html#typing.Callable)\[\[[Callable](https://docs.python.org/3/library/typing.html#typing.Callable)\[\[â€¦], None | [Value](graph/Value.md#max.graph.Value)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)] | [Iterable](https://docs.python.org/3/library/collections.abc.html#collections.abc.Iterable)\[[Value](graph/Value.md#max.graph.Value)\[[Any](https://docs.python.org/3/library/typing.html#typing.Any)]]]], CustomOpDef]

</dd></dl>